{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Spoofax Language Workbench \u00b6 Spoofax is a platform for developing textual (domain-specific) programming languages. The platform provides the following ingredients: Meta-languages for high-level declarative language definition An interactive environment for developing languages using these meta-languages Code generators that produces parsers, type checkers, compilers, interpreters, and other tools from language definitions Generation of full-featured Eclipse editor plugins from language definitions An API for programmatically combining the components of a language implementation With Spoofax you can focus on the essence of language definition and ignore irrelevant implementation details. Get started by downloading and installing Spoofax or build it from source .","title":"Spoofax: The Language Designer's Workbench"},{"location":"#the-spoofax-language-workbench","text":"Spoofax is a platform for developing textual (domain-specific) programming languages. The platform provides the following ingredients: Meta-languages for high-level declarative language definition An interactive environment for developing languages using these meta-languages Code generators that produces parsers, type checkers, compilers, interpreters, and other tools from language definitions Generation of full-featured Eclipse editor plugins from language definitions An API for programmatically combining the components of a language implementation With Spoofax you can focus on the essence of language definition and ignore irrelevant implementation details. Get started by downloading and installing Spoofax or build it from source .","title":"The Spoofax Language Workbench"},{"location":"getting-started/","text":"Getting started \u00b6 The quickest way to get started with Spoofax by downloading an instance of Eclipse with the latest release. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, use Homebrew on macOS, or download and build Spoofax from source. Installation \u00b6 The recommended way to get started with Spoofax is to download an Eclipse instance with the latest Spoofax plugin. The plugin also includes the Spoofax meta-languages. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, or download and build Spoofax from source. Choose the Eclipse Bundle installation (recommended) or the Eclipse Plugin installation: Eclipse Bundle Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Download Eclipse with Spoofax without an embedded JRE . Development releases . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew ( macOS) On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date. Quick Start \u00b6 Once installed, create a new Spoofax project: Right-click the Package Explorer , choose New \u2192 Project , and select Spoofax Language project from the Spoofax category. Provide a name for your new language and click Finish . Select the created language project and press Ctrl + Alt + B ( Cmd + Alt + B on macOS) to build the project. Create a new file with the extension registered to your language to test it. Follow one of the tutorials to learn more. Finding the filename extension of your language If you didn't explicitly specify a filename extension for your language, it is derived from the language name. You can find the filename extension for your language in editor/Main.esv at the extensions property.","title":"Getting started"},{"location":"getting-started/#getting-started","text":"The quickest way to get started with Spoofax by downloading an instance of Eclipse with the latest release. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, use Homebrew on macOS, or download and build Spoofax from source.","title":"Getting started"},{"location":"getting-started/#installation","text":"The recommended way to get started with Spoofax is to download an Eclipse instance with the latest Spoofax plugin. The plugin also includes the Spoofax meta-languages. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, or download and build Spoofax from source. Choose the Eclipse Bundle installation (recommended) or the Eclipse Plugin installation: Eclipse Bundle Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Download Eclipse with Spoofax without an embedded JRE . Development releases . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew ( macOS) On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Installation"},{"location":"getting-started/#quick-start","text":"Once installed, create a new Spoofax project: Right-click the Package Explorer , choose New \u2192 Project , and select Spoofax Language project from the Spoofax category. Provide a name for your new language and click Finish . Select the created language project and press Ctrl + Alt + B ( Cmd + Alt + B on macOS) to build the project. Create a new file with the extension registered to your language to test it. Follow one of the tutorials to learn more. Finding the filename extension of your language If you didn't explicitly specify a filename extension for your language, it is derived from the language name. You can find the filename extension for your language in editor/Main.esv at the extensions property.","title":"Quick Start"},{"location":"background/","text":"Background \u00b6 This section contains information on the ideas, architecture, and design decisions behind Spoofax. For the Spoofax language reference, see the References section. Publications : References to papers about the design and implementation of various aspects of Spoofax Statix : More about the Statix language for Static semantics definition Stratego : Motivation for the design of the Stratego transformation language Documentation : Explanation of how this documentation works","title":"Background"},{"location":"background/#background","text":"This section contains information on the ideas, architecture, and design decisions behind Spoofax. For the Spoofax language reference, see the References section. Publications : References to papers about the design and implementation of various aspects of Spoofax Statix : More about the Statix language for Static semantics definition Stratego : Motivation for the design of the Stratego transformation language Documentation : Explanation of how this documentation works","title":"Background"},{"location":"background/bibliography/","text":"Spoofax Bibliography \u00b6 Spoofax and its meta-languages have been described and motivated extensively in the academic literature. All references to Spoofax-related papers should have been collected in a bibliography on researchr from where the complete collection of bibtex entries can be obtained. (Let us know if we are missing publications in that collection.) This section provides references to that literature. Spoofax \u00b6 The first version of Spoofax was described in an award winning paper OOPSLA 2010 1 . (The paper won the best (student) paper award at OOPSLA 2010 and the Most Influential Paper Award at OOPSLA 2020.) The paper provides motivation for textual language workbenches and discusses the architecture of a language workbench based on declarative meta-languages. An introduction to Spoofax was included along with introductions to MPS and Xtext in V\u00f6lter's DSL Engineering book 2 . A paper in IEEE Software 3 considers Spoofax from a user's perspective. Spoofax was also one of the tools featured in a survey of language workbenches which was first published in SLE'13 4 and later extended in the Computer Languages journal 5 . Bibliographies \u00b6 SDF3 : papers about the syntax definition formalism and its predecessors Statix : papers about the static semantics meta-language and its predecessors Stratego : papers about the transformation meta-language References \u00b6 Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9 Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages . dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org . \u21a9 Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software , 31 \\(5\\) :35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100 , doi:10.1109/MS.2014.100 . \u21a9 Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11 , doi:10.1007/978-3-319-02654-1_11 . \u21a9 Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems & Structures , 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007 , doi:10.1016/j.cl.2015.08.007 . \u21a9","title":"Spoofax Bibliography"},{"location":"background/bibliography/#spoofax-bibliography","text":"Spoofax and its meta-languages have been described and motivated extensively in the academic literature. All references to Spoofax-related papers should have been collected in a bibliography on researchr from where the complete collection of bibtex entries can be obtained. (Let us know if we are missing publications in that collection.) This section provides references to that literature.","title":"Spoofax Bibliography"},{"location":"background/bibliography/#spoofax","text":"The first version of Spoofax was described in an award winning paper OOPSLA 2010 1 . (The paper won the best (student) paper award at OOPSLA 2010 and the Most Influential Paper Award at OOPSLA 2020.) The paper provides motivation for textual language workbenches and discusses the architecture of a language workbench based on declarative meta-languages. An introduction to Spoofax was included along with introductions to MPS and Xtext in V\u00f6lter's DSL Engineering book 2 . A paper in IEEE Software 3 considers Spoofax from a user's perspective. Spoofax was also one of the tools featured in a survey of language workbenches which was first published in SLE'13 4 and later extended in the Computer Languages journal 5 .","title":"Spoofax"},{"location":"background/bibliography/#bibliographies","text":"SDF3 : papers about the syntax definition formalism and its predecessors Statix : papers about the static semantics meta-language and its predecessors Stratego : papers about the transformation meta-language","title":"Bibliographies"},{"location":"background/bibliography/#references","text":"Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9 Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages . dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org . \u21a9 Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software , 31 \\(5\\) :35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100 , doi:10.1109/MS.2014.100 . \u21a9 Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11 , doi:10.1007/978-3-319-02654-1_11 . \u21a9 Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems & Structures , 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007 , doi:10.1016/j.cl.2015.08.007 . \u21a9","title":"References"},{"location":"background/bibliography/references/","text":"References \u00b6 The full Spoofax bibliography. 1: Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . 2: Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages . dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org . 3: Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software , 31 \\(5\\) :35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100 , doi:10.1109/MS.2014.100 . 4: Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11 , doi:10.1007/978-3-319-02654-1_11 . 5: Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems & Structures , 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007 , doi:10.1016/j.cl.2015.08.007 .","title":"References"},{"location":"background/bibliography/references/#references","text":"The full Spoofax bibliography. 1: Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . 2: Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages . dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org . 3: Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software , 31 \\(5\\) :35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100 , doi:10.1109/MS.2014.100 . 4: Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11 , doi:10.1007/978-3-319-02654-1_11 . 5: Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems & Structures , 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007 , doi:10.1016/j.cl.2015.08.007 .","title":"References"},{"location":"background/bibliography/sdf3/","text":"An SDF3 Bibliography \u00b6 SDF3 1 is the third generation in the SDF family of syntax definition formalisms, which were developed in the context of the ASF+SDF 2 , Stratego/XT 3 , and Spoofax 4 language workbenches. Kats et al. decribe the motivation for declarative syntax definition 5 . SDF \u00b6 The first SDF 6 supported modular composition of syntax definition, a direct correspondence between concrete and abstract syntax, and parsing with the full class of context-free grammars enabled by the Generalized-LR (GLR) parsing algorithm 7 8 . Its programming environment, as part of the ASF+SDF MetaEnvironment 9 , focused on live development of syntax definitions through incremental and modular scanner and parser generation 10 11 12 in order to provide fast turnaround times during language development. SDF2 \u00b6 The second generation, SDF2 encompassed a redesign of the internals of SDF without changing the surface syntax. The front-end of the implementation consisted of a transformation pipeline from the rich surface syntax to a minimal core (kernel) language 13 that served as input for parser generation. The key change of SDF2 was its integration of lexical and context-free syntax, supported by Scannerless GLR (SGLR) parsing 14 15 , enabling composition of languages with different lexical syntax 16 17 . SDF3 \u00b6 SDF3 is the latest member of the family and inherits many features of its predecessors. The most recognizable change is to the syntax of productions that should make it more familiar to users of other grammar formalisms. Further, it introduces new features in order to support multi-purpose interpretations of syntax definitions. The goals of the design of SDF3 are (1) to support the definition of the concrete and abstract syntax of formal languages (with an emphasis on programming languages), (2) to support declarative syntax definition so that there is no need to understand parsing algorithms in order to understand definitions 5 , (3) to make syntax definitions readable and understandable so that they can be used as reference documentation, and (4) to support execution of syntax definitions as parsers, but also for other syntactic operations, i.e to support multi-purpose interpretation based on a single source. The focus on multipurpose interpretation is driven by the role of SDF3 in the Spoofax language workbench 4 . Key features of SDF3 include Template productions 18 Error recovery 19 Layout constraints for layout-sensitive syntax 20 21 Safe and complete disambiguation of expression grammars 22 Placeholders and syntactic code completion 23 Future Work \u00b6 Parse table composition 24 , while implemented in a prototype, hasn't made into the production implementation yet. References \u00b6 Luis Eduardo de Souza Amorim and Eelco Visser. Multi-purpose syntax definition with SDF3. In Frank S. de Boer and Antonio Cerone, editors, Software Engineering and Formal Methods - 18 th International Conference, SEFM 2020, Amsterdam, The Netherlands, September 14-18, 2020, Proceedings , volume 12310 of Lecture Notes in Computer Science, 1\u201323. Springer, 2020. URL: https://doi.org/10.1007/978-3-030-58768-0_1 , doi:10.1007/978-3-030-58768-0_1 . \u21a9 Mark G. J. van den Brand, Arie van Deursen, Jan Heering, H. A. de Jong, Merijn de Jonge, Tobias Kuipers, Paul Klint, Leon Moonen, Pieter A. Olivier, Jeroen Scheerder, Jurgen J. Vinju, Eelco Visser, and Joost Visser. The ASF+SDF meta-environment: a component-based language development environment. In Reinhard Wilhelm, editor, Compiler Construction, 10 th International Conference, CC 2001 Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2001 Genova, Italy, April 2-6, 2001, Proceedings , volume 2027 of Lecture Notes in Computer Science, 365\u2013370. Springer, 2001. URL: https://doi.org/10.1016/S1571-0661 \\(04\\) 80917-4 , doi:10.1016/S1571-0661 \\(04\\) 80917-4 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming , 72 \\(1\\-2\\) :52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003 , doi:10.1016/j.scico.2007.11.003 . \u21a9 Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9 \u21a9 Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. Pure and declarative syntax definition: paradise lost and regained. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 918\u2013932. Reno/Tahoe, Nevada, 2010. ACM. URL: http://doi.acm.org/10.1145/1869459.1869535 , doi:10.1145/1869459.1869535 . \u21a9 \u21a9 Jan Heering, P. R. H. Hendriks, Paul Klint, and Jan Rekers. The syntax definition formalism SDF - reference manual. SIGPLAN Notices , 24 \\(11\\) :43\u201375, 1989. doi:10.1145/71605.71607 . \u21a9 Masaru Tomita. An efficient context-free parsing algorithm for natural languages. In IJCAI , 756\u2013764. 1985. \u21a9 Jan Rekers. Parser Generation for Interactive Environments . PhD thesis, University of Amsterdam, Amsterdam, The Netherlands, January 1992. \u21a9 Paul Klint. A meta-environment for generating programming environments. ACM Transactions on Software Engineering Methodology , 2 \\(2\\) :176\u2013201, 1993. doi:10.1145/151257.151260 . \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of lexical scanners. ACM Transactions on Programming Languages and Systems , 14 \\(4\\) :490\u2013520, 1992. doi:10.1145/133233.133240 . \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of parsers. IEEE Trans. Software Eng. , 16 \\(12\\) :1344\u20131351, 1990. \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Lazy and incremental program generation. ACM Transactions on Programming Languages and Systems , 16 \\(3\\) :1010\u20131023, 1994. doi:10.1145/177492.177750 . \u21a9 Eelco Visser. A family of syntax definition formalisms. In Mark G. J. van den Brand and Vania Vieira Estrela, editors, ASF+SDF 1995. A Workshop on Generating Tools from Algebraic Specifications . Technical Report P9504, Programming Research Group, University of Amsterdam, May 1995. \u21a9 Eelco Visser. Syntax Definition for Language Prototyping . PhD thesis, University of Amsterdam, September 1997. \u21a9 Eelco Visser. Scannerless generalized-LR parsing. Technical Report P9707, Programming Research Group, University of Amsterdam, July 1997. \u21a9 Eelco Visser. Meta-programming with concrete object syntax. In Don S. Batory, Charles Consel, and Walid Taha, editors, Generative Programming and Component Engineering, ACM SIGPLAN/SIGSOFT Conference, GPCE 2002, Pittsburgh, PA, USA, October 6-8, 2002, Proceedings , volume 2487 of Lecture Notes in Computer Science, 299\u2013315. Springer, 2002. URL: https://doi.org/10.1007/3-540-45821-2_19 , doi:10.1007/3-540-45821-2_19 . \u21a9 Martin Bravenboer and Eelco Visser. Concrete syntax for objects: domain-specific language embedding and assimilation without restrictions. In John M. Vlissides and Douglas C. Schmidt, editors, Proceedings of the 19 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2004 , 365\u2013383. Vancouver, BC, Canada, 2004. ACM. URL: http://doi.acm.org/10.1145/1028976.1029007 , doi:10.1145/1028976.1029007 . \u21a9 Tobi Vollebregt, Lennart C. L. Kats, and Eelco Visser. Declarative specification of template-based textual editors. In Anthony Sloane and Suzana Andova, editors, International Workshop on Language Descriptions, Tools, and Applications, LDTA '12, Tallinn, Estonia, March 31 - April 1, 2012 , 1\u20137. ACM, 2012. URL: http://doi.acm.org/10.1145/2427048.2427056 , doi:10.1145/2427048.2427056 . \u21a9 Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems , 34 \\(4\\) :15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678 , doi:10.1145/2400676.2400678 . \u21a9 Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14 . \u21a9 Luis Eduardo de Souza Amorim, Michael J. Steindorfer, Sebastian Erdweg, and Eelco Visser. Declarative specification of indentation rules: a tooling perspective on parsing and pretty-printing layout-sensitive languages. In David Pearce 0005, Tanja Mayerhofer, and Friedrich Steimann, editors, Proceedings of the 11 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2018, Boston, MA, USA, November 05-06, 2018 , 3\u201315. ACM, 2018. URL: https://doi.org/10.1145/3276604.3276607 , doi:10.1145/3276604.3276607 . \u21a9 Luis Eduardo de Souza Amorim. Declarative Syntax Definition for Modern Language Workbenches . PhD thesis, Delft University of Technology, Netherlands, 2019. base-search.net \\(fttudelft:oai:tudelft\\.nl:uuid:43d7992a\\-7077\\-47ba\\-b38f\\-113f5011d07f\\) . URL: https://www.base-search.net/Record/261b6c9463c1d4fe309e3c6104cd4d80fbc9d3cc8fbc66006f34130f481b506f . \u21a9 Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016 , 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374 , doi:10.1145/2997364.2997374 . \u21a9 Martin Bravenboer and Eelco Visser. Parse table composition. In Dragan Gasevic, Ralf L\u00e4mmel, and Eric Van Wyk, editors, Software Language Engineering, First International Conference, SLE 2008, Toulouse, France, September 29-30, 2008. Revised Selected Papers , volume 5452 of Lecture Notes in Computer Science, 74\u201394. Springer, 2009. URL: http://dx.doi.org/10.1007/978-3-642-00434-6_6 , doi:10.1007/978-3-642-00434-6_6 . \u21a9","title":"An SDF3 Bibliography"},{"location":"background/bibliography/sdf3/#an-sdf3-bibliography","text":"SDF3 1 is the third generation in the SDF family of syntax definition formalisms, which were developed in the context of the ASF+SDF 2 , Stratego/XT 3 , and Spoofax 4 language workbenches. Kats et al. decribe the motivation for declarative syntax definition 5 .","title":"An SDF3 Bibliography"},{"location":"background/bibliography/sdf3/#sdf","text":"The first SDF 6 supported modular composition of syntax definition, a direct correspondence between concrete and abstract syntax, and parsing with the full class of context-free grammars enabled by the Generalized-LR (GLR) parsing algorithm 7 8 . Its programming environment, as part of the ASF+SDF MetaEnvironment 9 , focused on live development of syntax definitions through incremental and modular scanner and parser generation 10 11 12 in order to provide fast turnaround times during language development.","title":"SDF"},{"location":"background/bibliography/sdf3/#sdf2","text":"The second generation, SDF2 encompassed a redesign of the internals of SDF without changing the surface syntax. The front-end of the implementation consisted of a transformation pipeline from the rich surface syntax to a minimal core (kernel) language 13 that served as input for parser generation. The key change of SDF2 was its integration of lexical and context-free syntax, supported by Scannerless GLR (SGLR) parsing 14 15 , enabling composition of languages with different lexical syntax 16 17 .","title":"SDF2"},{"location":"background/bibliography/sdf3/#sdf3","text":"SDF3 is the latest member of the family and inherits many features of its predecessors. The most recognizable change is to the syntax of productions that should make it more familiar to users of other grammar formalisms. Further, it introduces new features in order to support multi-purpose interpretations of syntax definitions. The goals of the design of SDF3 are (1) to support the definition of the concrete and abstract syntax of formal languages (with an emphasis on programming languages), (2) to support declarative syntax definition so that there is no need to understand parsing algorithms in order to understand definitions 5 , (3) to make syntax definitions readable and understandable so that they can be used as reference documentation, and (4) to support execution of syntax definitions as parsers, but also for other syntactic operations, i.e to support multi-purpose interpretation based on a single source. The focus on multipurpose interpretation is driven by the role of SDF3 in the Spoofax language workbench 4 . Key features of SDF3 include Template productions 18 Error recovery 19 Layout constraints for layout-sensitive syntax 20 21 Safe and complete disambiguation of expression grammars 22 Placeholders and syntactic code completion 23","title":"SDF3"},{"location":"background/bibliography/sdf3/#future-work","text":"Parse table composition 24 , while implemented in a prototype, hasn't made into the production implementation yet.","title":"Future Work"},{"location":"background/bibliography/sdf3/#references","text":"Luis Eduardo de Souza Amorim and Eelco Visser. Multi-purpose syntax definition with SDF3. In Frank S. de Boer and Antonio Cerone, editors, Software Engineering and Formal Methods - 18 th International Conference, SEFM 2020, Amsterdam, The Netherlands, September 14-18, 2020, Proceedings , volume 12310 of Lecture Notes in Computer Science, 1\u201323. Springer, 2020. URL: https://doi.org/10.1007/978-3-030-58768-0_1 , doi:10.1007/978-3-030-58768-0_1 . \u21a9 Mark G. J. van den Brand, Arie van Deursen, Jan Heering, H. A. de Jong, Merijn de Jonge, Tobias Kuipers, Paul Klint, Leon Moonen, Pieter A. Olivier, Jeroen Scheerder, Jurgen J. Vinju, Eelco Visser, and Joost Visser. The ASF+SDF meta-environment: a component-based language development environment. In Reinhard Wilhelm, editor, Compiler Construction, 10 th International Conference, CC 2001 Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2001 Genova, Italy, April 2-6, 2001, Proceedings , volume 2027 of Lecture Notes in Computer Science, 365\u2013370. Springer, 2001. URL: https://doi.org/10.1016/S1571-0661 \\(04\\) 80917-4 , doi:10.1016/S1571-0661 \\(04\\) 80917-4 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming , 72 \\(1\\-2\\) :52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003 , doi:10.1016/j.scico.2007.11.003 . \u21a9 Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9 \u21a9 Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. Pure and declarative syntax definition: paradise lost and regained. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 918\u2013932. Reno/Tahoe, Nevada, 2010. ACM. URL: http://doi.acm.org/10.1145/1869459.1869535 , doi:10.1145/1869459.1869535 . \u21a9 \u21a9 Jan Heering, P. R. H. Hendriks, Paul Klint, and Jan Rekers. The syntax definition formalism SDF - reference manual. SIGPLAN Notices , 24 \\(11\\) :43\u201375, 1989. doi:10.1145/71605.71607 . \u21a9 Masaru Tomita. An efficient context-free parsing algorithm for natural languages. In IJCAI , 756\u2013764. 1985. \u21a9 Jan Rekers. Parser Generation for Interactive Environments . PhD thesis, University of Amsterdam, Amsterdam, The Netherlands, January 1992. \u21a9 Paul Klint. A meta-environment for generating programming environments. ACM Transactions on Software Engineering Methodology , 2 \\(2\\) :176\u2013201, 1993. doi:10.1145/151257.151260 . \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of lexical scanners. ACM Transactions on Programming Languages and Systems , 14 \\(4\\) :490\u2013520, 1992. doi:10.1145/133233.133240 . \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of parsers. IEEE Trans. Software Eng. , 16 \\(12\\) :1344\u20131351, 1990. \u21a9 Jan Heering, Paul Klint, and Jan Rekers. Lazy and incremental program generation. ACM Transactions on Programming Languages and Systems , 16 \\(3\\) :1010\u20131023, 1994. doi:10.1145/177492.177750 . \u21a9 Eelco Visser. A family of syntax definition formalisms. In Mark G. J. van den Brand and Vania Vieira Estrela, editors, ASF+SDF 1995. A Workshop on Generating Tools from Algebraic Specifications . Technical Report P9504, Programming Research Group, University of Amsterdam, May 1995. \u21a9 Eelco Visser. Syntax Definition for Language Prototyping . PhD thesis, University of Amsterdam, September 1997. \u21a9 Eelco Visser. Scannerless generalized-LR parsing. Technical Report P9707, Programming Research Group, University of Amsterdam, July 1997. \u21a9 Eelco Visser. Meta-programming with concrete object syntax. In Don S. Batory, Charles Consel, and Walid Taha, editors, Generative Programming and Component Engineering, ACM SIGPLAN/SIGSOFT Conference, GPCE 2002, Pittsburgh, PA, USA, October 6-8, 2002, Proceedings , volume 2487 of Lecture Notes in Computer Science, 299\u2013315. Springer, 2002. URL: https://doi.org/10.1007/3-540-45821-2_19 , doi:10.1007/3-540-45821-2_19 . \u21a9 Martin Bravenboer and Eelco Visser. Concrete syntax for objects: domain-specific language embedding and assimilation without restrictions. In John M. Vlissides and Douglas C. Schmidt, editors, Proceedings of the 19 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2004 , 365\u2013383. Vancouver, BC, Canada, 2004. ACM. URL: http://doi.acm.org/10.1145/1028976.1029007 , doi:10.1145/1028976.1029007 . \u21a9 Tobi Vollebregt, Lennart C. L. Kats, and Eelco Visser. Declarative specification of template-based textual editors. In Anthony Sloane and Suzana Andova, editors, International Workshop on Language Descriptions, Tools, and Applications, LDTA '12, Tallinn, Estonia, March 31 - April 1, 2012 , 1\u20137. ACM, 2012. URL: http://doi.acm.org/10.1145/2427048.2427056 , doi:10.1145/2427048.2427056 . \u21a9 Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems , 34 \\(4\\) :15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678 , doi:10.1145/2400676.2400678 . \u21a9 Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14 . \u21a9 Luis Eduardo de Souza Amorim, Michael J. Steindorfer, Sebastian Erdweg, and Eelco Visser. Declarative specification of indentation rules: a tooling perspective on parsing and pretty-printing layout-sensitive languages. In David Pearce 0005, Tanja Mayerhofer, and Friedrich Steimann, editors, Proceedings of the 11 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2018, Boston, MA, USA, November 05-06, 2018 , 3\u201315. ACM, 2018. URL: https://doi.org/10.1145/3276604.3276607 , doi:10.1145/3276604.3276607 . \u21a9 Luis Eduardo de Souza Amorim. Declarative Syntax Definition for Modern Language Workbenches . PhD thesis, Delft University of Technology, Netherlands, 2019. base-search.net \\(fttudelft:oai:tudelft\\.nl:uuid:43d7992a\\-7077\\-47ba\\-b38f\\-113f5011d07f\\) . URL: https://www.base-search.net/Record/261b6c9463c1d4fe309e3c6104cd4d80fbc9d3cc8fbc66006f34130f481b506f . \u21a9 Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016 , 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374 , doi:10.1145/2997364.2997374 . \u21a9 Martin Bravenboer and Eelco Visser. Parse table composition. In Dragan Gasevic, Ralf L\u00e4mmel, and Eric Van Wyk, editors, Software Language Engineering, First International Conference, SLE 2008, Toulouse, France, September 29-30, 2008. Revised Selected Papers , volume 5452 of Lecture Notes in Computer Science, 74\u201394. Springer, 2009. URL: http://dx.doi.org/10.1007/978-3-642-00434-6_6 , doi:10.1007/978-3-642-00434-6_6 . \u21a9","title":"References"},{"location":"background/bibliography/statix/","text":"A Statix Bibliography \u00b6 The Statix 1 2 meta-language provides support for the declarative definition of the static semantics of programming languages in terms of unification constraints and scope graph constraints for name resolution 1 guaranteeing query stability 2 . Here we trace the development of the Statix language. The NaBL Name Binding Language \u00b6 The NaBL 3 language provides support for the declaration of the name binding rules of programming languages in terms of definitions , references , and scoping . The NaBL task engine supports incremental execution of type checkers based on NaBL 4 . While the paper used the WebDSL language as example, the NaBL analysis was only applied in production in the SDF3 language. The NaBL language is very declarative, but binding patterns such as sequential let and 'subsequent scope' are difficult to express in it. Scope Graphs \u00b6 The study of the semantics of NaBL (and its limits in expressiveness) led to the formulation of a general theory of name resolution based on scope graphs 5 . The vertices of scope graphs are scopes and the edges model reachability. Declarations are associated with scopes. Name resolution by means of a declarative resolution calculus is defined as finding a path from the scope of a reference to the scope of a declaration taking into account the structure of the scope graph extended with visibility rules formulated in terms of path well-formedness and path specificity. Constraint Language \u00b6 Based on the theory of name resolution, a constraint language was defined with a declarative and operational semantics 6 . The language was designed for a two stage type checking process. In the first phase unification and scope constraints are generated, in the second phase these constraints are solved. A distinctive feature of this approach with respect to other constraint-based approaches to type checking, is the fact that name resolution is deferred until constraint resolution. This makes the definition of type-dependent name resolution, e.g. for computing the types of record fields, straightforward. The NaBL2 language was a concrete implementation of this design and was integrated into Spoofax. It featured concrete syntax for unification and scope graph constraints, and rules for mapping AST nodes to constraints. The two stage type checking process entailed limitations for the type systems that could be expressed in NaBL2. In particular, it was not possible to generate constraints based on information computed during the second stage. For example, a subtyping rule operating on types computed during constraint resolution Furthermore, the NaBL2 language itself was untyped, making it easy to make errors in specifications. Statix Language \u00b6 The Statix language 1 was designed to overcome the limitations of NaBL2. The language is typed, with signatures describing the types of ASTs, and typing rules declaring the types of predicates. The type system of Statix is expressed in NaBL2, making the specification of rules statically checked and much less prone to errors. This also provided a useful testbed of the ideas of scope graphs and constraints. The generation and resolution of constraints is intertwined, in order to allow computing constraints over inferred information. Furthermore, in order to generalize the notions of visibility supported by the NaBL2 language, Statix features query constraints, in order to relate references to declarations, but also to compute sets of names based on broader criteria. For example, the definition of structural record types can be expressed by a query that produces all fields of a record. Necessarily these changes entail that queries need to be executed in a scope graph that is not in its final form. This necessitate a theory of query stability. Name resolution queries such be scheduled such that they produce stable results, i.e. results that would also be produced at the end of the process. The this end a theory of critical edges was developed that asserts when it is safe to perform a query in a certain scope 2 . The Statix solver implements the operational semantics on the language in order to automatically derive type checkers from specifications. Optimizations of this solver can be based on the generaly underlying theory and be applied to all languages for which Statix specifications have been written. One such optimization is the derivation of implicitly parallel type checkers from Statix specifications 7 . Editor Services \u00b6 A next step in the evolution of Statix is the derivation of semantic editor services such as renaming and code completion from specifications 8 . References \u00b6 Hendrik van Antwerpen, Casper Bach Poulsen, Arjen Rouvoet, and Eelco Visser. Scopes as types. Proceedings of the ACM on Programming Languages , 2018. URL: https://doi.org/10.1145/3276484 , doi:10.1145/3276484 . \u21a9 \u21a9 \u21a9 Arjen Rouvoet, Hendrik van Antwerpen, Casper Bach Poulsen, Robbert Krebbers, and Eelco Visser. Knowing when to ask: sound scheduling of name resolution in type checkers derived from declarative specifications. Proceedings of the ACM on Programming Languages , 2020. URL: https://doi.org/10.1145/3428248 , doi:10.1145/3428248 . \u21a9 \u21a9 \u21a9 Gabri\u00ebl Konat, Lennart C. L. Kats, Guido Wachsmuth, and Eelco Visser. Declarative name binding and scope rules. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 311\u2013331. Springer, 2012. URL: http://dx.doi.org/10.1007/978-3-642-36089-3_18 , doi:10.1007/978-3-642-36089-3_18 . \u21a9 Guido Wachsmuth, Gabri\u00ebl Konat, Vlad A. Vergu, Danny M. Groenewegen, and Eelco Visser. A language independent task engine for incremental name and type analysis. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 260\u2013280. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_15 , doi:10.1007/978-3-319-02654-1_15 . \u21a9 Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A theory of name resolution. In Jan Vitek, editor, Programming Languages and Systems - 24 th European Symposium on Programming, ESOP 2015, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18, 2015. Proceedings , volume 9032 of Lecture Notes in Computer Science, 205\u2013231. Springer, 2015. URL: http://dx.doi.org/10.1007/978-3-662-46669-8_9 , doi:10.1007/978-3-662-46669-8_9 . \u21a9 Hendrik van Antwerpen, Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A constraint language for static semantic analysis based on scope graphs. In Martin Erwig and Tiark Rompf, editors, Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, PEPM 2016, St. Petersburg, FL, USA, January 20 - 22, 2016 , 49\u201360. ACM, 2016. URL: http://doi.acm.org/10.1145/2847538.2847543 , doi:10.1145/2847538.2847543 . \u21a9 Hendrik van Antwerpen and Eelco Visser. Scope states: guarding safety of name resolution in parallel type checkers. In ECOOP . 2021. To appear. \u21a9 Dani\u00ebl A. A. Pelsmaeker, Hendrik van Antwerpen, and Eelco Visser. Towards language-parametric semantic editor services based on declarative type system specifications \\(brave new idea paper\\) . In Alastair F. Donaldson, editor, 33 rd European Conference on Object-Oriented Programming, ECOOP 2019, July 15-19, 2019, London, United Kingdom , volume 134 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2019. URL: https://doi.org/10.4230/LIPIcs.ECOOP.2019.26 , doi:10.4230/LIPIcs.ECOOP.2019.26 . \u21a9","title":"A Statix Bibliography"},{"location":"background/bibliography/statix/#a-statix-bibliography","text":"The Statix 1 2 meta-language provides support for the declarative definition of the static semantics of programming languages in terms of unification constraints and scope graph constraints for name resolution 1 guaranteeing query stability 2 . Here we trace the development of the Statix language.","title":"A Statix Bibliography"},{"location":"background/bibliography/statix/#the-nabl-name-binding-language","text":"The NaBL 3 language provides support for the declaration of the name binding rules of programming languages in terms of definitions , references , and scoping . The NaBL task engine supports incremental execution of type checkers based on NaBL 4 . While the paper used the WebDSL language as example, the NaBL analysis was only applied in production in the SDF3 language. The NaBL language is very declarative, but binding patterns such as sequential let and 'subsequent scope' are difficult to express in it.","title":"The NaBL Name Binding Language"},{"location":"background/bibliography/statix/#scope-graphs","text":"The study of the semantics of NaBL (and its limits in expressiveness) led to the formulation of a general theory of name resolution based on scope graphs 5 . The vertices of scope graphs are scopes and the edges model reachability. Declarations are associated with scopes. Name resolution by means of a declarative resolution calculus is defined as finding a path from the scope of a reference to the scope of a declaration taking into account the structure of the scope graph extended with visibility rules formulated in terms of path well-formedness and path specificity.","title":"Scope Graphs"},{"location":"background/bibliography/statix/#constraint-language","text":"Based on the theory of name resolution, a constraint language was defined with a declarative and operational semantics 6 . The language was designed for a two stage type checking process. In the first phase unification and scope constraints are generated, in the second phase these constraints are solved. A distinctive feature of this approach with respect to other constraint-based approaches to type checking, is the fact that name resolution is deferred until constraint resolution. This makes the definition of type-dependent name resolution, e.g. for computing the types of record fields, straightforward. The NaBL2 language was a concrete implementation of this design and was integrated into Spoofax. It featured concrete syntax for unification and scope graph constraints, and rules for mapping AST nodes to constraints. The two stage type checking process entailed limitations for the type systems that could be expressed in NaBL2. In particular, it was not possible to generate constraints based on information computed during the second stage. For example, a subtyping rule operating on types computed during constraint resolution Furthermore, the NaBL2 language itself was untyped, making it easy to make errors in specifications.","title":"Constraint Language"},{"location":"background/bibliography/statix/#statix-language","text":"The Statix language 1 was designed to overcome the limitations of NaBL2. The language is typed, with signatures describing the types of ASTs, and typing rules declaring the types of predicates. The type system of Statix is expressed in NaBL2, making the specification of rules statically checked and much less prone to errors. This also provided a useful testbed of the ideas of scope graphs and constraints. The generation and resolution of constraints is intertwined, in order to allow computing constraints over inferred information. Furthermore, in order to generalize the notions of visibility supported by the NaBL2 language, Statix features query constraints, in order to relate references to declarations, but also to compute sets of names based on broader criteria. For example, the definition of structural record types can be expressed by a query that produces all fields of a record. Necessarily these changes entail that queries need to be executed in a scope graph that is not in its final form. This necessitate a theory of query stability. Name resolution queries such be scheduled such that they produce stable results, i.e. results that would also be produced at the end of the process. The this end a theory of critical edges was developed that asserts when it is safe to perform a query in a certain scope 2 . The Statix solver implements the operational semantics on the language in order to automatically derive type checkers from specifications. Optimizations of this solver can be based on the generaly underlying theory and be applied to all languages for which Statix specifications have been written. One such optimization is the derivation of implicitly parallel type checkers from Statix specifications 7 .","title":"Statix Language"},{"location":"background/bibliography/statix/#editor-services","text":"A next step in the evolution of Statix is the derivation of semantic editor services such as renaming and code completion from specifications 8 .","title":"Editor Services"},{"location":"background/bibliography/statix/#references","text":"Hendrik van Antwerpen, Casper Bach Poulsen, Arjen Rouvoet, and Eelco Visser. Scopes as types. Proceedings of the ACM on Programming Languages , 2018. URL: https://doi.org/10.1145/3276484 , doi:10.1145/3276484 . \u21a9 \u21a9 \u21a9 Arjen Rouvoet, Hendrik van Antwerpen, Casper Bach Poulsen, Robbert Krebbers, and Eelco Visser. Knowing when to ask: sound scheduling of name resolution in type checkers derived from declarative specifications. Proceedings of the ACM on Programming Languages , 2020. URL: https://doi.org/10.1145/3428248 , doi:10.1145/3428248 . \u21a9 \u21a9 \u21a9 Gabri\u00ebl Konat, Lennart C. L. Kats, Guido Wachsmuth, and Eelco Visser. Declarative name binding and scope rules. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 311\u2013331. Springer, 2012. URL: http://dx.doi.org/10.1007/978-3-642-36089-3_18 , doi:10.1007/978-3-642-36089-3_18 . \u21a9 Guido Wachsmuth, Gabri\u00ebl Konat, Vlad A. Vergu, Danny M. Groenewegen, and Eelco Visser. A language independent task engine for incremental name and type analysis. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6 th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings , volume 8225 of Lecture Notes in Computer Science, 260\u2013280. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_15 , doi:10.1007/978-3-319-02654-1_15 . \u21a9 Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A theory of name resolution. In Jan Vitek, editor, Programming Languages and Systems - 24 th European Symposium on Programming, ESOP 2015, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18, 2015. Proceedings , volume 9032 of Lecture Notes in Computer Science, 205\u2013231. Springer, 2015. URL: http://dx.doi.org/10.1007/978-3-662-46669-8_9 , doi:10.1007/978-3-662-46669-8_9 . \u21a9 Hendrik van Antwerpen, Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A constraint language for static semantic analysis based on scope graphs. In Martin Erwig and Tiark Rompf, editors, Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, PEPM 2016, St. Petersburg, FL, USA, January 20 - 22, 2016 , 49\u201360. ACM, 2016. URL: http://doi.acm.org/10.1145/2847538.2847543 , doi:10.1145/2847538.2847543 . \u21a9 Hendrik van Antwerpen and Eelco Visser. Scope states: guarding safety of name resolution in parallel type checkers. In ECOOP . 2021. To appear. \u21a9 Dani\u00ebl A. A. Pelsmaeker, Hendrik van Antwerpen, and Eelco Visser. Towards language-parametric semantic editor services based on declarative type system specifications \\(brave new idea paper\\) . In Alastair F. Donaldson, editor, 33 rd European Conference on Object-Oriented Programming, ECOOP 2019, July 15-19, 2019, London, United Kingdom , volume 134 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2019. URL: https://doi.org/10.4230/LIPIcs.ECOOP.2019.26 , doi:10.4230/LIPIcs.ECOOP.2019.26 . \u21a9","title":"References"},{"location":"background/bibliography/stratego/","text":"A Stratego Bibliography \u00b6 The original publication on Stratego appeared in ICFP'98 1 and introduced named rewrite rules and a language of strategy combinators with an operational semantics. An important aspect of the design of Stratego is the separation of the language in a core language 2 of strategy combinators and a high-level 'sugar' language of rewrite rules that can be desugared to the core language. This is still the way that the Stratego compiler is organized. The original also introduced contextual terms. These where eventually replaced by dynamic rewrite rules 3 . The paper about dynamic rules 3 also provides a comprehensive overview of Stratego and its operational semantics. Stratego and its ecosystem are described in a number of system description papers, including Stratego 0.5 4 , Stratego/XT 0.16 5 , Stratego/XT 0.17 6 Recently, a gradual type system was designed for Stratego 7 . This design and its incremental compiler 8 are the basis for the Stratego2 version of the language. References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9 Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69 \\(1\\-2\\) :123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 \u21a9 Eelco Visser. Stratego: a language for program transformation based on rewriting strategies. In Aart Middeldorp, editor, Rewriting Techniques and Applications, 12 th International Conference, RTA 2001, Utrecht, The Netherlands, May 22-24, 2001, Proceedings , volume 2051 of Lecture Notes in Computer Science, 357\u2013362. Springer, 2001. URL: https://doi.org/10.1007/3-540-45127-7_27 , doi:10.1007/3-540-45127-7_27 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.16: components for transformation systems. In John Hatcliff and Frank Tip, editors, Proceedings of the 2006 ACM SIGPLAN Workshop on Partial Evaluation and Semantics-based Program Manipulation, 2006, Charleston, South Carolina, USA, January 9-10, 2006 , 95\u201399. ACM, 2006. URL: http://doi.acm.org/10.1145/1111542.1111558 , doi:10.1145/1111542.1111558 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming , 72 \\(1\\-2\\) :52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003 , doi:10.1016/j.scico.2007.11.003 . \u21a9 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9 Jeff Smits, Gabri\u00ebl Konat, and Eelco Visser. Constructing hybrid incremental compilers for cross-module extensibility with an internal build system. Programming Journal , 4 \\(3\\) :16, 2020. URL: https://doi.org/10.22152/programming-journal.org/2020/4/16 , doi:10.22152/programming-journal.org/2020/4/16 . \u21a9","title":"A Stratego Bibliography"},{"location":"background/bibliography/stratego/#a-stratego-bibliography","text":"The original publication on Stratego appeared in ICFP'98 1 and introduced named rewrite rules and a language of strategy combinators with an operational semantics. An important aspect of the design of Stratego is the separation of the language in a core language 2 of strategy combinators and a high-level 'sugar' language of rewrite rules that can be desugared to the core language. This is still the way that the Stratego compiler is organized. The original also introduced contextual terms. These where eventually replaced by dynamic rewrite rules 3 . The paper about dynamic rules 3 also provides a comprehensive overview of Stratego and its operational semantics. Stratego and its ecosystem are described in a number of system description papers, including Stratego 0.5 4 , Stratego/XT 0.16 5 , Stratego/XT 0.17 6 Recently, a gradual type system was designed for Stratego 7 . This design and its incremental compiler 8 are the basis for the Stratego2 version of the language.","title":"A Stratego Bibliography"},{"location":"background/bibliography/stratego/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9 Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69 \\(1\\-2\\) :123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 \u21a9 Eelco Visser. Stratego: a language for program transformation based on rewriting strategies. In Aart Middeldorp, editor, Rewriting Techniques and Applications, 12 th International Conference, RTA 2001, Utrecht, The Netherlands, May 22-24, 2001, Proceedings , volume 2051 of Lecture Notes in Computer Science, 357\u2013362. Springer, 2001. URL: https://doi.org/10.1007/3-540-45127-7_27 , doi:10.1007/3-540-45127-7_27 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.16: components for transformation systems. In John Hatcliff and Frank Tip, editors, Proceedings of the 2006 ACM SIGPLAN Workshop on Partial Evaluation and Semantics-based Program Manipulation, 2006, Charleston, South Carolina, USA, January 9-10, 2006 , 95\u201399. ACM, 2006. URL: http://doi.acm.org/10.1145/1111542.1111558 , doi:10.1145/1111542.1111558 . \u21a9 Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming , 72 \\(1\\-2\\) :52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003 , doi:10.1016/j.scico.2007.11.003 . \u21a9 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9 Jeff Smits, Gabri\u00ebl Konat, and Eelco Visser. Constructing hybrid incremental compilers for cross-module extensibility with an internal build system. Programming Journal , 4 \\(3\\) :16, 2020. URL: https://doi.org/10.22152/programming-journal.org/2020/4/16 , doi:10.22152/programming-journal.org/2020/4/16 . \u21a9","title":"References"},{"location":"background/documentation/","text":"Documentation \u00b6 This section explains the documentation's technology and structure, and how you can contribute. Technology \u00b6 This documentation uses MkDocs , a fast and simple static site generated that's geared towards building project documentation from Markdown files. In particular, this website uses MkDocs Material , which provides a clean look, easy customization, and many features for technical documentation. Structure \u00b6 The structure of this documentation follows the Grand Unified Theory of Documentation where documentation is split into four categories: Tutorials : oriented to learning , enabling newcomers to get started through a lesson, analogous to teaching a child how to cook. How-Tos : oriented to a particular goal , showing how to solve a specific problem through a series of steps, analogous to a recipe in a cookbook. Reference : oriented to information , describing the machinery through dry description, analogous to an encyclopaedia article. Background : oriented to understanding , explaining through discursive explanation, analogous to an article on culinary social history. Contributing \u00b6 Contributing to the documentation is easy. Quick changes and fixing typos can be done by clicking the button in the top-right corner of a page, and editing and saving the underlying Markdown file. More considerable contributions can be made by cloning this repository locally, and editing the Markdown files there. The easiest way to get a live preview (automatically reloading) of your changes, is by installing Docker and executing make from the root directory. This will serve the latest changes to localhost:8000 . MkDocs Reference Extensions Reference","title":"Documentation"},{"location":"background/documentation/#documentation","text":"This section explains the documentation's technology and structure, and how you can contribute.","title":"Documentation"},{"location":"background/documentation/#technology","text":"This documentation uses MkDocs , a fast and simple static site generated that's geared towards building project documentation from Markdown files. In particular, this website uses MkDocs Material , which provides a clean look, easy customization, and many features for technical documentation.","title":"Technology"},{"location":"background/documentation/#structure","text":"The structure of this documentation follows the Grand Unified Theory of Documentation where documentation is split into four categories: Tutorials : oriented to learning , enabling newcomers to get started through a lesson, analogous to teaching a child how to cook. How-Tos : oriented to a particular goal , showing how to solve a specific problem through a series of steps, analogous to a recipe in a cookbook. Reference : oriented to information , describing the machinery through dry description, analogous to an encyclopaedia article. Background : oriented to understanding , explaining through discursive explanation, analogous to an article on culinary social history.","title":"Structure"},{"location":"background/documentation/#contributing","text":"Contributing to the documentation is easy. Quick changes and fixing typos can be done by clicking the button in the top-right corner of a page, and editing and saving the underlying Markdown file. More considerable contributions can be made by cloning this repository locally, and editing the Markdown files there. The easiest way to get a live preview (automatically reloading) of your changes, is by installing Docker and executing make from the root directory. This will serve the latest changes to localhost:8000 . MkDocs Reference Extensions Reference","title":"Contributing"},{"location":"background/documentation/citations/","text":"Documentation Citations \u00b6 To cite a paper or work, first ensure the citation is in a bibliography ( .bib ) file in the /bibliographies/ directory. For example, in the bibliographies/spoofax.bib file, we find: @inproceedings { KatsV10 , title = {The {Spoofax} language workbench: rules for declarative specification of languages and {IDEs}} , author = {Lennart C. L. Kats and Eelco Visser} , year = {2010} , doi = {10.1145/1869459.1869497} , url = {https://doi.org/10.1145/1869459.1869497} , pages = {444-463} , booktitle = {Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010} , } Adding References To add a reference, add it on Researchr to the Spoofax bibliography . Then on the command-line, invoke the following to regenerate the spoofax.bib file: make bib Do not change the spoofax.bib file manually, it is generated and updated through Researchr . Then reference the work like this: The Spoofax language workbench[@KatsV10] is vital to declarative language development. Finally, add a place for the bibliography footnotes to be added (usually at the end of the file) by adding the following line to the file: \\bibliography The line will be rendered as: The Spoofax language workbench 1 is vital to declarative language development. And the references will be at the bottom of this page. If the citation appears rendered as Spoofax language workbench[^1] , then you might have forgotten to add a place for the bibliography. Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9","title":"Citations"},{"location":"background/documentation/citations/#documentation-citations","text":"To cite a paper or work, first ensure the citation is in a bibliography ( .bib ) file in the /bibliographies/ directory. For example, in the bibliographies/spoofax.bib file, we find: @inproceedings { KatsV10 , title = {The {Spoofax} language workbench: rules for declarative specification of languages and {IDEs}} , author = {Lennart C. L. Kats and Eelco Visser} , year = {2010} , doi = {10.1145/1869459.1869497} , url = {https://doi.org/10.1145/1869459.1869497} , pages = {444-463} , booktitle = {Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010} , } Adding References To add a reference, add it on Researchr to the Spoofax bibliography . Then on the command-line, invoke the following to regenerate the spoofax.bib file: make bib Do not change the spoofax.bib file manually, it is generated and updated through Researchr . Then reference the work like this: The Spoofax language workbench[@KatsV10] is vital to declarative language development. Finally, add a place for the bibliography footnotes to be added (usually at the end of the file) by adding the following line to the file: \\bibliography The line will be rendered as: The Spoofax language workbench 1 is vital to declarative language development. And the references will be at the bottom of this page. If the citation appears rendered as Spoofax language workbench[^1] , then you might have forgotten to add a place for the bibliography. Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010 , 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497 , doi:10.1145/1869459.1869497 . \u21a9","title":"Documentation Citations"},{"location":"background/documentation/links/","text":"Documentation Links \u00b6 Links to other parts of the documentation should be written as relative links and point to specific Markdown files. For example, to add a link to tutorials from the background/index.md page, the link should read: [ Tutorials ]( ../tutorials/index.md ) To link to the index page of a section, link to the index.md file. Avoid internal links without .md Even if it might seem to work, do not link to an internal page without specifying the .md file to link to. For example, do not use [Background](../background/) . These links will not work once the documentation has been deployed. Additionally, you won't see any warnings about these (possibly broken) links in the console when running mkdocs or its Docker image. Absolute Links are Not Supported Even if it might seem to work, do not link to an internal page using an absolute link. For example, do not use [Background](/background/index.md) . These links are not properly converted and will break once the documentation has been deployed.","title":"Links"},{"location":"background/documentation/links/#documentation-links","text":"Links to other parts of the documentation should be written as relative links and point to specific Markdown files. For example, to add a link to tutorials from the background/index.md page, the link should read: [ Tutorials ]( ../tutorials/index.md ) To link to the index page of a section, link to the index.md file. Avoid internal links without .md Even if it might seem to work, do not link to an internal page without specifying the .md file to link to. For example, do not use [Background](../background/) . These links will not work once the documentation has been deployed. Additionally, you won't see any warnings about these (possibly broken) links in the console when running mkdocs or its Docker image. Absolute Links are Not Supported Even if it might seem to work, do not link to an internal page using an absolute link. For example, do not use [Background](/background/index.md) . These links are not properly converted and will break once the documentation has been deployed.","title":"Documentation Links"},{"location":"background/documentation/pages/","text":"Documentation Pages \u00b6 To add a new page to the documentation: Create a Markdown ( .md ) file in an appropriate location in the docs/ folder; Add the page to the nav element in the mkdocs.yml file in the root of the repository. Overriding the title By default, the title shown in the Table of Contents is the title of the page. To override this, specify a title in the nav element explicitly. For example: nav : - Home : - index.md - Installation : getting-started.md By convention, the first page mentioned in nav under a section should be some index.md (without a title), and will be used as the index page (home page) for that section.","title":"Adding Pages"},{"location":"background/documentation/pages/#documentation-pages","text":"To add a new page to the documentation: Create a Markdown ( .md ) file in an appropriate location in the docs/ folder; Add the page to the nav element in the mkdocs.yml file in the root of the repository. Overriding the title By default, the title shown in the Table of Contents is the title of the page. To override this, specify a title in the nav element explicitly. For example: nav : - Home : - index.md - Installation : getting-started.md By convention, the first page mentioned in nav under a section should be some index.md (without a title), and will be used as the index page (home page) for that section.","title":"Documentation Pages"},{"location":"background/documentation/structure/","text":"Documentation Structure \u00b6 The structure of the documentation repository is as follows (hover over any of the files to see its description): \ud83d\udce6 / \u2523 \ud83d\udcc1 .github \u2523 \ud83d\udcc2 bibliographies \u2523 \ud83d\udcc2 docs \u2503 \u2523 \ud83d\udcc2 assets \u2503 \u2503 \u2523 \ud83d\udcdc favicon.png \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-dark.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-light.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero.svg \u2503 \u2503 \u2523 \ud83d\udcdc logo.svg \u2503 \u2503 \u2517 \ud83d\udcdc styles.css \u2503 \u2523 \ud83d\udcc2 background \u2503 \u2523 \ud83d\udcc2 howtos \u2503 \u2523 \ud83d\udcc2 reference \u2503 \u2523 \ud83d\udcc2 release \u2503 \u2523 \ud83d\udcc2 support \u2503 \u2523 \ud83d\udcc2 tutorials \u2503 \u2517 \ud83d\udcdc index.md \u2523 \ud83d\udcc1 overrides \u2503 \u2523 \ud83d\udcdc index.html \u2503 \u2517 \ud83d\udcdc main.html \u2523 \ud83d\udcdc .gitignore \u2523 \ud83d\udcdc Dockerfile \u2523 \ud83d\udcdc LICENSE \u2523 \ud83d\udcdc Makefile \u2523 \ud83d\udcdc mkdocs_requirements.txt \u2523 \ud83d\udcdc mkdocs.yml \u2517 \ud83d\udcdc README.md","title":"Structure"},{"location":"background/documentation/structure/#documentation-structure","text":"The structure of the documentation repository is as follows (hover over any of the files to see its description): \ud83d\udce6 / \u2523 \ud83d\udcc1 .github \u2523 \ud83d\udcc2 bibliographies \u2523 \ud83d\udcc2 docs \u2503 \u2523 \ud83d\udcc2 assets \u2503 \u2503 \u2523 \ud83d\udcdc favicon.png \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-dark.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-light.svg \u2503 \u2503 \u2523 \ud83d\udcdc hero.svg \u2503 \u2503 \u2523 \ud83d\udcdc logo.svg \u2503 \u2503 \u2517 \ud83d\udcdc styles.css \u2503 \u2523 \ud83d\udcc2 background \u2503 \u2523 \ud83d\udcc2 howtos \u2503 \u2523 \ud83d\udcc2 reference \u2503 \u2523 \ud83d\udcc2 release \u2503 \u2523 \ud83d\udcc2 support \u2503 \u2523 \ud83d\udcc2 tutorials \u2503 \u2517 \ud83d\udcdc index.md \u2523 \ud83d\udcc1 overrides \u2503 \u2523 \ud83d\udcdc index.html \u2503 \u2517 \ud83d\udcdc main.html \u2523 \ud83d\udcdc .gitignore \u2523 \ud83d\udcdc Dockerfile \u2523 \ud83d\udcdc LICENSE \u2523 \ud83d\udcdc Makefile \u2523 \ud83d\udcdc mkdocs_requirements.txt \u2523 \ud83d\udcdc mkdocs.yml \u2517 \ud83d\udcdc README.md","title":"Documentation Structure"},{"location":"background/documentation/troubleshooting/","text":"Documentation Troubleshooting \u00b6 Macro Syntax Error: Missing end of comment tag \u00b6 The macros in the documentation, including in code blocks, is expanded through the mkdocs-macros plugin which uses the Jinja2 template processor. Its template syntax is very advanced, allowing not only to replace simple references, but also more complex statements and comments. In this case, Jinja sees {# and interprets it as a comment. Of course, then it cannot find the end of the comment and produces an error. INFO - [macros] - ERROR # _Macro Syntax Error_ _Line 11 in Markdown file:_ **Missing end of comment tag** ```python {# This is not a Jinja comment } ``` To work around this, wrap the block in a {% raw %} and {% endraw %} tag. For example: {% raw %} ``` {# This is not a Jinja comment } ``` {% endraw %} Alternatively, if you still want to use other macros in the code, wrap the offending character sequence in a template: {{'{#'}} For example: ``` {{'{#'}} This is not a Jinja comment } ``` In both cases the example gets rendered as: {# This is not a Jinja comment }","title":"Troubleshooting"},{"location":"background/documentation/troubleshooting/#documentation-troubleshooting","text":"","title":"Documentation Troubleshooting"},{"location":"background/documentation/troubleshooting/#macro-syntax-error-missing-end-of-comment-tag","text":"The macros in the documentation, including in code blocks, is expanded through the mkdocs-macros plugin which uses the Jinja2 template processor. Its template syntax is very advanced, allowing not only to replace simple references, but also more complex statements and comments. In this case, Jinja sees {# and interprets it as a comment. Of course, then it cannot find the end of the comment and produces an error. INFO - [macros] - ERROR # _Macro Syntax Error_ _Line 11 in Markdown file:_ **Missing end of comment tag** ```python {# This is not a Jinja comment } ``` To work around this, wrap the block in a {% raw %} and {% endraw %} tag. For example: {% raw %} ``` {# This is not a Jinja comment } ``` {% endraw %} Alternatively, if you still want to use other macros in the code, wrap the offending character sequence in a template: {{'{#'}} For example: ``` {{'{#'}} This is not a Jinja comment } ``` In both cases the example gets rendered as: {# This is not a Jinja comment }","title":"Macro Syntax Error: Missing end of comment tag"},{"location":"background/statix/","text":"Statix Background \u00b6 rule selection open/closed world reasoning ( try /DWF/DLeq) desugaring of functional rules Internal representation of scope graphs Query Scheduling/Permission to Extend","title":"Statix Background"},{"location":"background/statix/#statix-background","text":"rule selection open/closed world reasoning ( try /DWF/DLeq) desugaring of functional rules Internal representation of scope graphs Query Scheduling/Permission to Extend","title":"Statix Background"},{"location":"background/stratego/","text":"Stratego \u00b6 The Stratego transformation was born from a pure rewriting approach to program transformation by the introduction of traversal combinators 1 and programmable rewriting strategies 2 . Strategic Rewriting \u00b6 This section reviews the classic definition of term rewriting and motivates the transition to strategic rewriting. Term rewriting Limitations of term rewriting Factoring out Traversal Strategic Rewriting Strategy Combinators \u00b6 Rather than defining high-level strategies as primitives, Stratego provides basic strategies combinators for composing strategies. The section in the reference manual provides a definition of all the combinators. Here we expand that description with many examples. Sequential combinators Term combinators Traveral combinators Type unifying traversals References \u00b6 Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2 nd International Workshop on the Theory and Practice of Algebraic Specifications \\(ASF\\+SDF 1997\\) , Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag. \u21a9 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"Stratego"},{"location":"background/stratego/#stratego","text":"The Stratego transformation was born from a pure rewriting approach to program transformation by the introduction of traversal combinators 1 and programmable rewriting strategies 2 .","title":"Stratego"},{"location":"background/stratego/#strategic-rewriting","text":"This section reviews the classic definition of term rewriting and motivates the transition to strategic rewriting. Term rewriting Limitations of term rewriting Factoring out Traversal Strategic Rewriting","title":"Strategic Rewriting"},{"location":"background/stratego/#strategy-combinators","text":"Rather than defining high-level strategies as primitives, Stratego provides basic strategies combinators for composing strategies. The section in the reference manual provides a definition of all the combinators. Here we expand that description with many examples. Sequential combinators Term combinators Traveral combinators Type unifying traversals","title":"Strategy Combinators"},{"location":"background/stratego/#references","text":"Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2 nd International Workshop on the Theory and Practice of Algebraic Specifications \\(ASF\\+SDF 1997\\) , Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag. \u21a9 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"References"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/","text":"Limitations of Rewriting \u00b6 Term rewriting can be used to implement transformations on programs represented by means of terms. Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The innermost strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances. Consider for example, the following extension of prop-dnf-rules with distribution rules to achieve conjunctive normal forms: module prop-cnf imports prop-eval-rules rules E : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) E : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies cnf = innermost ( E ) This rewrite system is non-terminating because after applying one of the and-over-or distribution rules, the or-over-and distribution rules introduced here can be applied, and vice versa. And ( Or ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"r\" )) - > Or ( And ( Atom ( \"p\" ), Atom ( \"r\" )), And ( Atom ( \"q\" ), Atom ( \"r\" ))) - > And ( Or ( Atom ( \"p\" ), And ( Atom ( \"q\" ), Atom ( \"r\" ))), Or ( Atom ( \"r\" ), And ( Atom ( \"q\" ), Atom ( \"r\" )))) - > ... There are a number of solutions to this problem. We will first discuss a couple of solutions within pure rewriting, and then show how programmable rewriting strategies can overcome the problems of these solutions. Attempt 1: Remodularization \u00b6 The non-termination of prop-cnf is due to the fact that the and-over-or and or-over-and distribution rules interfere with each other. This can be prevented by refactoring the module structure such that the two sets of rules are not present in the same rewrite system. For example, we could split module prop-dnf-rules into prop-simplify and prop-dnf2 as follows: module prop-simplify imports prop-eval-rules rules E : Impl ( x , y ) - > Or ( Not ( x ), y ) E : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) E : Not ( Not ( x )) - > x E : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) E : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) module prop-dnf2 imports prop-simplify rules E : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) E : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) strategies dnf = innermost ( E ) Now we can reuse the rules from prop-simplify without the and-over-or distribution rules to create a prop-cnf2 for normalizing to conjunctive normal form: module prop-cnf2 imports prop-simplify rules E : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) E : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies cnf = innermost ( E ) Although this solves the non-termination problem, it is not an ideal solution. In the first place it is not possible to apply the two transformations in the same program. In the second place, extrapolating the approach to fine-grained selection of rules might require definition of a single rule per module. Attempt 2: Functionalization \u00b6 Another common solution to this kind of problem is to introduce additional constructors that achieve normalization under a restricted set of rules. That is, the original set of rules p1 -> p2 is transformed into rules of the form f(p_1) -> p_2' , where f is some new constructor symbol and the right-hand side of the rule also contains such new constructors. In this style of programming, constructors such as f are called functions and are distinguished from constructors. Normal forms over such rewrite systems are assumed to be free of these function symbols; otherwise the function would have an incomplete definition. To illustrate the approach we adapt the DNF rules by introducing the function symbols Dnf and DnfR . (We ignore the evaluation rules in this example.) module prop-dnf3 imports libstrategolib prop signature constructors Dnf : Prop - > Prop DnfR : Prop - > Prop rules E : Dnf ( Atom ( x )) - > Atom ( x ) E : Dnf ( Not ( x )) - > DnfR ( Not ( Dnf ( x ))) E : Dnf ( And ( x , y )) - > DnfR ( And ( Dnf ( x ), Dnf ( y ))) E : Dnf ( Or ( x , y )) - > Or ( Dnf ( x ), Dnf ( y )) E : Dnf ( Impl ( x , y )) - > Dnf ( Or ( Not ( x ), y )) E : Dnf ( Eq ( x , y )) - > Dnf ( And ( Impl ( x , y ), Impl ( y , x ))) E : DnfR ( Not ( Not ( x ))) - > x E : DnfR ( Not ( And ( x , y ))) - > Or ( Dnf ( Not ( x )), Dnf ( Not ( y ))) E : DnfR ( Not ( Or ( x , y ))) - > Dnf ( And ( Not ( x ), Not ( y ))) D : DnfR ( Not ( x )) - > Not ( x ) E : DnfR ( And ( Or ( x , y ), z )) - > Or ( Dnf ( And ( x , z )), Dnf ( And ( y , z ))) E : DnfR ( And ( z , Or ( x , y ))) - > Or ( Dnf ( And ( z , x )), Dnf ( And ( z , y ))) D : DnfR ( And ( x , y )) - > And ( x , y ) strategies dnf = innermost ( E < + D ) The Dnf function mimics the innermost normalization strategy by recursively traversing terms. The auxiliary transformation function DnfR is used to encode the distribution and negation rules. The D rules are default rules that are only applied if none of the E rules apply, as specified by the strategy expression E <+ D . In order to compute the disjunctive normal form of a term, we have to apply the Dnf function to it, as illustrated in the following application of the prop-dnf3 program: < dnf > Dnf ( And ( Impl ( Atom ( \"r\" ), And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" ))) => Or ( And ( Not ( Atom ( \"r\" )), Atom ( \"p\" )), And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" ))) Intermezzo: DNF in Spoofax/Eclipse (move to tutorial?) \u00b6 If you\u2019re going to try to run this example in Spoofax/Eclipse, a few words of caution. First, it\u2019s easiest to just accumulate all of the different test modules as imports in your main language \u201c.str\u201d file. But if you do that, all of the rules will be in the same namespace. So you\u2019re going to want to use different identifiers (say E3 and D3 ) in place of E and D in your prop-dnf3.str file. Also, the concrete syntax has no way to represent the \u201cextra\u201d function symbol Dnf that is used here, so you\u2019ll want to use alternate triggering strategies like make-nf = innermost ( E3 < + D3 ) dnf3 : x - > < make-nf > Dnf ( x ) that wrap the input in Dnf( ... ) themselves. For conjunctive normal form we can create a similar definition, which can now co-exist with the definition of DNF . Indeed, we could then simultaneously rewrite one subterm to DNF and the other to CNF . E : DC ( x ) - > ( Dnf ( x ), Cnf ( x )) Evaluation \u00b6 In the solution above, the original rules have been completely intertwined with the Dnf transformation. The rules for negation cannot be reused in the definition of normalization to conjunctive normal form. For each new transformation a new traversal function and new transformation functions have to be defined. Many additional rules had to be added to traverse the term to find the places to apply the rules. In the modular solution we had 5 basic rules and 2 additional rules for DNF and 2 rules for CNF, 9 in total. In the functionalized version we needed 13 rules for each transformation, that is 26 rules in total.","title":"Limitations of Rewriting"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#limitations-of-rewriting","text":"Term rewriting can be used to implement transformations on programs represented by means of terms. Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The innermost strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances. Consider for example, the following extension of prop-dnf-rules with distribution rules to achieve conjunctive normal forms: module prop-cnf imports prop-eval-rules rules E : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) E : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies cnf = innermost ( E ) This rewrite system is non-terminating because after applying one of the and-over-or distribution rules, the or-over-and distribution rules introduced here can be applied, and vice versa. And ( Or ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"r\" )) - > Or ( And ( Atom ( \"p\" ), Atom ( \"r\" )), And ( Atom ( \"q\" ), Atom ( \"r\" ))) - > And ( Or ( Atom ( \"p\" ), And ( Atom ( \"q\" ), Atom ( \"r\" ))), Or ( Atom ( \"r\" ), And ( Atom ( \"q\" ), Atom ( \"r\" )))) - > ... There are a number of solutions to this problem. We will first discuss a couple of solutions within pure rewriting, and then show how programmable rewriting strategies can overcome the problems of these solutions.","title":"Limitations of Rewriting"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#attempt-1-remodularization","text":"The non-termination of prop-cnf is due to the fact that the and-over-or and or-over-and distribution rules interfere with each other. This can be prevented by refactoring the module structure such that the two sets of rules are not present in the same rewrite system. For example, we could split module prop-dnf-rules into prop-simplify and prop-dnf2 as follows: module prop-simplify imports prop-eval-rules rules E : Impl ( x , y ) - > Or ( Not ( x ), y ) E : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) E : Not ( Not ( x )) - > x E : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) E : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) module prop-dnf2 imports prop-simplify rules E : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) E : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) strategies dnf = innermost ( E ) Now we can reuse the rules from prop-simplify without the and-over-or distribution rules to create a prop-cnf2 for normalizing to conjunctive normal form: module prop-cnf2 imports prop-simplify rules E : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) E : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies cnf = innermost ( E ) Although this solves the non-termination problem, it is not an ideal solution. In the first place it is not possible to apply the two transformations in the same program. In the second place, extrapolating the approach to fine-grained selection of rules might require definition of a single rule per module.","title":"Attempt 1: Remodularization"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#attempt-2-functionalization","text":"Another common solution to this kind of problem is to introduce additional constructors that achieve normalization under a restricted set of rules. That is, the original set of rules p1 -> p2 is transformed into rules of the form f(p_1) -> p_2' , where f is some new constructor symbol and the right-hand side of the rule also contains such new constructors. In this style of programming, constructors such as f are called functions and are distinguished from constructors. Normal forms over such rewrite systems are assumed to be free of these function symbols; otherwise the function would have an incomplete definition. To illustrate the approach we adapt the DNF rules by introducing the function symbols Dnf and DnfR . (We ignore the evaluation rules in this example.) module prop-dnf3 imports libstrategolib prop signature constructors Dnf : Prop - > Prop DnfR : Prop - > Prop rules E : Dnf ( Atom ( x )) - > Atom ( x ) E : Dnf ( Not ( x )) - > DnfR ( Not ( Dnf ( x ))) E : Dnf ( And ( x , y )) - > DnfR ( And ( Dnf ( x ), Dnf ( y ))) E : Dnf ( Or ( x , y )) - > Or ( Dnf ( x ), Dnf ( y )) E : Dnf ( Impl ( x , y )) - > Dnf ( Or ( Not ( x ), y )) E : Dnf ( Eq ( x , y )) - > Dnf ( And ( Impl ( x , y ), Impl ( y , x ))) E : DnfR ( Not ( Not ( x ))) - > x E : DnfR ( Not ( And ( x , y ))) - > Or ( Dnf ( Not ( x )), Dnf ( Not ( y ))) E : DnfR ( Not ( Or ( x , y ))) - > Dnf ( And ( Not ( x ), Not ( y ))) D : DnfR ( Not ( x )) - > Not ( x ) E : DnfR ( And ( Or ( x , y ), z )) - > Or ( Dnf ( And ( x , z )), Dnf ( And ( y , z ))) E : DnfR ( And ( z , Or ( x , y ))) - > Or ( Dnf ( And ( z , x )), Dnf ( And ( z , y ))) D : DnfR ( And ( x , y )) - > And ( x , y ) strategies dnf = innermost ( E < + D ) The Dnf function mimics the innermost normalization strategy by recursively traversing terms. The auxiliary transformation function DnfR is used to encode the distribution and negation rules. The D rules are default rules that are only applied if none of the E rules apply, as specified by the strategy expression E <+ D . In order to compute the disjunctive normal form of a term, we have to apply the Dnf function to it, as illustrated in the following application of the prop-dnf3 program: < dnf > Dnf ( And ( Impl ( Atom ( \"r\" ), And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" ))) => Or ( And ( Not ( Atom ( \"r\" )), Atom ( \"p\" )), And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" )))","title":"Attempt 2: Functionalization"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#intermezzo-dnf-in-spoofaxeclipse-move-to-tutorial","text":"If you\u2019re going to try to run this example in Spoofax/Eclipse, a few words of caution. First, it\u2019s easiest to just accumulate all of the different test modules as imports in your main language \u201c.str\u201d file. But if you do that, all of the rules will be in the same namespace. So you\u2019re going to want to use different identifiers (say E3 and D3 ) in place of E and D in your prop-dnf3.str file. Also, the concrete syntax has no way to represent the \u201cextra\u201d function symbol Dnf that is used here, so you\u2019ll want to use alternate triggering strategies like make-nf = innermost ( E3 < + D3 ) dnf3 : x - > < make-nf > Dnf ( x ) that wrap the input in Dnf( ... ) themselves. For conjunctive normal form we can create a similar definition, which can now co-exist with the definition of DNF . Indeed, we could then simultaneously rewrite one subterm to DNF and the other to CNF . E : DC ( x ) - > ( Dnf ( x ), Cnf ( x ))","title":"Intermezzo: DNF in Spoofax/Eclipse (move to tutorial?)"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#evaluation","text":"In the solution above, the original rules have been completely intertwined with the Dnf transformation. The rules for negation cannot be reused in the definition of normalization to conjunctive normal form. For each new transformation a new traversal function and new transformation functions have to be defined. Many additional rules had to be added to traverse the term to find the places to apply the rules. In the modular solution we had 5 basic rules and 2 additional rules for DNF and 2 rules for CNF, 9 in total. In the functionalized version we needed 13 rules for each transformation, that is 26 rules in total.","title":"Evaluation"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/","text":"Strategic Rewriting \u00b6 Limitations of Term Rewriting \u00b6 Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The innermost strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances. The usual solution is to encode the strategy in the rewrite rules . But this intertwines the strategy with the rules, and makes the latter unreusable. Programmable Rewriting Strategies \u00b6 In general, there are two problems with the functional approach to encoding the control over the application of rewrite rules, when comparing it to the original term rewriting approach: traversal overhead and loss of separation of rules and strategies. In the first place, the functional encoding incurs a large overhead due to the explicit specification of traversal. In pure term rewriting, the strategy takes care of traversing the term in search of subterms to rewrite. In the functional approach traversal is spelled out in the definition of the function, requiring the specification of many additional rules. A traversal rule needs to be defined for each constructor in the signature and for each transformation. The overhead for transformation systems for real languages can be inferred from the number of constructors for some typical languages: language : constructors Tiger : 65 C : 140 Java : 140 COBOL : 300 - 1200 In the second place, rewrite rules and the strategy that defines their application are completely intertwined. Another advantage of pure term rewriting is the separation of the specification of the rules and the strategy that controls their application. Intertwining these specifications makes it more difficult to understand the specification, since rules cannot be distinguished from the transformation they are part of. Furthermore, intertwining makes it impossible to reuse the rules in a different transformation. Stratego introduces the paradigm of programmable rewriting strategies with generic traversals, a unifying solution in which application of rules can be carefully controlled, while incurring minimal traversal overhead and preserving separation of rules and strategies 1 . The following are the design criteria for strategies in Stratego: Separation of rules and strategy: Basic transformation rules can be defined separately from the strategy that applies them, such that they can be understood independently. Rule selection: A transformation can select the necessary set of rules from a collection (library) of rules. Control: A transformation can exercise complete control over the application of rules. This control may be fine-grained or course-grained depending on the application. No traversal overhead: Transformations can be defined without overhead for the definition of traversals. Reuse of rules: Rules can be reused in different transformations. Reuse of traversal schemas: Traversal schemas can be defined generically and reused in different transformations. Idioms of Strategic Rewriting \u00b6 We will examine the language constructs that Stratego provides for programming with strategies, starting with the low-level actions of building and matching terms. To get a feeling for the purpose of these constructs, we first look at a couple of typical idioms of strategic rewriting. Cascading Transformations \u00b6 The basic idiom of program transformation achieved with term rewriting is that of cascading transformations. Instead of applying a single complex transformation algorithm to a program, a number of small, independent transformations are applied in combination throughout a program or program unit to achieve the desired effect. Although each individual transformation step achieves little, the cumulative effect can be significant, since each transformation feeds on the results of the ones that came before it. One common cascading of transformations is accomplished by exhaustively applying rewrite rules to a subject term. In Stratego the definition of a cascading normalization strategy with respect to rules R1 , \u2026 , Rn can be formalized using the innermost strategy that we saw before: simplify = innermost ( R1 < + ... < + Rn ) The argument strategy of innermost is a selection of rules. By giving different names to rules, we can control the selection used in each transformation. There can be multiple applications of innermost to different sets of rules, such that different transformations can co-exist in the same module without interference. Thus, it is now possible to develop a large library of transformation rules that can be called upon when necessary, without having to compose a rewrite system by cutting and pasting. For example, the following module defines the normalization of proposition formulae to both disjunctive and to conjunctive normal form: module prop-laws imports prop rules DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DN : Not ( Not ( x )) - > x DMA : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) DMO : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) DAOL : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) DAOR : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) DOAL : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) DOAR : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies dnf = innermost ( DefI < + DefE < + DAOL < + DAOR < + DN < + DMA < + DMO ) cnf = innermost ( DefI < + DefE < + DOAL < + DOAR < + DN < + DMA < + DMO ) The rules are named, and for each strategy different selections from the rule set are made. One-pass Traversals \u00b6 Cascading transformations can be defined with other strategies as well, and these strategies need not be exhaustive, but can be simpler one-pass traversals. For example, constant folding of Boolean expressions only requires a simple one-pass bottom-up traversal. This can be achieved using the bottomup strategy according the following scheme: simplify = bottomup ( repeat ( R1 < + ... < + Rn )) The bottomup strategy applies its argument strategy to each subterm in a bottom-to-top traversal. The repeat strategy applies its argument strategy repeatedly to a term. Module prop-eval2 defines the evaluation rules for Boolean expressions and a strategy for applying them using this approach: module prop-eval2 imports libstrategolib prop rules Eval : Not ( True ()) - > False () Eval : Not ( False ()) - > True () Eval : And ( True (), x ) - > x Eval : And ( x , True ()) - > x Eval : And ( False (), x ) - > False () Eval : And ( x , False ()) - > False () Eval : Or ( True (), x ) - > True () Eval : Or ( x , True ()) - > True () Eval : Or ( False (), x ) - > x Eval : Or ( x , False ()) - > x Eval : Impl ( True (), x ) - > x Eval : Impl ( x , True ()) - > True () Eval : Impl ( False (), x ) - > True () Eval : Impl ( x , False ()) - > Not ( x ) Eval : Eq ( False (), x ) - > Not ( x ) Eval : Eq ( x , False ()) - > Not ( x ) Eval : Eq ( True (), x ) - > x Eval : Eq ( x , True ()) - > x strategies main = io-wrap ( eval ) eval = bottomup ( repeat ( Eval )) The strategy eval applies these rules in a bottom-up traversal over a term, using the bottomup(s) strategy. At each sub-term, the rules are applied repeatedly until no more rule applies using the repeat(s) strategy. This is sufficient for the Eval rules, since the rules never construct a term with subterms that can be rewritten. Another typical example of the use of one-pass traversals is desugaring, that is rewriting language constructs to more basic language constructs. Simple desugarings can usually be expressed using a single top-to-bottom traversal according to the scheme simplify = topdown ( try ( R1 < + ... < + Rn )) The topdown strategy applies its argument strategy to a term and then traverses the resulting term. The try strategy tries to apply its argument strategy once to a term. Module prop-desugar defines a number of desugaring rules for Boolean expressions, defining propositional operators in terms of others. For example, rule DefN defines Not in terms of Impl , and rule DefI defines Impl in terms of Or and Not . So not all rules should be applied in the same transformation or non-termination would result. module prop-desugar imports prop libstrategolib rules DefN : Not ( x ) - > Impl ( x , False ()) DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DefO1 : Or ( x , y ) - > Impl ( Not ( x ), y ) DefO2 : Or ( x , y ) - > Not ( And ( Not ( x ), Not ( y ))) DefA1 : And ( x , y ) - > Not ( Or ( Not ( x ), Not ( y ))) DefA2 : And ( x , y ) - > Not ( Impl ( x , Not ( y ))) IDefI : Or ( Not ( x ), y ) - > Impl ( x , y ) IDefE : And ( Impl ( x , y ), Impl ( y , x )) - > Eq ( x , y ) strategies desugar = topdown ( try ( DefI < + DefE )) impl-nf = topdown ( repeat ( DefN < + DefA2 < + DefO1 < + DefE )) main-desugar = io-wrap ( desugar ) main-inf = io-wrap ( impl-nf ) The strategies desugar and impl-nf define two different desugaring transformation based on these rules. The desugar strategy gets rid of the implication and equivalence operators, while the impl-nf strategy reduces an expression to implicative normal-form, a format in which only implication ( Impl ) and False() are used. A final example of a one-pass traversal is the downup strategy, which applies its argument transformation during a traversal on the way down, and again on the way up: simplify = downup ( repeat ( R1 < + ... < + Rn )) An application of this strategy is a more efficient implementation of constant folding for Boolean expressions: eval = downup ( repeat ( Eval )) This strategy reduces terms such as And ( ... big expression ... , False ()) in one step (to False() in this case), while the bottomup strategy defined above would first evaluate the big expression. Staged Transformations \u00b6 Cascading transformations apply a number of rules one after another to an entire tree. But in some cases this is not appropriate. For instance, two transformations may be inverses of one another, so that repeatedly applying one and then the other would lead to non-termination. To remedy this difficulty, Stratego supports the idiom of staged transformation. In staged computation, transformations are not applied to a subject term all at once, but rather in stages. In each stage, only rules from some particular subset of the entire set of available rules are applied. In the TAMPR program transformation system this idiom is called sequence of normal forms, since a program tree is transformed in a sequence of steps, each of which performs a normalization with respect to a specified set of rules. In Stratego this idiom can be expressed directly according to the following scheme: strategies simplify = innermost ( A1 < + ... < + Ak ) ; innermost ( B1 < + ... < + Bl ) ; ... ; innermost ( C1 < + ... < + Cm ) Local Transformations \u00b6 In conventional program optimization, transformations are applied throughout a program. In optimizing imperative programs, for example, complex transformations are applied to entire programs. In GHC-style compilation-by-transformation, small transformation steps are applied throughout programs. Another style of transformation is a mixture of these ideas. Instead of applying a complex transformation algorithm to a program we use staged, cascading transformations to accumulate small transformation steps for large effect. However, instead of applying transformations throughout the subject program, we often wish to apply them locally, i.e., only to selected parts of the subject program. This allows us to use transformations rules that would not be beneficial if applied everywhere. One example of a strategy which achieves such a transformation is strategies transformation = alltd ( trigger-transformation ; innermost ( A1 < + ... < + An ) ) The strategy alltd(s) descends into a term until a subterm is encountered for which the transformation s succeeds. In this case the strategy trigger-transformation recognizes a program fragment that should be transformed. Thus, cascading transformations are applied locally to terms for which the transformation is triggered. Of course more sophisticated strategies can be used for finding application locations, as well as for applying the rules locally. Nevertheless, the key observation underlying this idiom remains: Because the transformations to be applied are local, special knowledge about the subject program at the point of application can be used. This allows the application of rules that would not be otherwise applicable. References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"Strategic Rewriting"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#strategic-rewriting","text":"","title":"Strategic Rewriting"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#limitations-of-term-rewriting","text":"Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The innermost strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances. The usual solution is to encode the strategy in the rewrite rules . But this intertwines the strategy with the rules, and makes the latter unreusable.","title":"Limitations of Term Rewriting"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#programmable-rewriting-strategies","text":"In general, there are two problems with the functional approach to encoding the control over the application of rewrite rules, when comparing it to the original term rewriting approach: traversal overhead and loss of separation of rules and strategies. In the first place, the functional encoding incurs a large overhead due to the explicit specification of traversal. In pure term rewriting, the strategy takes care of traversing the term in search of subterms to rewrite. In the functional approach traversal is spelled out in the definition of the function, requiring the specification of many additional rules. A traversal rule needs to be defined for each constructor in the signature and for each transformation. The overhead for transformation systems for real languages can be inferred from the number of constructors for some typical languages: language : constructors Tiger : 65 C : 140 Java : 140 COBOL : 300 - 1200 In the second place, rewrite rules and the strategy that defines their application are completely intertwined. Another advantage of pure term rewriting is the separation of the specification of the rules and the strategy that controls their application. Intertwining these specifications makes it more difficult to understand the specification, since rules cannot be distinguished from the transformation they are part of. Furthermore, intertwining makes it impossible to reuse the rules in a different transformation. Stratego introduces the paradigm of programmable rewriting strategies with generic traversals, a unifying solution in which application of rules can be carefully controlled, while incurring minimal traversal overhead and preserving separation of rules and strategies 1 . The following are the design criteria for strategies in Stratego: Separation of rules and strategy: Basic transformation rules can be defined separately from the strategy that applies them, such that they can be understood independently. Rule selection: A transformation can select the necessary set of rules from a collection (library) of rules. Control: A transformation can exercise complete control over the application of rules. This control may be fine-grained or course-grained depending on the application. No traversal overhead: Transformations can be defined without overhead for the definition of traversals. Reuse of rules: Rules can be reused in different transformations. Reuse of traversal schemas: Traversal schemas can be defined generically and reused in different transformations.","title":"Programmable Rewriting Strategies"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#idioms-of-strategic-rewriting","text":"We will examine the language constructs that Stratego provides for programming with strategies, starting with the low-level actions of building and matching terms. To get a feeling for the purpose of these constructs, we first look at a couple of typical idioms of strategic rewriting.","title":"Idioms of Strategic Rewriting"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#cascading-transformations","text":"The basic idiom of program transformation achieved with term rewriting is that of cascading transformations. Instead of applying a single complex transformation algorithm to a program, a number of small, independent transformations are applied in combination throughout a program or program unit to achieve the desired effect. Although each individual transformation step achieves little, the cumulative effect can be significant, since each transformation feeds on the results of the ones that came before it. One common cascading of transformations is accomplished by exhaustively applying rewrite rules to a subject term. In Stratego the definition of a cascading normalization strategy with respect to rules R1 , \u2026 , Rn can be formalized using the innermost strategy that we saw before: simplify = innermost ( R1 < + ... < + Rn ) The argument strategy of innermost is a selection of rules. By giving different names to rules, we can control the selection used in each transformation. There can be multiple applications of innermost to different sets of rules, such that different transformations can co-exist in the same module without interference. Thus, it is now possible to develop a large library of transformation rules that can be called upon when necessary, without having to compose a rewrite system by cutting and pasting. For example, the following module defines the normalization of proposition formulae to both disjunctive and to conjunctive normal form: module prop-laws imports prop rules DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DN : Not ( Not ( x )) - > x DMA : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) DMO : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) DAOL : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) DAOR : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) DOAL : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) DOAR : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) strategies dnf = innermost ( DefI < + DefE < + DAOL < + DAOR < + DN < + DMA < + DMO ) cnf = innermost ( DefI < + DefE < + DOAL < + DOAR < + DN < + DMA < + DMO ) The rules are named, and for each strategy different selections from the rule set are made.","title":"Cascading Transformations"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#one-pass-traversals","text":"Cascading transformations can be defined with other strategies as well, and these strategies need not be exhaustive, but can be simpler one-pass traversals. For example, constant folding of Boolean expressions only requires a simple one-pass bottom-up traversal. This can be achieved using the bottomup strategy according the following scheme: simplify = bottomup ( repeat ( R1 < + ... < + Rn )) The bottomup strategy applies its argument strategy to each subterm in a bottom-to-top traversal. The repeat strategy applies its argument strategy repeatedly to a term. Module prop-eval2 defines the evaluation rules for Boolean expressions and a strategy for applying them using this approach: module prop-eval2 imports libstrategolib prop rules Eval : Not ( True ()) - > False () Eval : Not ( False ()) - > True () Eval : And ( True (), x ) - > x Eval : And ( x , True ()) - > x Eval : And ( False (), x ) - > False () Eval : And ( x , False ()) - > False () Eval : Or ( True (), x ) - > True () Eval : Or ( x , True ()) - > True () Eval : Or ( False (), x ) - > x Eval : Or ( x , False ()) - > x Eval : Impl ( True (), x ) - > x Eval : Impl ( x , True ()) - > True () Eval : Impl ( False (), x ) - > True () Eval : Impl ( x , False ()) - > Not ( x ) Eval : Eq ( False (), x ) - > Not ( x ) Eval : Eq ( x , False ()) - > Not ( x ) Eval : Eq ( True (), x ) - > x Eval : Eq ( x , True ()) - > x strategies main = io-wrap ( eval ) eval = bottomup ( repeat ( Eval )) The strategy eval applies these rules in a bottom-up traversal over a term, using the bottomup(s) strategy. At each sub-term, the rules are applied repeatedly until no more rule applies using the repeat(s) strategy. This is sufficient for the Eval rules, since the rules never construct a term with subterms that can be rewritten. Another typical example of the use of one-pass traversals is desugaring, that is rewriting language constructs to more basic language constructs. Simple desugarings can usually be expressed using a single top-to-bottom traversal according to the scheme simplify = topdown ( try ( R1 < + ... < + Rn )) The topdown strategy applies its argument strategy to a term and then traverses the resulting term. The try strategy tries to apply its argument strategy once to a term. Module prop-desugar defines a number of desugaring rules for Boolean expressions, defining propositional operators in terms of others. For example, rule DefN defines Not in terms of Impl , and rule DefI defines Impl in terms of Or and Not . So not all rules should be applied in the same transformation or non-termination would result. module prop-desugar imports prop libstrategolib rules DefN : Not ( x ) - > Impl ( x , False ()) DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DefO1 : Or ( x , y ) - > Impl ( Not ( x ), y ) DefO2 : Or ( x , y ) - > Not ( And ( Not ( x ), Not ( y ))) DefA1 : And ( x , y ) - > Not ( Or ( Not ( x ), Not ( y ))) DefA2 : And ( x , y ) - > Not ( Impl ( x , Not ( y ))) IDefI : Or ( Not ( x ), y ) - > Impl ( x , y ) IDefE : And ( Impl ( x , y ), Impl ( y , x )) - > Eq ( x , y ) strategies desugar = topdown ( try ( DefI < + DefE )) impl-nf = topdown ( repeat ( DefN < + DefA2 < + DefO1 < + DefE )) main-desugar = io-wrap ( desugar ) main-inf = io-wrap ( impl-nf ) The strategies desugar and impl-nf define two different desugaring transformation based on these rules. The desugar strategy gets rid of the implication and equivalence operators, while the impl-nf strategy reduces an expression to implicative normal-form, a format in which only implication ( Impl ) and False() are used. A final example of a one-pass traversal is the downup strategy, which applies its argument transformation during a traversal on the way down, and again on the way up: simplify = downup ( repeat ( R1 < + ... < + Rn )) An application of this strategy is a more efficient implementation of constant folding for Boolean expressions: eval = downup ( repeat ( Eval )) This strategy reduces terms such as And ( ... big expression ... , False ()) in one step (to False() in this case), while the bottomup strategy defined above would first evaluate the big expression.","title":"One-pass Traversals"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#staged-transformations","text":"Cascading transformations apply a number of rules one after another to an entire tree. But in some cases this is not appropriate. For instance, two transformations may be inverses of one another, so that repeatedly applying one and then the other would lead to non-termination. To remedy this difficulty, Stratego supports the idiom of staged transformation. In staged computation, transformations are not applied to a subject term all at once, but rather in stages. In each stage, only rules from some particular subset of the entire set of available rules are applied. In the TAMPR program transformation system this idiom is called sequence of normal forms, since a program tree is transformed in a sequence of steps, each of which performs a normalization with respect to a specified set of rules. In Stratego this idiom can be expressed directly according to the following scheme: strategies simplify = innermost ( A1 < + ... < + Ak ) ; innermost ( B1 < + ... < + Bl ) ; ... ; innermost ( C1 < + ... < + Cm )","title":"Staged Transformations"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#local-transformations","text":"In conventional program optimization, transformations are applied throughout a program. In optimizing imperative programs, for example, complex transformations are applied to entire programs. In GHC-style compilation-by-transformation, small transformation steps are applied throughout programs. Another style of transformation is a mixture of these ideas. Instead of applying a complex transformation algorithm to a program we use staged, cascading transformations to accumulate small transformation steps for large effect. However, instead of applying transformations throughout the subject program, we often wish to apply them locally, i.e., only to selected parts of the subject program. This allows us to use transformations rules that would not be beneficial if applied everywhere. One example of a strategy which achieves such a transformation is strategies transformation = alltd ( trigger-transformation ; innermost ( A1 < + ... < + An ) ) The strategy alltd(s) descends into a term until a subterm is encountered for which the transformation s succeeds. In this case the strategy trigger-transformation recognizes a program fragment that should be transformed. Thus, cascading transformations are applied locally to terms for which the transformation is triggered. Of course more sophisticated strategies can be used for finding application locations, as well as for applying the rules locally. Nevertheless, the key observation underlying this idiom remains: Because the transformations to be applied are local, special knowledge about the subject program at the point of application can be used. This allows the application of rules that would not be otherwise applicable.","title":"Local Transformations"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9","title":"References"},{"location":"background/stratego/strategic-rewriting/term-rewriting/","text":"Term Rewriting \u00b6 In term rewriting a term is transformed by repeated application of rewrite rules. To see how this works we take as example the language of propositional formulae, also known as Boolean expressions: module prop signature sorts Prop constructors False : Prop True : Prop Atom : String - > Prop Not : Prop - > Prop And : Prop * Prop - > Prop Or : Prop * Prop - > Prop Impl : Prop * Prop - > Prop Eq : Prop * Prop - > Prop Given this signature we can write terms such as And(Impl(True(),False()),False()) , and And(Atom(\"p\"),False())) . Atoms are also known as proposition letters; they are the variables in propositional formulae. That is, the truth value of an atom should be provided in order to fully evaluate an expression. Here we will evaluate expressions as far as possible, a transformation also known as constant folding. We will do this using rewrite rules that define how to simplify a single operator application. Term Patterns \u00b6 A term pattern is a term with meta variables, which are identifiers that are not declared as (nullary) constructors. For example, And(x, True()) is a term pattern with variable x . Variables in term patterns are sometimes called meta variables, to distinguish them from variables in the source language being processed. For example, while atoms in the proposition expressions are variables from the point of view of the language, they are not variables from the perspective of a Stratego program. A term pattern p matches with a term t , if there is a substitution that replaces the variables in p such that it becomes equal to t . For example, the pattern And(x, True()) matches the term And(Impl(True(),Atom(\"p\")),True()) because replacing the variable x in the pattern by Impl(True(),Atom(\"p\")) makes the pattern equal to the term. Note that And(Atom(\"x\"),True()) does not match the term And(Impl(True(),Atom(\"p\")),True()) , since the subterms Atom(\"x\") and Impl(True(),Atom(\"p\")) do not match. Rewrite Rules \u00b6 An unconditional rewrite rule has the form L : p1 -> p2 , where L is the name of the rule, p1 is the left-hand side and p2 the right-hand side term pattern. A rewrite rule L : p1 -> p2 applies to a term t when the pattern p1 matches t . The result is the instantiation of p2 with the variable bindings found during matching. For example, the rewrite rule E : Eq ( x , False ()) - > Not ( x ) rewrites the term Eq(Atom(\"q\"),False()) to Not(Atom(\"q\")) , since the variable x is bound to the subterm Atom(\"q\") . Evaluation Rules \u00b6 Now we can create similar evaluation rules for all constructors of sort Prop : module prop-eval-rules imports prop rules E : Not ( True ()) - > False () E : Not ( False ()) - > True () E : And ( True (), x ) - > x E : And ( x , True ()) - > x E : And ( False (), x ) - > False () E : And ( x , False ()) - > False () E : Or ( True (), x ) - > True () E : Or ( x , True ()) - > True () E : Or ( False (), x ) - > x E : Or ( x , False ()) - > x E : Impl ( True (), x ) - > x E : Impl ( x , True ()) - > True () E : Impl ( False (), x ) - > True () E : Impl ( x , False ()) - > Not ( x ) E : Eq ( False (), x ) - > Not ( x ) E : Eq ( x , False ()) - > Not ( x ) E : Eq ( True (), x ) - > x E : Eq ( x , True ()) - > x strategies eval = innermost ( E ) Note that all rules have the same name, which is allowed in Stratego. The module defines the eval strategy to apply innermost(E) to the input term. The innermost strategy from the library exhaustively applies its argument transformation to the term it is applied to, starting with inner subterms. As an aside, we have now seen Stratego modules with rules and strategies sections. It is worth noting that a module can have any number of sections of either type, and that there is no actual semantic difference between the two section headings. In fact, either rewrite rules and/or strategy definitions can occur in either kind of section. Nevertheless, it often helps with making your transformations clearer to generally segregate rules and strategy definitions, and so both headings are allowed so you can punctuate your Stratego modules with them to improve readability. The next commands apply the eval strategy to various terms. < eval > And ( Impl ( True (), And ( False , True )), True ) => False < eval > And ( Impl ( True , And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" )) => And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" )) Adding Rules to a Rewrite System \u00b6 Next we extend the rewrite rules above to rewrite a Boolean expression to disjunctive normal form. A Boolean expression is in disjunctive normal form if it conforms to the following signature: signature sorts Or And NAtom Atom constructors Or : Or * Or - > Or : And - > Or And : And * And - > And : NAtom - > And Not : Atom - > NAtom : Atom - > NAtom Atom : String - > Atom We use this signature only to describe what a disjunctive normal form is, not in an the actual Stratego program. This is not necessary, since terms conforming to the DNF signature are also Prop terms as defined before. For example, the disjunctive normal form of And ( Impl ( Atom ( \"r\" ), And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" )) is Or ( And ( Not ( Atom ( \"r\" )), Atom ( \"p\" )), And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" ))) Module prop-dnf-rules extends the rules defined in prop-eval-rules with rules to achieve disjunctive normal forms: module prop-dnf-rules imports prop-eval-rules rules E : Impl ( x , y ) - > Or ( Not ( x ), y ) E : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) E : Not ( Not ( x )) - > x E : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) E : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) E : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) E : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) strategies dnf = innermost ( E ) The first two rules rewrite implication ( Impl ) and equivalence ( Eq ) to combinations of And , Or , and Not . The third rule removes double negation. The fifth and sixth rules implement the well known DeMorgan laws. The last two rules define distribution of conjunction over disjunction.","title":"Term Rewriting"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#term-rewriting","text":"In term rewriting a term is transformed by repeated application of rewrite rules. To see how this works we take as example the language of propositional formulae, also known as Boolean expressions: module prop signature sorts Prop constructors False : Prop True : Prop Atom : String - > Prop Not : Prop - > Prop And : Prop * Prop - > Prop Or : Prop * Prop - > Prop Impl : Prop * Prop - > Prop Eq : Prop * Prop - > Prop Given this signature we can write terms such as And(Impl(True(),False()),False()) , and And(Atom(\"p\"),False())) . Atoms are also known as proposition letters; they are the variables in propositional formulae. That is, the truth value of an atom should be provided in order to fully evaluate an expression. Here we will evaluate expressions as far as possible, a transformation also known as constant folding. We will do this using rewrite rules that define how to simplify a single operator application.","title":"Term Rewriting"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#term-patterns","text":"A term pattern is a term with meta variables, which are identifiers that are not declared as (nullary) constructors. For example, And(x, True()) is a term pattern with variable x . Variables in term patterns are sometimes called meta variables, to distinguish them from variables in the source language being processed. For example, while atoms in the proposition expressions are variables from the point of view of the language, they are not variables from the perspective of a Stratego program. A term pattern p matches with a term t , if there is a substitution that replaces the variables in p such that it becomes equal to t . For example, the pattern And(x, True()) matches the term And(Impl(True(),Atom(\"p\")),True()) because replacing the variable x in the pattern by Impl(True(),Atom(\"p\")) makes the pattern equal to the term. Note that And(Atom(\"x\"),True()) does not match the term And(Impl(True(),Atom(\"p\")),True()) , since the subterms Atom(\"x\") and Impl(True(),Atom(\"p\")) do not match.","title":"Term Patterns"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#rewrite-rules","text":"An unconditional rewrite rule has the form L : p1 -> p2 , where L is the name of the rule, p1 is the left-hand side and p2 the right-hand side term pattern. A rewrite rule L : p1 -> p2 applies to a term t when the pattern p1 matches t . The result is the instantiation of p2 with the variable bindings found during matching. For example, the rewrite rule E : Eq ( x , False ()) - > Not ( x ) rewrites the term Eq(Atom(\"q\"),False()) to Not(Atom(\"q\")) , since the variable x is bound to the subterm Atom(\"q\") .","title":"Rewrite Rules"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#evaluation-rules","text":"Now we can create similar evaluation rules for all constructors of sort Prop : module prop-eval-rules imports prop rules E : Not ( True ()) - > False () E : Not ( False ()) - > True () E : And ( True (), x ) - > x E : And ( x , True ()) - > x E : And ( False (), x ) - > False () E : And ( x , False ()) - > False () E : Or ( True (), x ) - > True () E : Or ( x , True ()) - > True () E : Or ( False (), x ) - > x E : Or ( x , False ()) - > x E : Impl ( True (), x ) - > x E : Impl ( x , True ()) - > True () E : Impl ( False (), x ) - > True () E : Impl ( x , False ()) - > Not ( x ) E : Eq ( False (), x ) - > Not ( x ) E : Eq ( x , False ()) - > Not ( x ) E : Eq ( True (), x ) - > x E : Eq ( x , True ()) - > x strategies eval = innermost ( E ) Note that all rules have the same name, which is allowed in Stratego. The module defines the eval strategy to apply innermost(E) to the input term. The innermost strategy from the library exhaustively applies its argument transformation to the term it is applied to, starting with inner subterms. As an aside, we have now seen Stratego modules with rules and strategies sections. It is worth noting that a module can have any number of sections of either type, and that there is no actual semantic difference between the two section headings. In fact, either rewrite rules and/or strategy definitions can occur in either kind of section. Nevertheless, it often helps with making your transformations clearer to generally segregate rules and strategy definitions, and so both headings are allowed so you can punctuate your Stratego modules with them to improve readability. The next commands apply the eval strategy to various terms. < eval > And ( Impl ( True (), And ( False , True )), True ) => False < eval > And ( Impl ( True , And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" )) => And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" ))","title":"Evaluation Rules"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#adding-rules-to-a-rewrite-system","text":"Next we extend the rewrite rules above to rewrite a Boolean expression to disjunctive normal form. A Boolean expression is in disjunctive normal form if it conforms to the following signature: signature sorts Or And NAtom Atom constructors Or : Or * Or - > Or : And - > Or And : And * And - > And : NAtom - > And Not : Atom - > NAtom : Atom - > NAtom Atom : String - > Atom We use this signature only to describe what a disjunctive normal form is, not in an the actual Stratego program. This is not necessary, since terms conforming to the DNF signature are also Prop terms as defined before. For example, the disjunctive normal form of And ( Impl ( Atom ( \"r\" ), And ( Atom ( \"p\" ), Atom ( \"q\" ))), Atom ( \"p\" )) is Or ( And ( Not ( Atom ( \"r\" )), Atom ( \"p\" )), And ( And ( Atom ( \"p\" ), Atom ( \"q\" )), Atom ( \"p\" ))) Module prop-dnf-rules extends the rules defined in prop-eval-rules with rules to achieve disjunctive normal forms: module prop-dnf-rules imports prop-eval-rules rules E : Impl ( x , y ) - > Or ( Not ( x ), y ) E : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) E : Not ( Not ( x )) - > x E : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) E : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) E : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) E : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) strategies dnf = innermost ( E ) The first two rules rewrite implication ( Impl ) and equivalence ( Eq ) to combinations of And , Or , and Not . The third rule removes double negation. The fifth and sixth rules implement the well known DeMorgan laws. The last two rules define distribution of conjunction over disjunction.","title":"Adding Rules to a Rewrite System"},{"location":"background/stratego/strategic-rewriting/traversal-with-rules/","text":"Factoring out Traversal \u00b6 Continuing the inspection of limitations of term rewriting , we explore how term traversal can be factored out into separate rules. Attempt 3: Using Rules for Traversal \u00b6 We saw the following definition of the map strategy, which applies a strategy to each element of a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] The definition uses explicit recursive calls to the strategy in the right-hand side of the second rule. What map does is to traverse the list in order to apply the argument strategy to all elements. We can use the same technique to other term structures as well. We will explore the definition of traversals using the propositional formulae, where we introduced the following rewrite rules: module prop-rules imports libstrategolib prop rules DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DN : Not ( Not ( x )) - > x DMA : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) DMO : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) DAOL : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) DAOR : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) DOAL : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) DOAR : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) Above we saw how a functional style of rewriting could be encoded using extra constructors. In Stratego we can achieve a similar approach by using rule names, instead of extra constructors. Thus, one way to achieve normalization to disjunctive normal form, is the use of an explicitly programmed traversal, implemented using recursive rules, similarly to the map example above: module prop-dnf4 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnf : True () - > True () dnf : False () - > False () dnf : Atom ( x ) - > Atom ( x ) dnf : Not ( x ) - > < dnfred > Not (< dnf > x ) dnf : And ( x , y ) - > < dnfred > And (< dnf > x , < dnf > y ) dnf : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnf : Impl ( x , y ) - > < dnfred > Impl (< dnf > x , < dnf > y ) dnf : Eq ( x , y ) - > < dnfred > Eq (< dnf > x , < dnf > y ) strategies dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) The dnf rules recursively apply themselves to the direct subterms and then apply dnfred to actually apply the rewrite rules. We can reduce this program by abstracting over the base cases. Since there is no traversal into True , False , and Atom s, these rules can be be left out. module prop-dnf5 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnft : Not ( x ) - > < dnfred > Not (< dnf > x ) dnft : And ( x , y ) - > < dnfred > And (< dnf > x , < dnf > y ) dnft : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnft : Impl ( x , y ) - > < dnfred > Impl (< dnf > x , < dnf > y ) dnft : Eq ( x , y ) - > < dnfred > Eq (< dnf > x , < dnf > y ) strategies dnf = try ( dnft ) dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) The dnf strategy is now defined in terms of the dnft rules, which implement traversal over the constructors. By using try(dnft) , terms for which no traversal rule has been specified are not transformed. We can further simplify the definition by observing that the application of dnfred does not necessarily have to take place in the right-hand side of the traversal rules. module prop-dnf6 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnft : Not ( x ) - > Not (< dnf > x ) dnft : And ( x , y ) - > And (< dnf > x , < dnf > y ) dnft : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnft : Impl ( x , y ) - > Impl (< dnf > x , < dnf > y ) dnft : Eq ( x , y ) - > Eq (< dnf > x , < dnf > y ) strategies dnf = try ( dnft ); dnfred dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) In this program dnf first calls dnft to transform the subterms of the subject term, and then calls dnfred to apply the transformation rules (and possibly a recursive invocation of dnf ). The program above has two problems. First, the traversal behavior is mostly uniform, so we would like to specify that more concisely. We will address that concern below. Second, the traversal is not reusable, for example, to define a conjunctive normal form transformation. This last concern can be addressed by factoring out the recursive call to dnf and making it a parameter of the traversal rules. module prop-dnf7 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies dnf = try ( proptr ( dnf )); dnfred dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) cnf = try ( proptr ( cnf )); cnfred cnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf ) Now the traversal rules are reusable and used in two different transformations, by instantiation with a call to the particular strategy in which they are used ( dnf or cnf ). But we can do better, and also make the composition of this strategy reusable. module prop-dnf8 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( dnfred ) dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) cnf = propbu ( cnfred ) cnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf ) That is, the propbu(s) strategy defines a complete bottom-up traversal over proposition terms, applying the strategy s to a term after transforming its subterms. The strategy is completely independent of the dnf and cnf transformations, which instantiate the strategy using the dnfred and cnfred strategies. Come to think of it, dnfred and cnfred are somewhat useless now and can be inlined directly in the instantiation of the propbu(s) strategy: module prop-dnf9 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf )) Now we have defined a transformation independent traversal strategy that is specific for proposition terms.","title":"Factoring out Traversal"},{"location":"background/stratego/strategic-rewriting/traversal-with-rules/#factoring-out-traversal","text":"Continuing the inspection of limitations of term rewriting , we explore how term traversal can be factored out into separate rules.","title":"Factoring out Traversal"},{"location":"background/stratego/strategic-rewriting/traversal-with-rules/#attempt-3-using-rules-for-traversal","text":"We saw the following definition of the map strategy, which applies a strategy to each element of a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] The definition uses explicit recursive calls to the strategy in the right-hand side of the second rule. What map does is to traverse the list in order to apply the argument strategy to all elements. We can use the same technique to other term structures as well. We will explore the definition of traversals using the propositional formulae, where we introduced the following rewrite rules: module prop-rules imports libstrategolib prop rules DefI : Impl ( x , y ) - > Or ( Not ( x ), y ) DefE : Eq ( x , y ) - > And ( Impl ( x , y ), Impl ( y , x )) DN : Not ( Not ( x )) - > x DMA : Not ( And ( x , y )) - > Or ( Not ( x ), Not ( y )) DMO : Not ( Or ( x , y )) - > And ( Not ( x ), Not ( y )) DAOL : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) DAOR : And ( z , Or ( x , y )) - > Or ( And ( z , x ), And ( z , y )) DOAL : Or ( And ( x , y ), z ) - > And ( Or ( x , z ), Or ( y , z )) DOAR : Or ( z , And ( x , y )) - > And ( Or ( z , x ), Or ( z , y )) Above we saw how a functional style of rewriting could be encoded using extra constructors. In Stratego we can achieve a similar approach by using rule names, instead of extra constructors. Thus, one way to achieve normalization to disjunctive normal form, is the use of an explicitly programmed traversal, implemented using recursive rules, similarly to the map example above: module prop-dnf4 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnf : True () - > True () dnf : False () - > False () dnf : Atom ( x ) - > Atom ( x ) dnf : Not ( x ) - > < dnfred > Not (< dnf > x ) dnf : And ( x , y ) - > < dnfred > And (< dnf > x , < dnf > y ) dnf : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnf : Impl ( x , y ) - > < dnfred > Impl (< dnf > x , < dnf > y ) dnf : Eq ( x , y ) - > < dnfred > Eq (< dnf > x , < dnf > y ) strategies dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) The dnf rules recursively apply themselves to the direct subterms and then apply dnfred to actually apply the rewrite rules. We can reduce this program by abstracting over the base cases. Since there is no traversal into True , False , and Atom s, these rules can be be left out. module prop-dnf5 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnft : Not ( x ) - > < dnfred > Not (< dnf > x ) dnft : And ( x , y ) - > < dnfred > And (< dnf > x , < dnf > y ) dnft : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnft : Impl ( x , y ) - > < dnfred > Impl (< dnf > x , < dnf > y ) dnft : Eq ( x , y ) - > < dnfred > Eq (< dnf > x , < dnf > y ) strategies dnf = try ( dnft ) dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) The dnf strategy is now defined in terms of the dnft rules, which implement traversal over the constructors. By using try(dnft) , terms for which no traversal rule has been specified are not transformed. We can further simplify the definition by observing that the application of dnfred does not necessarily have to take place in the right-hand side of the traversal rules. module prop-dnf6 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules dnft : Not ( x ) - > Not (< dnf > x ) dnft : And ( x , y ) - > And (< dnf > x , < dnf > y ) dnft : Or ( x , y ) - > Or (< dnf > x , < dnf > y ) dnft : Impl ( x , y ) - > Impl (< dnf > x , < dnf > y ) dnft : Eq ( x , y ) - > Eq (< dnf > x , < dnf > y ) strategies dnf = try ( dnft ); dnfred dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) In this program dnf first calls dnft to transform the subterms of the subject term, and then calls dnfred to apply the transformation rules (and possibly a recursive invocation of dnf ). The program above has two problems. First, the traversal behavior is mostly uniform, so we would like to specify that more concisely. We will address that concern below. Second, the traversal is not reusable, for example, to define a conjunctive normal form transformation. This last concern can be addressed by factoring out the recursive call to dnf and making it a parameter of the traversal rules. module prop-dnf7 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies dnf = try ( proptr ( dnf )); dnfred dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) cnf = try ( proptr ( cnf )); cnfred cnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf ) Now the traversal rules are reusable and used in two different transformations, by instantiation with a call to the particular strategy in which they are used ( dnf or cnf ). But we can do better, and also make the composition of this strategy reusable. module prop-dnf8 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( dnfred ) dnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf ) cnf = propbu ( cnfred ) cnfred = try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf ) That is, the propbu(s) strategy defines a complete bottom-up traversal over proposition terms, applying the strategy s to a term after transforming its subterms. The strategy is completely independent of the dnf and cnf transformations, which instantiate the strategy using the dnfred and cnfred strategies. Come to think of it, dnfred and cnfred are somewhat useless now and can be inlined directly in the instantiation of the propbu(s) strategy: module prop-dnf9 imports libstrategolib prop-rules strategies main = io-wrap ( dnf ) rules proptr ( s ) : Not ( x ) - > Not (< s > x ) proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) proptr ( s ) : Or ( x , y ) - > Or (< s > x , < s > y ) proptr ( s ) : Impl ( x , y ) - > Impl (< s > x , < s > y ) proptr ( s ) : Eq ( x , y ) - > Eq (< s > x , < s > y ) strategies propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf )) Now we have defined a transformation independent traversal strategy that is specific for proposition terms.","title":"Attempt 3: Using Rules for Traversal"},{"location":"background/stratego/strategy-combinators/sequential/","text":"Sequential Combinators \u00b6 Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined 1 . Thus, Stratego consists of a core language 2 and a 'sugar' language defined by reduction to the core language. Identity and Failure \u00b6 The most basic operations in Stratego are id and fail . The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects. Sequential Composition \u00b6 The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails. Sequential composition is associative. Identity is a left and right unit for sequential composition; since id always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since fail always fails the next strategy will never be reached. This leads to the following equations: ( s1 ; s2 ) ; s3 = s1 ; ( s2 ; s3 ) id ; s = s s ; id = s fail ; s = fail However, not for all strategies s we have that failure is a right zero for sequential composition: s ; fail = fail // is not a law Although the composition s; fail will always fail, the execution of s may have side effects that are not performed by fail . For example, consider printing a term in s . As an example of the use of sequential composition consider the following rewrite rules. A : P ( Z (), x ) - > x B : P ( S ( x ), y ) - > P ( x , S ( y )) The following applications shows the effect of first applying B and then A : < B > ! P ( S ( Z ()), Z ()) => P ( S ( Z ), Z ) < A > P ( Z , S ( Z )) => S ( Z ) Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019: < B ; A > ! P ( S ( Z ()), Z ()) => S ( Z ) The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first: < B ; B > ! P ( S ( Z ()), Z ()) // fails Left Choice \u00b6 Choosing between rules to apply is achieved using one of several choice combinators, all of which are based on the guarded choice combinator. The common approach is that failure to apply one strategy leads to backtracking to an alternative strategy. The left choice or deterministic choice s1 <+ s2 tries to apply s1 and s2 in that order. That is, it first tries to apply s1 , and if that succeeds the choice succeeds. However, if the application of s1 fails, s2 is applied to the original term. Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless. ( s1 < + s2 ) < + s3 = s1 < + ( s2 < + s3 ) id < + s = id fail < + s = s s < + fail = s However, identity is not a right zero for left choice. That is, not for all strategies s we have that s < + id = s // is not a law The expression s <+ id always succeeds, even (especially) in the case that s fails, in which case the right-hand side of the equation fails of course. Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property ( s1 < + s2 ); s3 = ( s1 ; s3 ) < + ( s2 ; s3 ) // is not a law does not hold for all s1 , s2 , and s3 . The difference is illustrated by the following applications: <( B < + id ); B > P ( S ( Z ), Z ) // fails <( B ; B ) < + ( id ; B )> P ( S ( Z ()), Z ()) => P ( Z , S ( Z )) In the application of (B <+ id); B , the first application of B succeeds after which the choice is committed. The subsequent application of B then fails. This is equivalent to first applying (B <+ id) and then applying B to the result. The application of (B; B) <+ (id; B) , however, is successful; the application of B; B fails, after which the choice backtracks to id; B , which succeeds. Choosing between Transformations. \u00b6 The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules: PlusAssoc : Plus ( Plus ( e1 , e2 ), e3 ) - > Plus ( e1 , Plus ( e2 , e3 )) PlusZero : Plus ( Int ( \"0\" ), e ) - > e These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into PlusAssoc <+ PlusZero creates a strategy that transforms terms matching both rules as illustrated by the following applications: < PlusAssoc > Plus ( Int ( \"0\" ), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Int ( \"0\" ), Int ( \"3\" )) => Int ( \"3\" ) < PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) => Plus ( Var ( \"x\" ), Plus ( Int ( \"42\" ), Int ( \"3\" ))) Ordering Overlapping Rules. \u00b6 When two rules or strategies are mutually exlusive the order of applying them does not matter. In cases where strategies are overlapping, that is, succeed for the same terms, the order becomes crucial to determining the semantics of the composition. For example, consider the following rewrite rules reducing applications of Mem: Mem1 : Mem ( x ,[]) - > False () Mem2 : Mem ( x ,[ x | xs ]) - > True () Mem3 : Mem ( x ,[ y | ys ]) - > Mem ( x , ys ) Rules Mem2 and Mem3 have overlapping left-hand sides. Rule Mem2 only applies if the first argument is equal to the head element of the list in the second argument. Rule Mem3 applies always if the list in the second argument is non-empty. < Mem2 > Mem ( 1 , [ 1 , 2 , 3 ]) => True () < Mem3 > Mem ( 1 , [ 1 , 2 , 3 ]) => Mem ( 1 ,[ 2 , 3 ]) In such situations, depending on the order of the rules, different results are produced. (The rules form a non-confluent rewriting system.) By ordering the rules as Mem2 <+ Mem3 , rule Mem2 is tried before Mem3 , and we have a deterministic transformation strategy. Try \u00b6 A useful application of <+ in combination with id is the reflexive closure of a strategy s: try ( s ) = s < + id The user-defined strategy combinator try tries to apply its argument strategy s , but if that fails, just succeeds using id . Guarded Left Choice \u00b6 Sometimes it is not desirable to backtrack to the alternative specified in a choice. Rather, after passing a guard, the choice should be committed. This can be expressed using the guarded left choice operator s1 < s2 + s3 . If s1 succeeds s2 is applied, else s3 is applied. If s2 fails, the complete expression fails; no backtracking to s3 takes place. Properties. This combinator is a generalization of the left choice combinator <+ . s1 < + s2 = s1 < id + s2 The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard: id < s2 + s3 = s2 fail < s2 + s3 = s3 If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch. s1 < s2 + fail = s1 ; s2 Guarded choice is not associative: ( s1 < s2 + s3 ) < s4 + s5 = s1 < s2 + ( s3 < s4 + s5 ) // not a law To see why consider the possible traces of these expressions. For example, when s1 and s2 succeed subsequently, the left-hand side expression calls s4 , while the right-hand side expression does not. However, sequential composition distributes over guarded choice from left and right: ( s1 < s2 + s3 ); s4 = s1 < ( s2 ; s4 ) + ( s3 ; s4 ) s0 ; ( s1 < s2 + s3 ) = ( s0 ; s1 ) < s2 + s3 Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation not(s) of a strategy s , succeeds if s fails, and fails when it succeeds: not ( s ) = s < fail + id Since failure discards the effect of a (successful) transformation, this has the effect of testing whether s succeeds. So we have the following laws for not: not ( id ) = fail not ( fail ) = id However, side effects performed by s are not undone, of course. Therefore, the following equation does not hold: not ( not ( s )) = s // not a law Another example of the use of guarded choice is the restore-always combinator: restore-always ( s , r ) = s < r + ( r ; fail ) It applies a \u2018restore\u2019 strategy r after applying a strategy s , even if s fails, and preserves the success/failure behavior of s . Since fail discards the transformation effect of r , this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying s . If-then-else \u00b6 The guarded choice combinator is similar to the traditional if-then-else construct of programming languages. The difference is that the \u2018then\u2019 branch applies to the result of the application of the condition. Stratego\u2019s if s1 then s2 else s3 end construct is more like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but it\u2019s transformation effect is undone. However, the condition strategy s1 is still applied to the current term. The if s1 then s2 end strategy is similar; if the condition fails, the strategy succeeds. The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator: if s1 then s2 else s3 end ==> // transforms to where ( s1 ) < s2 + s3 The strategy where(s) succeeds if s succeeds, but returns the original subject term. The implementation of the where combinator is discussed in the section on matching and building terms . The following laws show that the branches are selected by success or failure of the condition: if id then s2 else s3 end = s2 if fail then s2 else s3 end = s3 The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch: if s1 then s2 end = where ( s1 ) < s2 + id Examples. The inclusive or or(s1, s2) succeeds if one of the strategies s1 or s2 succeeds, but guarantees that both are applied, in the order s1 first, then s2 : or ( s1 , s2 ) = if s1 then try ( where ( s2 )) else where ( s2 ) end This ensures that any side effects are always performed, in contrast to s1 <\\+ s2 , where s2 is only executed if s1 fails. (Thus, left choice implements a short circuit Boolean or.) Similarly, the following and(s1, s2) combinator is the non-short circuit version of Boolean conjunction: and ( s1 , s2 ) = if s1 then where ( s2 ) else where ( s2 ); fail end Switch \u00b6 The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice. The switch construct has the following form: switch s0 case s1 : s1 ' case s2 : s2 ' ... otherwise : sdef end The switch first applies the s0 strategy to the current term t resulting in a term t' . Then it tries the cases in turn applying each si to t' . As soon as this succeeds the corresponding case is selected and si' is applied to the t , the term to which the switch was applied. If none of the cases applies, the default strategy sdef from the otherwise is applied. The switch construct is syntactic sugar for a nested if-then-else: { x : where ( s0 => x ); if < s1 > x then s1 ' else if < s2 > x then s2 ' else if ... then ... else sdef end end end } Non-Deterministic Choice \u00b6 The deterministic left choice operator prescribes that the left alternative should be tried before the right alternative, and that the latter is only used if the first fails. There are applications where it is not necessary to define the order of the alternatives. In those cases non-deterministic choice can be used. The non-deterministic choice operator s1 + s2 chooses one of the two strategies s1 or s2 to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler. The + combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with + . The following transformation illustrates this: module A f = s1 module B f = s2 module main imports A B => f = s2 + s1 This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters. While the + combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <+ to avoid surprises. In the past, the + combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this: module A f = s1 f = s2 => f = s1 < + s2 Recursion \u00b6 Repeated application of a strategy can be achieved with recursion. There are two styles for doing this; with a recursive definition or using the fixpoint operator rec . A recursive definition is a normal strategy definition with a recursive call in its body. f ( s ) = ... f ( s ) ... Another way to define recursion is using the fixpoint operator rec x(s) , which recurses on applications of x within s. For example, the definition f ( s ) = rec x ( ... x ... ) is equivalent to the one above. The advantage of the rec operator is that it allows the definition of an unnamed strategy expression to be recursive. For example, in the definition g ( s ) = foo ; rec x ( ... x ... ); bar the strategy between foo and bar is a recursive strategy that does not recurse to g(s) . Originally, the rec operator was the only way to define recursive strategies. It is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope. The repeat strategy applies a transformation s until it fails. It is defined as a recursive definition using try as follows: try ( s ) = s < + id repeat ( s ) = try ( s ; repeat ( s )) An equivalent definition using rec is: repeat ( s ) = rec x ( try ( s ; x )) A Library of Iteration Strategies. \u00b6 Using sequential composition, choice, and recursion a large variety of iteration strategies can be defined. The following definitions are part of the Stratego Library (in module strategy/iteration ). repeat ( s ) = rec x ( try ( s ; x )) repeat ( s , c ) = ( s ; repeat ( s , c )) < + c repeat1 ( s , c ) = s ; ( repeat1 ( s , c ) < + c ) repeat1 ( s ) = repeat1 ( s , id ) repeat-until ( s , c ) = s ; if c then id else repeat-until ( s , c ) end while ( c , s ) = if c then s ; while ( c , s ) end do-while ( s , c ) = s ; if c then do-while ( s , c ) end References \u00b6 Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9","title":"Sequential Combinators"},{"location":"background/stratego/strategy-combinators/sequential/#sequential-combinators","text":"Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined 1 . Thus, Stratego consists of a core language 2 and a 'sugar' language defined by reduction to the core language.","title":"Sequential Combinators"},{"location":"background/stratego/strategy-combinators/sequential/#identity-and-failure","text":"The most basic operations in Stratego are id and fail . The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects.","title":"Identity and Failure"},{"location":"background/stratego/strategy-combinators/sequential/#sequential-composition","text":"The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails. Sequential composition is associative. Identity is a left and right unit for sequential composition; since id always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since fail always fails the next strategy will never be reached. This leads to the following equations: ( s1 ; s2 ) ; s3 = s1 ; ( s2 ; s3 ) id ; s = s s ; id = s fail ; s = fail However, not for all strategies s we have that failure is a right zero for sequential composition: s ; fail = fail // is not a law Although the composition s; fail will always fail, the execution of s may have side effects that are not performed by fail . For example, consider printing a term in s . As an example of the use of sequential composition consider the following rewrite rules. A : P ( Z (), x ) - > x B : P ( S ( x ), y ) - > P ( x , S ( y )) The following applications shows the effect of first applying B and then A : < B > ! P ( S ( Z ()), Z ()) => P ( S ( Z ), Z ) < A > P ( Z , S ( Z )) => S ( Z ) Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019: < B ; A > ! P ( S ( Z ()), Z ()) => S ( Z ) The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first: < B ; B > ! P ( S ( Z ()), Z ()) // fails","title":"Sequential Composition"},{"location":"background/stratego/strategy-combinators/sequential/#left-choice","text":"Choosing between rules to apply is achieved using one of several choice combinators, all of which are based on the guarded choice combinator. The common approach is that failure to apply one strategy leads to backtracking to an alternative strategy. The left choice or deterministic choice s1 <+ s2 tries to apply s1 and s2 in that order. That is, it first tries to apply s1 , and if that succeeds the choice succeeds. However, if the application of s1 fails, s2 is applied to the original term. Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless. ( s1 < + s2 ) < + s3 = s1 < + ( s2 < + s3 ) id < + s = id fail < + s = s s < + fail = s However, identity is not a right zero for left choice. That is, not for all strategies s we have that s < + id = s // is not a law The expression s <+ id always succeeds, even (especially) in the case that s fails, in which case the right-hand side of the equation fails of course. Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property ( s1 < + s2 ); s3 = ( s1 ; s3 ) < + ( s2 ; s3 ) // is not a law does not hold for all s1 , s2 , and s3 . The difference is illustrated by the following applications: <( B < + id ); B > P ( S ( Z ), Z ) // fails <( B ; B ) < + ( id ; B )> P ( S ( Z ()), Z ()) => P ( Z , S ( Z )) In the application of (B <+ id); B , the first application of B succeeds after which the choice is committed. The subsequent application of B then fails. This is equivalent to first applying (B <+ id) and then applying B to the result. The application of (B; B) <+ (id; B) , however, is successful; the application of B; B fails, after which the choice backtracks to id; B , which succeeds.","title":"Left Choice"},{"location":"background/stratego/strategy-combinators/sequential/#choosing-between-transformations","text":"The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules: PlusAssoc : Plus ( Plus ( e1 , e2 ), e3 ) - > Plus ( e1 , Plus ( e2 , e3 )) PlusZero : Plus ( Int ( \"0\" ), e ) - > e These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into PlusAssoc <+ PlusZero creates a strategy that transforms terms matching both rules as illustrated by the following applications: < PlusAssoc > Plus ( Int ( \"0\" ), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Int ( \"0\" ), Int ( \"3\" )) => Int ( \"3\" ) < PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) => Plus ( Var ( \"x\" ), Plus ( Int ( \"42\" ), Int ( \"3\" )))","title":"Choosing between Transformations."},{"location":"background/stratego/strategy-combinators/sequential/#ordering-overlapping-rules","text":"When two rules or strategies are mutually exlusive the order of applying them does not matter. In cases where strategies are overlapping, that is, succeed for the same terms, the order becomes crucial to determining the semantics of the composition. For example, consider the following rewrite rules reducing applications of Mem: Mem1 : Mem ( x ,[]) - > False () Mem2 : Mem ( x ,[ x | xs ]) - > True () Mem3 : Mem ( x ,[ y | ys ]) - > Mem ( x , ys ) Rules Mem2 and Mem3 have overlapping left-hand sides. Rule Mem2 only applies if the first argument is equal to the head element of the list in the second argument. Rule Mem3 applies always if the list in the second argument is non-empty. < Mem2 > Mem ( 1 , [ 1 , 2 , 3 ]) => True () < Mem3 > Mem ( 1 , [ 1 , 2 , 3 ]) => Mem ( 1 ,[ 2 , 3 ]) In such situations, depending on the order of the rules, different results are produced. (The rules form a non-confluent rewriting system.) By ordering the rules as Mem2 <+ Mem3 , rule Mem2 is tried before Mem3 , and we have a deterministic transformation strategy.","title":"Ordering Overlapping Rules."},{"location":"background/stratego/strategy-combinators/sequential/#try","text":"A useful application of <+ in combination with id is the reflexive closure of a strategy s: try ( s ) = s < + id The user-defined strategy combinator try tries to apply its argument strategy s , but if that fails, just succeeds using id .","title":"Try"},{"location":"background/stratego/strategy-combinators/sequential/#guarded-left-choice","text":"Sometimes it is not desirable to backtrack to the alternative specified in a choice. Rather, after passing a guard, the choice should be committed. This can be expressed using the guarded left choice operator s1 < s2 + s3 . If s1 succeeds s2 is applied, else s3 is applied. If s2 fails, the complete expression fails; no backtracking to s3 takes place. Properties. This combinator is a generalization of the left choice combinator <+ . s1 < + s2 = s1 < id + s2 The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard: id < s2 + s3 = s2 fail < s2 + s3 = s3 If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch. s1 < s2 + fail = s1 ; s2 Guarded choice is not associative: ( s1 < s2 + s3 ) < s4 + s5 = s1 < s2 + ( s3 < s4 + s5 ) // not a law To see why consider the possible traces of these expressions. For example, when s1 and s2 succeed subsequently, the left-hand side expression calls s4 , while the right-hand side expression does not. However, sequential composition distributes over guarded choice from left and right: ( s1 < s2 + s3 ); s4 = s1 < ( s2 ; s4 ) + ( s3 ; s4 ) s0 ; ( s1 < s2 + s3 ) = ( s0 ; s1 ) < s2 + s3 Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation not(s) of a strategy s , succeeds if s fails, and fails when it succeeds: not ( s ) = s < fail + id Since failure discards the effect of a (successful) transformation, this has the effect of testing whether s succeeds. So we have the following laws for not: not ( id ) = fail not ( fail ) = id However, side effects performed by s are not undone, of course. Therefore, the following equation does not hold: not ( not ( s )) = s // not a law Another example of the use of guarded choice is the restore-always combinator: restore-always ( s , r ) = s < r + ( r ; fail ) It applies a \u2018restore\u2019 strategy r after applying a strategy s , even if s fails, and preserves the success/failure behavior of s . Since fail discards the transformation effect of r , this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying s .","title":"Guarded Left Choice"},{"location":"background/stratego/strategy-combinators/sequential/#if-then-else","text":"The guarded choice combinator is similar to the traditional if-then-else construct of programming languages. The difference is that the \u2018then\u2019 branch applies to the result of the application of the condition. Stratego\u2019s if s1 then s2 else s3 end construct is more like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but it\u2019s transformation effect is undone. However, the condition strategy s1 is still applied to the current term. The if s1 then s2 end strategy is similar; if the condition fails, the strategy succeeds. The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator: if s1 then s2 else s3 end ==> // transforms to where ( s1 ) < s2 + s3 The strategy where(s) succeeds if s succeeds, but returns the original subject term. The implementation of the where combinator is discussed in the section on matching and building terms . The following laws show that the branches are selected by success or failure of the condition: if id then s2 else s3 end = s2 if fail then s2 else s3 end = s3 The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch: if s1 then s2 end = where ( s1 ) < s2 + id Examples. The inclusive or or(s1, s2) succeeds if one of the strategies s1 or s2 succeeds, but guarantees that both are applied, in the order s1 first, then s2 : or ( s1 , s2 ) = if s1 then try ( where ( s2 )) else where ( s2 ) end This ensures that any side effects are always performed, in contrast to s1 <\\+ s2 , where s2 is only executed if s1 fails. (Thus, left choice implements a short circuit Boolean or.) Similarly, the following and(s1, s2) combinator is the non-short circuit version of Boolean conjunction: and ( s1 , s2 ) = if s1 then where ( s2 ) else where ( s2 ); fail end","title":"If-then-else"},{"location":"background/stratego/strategy-combinators/sequential/#switch","text":"The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice. The switch construct has the following form: switch s0 case s1 : s1 ' case s2 : s2 ' ... otherwise : sdef end The switch first applies the s0 strategy to the current term t resulting in a term t' . Then it tries the cases in turn applying each si to t' . As soon as this succeeds the corresponding case is selected and si' is applied to the t , the term to which the switch was applied. If none of the cases applies, the default strategy sdef from the otherwise is applied. The switch construct is syntactic sugar for a nested if-then-else: { x : where ( s0 => x ); if < s1 > x then s1 ' else if < s2 > x then s2 ' else if ... then ... else sdef end end end }","title":"Switch"},{"location":"background/stratego/strategy-combinators/sequential/#non-deterministic-choice","text":"The deterministic left choice operator prescribes that the left alternative should be tried before the right alternative, and that the latter is only used if the first fails. There are applications where it is not necessary to define the order of the alternatives. In those cases non-deterministic choice can be used. The non-deterministic choice operator s1 + s2 chooses one of the two strategies s1 or s2 to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler. The + combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with + . The following transformation illustrates this: module A f = s1 module B f = s2 module main imports A B => f = s2 + s1 This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters. While the + combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <+ to avoid surprises. In the past, the + combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this: module A f = s1 f = s2 => f = s1 < + s2","title":"Non-Deterministic Choice"},{"location":"background/stratego/strategy-combinators/sequential/#recursion","text":"Repeated application of a strategy can be achieved with recursion. There are two styles for doing this; with a recursive definition or using the fixpoint operator rec . A recursive definition is a normal strategy definition with a recursive call in its body. f ( s ) = ... f ( s ) ... Another way to define recursion is using the fixpoint operator rec x(s) , which recurses on applications of x within s. For example, the definition f ( s ) = rec x ( ... x ... ) is equivalent to the one above. The advantage of the rec operator is that it allows the definition of an unnamed strategy expression to be recursive. For example, in the definition g ( s ) = foo ; rec x ( ... x ... ); bar the strategy between foo and bar is a recursive strategy that does not recurse to g(s) . Originally, the rec operator was the only way to define recursive strategies. It is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope. The repeat strategy applies a transformation s until it fails. It is defined as a recursive definition using try as follows: try ( s ) = s < + id repeat ( s ) = try ( s ; repeat ( s )) An equivalent definition using rec is: repeat ( s ) = rec x ( try ( s ; x ))","title":"Recursion"},{"location":"background/stratego/strategy-combinators/sequential/#a-library-of-iteration-strategies","text":"Using sequential composition, choice, and recursion a large variety of iteration strategies can be defined. The following definitions are part of the Stratego Library (in module strategy/iteration ). repeat ( s ) = rec x ( try ( s ; x )) repeat ( s , c ) = ( s ; repeat ( s , c )) < + c repeat1 ( s , c ) = s ; ( repeat1 ( s , c ) < + c ) repeat1 ( s ) = repeat1 ( s , id ) repeat-until ( s , c ) = s ; if c then id else repeat-until ( s , c ) end while ( c , s ) = if c then s ; while ( c , s ) end do-while ( s , c ) = s ; if c then do-while ( s , c ) end","title":"A Library of Iteration Strategies."},{"location":"background/stratego/strategy-combinators/sequential/#references","text":"Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9","title":"References"},{"location":"background/stratego/strategy-combinators/term/","text":"Term Combinators \u00b6 Previously we have presented rewrite rules as basic transformation steps. However, rules are not atomic transformation actions. To see this, consider what happens when the rewrite rule DAO : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) is applied. First it matches the subject term against the pattern And(Or(x, y), z) in the left-hand side. This means that a substitution for the variables x , y , and z is sought, that makes the pattern equal to the subject term. If the match fails, the rule fails. If the match succeeds, the pattern Or(And(x, z), And(y, z)) on the right-hand side is instantiated with the bindings found during the match of the left-hand side. The instantiated term then replaces the original subject term. Furthermore, the rule limits the scope of the variables occurring in the rule. That is, the variables x , y , z are local to this rule. After the rule is applied the bindings to these variables are invisible again. Thus, rather than considering rules as the atomic actions of transformation programs, Stratego provides their constituents, that is building terms from patterns and matching terms against patterns, as atomic actions, and makes these available to the programmer. In this section we define the basic actions and their use in the composition of more complex operations such as various flavors of rewrite rules. Building Terms \u00b6 The build operation !p replaces the subject term with the instantiation of the pattern p using the bindings from the environment to the variables occurring in p . For example, the strategy !Or(And(x, z), And(y, z)) replaces the subject term with the instantiation of Or(And(x, z), And(y, z)) using bindings to variables x , y and z . ! Int ( \"10\" ) => Int ( \"10\" ) ! Plus ( Var ( \"a\" ), Int ( \"10\" )) => Plus ( Var ( \"a\" ), Int ( \"10\" )) It is possible to build terms with variables. We call this building a term pattern. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern p . For example, in a context where e is bound to Var(\"b\") ! Plus ( Var ( \"a\" ), e ) => Plus ( Var ( \"a\" ), Var ( \"b\" )) Matching Terms \u00b6 Pattern matching allows the analysis of terms. The simplest case is matching against a literal term. The match operation ?t matches the subject term against the term t . < ? Plus ( Var ( \"a\" ), Int ( \"3\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // succeeds < ? Plus ( Int ( \"3\" ), Var ( \"b\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy ?x compares the current term ( t ) to variable x . It binds variable x to term t in the environment. A variable can only be bound once, or to the same term. < ? e > Plus ( Var ( \"a\" ), Int ( \"3\" )) // binds e to Plus(Var(\"a\"),Int(\"3\")) < ? e > ! Int ( \"17\" ) // fails The general case is matching against an arbitrary term pattern. The match strategy ?p compares the current term to a pattern p . It will add bindings for the variables in pattern p to the environment. The wildcard _ in a match will match any term. < ? Plus ( e , _ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // e is bound to Var(\"a\") Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term. < ? Plus ( e , e )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails < ? Plus ( e , e )> ! Plus ( Var ( \"a\" ), Var ( \"a\" )) // e is bound to Var(\"a\") Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching: equal = ? ( x , x ) equal (| x ) = ? x The equal strategy tests whether the current term is a a pair of the same terms. The equal(|x) strategy tests whether the current term is equal to the argument term. < equal >( \"a\" , \"a\" ) // succeeds < equal >( \"a\" , \"b\" ) // fails < equal (| Foo ( Baz ()))> Foo ( Bar ()) // fails < equal (| Foo ( Bar ()))> Foo ( Bar ()) // succeeds Implementing Rewrite Rules \u00b6 Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build: < ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build. Stratego provides syntactic sugar for various combinations of match and build. Anonymous Rewrite Rule \u00b6 An anonymous rewrite rule (p1 -> p2) transforms a term matching p1 into an instantiation of p2 . Such a rule is equivalent to the sequence ?p1; !p2 . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) Term variable scope \u00b6 Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because e2 is bound to Int(\"3\") and does not match with Var(\"b\") . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) // e1 is bound to Var(\"a\") // e2 is bound to Int(\"3\") <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Var ( \"b\" )) // fails To use a variable name more than once Stratego provides term variable scope. A scope {x1,...,xn : s} locally undefines the variables xi . That is, the binding to a variable xi outside the scope is not visible inside it, nor is the binding to xi inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times. <{ e3 , e4 : ( Plus ( e3 , e4 ) - > Plus ( e4 , e3 ))}> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) // e3 is not bound to a term <{ e3 , e4 : ( Plus ( e3 , e4 ) - > Plus ( e4 , e3 ))}> Plus ( Var ( \"a\" ), Var ( \"b\" )) => Plus ( Var ( \"b\" ), Var ( \"a\" )) Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name: SwapArgs = { e1 , e2 : ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))} < SwapArgs > Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) Implicit Variable Scope \u00b6 When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write SwapArgs = { e1 , e2 : ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))} However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as let SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) in ... end While the variables are bound in the enclosing definition, they are not restricted to SwapArgs in this case, since in a let you typically want to use bindings to variables in the enclosing code. Where \u00b6 Often it is useful to apply a strategy only to test whether some property holds or to compute some auxiliary result. For this purpose, Stratego provides the where(s) combinator, which applies s to the current term, but restores that term afterwards. Any bindings to variables are kept, however. < where ( ? Plus ( Int ( i ), Int ( j )); < addS >( i , j ) => k )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Int ( \"14\" ), Int ( \"3\" )) // i is bound to \"14\" // k is bound to \"17\" With the match and build constructs where(s) is in fact just syntactic sugar for {x: ?x; s; !x} with x a fresh variable not occurring in s . Thus, the current subject term is saved by binding it to a new variable x , then the strategy s is applied, and finally, the original term is restored by building x . Conditional Rewrite Rules \u00b6 A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules. A conditional rule L: p1 -> p2 where s is a simple rule extended with an additional computation s which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side. For example, the EvalPlus rule in the following session uses a condition to compute the sum of i and j : EvalPlus : Plus ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k < EvalPlus > Plus ( Int ( \"14\" ), Int ( \"3\" )) => Int ( \"17\" ) A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form L : p1 - > p2 where s is syntactic sugar for L = ? p1 ; where ( s ); ! p2 Thus, after the match with p1 succeeds the strategy s is applied to the subject term. Only if the application of s succeeds, is the right-hand side p2 built. Note that since s is applied within a where, the build !p2 is applied to the original subject term; only variable bindings computed within s can be used in p2 . As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition. EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k The addition is computed by applying the primitive strategy addS to the pair of integers (i,j) and matching the result against the variable k , which is then used in the right-hand side. This rule is desugared to EvalPlus = ? Add ( Int ( i ), Int ( j )); where ( ! ( i , j ); addS ; ? k ); ! Int ( k ) Lambda Rules \u00b6 Sometimes it is useful to define a rule anonymously within a strategy expression. The syntax for anonymous rules with scopes is a bit much since it requires enumerating all variables. A lambda rule of the form \\ p1 - > p2 where s \\ is an anonymous rewrite rule for which the variables in the left-hand side p1 are local to the rule, that is, it is equivalent to an expression of the form { x1 , ... , xn : ( p1 - > p2 where s )} with x1 ,\u2026, xn the variables of p1 . This means that any variables used in s and p2 that do not occur in p1 are bound in the context of the rule. A typical example of the use of an anonymous rule is < map ( \\ ( x , y ) - > x \\ )> [( 1 , 2 ),( 3 , 4 ),( 5 , 6 )] => [ 1 , 3 , 5 ] Apply and Match \u00b6 One frequently occuring scenario is that of applying a strategy to a term and then matching the result against a pattern. This typically occurs in the condition of a rule. In the constant folding example above we saw this scenario: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k In the condition, first the term (i,j) is built, then the strategy addS is applied to it, and finally the result is matched against the pattern k . To improve the readability of such expressions, the following two constructs are provided. The operation <s> p captures the notion of applying a strategy to a term, i.e., the scenario !p; s . The operation s => p capture the notion of applying a strategy to the current subject term and then matching the result against the pattern p , i.e., s; ?p . The combined operation <s> p1 => p2 thus captures the notion of applying a strategy to a term p1 and matching the result against p2 , i.e, !p1; s; ?p2 . Using this notation we can improve the constant folding rule above as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k Applying Strategies in Build \u00b6 Sometimes it useful to apply a strategy directly to a subterm of a pattern, for example in the right-hand side of a rule, instead of computing a value in a condition, binding the result to a variable, and then using the variable in the build pattern. The constant folding rule above, for example, could be further simplified by directly applying the addition in the right-hand side: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int (< addS >( i , j )) This abbreviates the conditional rule above. In general, a strategy application in a build pattern can always be expressed by computing the application before the build and binding the result to a new variable, which then replaces the application in the build pattern. Another example is the following definition of the map(s) strategy, which applies a strategy to each term in a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] Auxiliary Values \u00b6 As mentioned above, it can be convenient to apply a strategy only to compute some auxiliary result. Although the where construct created to constrain when a rule or strategy may apply (as covered above) can be used for this purpose, often it is better to use the with strategy specifically designed with computing auxiliaries in mind. Specifically, if s is any strategy, the strategy with(s) executes s on the current subject term and then restores the current subject term. In other words, s is executed solely for its side effects, such as binding variables. In this respect, with is like where . However, with(s) differs in a key way: if the strategy s fails, Stratego immediately stops with an error, reporting the strategy that failed. Thus, if with(s) is used for auxiliary computations that really should not fail if the transformation is proceeding properly, there is no opportunity for Stratego to backtrack and/or continue applying other strategies, potentially creating an error at a point far removed from the place that things actually went awry. In short, using with(s) instead of where(s) any time the intention is not to constrain the applicability of a rule or strategy generally makes debugging your Stratego program significantly easier. Also as with where , we can add a with clause to a rewrite rule in exactly the same way. In other words, L : p1 - > p2 with s is syntactic sugar for L = ? p1 ; with ( s ); ! p2 So as an example, the where version of EvalPlus above would be better cast as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with < addS >( i , j ) => k because after all, there is no chance that Stratego will be unable to add two integers, and so if the contents of the with clause fails it means something has gone wrong \u2013 perhaps an Int term somehow ended up with a parameter that does not actually represent an integer \u2013 and Stratego should quit now. Assignment \u00b6 The assignment combinator := is a variation of apply-and-match with terms on both sides of the assignment. The strategy p1 := p2 builds p2 and matches the result against p1 , i.e. it is syntactic sugar for !p2; ?p1 . The strategy is often combine with strategy application into p1 := <s>p2 , which is equivalent to <s>p2 => p1 , but more familiar to an audience with an imperative mindset. For example, consider the following rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with k := < addS >( i , j ) Term Wrap \u00b6 One often write rules of the form x -> Foo(Bar(x)) , i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as !Foo(Bar(<id>)) . In general, a term wrap is a build strategy !p[<s>] containing one or more strategy applications <s> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <s> is replaced with the term resulting from applying s to the current subject term, i.e., the one that is being replaced by the build. The following applications illustrate some uses of term wraps: < ! (< id >,< id >)> 3 => ( 3 , 3 ) <(< Fst ; inc >,< Snd >)> ( 3 , 3 ) => ( 4 , 3 ) < ! Call (< id >, [])> \"foobar\" => Call ( \"foobar\" , []) mod2 = < mod >(< id >, 2 ) < mod2 > 6 => 0 As should now be a common pattern, term projects are implemented by translation to a combination of match and build expressions. Thus, a term wrap !p[<s>] is translated to a strategy expression { x : where ( s => x ); ! p [ x ]} where x is a fresh variable not occurring in s . In other words, the strategy s is applied to the current subject term, i.e., the term to which the build is applied. As an example, the term wrap !Foo(Bar(<id>)) is desugared to the strategy { x : where ( id => x ); ! Foo ( Bar ( x ))} which after simplification is equivalent to {x: ?x; !Foo(Bar(x))} , i.e., exactly the original lambda rule \\x -> Foo(Bar(x))\\ . Term Project \u00b6 Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern. For example, the expression ?And(<id>,x) matches terms of the form And(t1,t2) and reduces them to the first subterm t1 . Another example is the strategy map ( ? FunDec (< id >, _ , _ )) which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the FunDec constructor. Here are some more examples: < ? [ _ |< id >]> [ 1 , 2 , 3 ] => [ 2 , 3 ] < ? Call (< id >, [])> Call ( \"foobar\" , []) => \"foobar\" Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, ?Call(x, <?args; length => 3>) matches only with function calls with three arguments. A match expression ?p[<s>] is desugared as { x : ? p [ x ]; < s > x } That is, after the pattern p[x] matches, it is reduced to the subterm bound to x to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on.","title":"Term Combinators"},{"location":"background/stratego/strategy-combinators/term/#term-combinators","text":"Previously we have presented rewrite rules as basic transformation steps. However, rules are not atomic transformation actions. To see this, consider what happens when the rewrite rule DAO : And ( Or ( x , y ), z ) - > Or ( And ( x , z ), And ( y , z )) is applied. First it matches the subject term against the pattern And(Or(x, y), z) in the left-hand side. This means that a substitution for the variables x , y , and z is sought, that makes the pattern equal to the subject term. If the match fails, the rule fails. If the match succeeds, the pattern Or(And(x, z), And(y, z)) on the right-hand side is instantiated with the bindings found during the match of the left-hand side. The instantiated term then replaces the original subject term. Furthermore, the rule limits the scope of the variables occurring in the rule. That is, the variables x , y , z are local to this rule. After the rule is applied the bindings to these variables are invisible again. Thus, rather than considering rules as the atomic actions of transformation programs, Stratego provides their constituents, that is building terms from patterns and matching terms against patterns, as atomic actions, and makes these available to the programmer. In this section we define the basic actions and their use in the composition of more complex operations such as various flavors of rewrite rules.","title":"Term Combinators"},{"location":"background/stratego/strategy-combinators/term/#building-terms","text":"The build operation !p replaces the subject term with the instantiation of the pattern p using the bindings from the environment to the variables occurring in p . For example, the strategy !Or(And(x, z), And(y, z)) replaces the subject term with the instantiation of Or(And(x, z), And(y, z)) using bindings to variables x , y and z . ! Int ( \"10\" ) => Int ( \"10\" ) ! Plus ( Var ( \"a\" ), Int ( \"10\" )) => Plus ( Var ( \"a\" ), Int ( \"10\" )) It is possible to build terms with variables. We call this building a term pattern. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern p . For example, in a context where e is bound to Var(\"b\") ! Plus ( Var ( \"a\" ), e ) => Plus ( Var ( \"a\" ), Var ( \"b\" ))","title":"Building Terms"},{"location":"background/stratego/strategy-combinators/term/#matching-terms","text":"Pattern matching allows the analysis of terms. The simplest case is matching against a literal term. The match operation ?t matches the subject term against the term t . < ? Plus ( Var ( \"a\" ), Int ( \"3\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // succeeds < ? Plus ( Int ( \"3\" ), Var ( \"b\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy ?x compares the current term ( t ) to variable x . It binds variable x to term t in the environment. A variable can only be bound once, or to the same term. < ? e > Plus ( Var ( \"a\" ), Int ( \"3\" )) // binds e to Plus(Var(\"a\"),Int(\"3\")) < ? e > ! Int ( \"17\" ) // fails The general case is matching against an arbitrary term pattern. The match strategy ?p compares the current term to a pattern p . It will add bindings for the variables in pattern p to the environment. The wildcard _ in a match will match any term. < ? Plus ( e , _ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // e is bound to Var(\"a\") Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term. < ? Plus ( e , e )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails < ? Plus ( e , e )> ! Plus ( Var ( \"a\" ), Var ( \"a\" )) // e is bound to Var(\"a\") Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching: equal = ? ( x , x ) equal (| x ) = ? x The equal strategy tests whether the current term is a a pair of the same terms. The equal(|x) strategy tests whether the current term is equal to the argument term. < equal >( \"a\" , \"a\" ) // succeeds < equal >( \"a\" , \"b\" ) // fails < equal (| Foo ( Baz ()))> Foo ( Bar ()) // fails < equal (| Foo ( Bar ()))> Foo ( Bar ()) // succeeds","title":"Matching Terms"},{"location":"background/stratego/strategy-combinators/term/#implementing-rewrite-rules","text":"Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build: < ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build. Stratego provides syntactic sugar for various combinations of match and build.","title":"Implementing Rewrite Rules"},{"location":"background/stratego/strategy-combinators/term/#anonymous-rewrite-rule","text":"An anonymous rewrite rule (p1 -> p2) transforms a term matching p1 into an instantiation of p2 . Such a rule is equivalent to the sequence ?p1; !p2 . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" ))","title":"Anonymous Rewrite Rule"},{"location":"background/stratego/strategy-combinators/term/#term-variable-scope","text":"Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because e2 is bound to Int(\"3\") and does not match with Var(\"b\") . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) // e1 is bound to Var(\"a\") // e2 is bound to Int(\"3\") <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Var ( \"b\" )) // fails To use a variable name more than once Stratego provides term variable scope. A scope {x1,...,xn : s} locally undefines the variables xi . That is, the binding to a variable xi outside the scope is not visible inside it, nor is the binding to xi inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times. <{ e3 , e4 : ( Plus ( e3 , e4 ) - > Plus ( e4 , e3 ))}> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) // e3 is not bound to a term <{ e3 , e4 : ( Plus ( e3 , e4 ) - > Plus ( e4 , e3 ))}> Plus ( Var ( \"a\" ), Var ( \"b\" )) => Plus ( Var ( \"b\" ), Var ( \"a\" )) Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name: SwapArgs = { e1 , e2 : ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))} < SwapArgs > Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" ))","title":"Term variable scope"},{"location":"background/stratego/strategy-combinators/term/#implicit-variable-scope","text":"When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write SwapArgs = { e1 , e2 : ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))} However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as let SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) in ... end While the variables are bound in the enclosing definition, they are not restricted to SwapArgs in this case, since in a let you typically want to use bindings to variables in the enclosing code.","title":"Implicit Variable Scope"},{"location":"background/stratego/strategy-combinators/term/#where","text":"Often it is useful to apply a strategy only to test whether some property holds or to compute some auxiliary result. For this purpose, Stratego provides the where(s) combinator, which applies s to the current term, but restores that term afterwards. Any bindings to variables are kept, however. < where ( ? Plus ( Int ( i ), Int ( j )); < addS >( i , j ) => k )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Int ( \"14\" ), Int ( \"3\" )) // i is bound to \"14\" // k is bound to \"17\" With the match and build constructs where(s) is in fact just syntactic sugar for {x: ?x; s; !x} with x a fresh variable not occurring in s . Thus, the current subject term is saved by binding it to a new variable x , then the strategy s is applied, and finally, the original term is restored by building x .","title":"Where"},{"location":"background/stratego/strategy-combinators/term/#conditional-rewrite-rules","text":"A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules. A conditional rule L: p1 -> p2 where s is a simple rule extended with an additional computation s which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side. For example, the EvalPlus rule in the following session uses a condition to compute the sum of i and j : EvalPlus : Plus ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k < EvalPlus > Plus ( Int ( \"14\" ), Int ( \"3\" )) => Int ( \"17\" ) A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form L : p1 - > p2 where s is syntactic sugar for L = ? p1 ; where ( s ); ! p2 Thus, after the match with p1 succeeds the strategy s is applied to the subject term. Only if the application of s succeeds, is the right-hand side p2 built. Note that since s is applied within a where, the build !p2 is applied to the original subject term; only variable bindings computed within s can be used in p2 . As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition. EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k The addition is computed by applying the primitive strategy addS to the pair of integers (i,j) and matching the result against the variable k , which is then used in the right-hand side. This rule is desugared to EvalPlus = ? Add ( Int ( i ), Int ( j )); where ( ! ( i , j ); addS ; ? k ); ! Int ( k )","title":"Conditional Rewrite Rules"},{"location":"background/stratego/strategy-combinators/term/#lambda-rules","text":"Sometimes it is useful to define a rule anonymously within a strategy expression. The syntax for anonymous rules with scopes is a bit much since it requires enumerating all variables. A lambda rule of the form \\ p1 - > p2 where s \\ is an anonymous rewrite rule for which the variables in the left-hand side p1 are local to the rule, that is, it is equivalent to an expression of the form { x1 , ... , xn : ( p1 - > p2 where s )} with x1 ,\u2026, xn the variables of p1 . This means that any variables used in s and p2 that do not occur in p1 are bound in the context of the rule. A typical example of the use of an anonymous rule is < map ( \\ ( x , y ) - > x \\ )> [( 1 , 2 ),( 3 , 4 ),( 5 , 6 )] => [ 1 , 3 , 5 ]","title":"Lambda Rules"},{"location":"background/stratego/strategy-combinators/term/#apply-and-match","text":"One frequently occuring scenario is that of applying a strategy to a term and then matching the result against a pattern. This typically occurs in the condition of a rule. In the constant folding example above we saw this scenario: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k In the condition, first the term (i,j) is built, then the strategy addS is applied to it, and finally the result is matched against the pattern k . To improve the readability of such expressions, the following two constructs are provided. The operation <s> p captures the notion of applying a strategy to a term, i.e., the scenario !p; s . The operation s => p capture the notion of applying a strategy to the current subject term and then matching the result against the pattern p , i.e., s; ?p . The combined operation <s> p1 => p2 thus captures the notion of applying a strategy to a term p1 and matching the result against p2 , i.e, !p1; s; ?p2 . Using this notation we can improve the constant folding rule above as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k","title":"Apply and Match"},{"location":"background/stratego/strategy-combinators/term/#applying-strategies-in-build","text":"Sometimes it useful to apply a strategy directly to a subterm of a pattern, for example in the right-hand side of a rule, instead of computing a value in a condition, binding the result to a variable, and then using the variable in the build pattern. The constant folding rule above, for example, could be further simplified by directly applying the addition in the right-hand side: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int (< addS >( i , j )) This abbreviates the conditional rule above. In general, a strategy application in a build pattern can always be expressed by computing the application before the build and binding the result to a new variable, which then replaces the application in the build pattern. Another example is the following definition of the map(s) strategy, which applies a strategy to each term in a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ]","title":"Applying Strategies in Build"},{"location":"background/stratego/strategy-combinators/term/#auxiliary-values","text":"As mentioned above, it can be convenient to apply a strategy only to compute some auxiliary result. Although the where construct created to constrain when a rule or strategy may apply (as covered above) can be used for this purpose, often it is better to use the with strategy specifically designed with computing auxiliaries in mind. Specifically, if s is any strategy, the strategy with(s) executes s on the current subject term and then restores the current subject term. In other words, s is executed solely for its side effects, such as binding variables. In this respect, with is like where . However, with(s) differs in a key way: if the strategy s fails, Stratego immediately stops with an error, reporting the strategy that failed. Thus, if with(s) is used for auxiliary computations that really should not fail if the transformation is proceeding properly, there is no opportunity for Stratego to backtrack and/or continue applying other strategies, potentially creating an error at a point far removed from the place that things actually went awry. In short, using with(s) instead of where(s) any time the intention is not to constrain the applicability of a rule or strategy generally makes debugging your Stratego program significantly easier. Also as with where , we can add a with clause to a rewrite rule in exactly the same way. In other words, L : p1 - > p2 with s is syntactic sugar for L = ? p1 ; with ( s ); ! p2 So as an example, the where version of EvalPlus above would be better cast as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with < addS >( i , j ) => k because after all, there is no chance that Stratego will be unable to add two integers, and so if the contents of the with clause fails it means something has gone wrong \u2013 perhaps an Int term somehow ended up with a parameter that does not actually represent an integer \u2013 and Stratego should quit now.","title":"Auxiliary Values"},{"location":"background/stratego/strategy-combinators/term/#assignment","text":"The assignment combinator := is a variation of apply-and-match with terms on both sides of the assignment. The strategy p1 := p2 builds p2 and matches the result against p1 , i.e. it is syntactic sugar for !p2; ?p1 . The strategy is often combine with strategy application into p1 := <s>p2 , which is equivalent to <s>p2 => p1 , but more familiar to an audience with an imperative mindset. For example, consider the following rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with k := < addS >( i , j )","title":"Assignment"},{"location":"background/stratego/strategy-combinators/term/#term-wrap","text":"One often write rules of the form x -> Foo(Bar(x)) , i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as !Foo(Bar(<id>)) . In general, a term wrap is a build strategy !p[<s>] containing one or more strategy applications <s> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <s> is replaced with the term resulting from applying s to the current subject term, i.e., the one that is being replaced by the build. The following applications illustrate some uses of term wraps: < ! (< id >,< id >)> 3 => ( 3 , 3 ) <(< Fst ; inc >,< Snd >)> ( 3 , 3 ) => ( 4 , 3 ) < ! Call (< id >, [])> \"foobar\" => Call ( \"foobar\" , []) mod2 = < mod >(< id >, 2 ) < mod2 > 6 => 0 As should now be a common pattern, term projects are implemented by translation to a combination of match and build expressions. Thus, a term wrap !p[<s>] is translated to a strategy expression { x : where ( s => x ); ! p [ x ]} where x is a fresh variable not occurring in s . In other words, the strategy s is applied to the current subject term, i.e., the term to which the build is applied. As an example, the term wrap !Foo(Bar(<id>)) is desugared to the strategy { x : where ( id => x ); ! Foo ( Bar ( x ))} which after simplification is equivalent to {x: ?x; !Foo(Bar(x))} , i.e., exactly the original lambda rule \\x -> Foo(Bar(x))\\ .","title":"Term Wrap"},{"location":"background/stratego/strategy-combinators/term/#term-project","text":"Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern. For example, the expression ?And(<id>,x) matches terms of the form And(t1,t2) and reduces them to the first subterm t1 . Another example is the strategy map ( ? FunDec (< id >, _ , _ )) which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the FunDec constructor. Here are some more examples: < ? [ _ |< id >]> [ 1 , 2 , 3 ] => [ 2 , 3 ] < ? Call (< id >, [])> Call ( \"foobar\" , []) => \"foobar\" Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, ?Call(x, <?args; length => 3>) matches only with function calls with three arguments. A match expression ?p[<s>] is desugared as { x : ? p [ x ]; < s > x } That is, after the pattern p[x] matches, it is reduced to the subterm bound to x to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on.","title":"Term Project"},{"location":"background/stratego/strategy-combinators/traversal/","text":"Traversal Combinators \u00b6 There are many ways to traverse a tree. For example, a bottom-up traversal, visits the subterms of a node before it visits the node itself, while a top-down traversal visits nodes before it visits children. One-pass traversals traverse the tree one time, while fixed-point traversals, such as innermost, repeatedly traverse a term until a normal form is reached. Rather than provide built-in implementations for all traversals needed in transformations, Stratego defines traversals in terms of the primitive ingredients of traversal. For example, a top-down, one-pass traversal strategy will first visit a node, and then descend to the children of a node in order to recursively traverse all subterms. Similarly, the bottom-up, fixed-point traversal strategy innermost, will first descend to the children of a node in order to recursively traverse all subterms, then visit the node itself, and possibly recursively reapply the strategy. Traversal in Stratego is based on the observation 1 that a full term traversal is a recursive closure of a one-step descent, that is, an operation that applies a strategy to one or more direct subterms of the subject term. By separating this one-step descent operator from recursion, and making it a first-class operation, many different traversals can be defined. Here we explore the ways in which Stratego supports the definition of traversal strategies. We start with explicitly programmed traversals using recursive traversal rules. Next, congruences operators provide a more concise notation for such data-type specific traversal rules. Finally, generic traversal operators support data type independent definitions of traversals, which can be reused for any data type. Given these basic mechanisms, we conclude with an exploration of idioms for traversal and standard traversal strategies in the Stratego Library. Congruence Operators \u00b6 Congruence operators provide a convenient abbreviation of traversal with rewrite rules . A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor c declared in a signature, there is a corresponding congruence operator c(s1 , ..., sn) , which applies to terms of the form c(t1 , ..., tn) by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match. For example, consider the following signature of expressions: module expressions signature sorts Exp constructors Int : String - > Exp Var : String - > Exp Plus : Exp * Exp - > Exp Times : Exp * Exp - > Exp The following applications apply the congruence operators Plus and Times to a term: < Plus ( ! Var ( \"a\" ), id )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < Times ( id , ! Int ( \"42\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor. Defining Traversals with Congruences \u00b6 Since congruence operators define a one-step traversal for a specific constructor, they capture the pattern of traversal rules . That is, a traversal rule such as proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) can be written by the congruence And(s,s) . Applying this to the prop-dnf program we can replace the traversal rules by congruences as follows: module prop-dnf10 imports prop-rules strategies proptr ( s ) = Not ( s ) < + And ( s , s ) < + Or ( s , s ) < + Impl ( s , s ) < + Eq ( s , s ) propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf )) Traversing Tuples and Lists \u00b6 Congruences can also be applied to tuples, (s1,s2,...,sn) , and lists, [s1,s2,...,sn] . A special list congruence is [] which \u2018visits\u2019 the empty list. As an example, consider again the definition of map(s) using recursive traversal rules: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] Using list congruences we can define this strategy as: map ( s ) = [] < + [ s | map ( s )] The [] congruence matches an empty list. The [s | map(s)] congruence matches a non-empty list, and applies s to the head of the list and map(s) to the tail. Thus, map(s) applies s to each element of a list: < map ( inc )> [ 1 , 2 , 3 ] => [ 2 , 3 , 4 ] Note that map(s) only succeeds if s succeeds for each element of the list. The fetch and filter strategies are variations on map that use the failure of s to list elements. fetch ( s ) = [ s | id ] < + [ id | fetch ( s )] The fetch strategy traverses a list until it finds a element for which s succeeds and then stops. That element is the only one that is transformed. filter ( s ) = [] + ([ s | filter ( s )] < + ? [ |< id >]; filter ( s )) The filter strategy applies s to each element of a list, but only keeps the elements for which it succeeds. even = where (< eq >(< mod >(< id >, 2 ), 0 )) < filter ( even )> [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ] => [ 2 , 4 , 6 , 8 ] Format Checking \u00b6 Another application of congruences is in the definition of format checkers. A format checker describes a subset of a term language using a recursive pattern. This can be used to verify input or output of a transformation, and for documentation purposes. Format checkers defined with congruences can check subsets of signatures or regular tree grammars. For example, the subset of terms of a signature in a some normal form. As an example, consider checking the output of the dnf and cnf transformations. conj ( s ) = And ( conj ( s ), conj ( s )) < + s disj ( s ) = Or ( disj ( s ), disj ( s )) < + s // Conjunctive normal form conj-nf = conj ( disj ( Not ( Atom ( id )) < + Atom ( id ))) // Disjunctive normal form disj-nf = disj ( conj ( Not ( Atom ( id )) < + Atom ( id ))) The strategies conj(s) and disj(s) check that the subject term is a conjunct or a disjunct, respectively, with terms satisfying s at the leaves. The strategies conj-nf and disj-nf check that the subject term is in conjunctive or disjunctive normal form, respectively. Generic Traversal \u00b6 Using congruence operators we constructed a generic, i.e. transformation independent, bottom-up traversal for proposition terms. The same can be done for other data types. However, since the sets of constructors of abstract syntax trees of typical programming languages can be quite large, this may still amount to quite a bit of work that is not reusable across data types; even though a strategy such as bottom-up traversal, is basically data-type independent. Thus, Stratego provides generic traversal by means of several generic one-step descent operators. The operator all , applies a strategy to all direct subterms. The operator one , applies a strategy to one direct subterm, and the operator some , applies a strategy to as many direct subterms as possible, and at least one. Visiting All Subterms \u00b6 The all(s) strategy transforms a constructor application by applying the parameter strategy s to each direct subterm. An application of all(s) fails if the application to one of the subterms fails. The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms. That is, it is not possible to do something special for a particular subterm (that\u2019s what congruences are for). < all ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Var ( \"a\" )) < all ( ! Var ( \"z\" ))> Times ( Var ( \"b\" ), Int ( \"3\" )) => Times ( Var ( \"z\" ), Var ( \"z\" )) Defining Traversals with All \u00b6 The all(s) operator is really the ultimate replacement for the traversal with rules idiom. Instead of specifying a rule or congruence for each constructor, the single application of the all operator takes care of traversing all constructors. Thus, we can replace the propbu strategy by a completely generic definition of bottom-up traversal. Consider again the last definition of propbu : proptr ( s ) = Not ( s ) < + And ( s , s ) < + Or ( s , s ) < + Impl ( s , s ) < + Eq ( s , s ) propbu ( s ) = try ( proptr ( propbu ( s ))); s The role of proptr(s) in this definition can be replaced by all(s) , since that achieves exactly the same, namely applying s to the direct subterms of constructors: propbu ( s ) = all ( propbu ( s )); s Moreover, all succeeds on any constructor in any signature, so we can also drop the try as well, which was there only because proptr fails on the Atom(...) , True() , and False() nodes at the leaves. However, the strategy now is completely generic, i.e. independent of the particular structure it is applied to. In the Stratego Library this strategy is called bottomup(s) , and defined as follows: bottomup ( s ) = all ( bottomup ( s )); s It first recursively transforms the subterms of the subject term and then applies s to the result. Using this definition, the normalization of propositions now reduces to the following module, which is only concerned with the selection and composition of rewrite rules: module prop-dnf11 imports prop-rules strategies dnf = bottomup ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = bottomup ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf )) In fact, these definitions still contain a reusable pattern. With a little squinting we see that the definitions match the following pattern: dnf = bottomup ( try ( dnf-rules ; dnf )) cnf = bottomup ( try ( cnf-rules ; cnf )) In which we can recognize the definition of innermost reduction, which the Stratego Library defines as: innermost ( s ) = bottomup ( try ( s ; innermost ( s ))) The innermost strategy performs a bottom-up traversal of a term. After transforming the subterms of a term it tries to apply the transformation s . If successful the result is recursively transformed with an application of innermost . This brings us to the final form for the proposition normalizations: module prop-dnf12 imports prop-rules strategies dnf = innermost ( DN < + DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ) cnf = innermost ( DN < + DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ) Different transformations can be achieved by using a selection of rules and a strategy, which is generic, yet defined in Stratego itself using strategy combinators. Visiting One Subterm \u00b6 The one(s) strategy transforms a constructor application by applying the parameter strategy s to exactly one direct subterm. An application of one(s) fails if the application to all of the subterms fails. The following applications illustrate the behavior of the combinator: < one ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < one ( \\ Int ( x ) - > Int (< addS >( x , \"1\" )) \\ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"4\" )) < one ( ? Plus ( _ , _ ))> Plus ( Var ( \"a\" ), Int ( \"4\" )) // fails Defining Traversals with One \u00b6 A frequently used application of one is the oncetd(s) traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied. oncetd ( s ) = s < + one ( oncetd ( s )) Thus, s is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to oncetd(s) . An application of oncetd is the contains(|t) strategy, which checks whether the subject term contains a subterm that is equal to t. contains (| t ) = oncetd ( ? t ) Through the depth first search of oncetd , either an occurrence of t is found, or all subterms are verified to be unequal to t . Here are some other one-pass traversals using the one combinator: oncebu ( s ) = one ( oncebu ( s )) < + s spinetd ( s ) = s ; try ( one ( spinetd ( s ))) spinebu ( s ) = try ( one ( spinebu ( s ))); s Here are some fixe-point traversals, i.e., traversals that apply their argument transformation exhaustively to the subject term. reduce ( s ) = repeat ( rec x ( one ( x ) + s )) outermost ( s ) = repeat ( oncetd ( s )) innermostI ( s ) = repeat ( oncebu ( s )) The difference is the subterm selection strategy. Visiting Some Subterms \u00b6 The some(s) strategy transforms a constructor application by applying the parameter strategy s to as many direct subterms as possible and at least one. An application of some(s) fails if the application to all of the subterms fails. Some one-pass traversals based on some: sometd ( s ) = s < + some ( sometd ( s )) somebu ( s ) = some ( somebu ( s )) < + s A fixed-point traversal with some: reduce-par ( s ) = repeat ( rec x ( some ( x ) + s )) References \u00b6 Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2 nd International Workshop on the Theory and Practice of Algebraic Specifications \\(ASF\\+SDF 1997\\) , Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag. \u21a9","title":"Traversal Combinators"},{"location":"background/stratego/strategy-combinators/traversal/#traversal-combinators","text":"There are many ways to traverse a tree. For example, a bottom-up traversal, visits the subterms of a node before it visits the node itself, while a top-down traversal visits nodes before it visits children. One-pass traversals traverse the tree one time, while fixed-point traversals, such as innermost, repeatedly traverse a term until a normal form is reached. Rather than provide built-in implementations for all traversals needed in transformations, Stratego defines traversals in terms of the primitive ingredients of traversal. For example, a top-down, one-pass traversal strategy will first visit a node, and then descend to the children of a node in order to recursively traverse all subterms. Similarly, the bottom-up, fixed-point traversal strategy innermost, will first descend to the children of a node in order to recursively traverse all subterms, then visit the node itself, and possibly recursively reapply the strategy. Traversal in Stratego is based on the observation 1 that a full term traversal is a recursive closure of a one-step descent, that is, an operation that applies a strategy to one or more direct subterms of the subject term. By separating this one-step descent operator from recursion, and making it a first-class operation, many different traversals can be defined. Here we explore the ways in which Stratego supports the definition of traversal strategies. We start with explicitly programmed traversals using recursive traversal rules. Next, congruences operators provide a more concise notation for such data-type specific traversal rules. Finally, generic traversal operators support data type independent definitions of traversals, which can be reused for any data type. Given these basic mechanisms, we conclude with an exploration of idioms for traversal and standard traversal strategies in the Stratego Library.","title":"Traversal Combinators"},{"location":"background/stratego/strategy-combinators/traversal/#congruence-operators","text":"Congruence operators provide a convenient abbreviation of traversal with rewrite rules . A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor c declared in a signature, there is a corresponding congruence operator c(s1 , ..., sn) , which applies to terms of the form c(t1 , ..., tn) by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match. For example, consider the following signature of expressions: module expressions signature sorts Exp constructors Int : String - > Exp Var : String - > Exp Plus : Exp * Exp - > Exp Times : Exp * Exp - > Exp The following applications apply the congruence operators Plus and Times to a term: < Plus ( ! Var ( \"a\" ), id )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < Times ( id , ! Int ( \"42\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor.","title":"Congruence Operators"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-congruences","text":"Since congruence operators define a one-step traversal for a specific constructor, they capture the pattern of traversal rules . That is, a traversal rule such as proptr ( s ) : And ( x , y ) - > And (< s > x , < s > y ) can be written by the congruence And(s,s) . Applying this to the prop-dnf program we can replace the traversal rules by congruences as follows: module prop-dnf10 imports prop-rules strategies proptr ( s ) = Not ( s ) < + And ( s , s ) < + Or ( s , s ) < + Impl ( s , s ) < + Eq ( s , s ) propbu ( s ) = try ( proptr ( propbu ( s ))); s strategies dnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = propbu ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf ))","title":"Defining Traversals with Congruences"},{"location":"background/stratego/strategy-combinators/traversal/#traversing-tuples-and-lists","text":"Congruences can also be applied to tuples, (s1,s2,...,sn) , and lists, [s1,s2,...,sn] . A special list congruence is [] which \u2018visits\u2019 the empty list. As an example, consider again the definition of map(s) using recursive traversal rules: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] Using list congruences we can define this strategy as: map ( s ) = [] < + [ s | map ( s )] The [] congruence matches an empty list. The [s | map(s)] congruence matches a non-empty list, and applies s to the head of the list and map(s) to the tail. Thus, map(s) applies s to each element of a list: < map ( inc )> [ 1 , 2 , 3 ] => [ 2 , 3 , 4 ] Note that map(s) only succeeds if s succeeds for each element of the list. The fetch and filter strategies are variations on map that use the failure of s to list elements. fetch ( s ) = [ s | id ] < + [ id | fetch ( s )] The fetch strategy traverses a list until it finds a element for which s succeeds and then stops. That element is the only one that is transformed. filter ( s ) = [] + ([ s | filter ( s )] < + ? [ |< id >]; filter ( s )) The filter strategy applies s to each element of a list, but only keeps the elements for which it succeeds. even = where (< eq >(< mod >(< id >, 2 ), 0 )) < filter ( even )> [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ] => [ 2 , 4 , 6 , 8 ]","title":"Traversing Tuples and Lists"},{"location":"background/stratego/strategy-combinators/traversal/#format-checking","text":"Another application of congruences is in the definition of format checkers. A format checker describes a subset of a term language using a recursive pattern. This can be used to verify input or output of a transformation, and for documentation purposes. Format checkers defined with congruences can check subsets of signatures or regular tree grammars. For example, the subset of terms of a signature in a some normal form. As an example, consider checking the output of the dnf and cnf transformations. conj ( s ) = And ( conj ( s ), conj ( s )) < + s disj ( s ) = Or ( disj ( s ), disj ( s )) < + s // Conjunctive normal form conj-nf = conj ( disj ( Not ( Atom ( id )) < + Atom ( id ))) // Disjunctive normal form disj-nf = disj ( conj ( Not ( Atom ( id )) < + Atom ( id ))) The strategies conj(s) and disj(s) check that the subject term is a conjunct or a disjunct, respectively, with terms satisfying s at the leaves. The strategies conj-nf and disj-nf check that the subject term is in conjunctive or disjunctive normal form, respectively.","title":"Format Checking"},{"location":"background/stratego/strategy-combinators/traversal/#generic-traversal","text":"Using congruence operators we constructed a generic, i.e. transformation independent, bottom-up traversal for proposition terms. The same can be done for other data types. However, since the sets of constructors of abstract syntax trees of typical programming languages can be quite large, this may still amount to quite a bit of work that is not reusable across data types; even though a strategy such as bottom-up traversal, is basically data-type independent. Thus, Stratego provides generic traversal by means of several generic one-step descent operators. The operator all , applies a strategy to all direct subterms. The operator one , applies a strategy to one direct subterm, and the operator some , applies a strategy to as many direct subterms as possible, and at least one.","title":"Generic Traversal"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-all-subterms","text":"The all(s) strategy transforms a constructor application by applying the parameter strategy s to each direct subterm. An application of all(s) fails if the application to one of the subterms fails. The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms. That is, it is not possible to do something special for a particular subterm (that\u2019s what congruences are for). < all ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Var ( \"a\" )) < all ( ! Var ( \"z\" ))> Times ( Var ( \"b\" ), Int ( \"3\" )) => Times ( Var ( \"z\" ), Var ( \"z\" ))","title":"Visiting All Subterms"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-all","text":"The all(s) operator is really the ultimate replacement for the traversal with rules idiom. Instead of specifying a rule or congruence for each constructor, the single application of the all operator takes care of traversing all constructors. Thus, we can replace the propbu strategy by a completely generic definition of bottom-up traversal. Consider again the last definition of propbu : proptr ( s ) = Not ( s ) < + And ( s , s ) < + Or ( s , s ) < + Impl ( s , s ) < + Eq ( s , s ) propbu ( s ) = try ( proptr ( propbu ( s ))); s The role of proptr(s) in this definition can be replaced by all(s) , since that achieves exactly the same, namely applying s to the direct subterms of constructors: propbu ( s ) = all ( propbu ( s )); s Moreover, all succeeds on any constructor in any signature, so we can also drop the try as well, which was there only because proptr fails on the Atom(...) , True() , and False() nodes at the leaves. However, the strategy now is completely generic, i.e. independent of the particular structure it is applied to. In the Stratego Library this strategy is called bottomup(s) , and defined as follows: bottomup ( s ) = all ( bottomup ( s )); s It first recursively transforms the subterms of the subject term and then applies s to the result. Using this definition, the normalization of propositions now reduces to the following module, which is only concerned with the selection and composition of rewrite rules: module prop-dnf11 imports prop-rules strategies dnf = bottomup ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ); dnf )) cnf = bottomup ( try ( DN < + ( DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ); cnf )) In fact, these definitions still contain a reusable pattern. With a little squinting we see that the definitions match the following pattern: dnf = bottomup ( try ( dnf-rules ; dnf )) cnf = bottomup ( try ( cnf-rules ; cnf )) In which we can recognize the definition of innermost reduction, which the Stratego Library defines as: innermost ( s ) = bottomup ( try ( s ; innermost ( s ))) The innermost strategy performs a bottom-up traversal of a term. After transforming the subterms of a term it tries to apply the transformation s . If successful the result is recursively transformed with an application of innermost . This brings us to the final form for the proposition normalizations: module prop-dnf12 imports prop-rules strategies dnf = innermost ( DN < + DefI < + DefE < + DMA < + DMO < + DAOL < + DAOR ) cnf = innermost ( DN < + DefI < + DefE < + DMA < + DMO < + DOAL < + DOAR ) Different transformations can be achieved by using a selection of rules and a strategy, which is generic, yet defined in Stratego itself using strategy combinators.","title":"Defining Traversals with All"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-one-subterm","text":"The one(s) strategy transforms a constructor application by applying the parameter strategy s to exactly one direct subterm. An application of one(s) fails if the application to all of the subterms fails. The following applications illustrate the behavior of the combinator: < one ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < one ( \\ Int ( x ) - > Int (< addS >( x , \"1\" )) \\ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"4\" )) < one ( ? Plus ( _ , _ ))> Plus ( Var ( \"a\" ), Int ( \"4\" )) // fails","title":"Visiting One Subterm"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-one","text":"A frequently used application of one is the oncetd(s) traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied. oncetd ( s ) = s < + one ( oncetd ( s )) Thus, s is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to oncetd(s) . An application of oncetd is the contains(|t) strategy, which checks whether the subject term contains a subterm that is equal to t. contains (| t ) = oncetd ( ? t ) Through the depth first search of oncetd , either an occurrence of t is found, or all subterms are verified to be unequal to t . Here are some other one-pass traversals using the one combinator: oncebu ( s ) = one ( oncebu ( s )) < + s spinetd ( s ) = s ; try ( one ( spinetd ( s ))) spinebu ( s ) = try ( one ( spinebu ( s ))); s Here are some fixe-point traversals, i.e., traversals that apply their argument transformation exhaustively to the subject term. reduce ( s ) = repeat ( rec x ( one ( x ) + s )) outermost ( s ) = repeat ( oncetd ( s )) innermostI ( s ) = repeat ( oncebu ( s )) The difference is the subterm selection strategy.","title":"Defining Traversals with One"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-some-subterms","text":"The some(s) strategy transforms a constructor application by applying the parameter strategy s to as many direct subterms as possible and at least one. An application of some(s) fails if the application to all of the subterms fails. Some one-pass traversals based on some: sometd ( s ) = s < + some ( sometd ( s )) somebu ( s ) = some ( somebu ( s )) < + s A fixed-point traversal with some: reduce-par ( s ) = repeat ( rec x ( some ( x ) + s ))","title":"Visiting Some Subterms"},{"location":"background/stratego/strategy-combinators/traversal/#references","text":"Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2 nd International Workshop on the Theory and Practice of Algebraic Specifications \\(ASF\\+SDF 1997\\) , Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag. \u21a9","title":"References"},{"location":"background/stratego/strategy-combinators/type-unifying/","text":"Type Unifying Traversal \u00b6 In this section we consider the class of type unifying strategies, in which terms of different types are mapped onto one type. The application area for this type of strategy is analysis of expressions with examples such as free variables collection and call-graph extraction. We consider the following example problems: term-size : Count the number of nodes in a term occurrences : Count number of occurrences of a subterm in a term collect-vars : Collect all variables in expression free-vars : Collect all free variables in expression These problems have in common that they reduce a structure to a single value or to a collection of derived values. The structure of the original term is usually lost. We start with examining these problems in the context of lists, and then generalize the solutions we find there to arbitrary terms using generic term deconstruction , which allows concise implementation of generic type unifying strategies. Type Unifying List Transformations \u00b6 We start with considering type-unifying operations on lists. Sum \u00b6 Reducing a list to a value can be conveniently expressed by means of a fold , which has as parameters operations for reducing the list constructors. The foldr/2 strategy reduces a list by replacing each Cons by an application of s2 , and the empty list by s1 . foldr ( s1 , s2 ) = []; s1 < + \\ [ y | ys ] - > < s2 >( y , < foldr ( s1 , s2 )> ys ) \\ Thus, when applied to a list with three terms the result is < foldr ( s1 , s2 )> [ t1 , t2 , t3 ] => < s2 >( t1 , < s2 >( t2 , < s2 >( t3 , < s1 > []))) A typical application of foldr/2 is sum , which reduces a list to the sum of its elements. It sums the elements of a list of integers, using 0 for the empty list and add to combine the head of a list and the result of folding the tail. sum = foldr ( ! 0 , add ) The effect of sum is illustrated by the following application: < foldr ( ! 0 , add )> [ 1 , 2 , 3 ] => < add >( 1 , < add >( 2 , < add >( 3 , < ! 0 > []))) => 6 Note the build operator for replacing the empty list with 0 ; writing foldr(0, add) would be wrong, since 0 by itself is a congruence operator, which basically matches the subject term with the term 0 (rather than replacing it). Size \u00b6 The foldr/2 strategy does not touch the elements of a list. The foldr/3 strategy is a combination of fold and map that extends foldr/2 with a parameter that is applied to the elements of the list. foldr ( s1 , s2 , f ) = []; s1 < + \\ [ y | ys ] - > < s2 >(< f > y , < foldr ( s1 , s2 , f )> ys ) \\ Thus, when applying it to a list with three elements, we get: < foldr ( s1 , s2 )> [ t1 , t2 , t3 ] => < s2 >(< f > t1 , < s2 >(< f > t2 , < s2 >(< f > t3 , < s1 > []))) Now we can solve our first example problem term-size . The size of a list is its length, which corresponds to the sum of the list with the elements replaced by 1 . length = foldr ( ! 0 , add , ! 1 ) Number of occurrences \u00b6 The number of occurrences in a list of terms that satisfy some predicate, entails only counting those elements in the list for which the predicate succeeds. (Where a predicate is implemented with a strategy that succeeds only for the elements in the domain of the predicate.) This follows the same pattern as counting the length of a list, but now only counting the elements for which s succeeds. list-occurrences ( s ) = foldr ( ! 0 , add , s < ! 1 + ! 0 ) Using list-occurrences and a match strategy we can count the number of variables in a list: list-occurrences ( ? Var ( _ )) Collect \u00b6 The next problem is to collect all terms for which a strategy succeeds. We have already seen how to do this for lists. The filter strategy reduces a list to the elements for which its argument strategy succeeds. filter ( s ) = [] < + [ s | filter ( s )] < + ? [ |< filter ( s )>] Collecting the variables in a list is a matter of filtering with the ?Var(_) match. filter ( ? Var ( _ )) The final problem, collecting the free variables in a term, does not really have a counter part in lists, but we can mimick this if we consider having two lists; where the second list is the one with the bound variables that should be excluded. ( filter ( ? Var ( _ )), id ); diff This collects the variables in the first list and subtracts the variables in the second list. Extending Fold to Expressions \u00b6 We have seen how to do typical analysis transformations on lists. How can we generalize this to arbitrary terms? The general idea of a folding operator is that it replaces the constructors of a data-type by applying a function to combine the reduced arguments of constructor applications. For example, the following definition is a sketch for a fold over abstract syntax trees: fold-exp ( binop , assign , if , ... ) = rec f ( fold-binop ( f , binop ) < + fold-assign ( f , assign ) < + fold-if ( f , if ) < + ... ) fold-binop ( f , s ) : BinOp ( op , e1 , e2 ) - > < s >( op , < f > e1 , < f > e2 ) fold-assign ( f , s ) : Assign ( e1 , e2 ) - > < s >(< f > e1 , < f > e2 ) fold-if ( f , s ) : If ( e1 , e2 , e3 ) - > < s >(< f > e1 , < f > e2 , < f > e3 ) For each constructor of the data-type the fold has an argument strategy and a rule that matches applications of the constructor, which it replaces with an application of the strategy to the tuple of subterms reduced by a recursive invocation of the fold. Instantiation of this strategy requires a rule for each constructor of the data-type. For instance, the following instantiation defines term-size using fold-exp by providing rules that sum up the sizes of the subterms and add one ( inc ) to account for the node itself. term-size = fold-exp ( BinOpSize , AssignSize , IfSize , ... ) BinOpSize : ( Plus (), e1 , e2 ) - > < add ; inc >( e1 , e2 ) AssignSize : ( e1 , e2 ) - > < add ; inc >( e1 , e2 ) IfSize : ( e1 , e2 , e3 ) - > < add ; inc >( e1 , < add >( e2 , e3 )) This looks suspiciously like the traversal with rules pattern. Defining folds in this manner has several limitations. In the definition of fold, one parameter for each constructor is provided and traversal is defined explicitly for each constructor. Furthermore, in the instantiation of fold, one rule for each constructor is needed, and the default behaviour is not generically specified. One solution would be to use the generic traversal strategy bottomup to deal with fold: fold-exp ( s ) = bottomup ( s ) term-size = fold-exp ( BinOpSize < + AssignSize < + IfSize < + ... ) BinOpSize : BinOp ( Plus (), e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) AssignSize : Assign ( e1 , e2 ) - > < add >( e1 , e2 ) IfSize : If ( e1 , e2 , e3 ) - > < add >( e1 , < add >( e2 , e3 )) Although the recursive application to subterms is now defined generically, one still has to specify rules for the default behavior. Generic Term Deconstruction \u00b6 Instead of having folding rules that are specific to a data type, such as BinOpSize : BinOp ( op , e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) AssignSize : Assign ( e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) we would like to have a generic definition of the form CSize : c ( e1 , e2 , ... ) - > < add >( e1 , < add >( e2 , ... )) This requires generic decomposition of a constructor application into its constructor and the list with children. This can be done using the # operator. The match strategy ?p1#(p2) decomposes a constructor application into its constructor name and the list of direct subterms. Matching such a pattern against a term of the form C(t1,...,tn) results in a match of \"C\" against p1 and a match of [t1,...,tn] against p2 . < ? c # ( xs )> Plus ( Int ( \"1\" ), Var ( \"2\" )) // variable c bound to \"Plus\" // variable xs bound to [Int(\"1\"), Var(\"2\")] Crush \u00b6 Using generic term deconstruction we can generalize the type unifying operations on lists to arbitrary terms. In analogy with the generic traversal operators we need a generic one-level reduction operator. The crush/3 strategy reduces a constructor application by folding the list of its subterms using foldr/3 . crush ( nul , sum , s ) : c # ( xs ) - > < foldr ( nul , sum , s )> xs Thus, crush performs a fold-map over the direct subterms of a term as illustrated by the following application: < crush ( s1 , s2 , f )> C ( t1 , t2 ) => < s2 >(< f > t1 , < s2 >(< f > t2 , < s1 >[])) The following application instantiates this application in two ways: < crush ( id , id , id )> Plus ( Int ( \"1\" ), Var ( \"2\" )) => ( Int ( \"1\" ),( Var ( \"2\" ),[])) < crush ( ! Tail (< id >), ! Sum (< Fst >,< Snd >), ! Arg (< id >))> Plus ( Int ( \"1\" ), Var ( \"2\" )) => Sum ( Arg ( Int ( \"1\" )), Sum ( Arg ( Var ( \"2\" )), Tail ([]))) The crush strategy is the tool we need to implement solutions for the example problems above. Size \u00b6 Counting the number of direct subterms of a term is similar to counting the number of elements of a list. The definition of node-size is the same as the definition of length , except that it uses crush instead of foldr : node-size = crush ( ! 0 , add , ! 1 ) Counting the number of subterms (nodes) in a term is a similar problem. But, instead of counting each direct subterm as 1 , we need to count its subterms. term-size = crush ( ! 1 , add , term-size ) The term-size strategy achieves this simply with a recursive call to itself. < node-size > Plus ( Int ( \"1\" ), Var ( \"2\" )) => 2 < term-size > Plus ( Int ( \"1\" ), Var ( \"2\" )) => 5 Occurrences \u00b6 Counting the number of occurrences of a certain term in another term, or more generally, counting the number of subterms that satisfy some predicate is similar to counting the term size. However, only those terms satisfying the predicate should be counted. The solution is again similar to the solution for lists, but now using crush. om-occurrences ( s ) = s < ! 1 + crush ( ! 0 , add , om-occurrences ( s )) The om-occurrences strategy counts the outermost subterms satisfying s . That is, the strategy stops counting as soon as it finds a subterm for which s succeeds. The following strategy counts all occurrences: occurrences ( s ) = < add >(< s < ! 1 + ! 0 >, < crush ( ! 0 , add , occurrences ( s ))>) It counts the current term if it satisfies s and adds that to the occurrences in the subterms. < om-occurrences ( ? Int ( _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 2 < om-occurrences ( ? Plus ( _ , _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 1 < occurrences ( ? Plus ( _ , _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 2 Collect \u00b6 Collecting the subterms that satisfy a predicate is similar to counting, but now a list of subterms is produced. The collect(s) strategy collects all outermost occurrences satisfying s . collect ( s ) = ! [< s >] < + crush ( ! [], union , collect ( s )) When encountering a subterm for which s succeeds, a singleton list is produced. For other terms, the matching subterms are collected for each direct subterm, and the resulting lists are combined with union to remove duplicates. A typical application of collect is the collection of all variables in an expression, which can be defined as follows: get-vars = collect ( ? Var ( _ )) Applying get-vars to an expression AST produces the list of all subterms matching Var(_) . The collect-all(s) strategy collects all occurrences satisfying s. collect-all ( s ) = ! [< s > | < crush ( ! [], union , collect ( s ))>] < + crush ( ! [], union , collect ( s )) If s succeeds for the subject term combines the subject term with the collected terms from the subterms. Free Variables \u00b6 Collecting the variables in an expression is easy, as we saw above. However, when dealing with languages with variable bindings, a common operation is to extract only the free variables in an expression or block of statements. That is, the occurrences of variables that are not bound by a variable declaration. For example, in the expression x + let var y := x + 1 in f ( y , a + x + b ) end the free variables are {x, a, b} , but not y , since it is bound by the declaration in the let. Similarly, in the function definition function f ( x : int ) = let var y := h ( x ) in x + g ( z ) * y end the only free variable is z since x and y are declared. Here is a free variable extraction strategy for Tiger expressions. The crush alternative takes care of the non-special constructors, while ExpVars and FreeVars deal with the special cases, i.e. variables and variable binding constructs: free-vars = ExpVars < + FreeVars ( free-vars ) < + crush ( ! [], union , free-vars ) ExpVars : Var ( x ) - > [ x ] FreeVars ( fv ) : Let ([ VarDec ( x , t , e1 )], e2 ) - > < union >(< fv > e1 , < diff >(< fv > e2 , [ x ])) FreeVars ( fv ) : Let ([ FunctionDec ( fdecs )], e2 ) - > < diff >(< union >(< fv > fdecs , < fv > e2 ), fs ) where < map ( ? FunDec (< id >, _ , _ , _ ))> fdecs => fs FreeVars ( fv ) : FunDec ( f , xs , t , e ) - > < diff >(< fv > e , xs ) where < map ( Fst )> xs => xs The FreeVars rules for binding constructs use their fv parameter to recursively get the free variables from subterms, and they subtract the bound variables from any free variables found using diff. We can even capture the pattern exhibited here in a generic collection algorithm with support for special cases: collect-exc ( base , special : ( a - > b ) * a - > b ) = base < + special ( collect-exc ( base , special )) < + crush ( ! [], union , collect-exc ( base , special )) The special parameter is a strategy parameterized with a recursive call to the collection strategy. The original definition of free-vars above, can now be replaced with free-vars = collect-exc ( ExpVars , FreeVars ) Generic Term Construction \u00b6 It can also be useful to construct terms generically. For example, in parse tree implosion, application nodes should be reduced to constructor applications. Hence build operators can also use the # operator. In a strategy !p1#(p2) , the current subject term is replaced by a constructor application, where the constructor name is provided by p1 and the list of subterms by p2 . So, if p1 evaluates to \"C\" and p2 evaluates to [t1,...,tn] , the expression !p1#(p2) build the term C(t1,...,tn) . Imploding Parse Trees \u00b6 A typical application of generic term construction is the implosion of parse trees to abstract syntax trees performed by implode-asfix . Parse trees produced by sglr have the form: appl ( prod ( sorts , sort , attrs ([ cons ( \"C\" )])),[ t1 , ... , tn ]) That is, a node in a parse tree consists of an encoding of the original production from the syntax definition, and a list with subtrees. The production includes a constructor annotation cons(\"C\") with the name of the abstract syntax tree constructor. Such a tree node should be imploded to an abstract syntax tree node of the form C(t1,...,tn) . Thus, this requires the construction of a term with constructor C given the string with its name. The following implosion strategy achieves this using generic term construction: implode = appl ( id , map ( implode )); Implode Implode : appl ( prod ( sorts , sort , attrs ([ cons ( c )])), ts ) - > c # ( ts ) The Implode rule rewrites an appl term to a constructor application, by extracting the constructor name from the production and then using generic term construction to apply the constructor. Note that this is a gross over simplification of the actual implementation of implode-asfix . See the source code for the full strategy. Generic term construction and deconstruction support the definition of generic analysis and generic translation problems. The generic solutions for the example problems term size, number of occurrences, and subterm collection demonstrate the general approach to solving these types of problems.","title":"Type Unifying Traversal"},{"location":"background/stratego/strategy-combinators/type-unifying/#type-unifying-traversal","text":"In this section we consider the class of type unifying strategies, in which terms of different types are mapped onto one type. The application area for this type of strategy is analysis of expressions with examples such as free variables collection and call-graph extraction. We consider the following example problems: term-size : Count the number of nodes in a term occurrences : Count number of occurrences of a subterm in a term collect-vars : Collect all variables in expression free-vars : Collect all free variables in expression These problems have in common that they reduce a structure to a single value or to a collection of derived values. The structure of the original term is usually lost. We start with examining these problems in the context of lists, and then generalize the solutions we find there to arbitrary terms using generic term deconstruction , which allows concise implementation of generic type unifying strategies.","title":"Type Unifying Traversal"},{"location":"background/stratego/strategy-combinators/type-unifying/#type-unifying-list-transformations","text":"We start with considering type-unifying operations on lists.","title":"Type Unifying List Transformations"},{"location":"background/stratego/strategy-combinators/type-unifying/#sum","text":"Reducing a list to a value can be conveniently expressed by means of a fold , which has as parameters operations for reducing the list constructors. The foldr/2 strategy reduces a list by replacing each Cons by an application of s2 , and the empty list by s1 . foldr ( s1 , s2 ) = []; s1 < + \\ [ y | ys ] - > < s2 >( y , < foldr ( s1 , s2 )> ys ) \\ Thus, when applied to a list with three terms the result is < foldr ( s1 , s2 )> [ t1 , t2 , t3 ] => < s2 >( t1 , < s2 >( t2 , < s2 >( t3 , < s1 > []))) A typical application of foldr/2 is sum , which reduces a list to the sum of its elements. It sums the elements of a list of integers, using 0 for the empty list and add to combine the head of a list and the result of folding the tail. sum = foldr ( ! 0 , add ) The effect of sum is illustrated by the following application: < foldr ( ! 0 , add )> [ 1 , 2 , 3 ] => < add >( 1 , < add >( 2 , < add >( 3 , < ! 0 > []))) => 6 Note the build operator for replacing the empty list with 0 ; writing foldr(0, add) would be wrong, since 0 by itself is a congruence operator, which basically matches the subject term with the term 0 (rather than replacing it).","title":"Sum"},{"location":"background/stratego/strategy-combinators/type-unifying/#size","text":"The foldr/2 strategy does not touch the elements of a list. The foldr/3 strategy is a combination of fold and map that extends foldr/2 with a parameter that is applied to the elements of the list. foldr ( s1 , s2 , f ) = []; s1 < + \\ [ y | ys ] - > < s2 >(< f > y , < foldr ( s1 , s2 , f )> ys ) \\ Thus, when applying it to a list with three elements, we get: < foldr ( s1 , s2 )> [ t1 , t2 , t3 ] => < s2 >(< f > t1 , < s2 >(< f > t2 , < s2 >(< f > t3 , < s1 > []))) Now we can solve our first example problem term-size . The size of a list is its length, which corresponds to the sum of the list with the elements replaced by 1 . length = foldr ( ! 0 , add , ! 1 )","title":"Size"},{"location":"background/stratego/strategy-combinators/type-unifying/#number-of-occurrences","text":"The number of occurrences in a list of terms that satisfy some predicate, entails only counting those elements in the list for which the predicate succeeds. (Where a predicate is implemented with a strategy that succeeds only for the elements in the domain of the predicate.) This follows the same pattern as counting the length of a list, but now only counting the elements for which s succeeds. list-occurrences ( s ) = foldr ( ! 0 , add , s < ! 1 + ! 0 ) Using list-occurrences and a match strategy we can count the number of variables in a list: list-occurrences ( ? Var ( _ ))","title":"Number of occurrences"},{"location":"background/stratego/strategy-combinators/type-unifying/#collect","text":"The next problem is to collect all terms for which a strategy succeeds. We have already seen how to do this for lists. The filter strategy reduces a list to the elements for which its argument strategy succeeds. filter ( s ) = [] < + [ s | filter ( s )] < + ? [ |< filter ( s )>] Collecting the variables in a list is a matter of filtering with the ?Var(_) match. filter ( ? Var ( _ )) The final problem, collecting the free variables in a term, does not really have a counter part in lists, but we can mimick this if we consider having two lists; where the second list is the one with the bound variables that should be excluded. ( filter ( ? Var ( _ )), id ); diff This collects the variables in the first list and subtracts the variables in the second list.","title":"Collect"},{"location":"background/stratego/strategy-combinators/type-unifying/#extending-fold-to-expressions","text":"We have seen how to do typical analysis transformations on lists. How can we generalize this to arbitrary terms? The general idea of a folding operator is that it replaces the constructors of a data-type by applying a function to combine the reduced arguments of constructor applications. For example, the following definition is a sketch for a fold over abstract syntax trees: fold-exp ( binop , assign , if , ... ) = rec f ( fold-binop ( f , binop ) < + fold-assign ( f , assign ) < + fold-if ( f , if ) < + ... ) fold-binop ( f , s ) : BinOp ( op , e1 , e2 ) - > < s >( op , < f > e1 , < f > e2 ) fold-assign ( f , s ) : Assign ( e1 , e2 ) - > < s >(< f > e1 , < f > e2 ) fold-if ( f , s ) : If ( e1 , e2 , e3 ) - > < s >(< f > e1 , < f > e2 , < f > e3 ) For each constructor of the data-type the fold has an argument strategy and a rule that matches applications of the constructor, which it replaces with an application of the strategy to the tuple of subterms reduced by a recursive invocation of the fold. Instantiation of this strategy requires a rule for each constructor of the data-type. For instance, the following instantiation defines term-size using fold-exp by providing rules that sum up the sizes of the subterms and add one ( inc ) to account for the node itself. term-size = fold-exp ( BinOpSize , AssignSize , IfSize , ... ) BinOpSize : ( Plus (), e1 , e2 ) - > < add ; inc >( e1 , e2 ) AssignSize : ( e1 , e2 ) - > < add ; inc >( e1 , e2 ) IfSize : ( e1 , e2 , e3 ) - > < add ; inc >( e1 , < add >( e2 , e3 )) This looks suspiciously like the traversal with rules pattern. Defining folds in this manner has several limitations. In the definition of fold, one parameter for each constructor is provided and traversal is defined explicitly for each constructor. Furthermore, in the instantiation of fold, one rule for each constructor is needed, and the default behaviour is not generically specified. One solution would be to use the generic traversal strategy bottomup to deal with fold: fold-exp ( s ) = bottomup ( s ) term-size = fold-exp ( BinOpSize < + AssignSize < + IfSize < + ... ) BinOpSize : BinOp ( Plus (), e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) AssignSize : Assign ( e1 , e2 ) - > < add >( e1 , e2 ) IfSize : If ( e1 , e2 , e3 ) - > < add >( e1 , < add >( e2 , e3 )) Although the recursive application to subterms is now defined generically, one still has to specify rules for the default behavior.","title":"Extending Fold to Expressions"},{"location":"background/stratego/strategy-combinators/type-unifying/#generic-term-deconstruction","text":"Instead of having folding rules that are specific to a data type, such as BinOpSize : BinOp ( op , e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) AssignSize : Assign ( e1 , e2 ) - > < add >( 1 , < add >( e1 , e2 )) we would like to have a generic definition of the form CSize : c ( e1 , e2 , ... ) - > < add >( e1 , < add >( e2 , ... )) This requires generic decomposition of a constructor application into its constructor and the list with children. This can be done using the # operator. The match strategy ?p1#(p2) decomposes a constructor application into its constructor name and the list of direct subterms. Matching such a pattern against a term of the form C(t1,...,tn) results in a match of \"C\" against p1 and a match of [t1,...,tn] against p2 . < ? c # ( xs )> Plus ( Int ( \"1\" ), Var ( \"2\" )) // variable c bound to \"Plus\" // variable xs bound to [Int(\"1\"), Var(\"2\")]","title":"Generic Term Deconstruction"},{"location":"background/stratego/strategy-combinators/type-unifying/#crush","text":"Using generic term deconstruction we can generalize the type unifying operations on lists to arbitrary terms. In analogy with the generic traversal operators we need a generic one-level reduction operator. The crush/3 strategy reduces a constructor application by folding the list of its subterms using foldr/3 . crush ( nul , sum , s ) : c # ( xs ) - > < foldr ( nul , sum , s )> xs Thus, crush performs a fold-map over the direct subterms of a term as illustrated by the following application: < crush ( s1 , s2 , f )> C ( t1 , t2 ) => < s2 >(< f > t1 , < s2 >(< f > t2 , < s1 >[])) The following application instantiates this application in two ways: < crush ( id , id , id )> Plus ( Int ( \"1\" ), Var ( \"2\" )) => ( Int ( \"1\" ),( Var ( \"2\" ),[])) < crush ( ! Tail (< id >), ! Sum (< Fst >,< Snd >), ! Arg (< id >))> Plus ( Int ( \"1\" ), Var ( \"2\" )) => Sum ( Arg ( Int ( \"1\" )), Sum ( Arg ( Var ( \"2\" )), Tail ([]))) The crush strategy is the tool we need to implement solutions for the example problems above.","title":"Crush"},{"location":"background/stratego/strategy-combinators/type-unifying/#size_1","text":"Counting the number of direct subterms of a term is similar to counting the number of elements of a list. The definition of node-size is the same as the definition of length , except that it uses crush instead of foldr : node-size = crush ( ! 0 , add , ! 1 ) Counting the number of subterms (nodes) in a term is a similar problem. But, instead of counting each direct subterm as 1 , we need to count its subterms. term-size = crush ( ! 1 , add , term-size ) The term-size strategy achieves this simply with a recursive call to itself. < node-size > Plus ( Int ( \"1\" ), Var ( \"2\" )) => 2 < term-size > Plus ( Int ( \"1\" ), Var ( \"2\" )) => 5","title":"Size"},{"location":"background/stratego/strategy-combinators/type-unifying/#occurrences","text":"Counting the number of occurrences of a certain term in another term, or more generally, counting the number of subterms that satisfy some predicate is similar to counting the term size. However, only those terms satisfying the predicate should be counted. The solution is again similar to the solution for lists, but now using crush. om-occurrences ( s ) = s < ! 1 + crush ( ! 0 , add , om-occurrences ( s )) The om-occurrences strategy counts the outermost subterms satisfying s . That is, the strategy stops counting as soon as it finds a subterm for which s succeeds. The following strategy counts all occurrences: occurrences ( s ) = < add >(< s < ! 1 + ! 0 >, < crush ( ! 0 , add , occurrences ( s ))>) It counts the current term if it satisfies s and adds that to the occurrences in the subterms. < om-occurrences ( ? Int ( _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 2 < om-occurrences ( ? Plus ( _ , _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 1 < occurrences ( ? Plus ( _ , _ ))> Plus ( Int ( \"1\" ), Plus ( Int ( \"34\" ), Var ( \"2\" ))) => 2","title":"Occurrences"},{"location":"background/stratego/strategy-combinators/type-unifying/#collect_1","text":"Collecting the subterms that satisfy a predicate is similar to counting, but now a list of subterms is produced. The collect(s) strategy collects all outermost occurrences satisfying s . collect ( s ) = ! [< s >] < + crush ( ! [], union , collect ( s )) When encountering a subterm for which s succeeds, a singleton list is produced. For other terms, the matching subterms are collected for each direct subterm, and the resulting lists are combined with union to remove duplicates. A typical application of collect is the collection of all variables in an expression, which can be defined as follows: get-vars = collect ( ? Var ( _ )) Applying get-vars to an expression AST produces the list of all subterms matching Var(_) . The collect-all(s) strategy collects all occurrences satisfying s. collect-all ( s ) = ! [< s > | < crush ( ! [], union , collect ( s ))>] < + crush ( ! [], union , collect ( s )) If s succeeds for the subject term combines the subject term with the collected terms from the subterms.","title":"Collect"},{"location":"background/stratego/strategy-combinators/type-unifying/#free-variables","text":"Collecting the variables in an expression is easy, as we saw above. However, when dealing with languages with variable bindings, a common operation is to extract only the free variables in an expression or block of statements. That is, the occurrences of variables that are not bound by a variable declaration. For example, in the expression x + let var y := x + 1 in f ( y , a + x + b ) end the free variables are {x, a, b} , but not y , since it is bound by the declaration in the let. Similarly, in the function definition function f ( x : int ) = let var y := h ( x ) in x + g ( z ) * y end the only free variable is z since x and y are declared. Here is a free variable extraction strategy for Tiger expressions. The crush alternative takes care of the non-special constructors, while ExpVars and FreeVars deal with the special cases, i.e. variables and variable binding constructs: free-vars = ExpVars < + FreeVars ( free-vars ) < + crush ( ! [], union , free-vars ) ExpVars : Var ( x ) - > [ x ] FreeVars ( fv ) : Let ([ VarDec ( x , t , e1 )], e2 ) - > < union >(< fv > e1 , < diff >(< fv > e2 , [ x ])) FreeVars ( fv ) : Let ([ FunctionDec ( fdecs )], e2 ) - > < diff >(< union >(< fv > fdecs , < fv > e2 ), fs ) where < map ( ? FunDec (< id >, _ , _ , _ ))> fdecs => fs FreeVars ( fv ) : FunDec ( f , xs , t , e ) - > < diff >(< fv > e , xs ) where < map ( Fst )> xs => xs The FreeVars rules for binding constructs use their fv parameter to recursively get the free variables from subterms, and they subtract the bound variables from any free variables found using diff. We can even capture the pattern exhibited here in a generic collection algorithm with support for special cases: collect-exc ( base , special : ( a - > b ) * a - > b ) = base < + special ( collect-exc ( base , special )) < + crush ( ! [], union , collect-exc ( base , special )) The special parameter is a strategy parameterized with a recursive call to the collection strategy. The original definition of free-vars above, can now be replaced with free-vars = collect-exc ( ExpVars , FreeVars )","title":"Free Variables"},{"location":"background/stratego/strategy-combinators/type-unifying/#generic-term-construction","text":"It can also be useful to construct terms generically. For example, in parse tree implosion, application nodes should be reduced to constructor applications. Hence build operators can also use the # operator. In a strategy !p1#(p2) , the current subject term is replaced by a constructor application, where the constructor name is provided by p1 and the list of subterms by p2 . So, if p1 evaluates to \"C\" and p2 evaluates to [t1,...,tn] , the expression !p1#(p2) build the term C(t1,...,tn) .","title":"Generic Term Construction"},{"location":"background/stratego/strategy-combinators/type-unifying/#imploding-parse-trees","text":"A typical application of generic term construction is the implosion of parse trees to abstract syntax trees performed by implode-asfix . Parse trees produced by sglr have the form: appl ( prod ( sorts , sort , attrs ([ cons ( \"C\" )])),[ t1 , ... , tn ]) That is, a node in a parse tree consists of an encoding of the original production from the syntax definition, and a list with subtrees. The production includes a constructor annotation cons(\"C\") with the name of the abstract syntax tree constructor. Such a tree node should be imploded to an abstract syntax tree node of the form C(t1,...,tn) . Thus, this requires the construction of a term with constructor C given the string with its name. The following implosion strategy achieves this using generic term construction: implode = appl ( id , map ( implode )); Implode Implode : appl ( prod ( sorts , sort , attrs ([ cons ( c )])), ts ) - > c # ( ts ) The Implode rule rewrites an appl term to a constructor application, by extracting the constructor name from the production and then using generic term construction to apply the constructor. Note that this is a gross over simplification of the actual implementation of implode-asfix . See the source code for the full strategy. Generic term construction and deconstruction support the definition of generic analysis and generic translation problems. The generic solutions for the example problems term size, number of occurrences, and subterm collection demonstrate the general approach to solving these types of problems.","title":"Imploding Parse Trees"},{"location":"howtos/","text":"How-To's \u00b6 These are some How-To's that help you to get to a specific goal or result with Spoofax. For hands-on tutorials on learning Spoofax, see the Tutorials section. For the Spoofax languages references, see the References section. Spoofax Installation \u00b6 Install the Eclipse with Spoofax Plugin Bundle Install the Spoofax Eclipse Plugin Manually Install Spoofax from Source Stratego \u00b6 How to generate Stratego signatures How to run Stratego programs How to generate pretty-printers How to debug Stratego programs Exchange Terms Inspect Terms Editor Services \u00b6 Add Rename Refactoring to an Existing Project Spoofax Development \u00b6 Install Requirements for Spoofax Install Maven for Spoofax Build Spoofax Develop Spoofax Release Spoofax","title":"How-To's"},{"location":"howtos/#how-tos","text":"These are some How-To's that help you to get to a specific goal or result with Spoofax. For hands-on tutorials on learning Spoofax, see the Tutorials section. For the Spoofax languages references, see the References section.","title":"How-To's"},{"location":"howtos/#spoofax-installation","text":"Install the Eclipse with Spoofax Plugin Bundle Install the Spoofax Eclipse Plugin Manually Install Spoofax from Source","title":"Spoofax Installation"},{"location":"howtos/#stratego","text":"How to generate Stratego signatures How to run Stratego programs How to generate pretty-printers How to debug Stratego programs Exchange Terms Inspect Terms","title":"Stratego"},{"location":"howtos/#editor-services","text":"Add Rename Refactoring to an Existing Project","title":"Editor Services"},{"location":"howtos/#spoofax-development","text":"Install Requirements for Spoofax Install Maven for Spoofax Build Spoofax Develop Spoofax Release Spoofax","title":"Spoofax Development"},{"location":"howtos/development/","text":"Spoofax Development \u00b6 This is the reference manual for building and developing Spoofax, as well as information about its internals. Introduction \u00b6 Spoofax is the integration of many different tools, compilers, (meta-)languages, (meta-)libraries, and runtime components. This integration is made concrete in the spoofax-releng Git repository on GitHub. This repository contains all components via Git submodules , which are updated by our build farm that builds Spoofax whenever one of its components in a submodule changes. Spoofax currently contains the following subcomponents as submodules: releng - Release engineering scripts for managing and building the spoofax-releng repostory. Java libraries and runtimes mb-rep \u2014 Libraries for program representation such as abstract terms mb-exec \u2014 Stratego interpreter and utilities jsglr \u2014 JSGLR parser spoofax \u2014 Spoofax Core, a cross platform API to Spoofax languages spoofax-maven \u2014 Maven integration for Spoofax Core spoofax-sunshine \u2014 Command-line integration for Spoofax Core spoofax-eclipse \u2014 Eclipse plugin for Spoofax Core spoofax-intellij \u2014 IntelliJ plugin for Spoofax Core Meta-languages and libraries esv \u2014 Editor service language sdf \u2014 Syntax Definition Formalisms, containing the SDF2 and SDF 3 languages stratego and strategoxt \u2014 Stratego compiler, runtime, and editor nabl \u2014 Name binding languages, containing the NaBL and NaBL2 languages, and support libraries for NaBL2 ts \u2014 Type system language dynsem \u2014 Dynamic semantics language metaborg-coq \u2014 Coq signatures and syntax definition spt \u2014 Spoofax testing language runtime-libraries \u2014 NaBL support libraries, incremental task engine for incremental name and type analysis Furthermore, this repository contains a Bash script ./b that redirects into the Python release engineering scripts in the releng submodule. These scripts support managing this Git repository, version management, generation of Eclipse instances, building Spoofax, and releasing new versions of Spoofax. The following how-tos explain how to set up Maven and other required tools for building and developing Spoofax, how to build and develop Spoofax, how to write this documentation, and explains some of the internals of Spoofax components. Requirements Maven Building Developing Releasing","title":"Spoofax Development"},{"location":"howtos/development/#spoofax-development","text":"This is the reference manual for building and developing Spoofax, as well as information about its internals.","title":"Spoofax Development"},{"location":"howtos/development/#introduction","text":"Spoofax is the integration of many different tools, compilers, (meta-)languages, (meta-)libraries, and runtime components. This integration is made concrete in the spoofax-releng Git repository on GitHub. This repository contains all components via Git submodules , which are updated by our build farm that builds Spoofax whenever one of its components in a submodule changes. Spoofax currently contains the following subcomponents as submodules: releng - Release engineering scripts for managing and building the spoofax-releng repostory. Java libraries and runtimes mb-rep \u2014 Libraries for program representation such as abstract terms mb-exec \u2014 Stratego interpreter and utilities jsglr \u2014 JSGLR parser spoofax \u2014 Spoofax Core, a cross platform API to Spoofax languages spoofax-maven \u2014 Maven integration for Spoofax Core spoofax-sunshine \u2014 Command-line integration for Spoofax Core spoofax-eclipse \u2014 Eclipse plugin for Spoofax Core spoofax-intellij \u2014 IntelliJ plugin for Spoofax Core Meta-languages and libraries esv \u2014 Editor service language sdf \u2014 Syntax Definition Formalisms, containing the SDF2 and SDF 3 languages stratego and strategoxt \u2014 Stratego compiler, runtime, and editor nabl \u2014 Name binding languages, containing the NaBL and NaBL2 languages, and support libraries for NaBL2 ts \u2014 Type system language dynsem \u2014 Dynamic semantics language metaborg-coq \u2014 Coq signatures and syntax definition spt \u2014 Spoofax testing language runtime-libraries \u2014 NaBL support libraries, incremental task engine for incremental name and type analysis Furthermore, this repository contains a Bash script ./b that redirects into the Python release engineering scripts in the releng submodule. These scripts support managing this Git repository, version management, generation of Eclipse instances, building Spoofax, and releasing new versions of Spoofax. The following how-tos explain how to set up Maven and other required tools for building and developing Spoofax, how to build and develop Spoofax, how to write this documentation, and explains some of the internals of Spoofax components. Requirements Maven Building Developing Releasing","title":"Introduction"},{"location":"howtos/development/building/","text":"Building Spoofax \u00b6 This how-to guides you on how to build Spoofax from scratch, via the command-line. Cloning the Source Code \u00b6 Clone the source code from the spoofax-releng repository with the following commands: macOS git clone --recursive https://github.com/metaborg/spoofax-releng.git cd spoofax-releng macOS Catalina, Big Sur, or newer On macOS Catalina, Big Sur, or newer, you have to install coreutils and Docker to be able to build Spoofax. This is temporary, until the 32-bit binaries for sdf2table and implodePT have been phased out. See the requirements for Spoofax Development for more information. Linux git clone --recursive https://github.com/metaborg/spoofax-releng.git cd spoofax-releng Windows git clone - -recursive https :// github . com / metaborg / spoofax-releng . git cd spoofax-releng cd releng \\ releng py -m pip install -r .\\ requirements . txt Cloning and updating submodules can take a while, since we have many submodules and some have a large history. Start a Build \u00b6 To build Spoofax, simply execute: macOS ./b build all Linux ./b build all Windows .\\ bd . bat build all This downloads the latest Stratego/XT, and builds Spoofax. If you also want to build Stratego/XT from scratch, execute: macOS ./b build -st all Linux ./b build -st all Windows .\\ bd . bat build -st all The -s flag build Stratego/XT instead of downloading it, and -t skips the Stratego/XT tests since they are very lengthy. The all part of the command indicates that we want to build all components. For example, if you would only like to build the Java components of Spoofax, and skip the Eclipse plugins, execute: macOS ./b build java Use ./b build to get a list of components available for building, and ./b build --help for help on all the command-line flags and switches. Linux ./b build java Use ./b build to get a list of components available for building, and ./b build --help for help on all the command-line flags and switches. Windows .\\ bd . bat build java Use .\\bd.bat build to get a list of components available for building, and .\\bd.bat build --help for help on all the command-line flags and switches. If you have opened a project in the repository in Eclipse, you must turn off Project \u2023 Build Automatically in Eclipse, otherwise the Maven and Eclipse compilers will interfere and possibly fail the build. After the Maven build is finished, enable Build Automatically again. Updating the Source Code \u00b6 If you want to update the repository and submodules, execute: macOS git pull --rebase ./b checkout ./b update Linux git pull --rebase ./b checkout ./b update Windows git pull - -rebase .\\ bd . bat checkout .\\ bd . bat update The git pull command will update any changes in the main repository. The ./b checkout command will check out the correct branches in all submodules, because Git does not do this automatically. The ./b update command will update all submodules. Switching to a Different Branch \u00b6 Switching to a different branch, for example the spoofax-release branch, is done with the following commands: macOS git checkout spoofax-release git pull --rebase git submodule update --init --remote --recursive ./b checkout ./b update Linux git checkout spoofax-release git pull --rebase git submodule update --init --remote --recursive ./b checkout ./b update Windows git checkout spoofax-release git pull - -rebase git submodule update - -init - -remote - -recursive .\\ bd . bat checkout .\\ bd . bat update Troubleshooting \u00b6 Resetting and Cleaning \u00b6 If updating or checking out a branch of submodule fails (because of unstaged or conflicting changes), you can try to resolve it yourself, or you can reset and clean everything. Reset and clean all submodules using: macOS ./b reset ./b clean Linux ./b checkout ./b update Windows .\\ bd . bat reset .\\ bd . bat clean Risk of loss of data Resetting and cleaning deletes uncommitted and unpushed changes , which can cause permanent data loss . Make sure all your changes are committed and pushed! Weird Compilation Errors \u00b6 If you get any weird compilation errors during the command-line build, make sure that Project \u2023 Build Automatically is turned off in Eclipse.","title":"Building"},{"location":"howtos/development/building/#building-spoofax","text":"This how-to guides you on how to build Spoofax from scratch, via the command-line.","title":"Building Spoofax"},{"location":"howtos/development/building/#cloning-the-source-code","text":"Clone the source code from the spoofax-releng repository with the following commands: macOS git clone --recursive https://github.com/metaborg/spoofax-releng.git cd spoofax-releng macOS Catalina, Big Sur, or newer On macOS Catalina, Big Sur, or newer, you have to install coreutils and Docker to be able to build Spoofax. This is temporary, until the 32-bit binaries for sdf2table and implodePT have been phased out. See the requirements for Spoofax Development for more information. Linux git clone --recursive https://github.com/metaborg/spoofax-releng.git cd spoofax-releng Windows git clone - -recursive https :// github . com / metaborg / spoofax-releng . git cd spoofax-releng cd releng \\ releng py -m pip install -r .\\ requirements . txt Cloning and updating submodules can take a while, since we have many submodules and some have a large history.","title":"Cloning the Source Code"},{"location":"howtos/development/building/#start-a-build","text":"To build Spoofax, simply execute: macOS ./b build all Linux ./b build all Windows .\\ bd . bat build all This downloads the latest Stratego/XT, and builds Spoofax. If you also want to build Stratego/XT from scratch, execute: macOS ./b build -st all Linux ./b build -st all Windows .\\ bd . bat build -st all The -s flag build Stratego/XT instead of downloading it, and -t skips the Stratego/XT tests since they are very lengthy. The all part of the command indicates that we want to build all components. For example, if you would only like to build the Java components of Spoofax, and skip the Eclipse plugins, execute: macOS ./b build java Use ./b build to get a list of components available for building, and ./b build --help for help on all the command-line flags and switches. Linux ./b build java Use ./b build to get a list of components available for building, and ./b build --help for help on all the command-line flags and switches. Windows .\\ bd . bat build java Use .\\bd.bat build to get a list of components available for building, and .\\bd.bat build --help for help on all the command-line flags and switches. If you have opened a project in the repository in Eclipse, you must turn off Project \u2023 Build Automatically in Eclipse, otherwise the Maven and Eclipse compilers will interfere and possibly fail the build. After the Maven build is finished, enable Build Automatically again.","title":"Start a Build"},{"location":"howtos/development/building/#updating-the-source-code","text":"If you want to update the repository and submodules, execute: macOS git pull --rebase ./b checkout ./b update Linux git pull --rebase ./b checkout ./b update Windows git pull - -rebase .\\ bd . bat checkout .\\ bd . bat update The git pull command will update any changes in the main repository. The ./b checkout command will check out the correct branches in all submodules, because Git does not do this automatically. The ./b update command will update all submodules.","title":"Updating the Source Code"},{"location":"howtos/development/building/#switching-to-a-different-branch","text":"Switching to a different branch, for example the spoofax-release branch, is done with the following commands: macOS git checkout spoofax-release git pull --rebase git submodule update --init --remote --recursive ./b checkout ./b update Linux git checkout spoofax-release git pull --rebase git submodule update --init --remote --recursive ./b checkout ./b update Windows git checkout spoofax-release git pull - -rebase git submodule update - -init - -remote - -recursive .\\ bd . bat checkout .\\ bd . bat update","title":"Switching to a Different Branch"},{"location":"howtos/development/building/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"howtos/development/building/#resetting-and-cleaning","text":"If updating or checking out a branch of submodule fails (because of unstaged or conflicting changes), you can try to resolve it yourself, or you can reset and clean everything. Reset and clean all submodules using: macOS ./b reset ./b clean Linux ./b checkout ./b update Windows .\\ bd . bat reset .\\ bd . bat clean Risk of loss of data Resetting and cleaning deletes uncommitted and unpushed changes , which can cause permanent data loss . Make sure all your changes are committed and pushed!","title":"Resetting and Cleaning"},{"location":"howtos/development/building/#weird-compilation-errors","text":"If you get any weird compilation errors during the command-line build, make sure that Project \u2023 Build Automatically is turned off in Eclipse.","title":"Weird Compilation Errors"},{"location":"howtos/development/developing/","text":"Developing Spoofax \u00b6 If you are developing a project that is included in Spoofax, it is recommended to set up a development environment. This how-to describes how to set up such a development environment. A working Spoofax build is required before being able to develop. You must be able to successfully build Spoofax by running ./b build all . Do not continue if this does not work. See the instructions on how to build Spoofax . Eclipse \u00b6 Currently, an Eclipse development environment is the most supported environment. An Eclipse development environment can be generated with our scripts. Generating an Eclipse Instance \u00b6 The ./b script in the spoofax-releng repository can generate an Eclipse installation for you. Change directory into the spoofax-releng repository and run: ./b gen-spoofax -l -d ~/eclipse/spoofax-dev This will download and install Eclipse into ~/eclipse/spoofax-dev with the right plugins and eclipse.ini for Spoofax development. The locally built version of the Spoofax plugin will be installed into that Eclipse. Generating an Eclipse installation can take several minutes. After it\u2019s done generating, open the Eclipse installation and confirm that it works by creating a Spoofax project. Installation failed. Cannot complete the install because of a conflicting dependency If you get an error \"Installation failed. Cannot complete the install because of a conflicting dependency.\" , then make sure there is not an existing Eclipse instance at the destination. macOS: To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime If upon starting Eclipse you get the error \"To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime\" , then you should install a Java JDK 8 or newer for Eclipse to use. If you installed one through SDKMAN! then you have to point Eclipse to it. To do this, edit the Contents/Eclipse/eclipse.ini file in the Eclipse application package content. Add the following lines at the start of the file, where is your username: -vm /Users/<USERNAME>/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib Fixing Eclipse Settings \u00b6 Some Eclipse settings unfortunately have sub-optimal defaults. Go to the Eclipse preferences and set these options: General Enable : Keep next/previous editor, view and perspectives dialog open General \u2023 Startup and Shutdown Enable : Refresh workspace on startup General \u2023 Workspace Enable : Refresh using native hooks or polling Maven Enable : Do not automatically update dependencies from remote repositories Enable : Download Artifact Sources Enable : Download Artifact JavaDoc Maven \u2023 Annotation Processing Enable : Automatically configure JDT APT Maven \u2023 User Interface Enable : Open XML page in the POM editor by default Run/Debug \u2023 Launching Disable : Build (if required) before launching Developing \u00b6 Import the projects you\u2019d like to develop. To import Java and language projects, use Import \u2023 Maven \u2023 Existing Maven Projects . Eclipse plugins are still imported with Import \u2023 General \u2023 Existing Projects into Workspace . Running \u00b6 To test your changes in the Spoofax Eclipse plugin, import the org.metaborg.spoofax.eclipse project from the spoofax-eclipse repository, which provides launch configurations for starting new Eclipse instances (a \u201cguest\u201d Eclipse). Press the little down arrow next to the bug icon (next to the play icon) and choose Spoofax Eclipse Plugin to start a new Eclipse instance that contains your changes. If it is not in the list of recently used configurations, click Debug configurations... , it should be under Eclipse Application configurations . Some tricks: If you change a (meta-)language and want to test it in a new Eclipse instance, import that language\u2019s corresponding Eclipse plugin project. For example, org.metaborg.meta.lang.nabl has Eclipse plugin project org.metaborg.meta.lang.nabl.eclipse . Then compile both those projects from the command-line (don\u2019t forget to turn off Build Automatically in Eclipse), and start a new Eclipse instance. A different way to test the (meta-)language change is to import that language project into the workspace of the guest Eclipse. Because we use Maven snapshot versions, the built-in version will be overridden when you build the language in the guest eclipse. Troubleshooting \u00b6 If there are many errors in a project, try updating the Maven project. Right click the project and choose Maven \u2023 Update Project... , uncheck Clean projects in the new dialog and press OK . This will update the project from the POM file, update any dependencies, and trigger a build. If this does not solve the problems, try it again but this time with Clean projects checked. Note that if you clean a language project, it has to be rebuilt from the command-line. Restarting Eclipse and repeating these steps may also help. Multiple projects can be updated by selecting multiple projects in the package/project explorer, or by checking projects in the update dialog. If you have particular trouble with org.eclipse.* plugins in the MANIFEST.MF file that do not resolve, try the following. Go to Preferences \u2023 Plug-in Development \u2023 Target Platform , most likely there will not be an active Running Platform there. You can use Add... to add a new one if there isn\u2019t one already. Select the Default option, click Next , then click Finish . Check the box next to the platform to activate it. Advanced: Developing from Scratch \u00b6 In some cases it can be beneficial to have full control over all projects, instead of relying on Maven artifacts and the installed Spoofax plugin. To develop completely from scratch, uninstall Spoofax from Eclipse, and import all projects by importing releng/eclipse/import/pom.xml , which will import all relevant projects automatically. If you change a language project, build them on the command-line, because languages cannot be built inside Eclipse without the Spoofax plugin. IntelliJ \u00b6 Easiest is to install the latest release of the Spoofax plugin in an installation of IntelliJ IDEA. Otherwise, you may want to build it from source, and to run the built plugin inside a special sandbox-instance of IntelliJ IDEA, execute the following command: ./gradlew runIdea Alternatively, in IntelliJ IDEA you can invoke the IntelliJ Plugin run/debug configuration. You can use this to run or debug the IntelliJ IDEA plugin code. However, this cannot be used to debug the JPS Spoofax build process. To debug the JPS Spoofax build process, you need to execute the following command: ./gradlew debugJps ...or invoke the IntelliJ Plugin (Debug JPS) run configuration ( not debug ) from IntelliJ. Then in the sandbox IntelliJ IDEA instance you enable the Debug Build Process action ( Ctrl + Shift + A ). Then you start a build. IntelliJ will wait for a debugger to be attached to port 5005. Attach a debugger, and the build will continue. From the Spoofax plugin\u2019s IntelliJ IDEA project, you can invoke the JPS Plugin remote debug configuration to attach the debugger. Logging \u00b6 To get debug logging in IntelliJ, locate the bin/log.xml file in the IntelliJ folder and add the following snippet in the <log4j:configuration> element, just above the <root> element: <category name= \"#org.metaborg\" additivity= \"true\" > <priority value= \"DEBUG\" /> <appender-ref ref= \"CONSOLE-DEBUG\" /> <appender-ref ref= \"FILE\" /> </category>","title":"Developing"},{"location":"howtos/development/developing/#developing-spoofax","text":"If you are developing a project that is included in Spoofax, it is recommended to set up a development environment. This how-to describes how to set up such a development environment. A working Spoofax build is required before being able to develop. You must be able to successfully build Spoofax by running ./b build all . Do not continue if this does not work. See the instructions on how to build Spoofax .","title":"Developing Spoofax"},{"location":"howtos/development/developing/#eclipse","text":"Currently, an Eclipse development environment is the most supported environment. An Eclipse development environment can be generated with our scripts.","title":"Eclipse"},{"location":"howtos/development/developing/#generating-an-eclipse-instance","text":"The ./b script in the spoofax-releng repository can generate an Eclipse installation for you. Change directory into the spoofax-releng repository and run: ./b gen-spoofax -l -d ~/eclipse/spoofax-dev This will download and install Eclipse into ~/eclipse/spoofax-dev with the right plugins and eclipse.ini for Spoofax development. The locally built version of the Spoofax plugin will be installed into that Eclipse. Generating an Eclipse installation can take several minutes. After it\u2019s done generating, open the Eclipse installation and confirm that it works by creating a Spoofax project. Installation failed. Cannot complete the install because of a conflicting dependency If you get an error \"Installation failed. Cannot complete the install because of a conflicting dependency.\" , then make sure there is not an existing Eclipse instance at the destination. macOS: To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime If upon starting Eclipse you get the error \"To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime\" , then you should install a Java JDK 8 or newer for Eclipse to use. If you installed one through SDKMAN! then you have to point Eclipse to it. To do this, edit the Contents/Eclipse/eclipse.ini file in the Eclipse application package content. Add the following lines at the start of the file, where is your username: -vm /Users/<USERNAME>/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib","title":"Generating an Eclipse Instance"},{"location":"howtos/development/developing/#fixing-eclipse-settings","text":"Some Eclipse settings unfortunately have sub-optimal defaults. Go to the Eclipse preferences and set these options: General Enable : Keep next/previous editor, view and perspectives dialog open General \u2023 Startup and Shutdown Enable : Refresh workspace on startup General \u2023 Workspace Enable : Refresh using native hooks or polling Maven Enable : Do not automatically update dependencies from remote repositories Enable : Download Artifact Sources Enable : Download Artifact JavaDoc Maven \u2023 Annotation Processing Enable : Automatically configure JDT APT Maven \u2023 User Interface Enable : Open XML page in the POM editor by default Run/Debug \u2023 Launching Disable : Build (if required) before launching","title":"Fixing Eclipse Settings"},{"location":"howtos/development/developing/#developing","text":"Import the projects you\u2019d like to develop. To import Java and language projects, use Import \u2023 Maven \u2023 Existing Maven Projects . Eclipse plugins are still imported with Import \u2023 General \u2023 Existing Projects into Workspace .","title":"Developing"},{"location":"howtos/development/developing/#running","text":"To test your changes in the Spoofax Eclipse plugin, import the org.metaborg.spoofax.eclipse project from the spoofax-eclipse repository, which provides launch configurations for starting new Eclipse instances (a \u201cguest\u201d Eclipse). Press the little down arrow next to the bug icon (next to the play icon) and choose Spoofax Eclipse Plugin to start a new Eclipse instance that contains your changes. If it is not in the list of recently used configurations, click Debug configurations... , it should be under Eclipse Application configurations . Some tricks: If you change a (meta-)language and want to test it in a new Eclipse instance, import that language\u2019s corresponding Eclipse plugin project. For example, org.metaborg.meta.lang.nabl has Eclipse plugin project org.metaborg.meta.lang.nabl.eclipse . Then compile both those projects from the command-line (don\u2019t forget to turn off Build Automatically in Eclipse), and start a new Eclipse instance. A different way to test the (meta-)language change is to import that language project into the workspace of the guest Eclipse. Because we use Maven snapshot versions, the built-in version will be overridden when you build the language in the guest eclipse.","title":"Running"},{"location":"howtos/development/developing/#troubleshooting","text":"If there are many errors in a project, try updating the Maven project. Right click the project and choose Maven \u2023 Update Project... , uncheck Clean projects in the new dialog and press OK . This will update the project from the POM file, update any dependencies, and trigger a build. If this does not solve the problems, try it again but this time with Clean projects checked. Note that if you clean a language project, it has to be rebuilt from the command-line. Restarting Eclipse and repeating these steps may also help. Multiple projects can be updated by selecting multiple projects in the package/project explorer, or by checking projects in the update dialog. If you have particular trouble with org.eclipse.* plugins in the MANIFEST.MF file that do not resolve, try the following. Go to Preferences \u2023 Plug-in Development \u2023 Target Platform , most likely there will not be an active Running Platform there. You can use Add... to add a new one if there isn\u2019t one already. Select the Default option, click Next , then click Finish . Check the box next to the platform to activate it.","title":"Troubleshooting"},{"location":"howtos/development/developing/#advanced-developing-from-scratch","text":"In some cases it can be beneficial to have full control over all projects, instead of relying on Maven artifacts and the installed Spoofax plugin. To develop completely from scratch, uninstall Spoofax from Eclipse, and import all projects by importing releng/eclipse/import/pom.xml , which will import all relevant projects automatically. If you change a language project, build them on the command-line, because languages cannot be built inside Eclipse without the Spoofax plugin.","title":"Advanced: Developing from Scratch"},{"location":"howtos/development/developing/#intellij","text":"Easiest is to install the latest release of the Spoofax plugin in an installation of IntelliJ IDEA. Otherwise, you may want to build it from source, and to run the built plugin inside a special sandbox-instance of IntelliJ IDEA, execute the following command: ./gradlew runIdea Alternatively, in IntelliJ IDEA you can invoke the IntelliJ Plugin run/debug configuration. You can use this to run or debug the IntelliJ IDEA plugin code. However, this cannot be used to debug the JPS Spoofax build process. To debug the JPS Spoofax build process, you need to execute the following command: ./gradlew debugJps ...or invoke the IntelliJ Plugin (Debug JPS) run configuration ( not debug ) from IntelliJ. Then in the sandbox IntelliJ IDEA instance you enable the Debug Build Process action ( Ctrl + Shift + A ). Then you start a build. IntelliJ will wait for a debugger to be attached to port 5005. Attach a debugger, and the build will continue. From the Spoofax plugin\u2019s IntelliJ IDEA project, you can invoke the JPS Plugin remote debug configuration to attach the debugger.","title":"IntelliJ"},{"location":"howtos/development/developing/#logging","text":"To get debug logging in IntelliJ, locate the bin/log.xml file in the IntelliJ folder and add the following snippet in the <log4j:configuration> element, just above the <root> element: <category name= \"#org.metaborg\" additivity= \"true\" > <priority value= \"DEBUG\" /> <appender-ref ref= \"CONSOLE-DEBUG\" /> <appender-ref ref= \"FILE\" /> </category>","title":"Logging"},{"location":"howtos/development/maven/","text":"Spoofax Development Maven Setup \u00b6 Maven is a project management and build tool for software projects. Most components in Spoofax are built with Maven. This how-to will guide you to setup Maven for Spoofax 2 development. Installation \u00b6 Maven can be downloaded and installed from https://maven.apache.org/download.cgi . We require Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2). On macOs, Maven can be easily installed with Homebrew by executing: brew install maven Confirm the installation was successful and the version is supported by running mvn --version . Memory Allocation \u00b6 By default, Maven does not assign a lot of memory to the JVM that it runs in, which may lead to out-of-memory exceptions during builds. To increase the allocated memory, execute before building: export MAVEN_OPTS = \"-Xms512m -Xmx1024m -Xss16m\" Such an export is not permanent. To make it permanent, add that line to ~/.bashrc or equivalent for your OS/shell (create the file if it does not exist), which will execute it whenever a new shell is opened. Proxy Settings \u00b6 If you are behind a proxy, please put the proxy settings in your ~/.m2/settings.xml file. When you use the ./b script to build Spoofax, the MAVEN_OPTS environment variable is overridden to ensure the memory options above are supplied, so using command-line options in the environment variable for the proxy settings does not work. Spoofax Maven Artifacts \u00b6 Spoofax\u2019s Maven artifacts are hosted on our artifact server at artifacts.metaborg.org . To use these artifacts, repositories have to be added to your Maven configuration. This configuration is required when building and developing Spoofax. Repositories can be added to your local Maven settings file (which is recommended), or to a project\u2019s POM file. Simple: Local Settings File \u00b6 The recommended approach is to add repositories to your local Maven settings file, located at ~/.m2/settings.xml . If you have not created this file yet, or want to completely replace it, simply create it with the following content: ~/.m2/settings.xml <?xml version=\"1.0\" ?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <profiles> <profile> <id> add-metaborg-release-repos </id> <activation> <activeByDefault> true </activeByDefault> </activation> <repositories> <repository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> <profile> <id> add-metaborg-snapshot-repos </id> <activation> <activeByDefault> true </activeByDefault> </activation> <repositories> <repository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> </profiles> <mirrors> <mirror> <id> metaborg-central-mirror </id> <url> https://artifacts.metaborg.org/content/repositories/central/ </url> <mirrorOf> central </mirrorOf> </mirror> </mirrors> </settings> If you\u2019ve already created a settings file before and want to add the repositories, just add the profile element (and the profiles element if it does not exist yet) to the settings file. Advanced: Project POM File \u00b6 Repositories can also be added directly to a project\u2019s POM file, which only set the repositories for that particular project. This is not recommended, because it makes repositories harder to change by users, and duplicates the configuration. But it can be convenient, because it does not require an external settings file. To do this, just add the the following content to the POM file: ~/.m2/settings.xml <repositories> <repository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </repository> <repository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </pluginRepository> <pluginRepository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </pluginRepository> </pluginRepositories> Maven Central Repository Mirror \u00b6 Artifacts of most open source projects are hosted in the Maven Central Repository . If you are building any project using Maven, many artifacts will be downloaded from that server. While it is a fast server, it can still take a while to download all required artifacts for big projects. If you are on the TU Delft network, you can use our local mirror of Maven Central to speed things up. Using the mirroring requires a change in your local ~/.m2/settings.xml file. If this file does not exist, create it with the following content: ~/.m2/settings.xml <?xml version=\"1.0\" ?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <mirrors> <mirror> <id> metaborg-central-mirror </id> <url> https://artifacts.metaborg.org/content/repositories/central/ </url> <mirrorOf> central </mirrorOf> </mirror> </mirrors> </settings> If you\u2019ve already created a settings file before and want to add the mirror configuration, just add the mirror element (and the mirrors element if it does not exist yet) to the settings file.","title":"Maven"},{"location":"howtos/development/maven/#spoofax-development-maven-setup","text":"Maven is a project management and build tool for software projects. Most components in Spoofax are built with Maven. This how-to will guide you to setup Maven for Spoofax 2 development.","title":"Spoofax Development Maven Setup"},{"location":"howtos/development/maven/#installation","text":"Maven can be downloaded and installed from https://maven.apache.org/download.cgi . We require Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2). On macOs, Maven can be easily installed with Homebrew by executing: brew install maven Confirm the installation was successful and the version is supported by running mvn --version .","title":"Installation"},{"location":"howtos/development/maven/#memory-allocation","text":"By default, Maven does not assign a lot of memory to the JVM that it runs in, which may lead to out-of-memory exceptions during builds. To increase the allocated memory, execute before building: export MAVEN_OPTS = \"-Xms512m -Xmx1024m -Xss16m\" Such an export is not permanent. To make it permanent, add that line to ~/.bashrc or equivalent for your OS/shell (create the file if it does not exist), which will execute it whenever a new shell is opened.","title":"Memory Allocation"},{"location":"howtos/development/maven/#proxy-settings","text":"If you are behind a proxy, please put the proxy settings in your ~/.m2/settings.xml file. When you use the ./b script to build Spoofax, the MAVEN_OPTS environment variable is overridden to ensure the memory options above are supplied, so using command-line options in the environment variable for the proxy settings does not work.","title":"Proxy Settings"},{"location":"howtos/development/maven/#spoofax-maven-artifacts","text":"Spoofax\u2019s Maven artifacts are hosted on our artifact server at artifacts.metaborg.org . To use these artifacts, repositories have to be added to your Maven configuration. This configuration is required when building and developing Spoofax. Repositories can be added to your local Maven settings file (which is recommended), or to a project\u2019s POM file.","title":"Spoofax Maven Artifacts"},{"location":"howtos/development/maven/#simple-local-settings-file","text":"The recommended approach is to add repositories to your local Maven settings file, located at ~/.m2/settings.xml . If you have not created this file yet, or want to completely replace it, simply create it with the following content: ~/.m2/settings.xml <?xml version=\"1.0\" ?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <profiles> <profile> <id> add-metaborg-release-repos </id> <activation> <activeByDefault> true </activeByDefault> </activation> <repositories> <repository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> <profile> <id> add-metaborg-snapshot-repos </id> <activation> <activeByDefault> true </activeByDefault> </activation> <repositories> <repository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> </profiles> <mirrors> <mirror> <id> metaborg-central-mirror </id> <url> https://artifacts.metaborg.org/content/repositories/central/ </url> <mirrorOf> central </mirrorOf> </mirror> </mirrors> </settings> If you\u2019ve already created a settings file before and want to add the repositories, just add the profile element (and the profiles element if it does not exist yet) to the settings file.","title":"Simple: Local Settings File"},{"location":"howtos/development/maven/#advanced-project-pom-file","text":"Repositories can also be added directly to a project\u2019s POM file, which only set the repositories for that particular project. This is not recommended, because it makes repositories harder to change by users, and duplicates the configuration. But it can be convenient, because it does not require an external settings file. To do this, just add the the following content to the POM file: ~/.m2/settings.xml <repositories> <repository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </repository> <repository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> metaborg-release-repo </id> <url> https://artifacts.metaborg.org/content/repositories/releases/ </url> <releases> <enabled> true </enabled> </releases> <snapshots> <enabled> false </enabled> </snapshots> </pluginRepository> <pluginRepository> <id> metaborg-snapshot-repo </id> <url> https://artifacts.metaborg.org/content/repositories/snapshots/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </pluginRepository> </pluginRepositories>","title":"Advanced: Project POM File"},{"location":"howtos/development/maven/#maven-central-repository-mirror","text":"Artifacts of most open source projects are hosted in the Maven Central Repository . If you are building any project using Maven, many artifacts will be downloaded from that server. While it is a fast server, it can still take a while to download all required artifacts for big projects. If you are on the TU Delft network, you can use our local mirror of Maven Central to speed things up. Using the mirroring requires a change in your local ~/.m2/settings.xml file. If this file does not exist, create it with the following content: ~/.m2/settings.xml <?xml version=\"1.0\" ?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <mirrors> <mirror> <id> metaborg-central-mirror </id> <url> https://artifacts.metaborg.org/content/repositories/central/ </url> <mirrorOf> central </mirrorOf> </mirror> </mirrors> </settings> If you\u2019ve already created a settings file before and want to add the mirror configuration, just add the mirror element (and the mirrors element if it does not exist yet) to the settings file.","title":"Maven Central Repository Mirror"},{"location":"howtos/development/releasing/","text":"Releasing Spoofax \u00b6 This how-to describes how to release Spoofax. Requirements \u00b6 To release Spoofax, you must first be able to build Spoofax. Follow the Maven and Building guides first. To publish releases, you will need write access to the spoofax-releng repository, to all submodule repositories in that repository, and to this documentation repository. An account with deploy access to our artifact server is required. Ask an administrator of the Programming Languages group to get access to the repositories and artifact server. Instructions \u00b6 Prepare Maven deploy settings. Open your ~/.m2/settings.xml file. Add a <servers></servers> section if it does not exist. Add a server to the servers section with id metaborg-nexus that contains your username and password to our artifact server: <server> <id> metaborg-nexus </id> <username> myusername </username> <password> mypassword </password> </server> Optionally encrypt your password by following the Password Encryption guide . Prepare the repository containing the build scripts. Clone or re-use an existing clone of spoofax-releng on the master branch. See Cloning the source code . Update it to the latest commit with: git pull --rebase && ./b checkout -y && ./b update To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs: ./b set-remote -s Prepare the source code repository. Make a separate clone (or re-use an existing one if you have released Spoofax before) of the spoofax-release branch of spoofax-releng . This must be a separate clone in a different directory from the first one. See Cloning the source code . Why two separate clones of spoofax-releng ? The reason for two separate clones of spoofax-releng is that the release script will modify the files in the repository, which could include files of the release script itself. Therefore, we make a separate clone which the release script acts upon, so that it does not interfere with itself. If reusing an existing clone, ensure that it is checked out to spoofax-release with: git checkout spoofax-release ...and update it to the latest commit with: git pull --rebase && ./b checkout -y && ./b update If there are new submodules repositories, follow the steps for preparing new submodules below. To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs: ./b set-remote -s Perform the release. Change directory into the repository cloned in step 2. For example: cd /Users/gohla/spoofax/master/spoofax-releng Get an absolute path to the repository cloned in step 3. For example: /Users/gohla/spoofax/release/spoofax-releng Determine whether the release will be patch or minor/major . For a patch release, we do not bump the development version. For a minor or major release, we do. Figure out what the current development version of Spoofax is, what the next release version should be, and if doing a non-patch release, what the next development version should be. The release script will change the current development version into the next release version, deploy that, and then change the current development version to the next development version, and commit that. Setting the next development version is optional. Execute the release script with the parameters you gathered: ./b --repo <release-repository> release \\ spoofax-release <release-version> \\ master <current-development-version> \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username <artifact-server-username> \\ --nexus-password <artifact-server-password> \\ --nexus-repo releases ...or for a major version, with --next-develop-version : ./b --repo <release-repository> release \\ spoofax-release <release-version> \\ master <current-development-version> \\ --next-develop-version <next-development-version> \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username <artifact-server-username> \\ --nexus-password <artifact-server-password> \\ --nexus-repo releases For example, if we currently are at development version 2.6.0-SNAPSHOT , and would like to release minor version 2.6.0 , and update the development version to 2.7.0-SNAPSHOT , we would execute the following command: cd /Users/gohla/spoofax/master/spoofax-releng ./b --repo /Users/gohla/spoofax/release/spoofax-releng release \\ spoofax-release 2 .6.0 \\ master 2 .6.0-SNAPSHOT \\ --next-develop-version 2 .7.0-SNAPSHOT \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username myusername \\ --nexus-password mypassword \\ --nexus-repo releases Unfortunately, it is currently not possible to encrypt the artifact server password passed to the build script. New spoofax-releng Submodules \u00b6 When adding a new submodule to the spoofax-releng repository, the following steps must be performed before starting the automated release process: Add a spoofax-release branch to the submodule (pointing to the current master branch), and push that branch. Add the submodule to the .gitmodule file in the spoofax-release branch of the spoofax-releng repository. Make sure that the branch of the submodule is set to spoofax-release , and that the remote is using an https URL. Commit and push this change. Updating the Release Archive \u00b6 To update the release archive of this documentation site, perform the following steps after a release: Update include files: Copy include/hyperlink/download-<current-release-version>.rst to new file include/hyperlink/download-<release-version>.rst , replace all instances of <current-release-version> in that new file with <release-version> , and update the date to the current date. In include/hyperlink/download-rel.rst , replace all instances of <current-release-version> with <release-version> . In include/hyperlink/download-dev.rst , update the development version to <next-development-version> . In include/_all.rst , add a new line to include the newly copied file: .. include:: /include/hyperlink/download-<release-version>.rst. Update source/release/migrate/<release-version>.rst (only if migrations are necessary): Remove stub notice. Update source/release/note/<release-version>.rst : Remove stub notice. Add small summary of the release as an introduction. Include download links, which can be copied and have their versions replaced from a previous release. Create new stub files for the next release: Create a new migration guide stub file. Create a new release notes stub file. Update source/release/note/index.rst : Move stub for this release to the top of the notes. Add new stub file at the bottom of the notes. Update source/release/migrate/index.rst : Move stub for this release to the top of the migration guides. Add new stub file at the bottom of the migration guides. Update conf.py : Update version variable. Update copyright variable with new year, if needed.","title":"Releasing"},{"location":"howtos/development/releasing/#releasing-spoofax","text":"This how-to describes how to release Spoofax.","title":"Releasing Spoofax"},{"location":"howtos/development/releasing/#requirements","text":"To release Spoofax, you must first be able to build Spoofax. Follow the Maven and Building guides first. To publish releases, you will need write access to the spoofax-releng repository, to all submodule repositories in that repository, and to this documentation repository. An account with deploy access to our artifact server is required. Ask an administrator of the Programming Languages group to get access to the repositories and artifact server.","title":"Requirements"},{"location":"howtos/development/releasing/#instructions","text":"Prepare Maven deploy settings. Open your ~/.m2/settings.xml file. Add a <servers></servers> section if it does not exist. Add a server to the servers section with id metaborg-nexus that contains your username and password to our artifact server: <server> <id> metaborg-nexus </id> <username> myusername </username> <password> mypassword </password> </server> Optionally encrypt your password by following the Password Encryption guide . Prepare the repository containing the build scripts. Clone or re-use an existing clone of spoofax-releng on the master branch. See Cloning the source code . Update it to the latest commit with: git pull --rebase && ./b checkout -y && ./b update To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs: ./b set-remote -s Prepare the source code repository. Make a separate clone (or re-use an existing one if you have released Spoofax before) of the spoofax-release branch of spoofax-releng . This must be a separate clone in a different directory from the first one. See Cloning the source code . Why two separate clones of spoofax-releng ? The reason for two separate clones of spoofax-releng is that the release script will modify the files in the repository, which could include files of the release script itself. Therefore, we make a separate clone which the release script acts upon, so that it does not interfere with itself. If reusing an existing clone, ensure that it is checked out to spoofax-release with: git checkout spoofax-release ...and update it to the latest commit with: git pull --rebase && ./b checkout -y && ./b update If there are new submodules repositories, follow the steps for preparing new submodules below. To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs: ./b set-remote -s Perform the release. Change directory into the repository cloned in step 2. For example: cd /Users/gohla/spoofax/master/spoofax-releng Get an absolute path to the repository cloned in step 3. For example: /Users/gohla/spoofax/release/spoofax-releng Determine whether the release will be patch or minor/major . For a patch release, we do not bump the development version. For a minor or major release, we do. Figure out what the current development version of Spoofax is, what the next release version should be, and if doing a non-patch release, what the next development version should be. The release script will change the current development version into the next release version, deploy that, and then change the current development version to the next development version, and commit that. Setting the next development version is optional. Execute the release script with the parameters you gathered: ./b --repo <release-repository> release \\ spoofax-release <release-version> \\ master <current-development-version> \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username <artifact-server-username> \\ --nexus-password <artifact-server-password> \\ --nexus-repo releases ...or for a major version, with --next-develop-version : ./b --repo <release-repository> release \\ spoofax-release <release-version> \\ master <current-development-version> \\ --next-develop-version <next-development-version> \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username <artifact-server-username> \\ --nexus-password <artifact-server-password> \\ --nexus-repo releases For example, if we currently are at development version 2.6.0-SNAPSHOT , and would like to release minor version 2.6.0 , and update the development version to 2.7.0-SNAPSHOT , we would execute the following command: cd /Users/gohla/spoofax/master/spoofax-releng ./b --repo /Users/gohla/spoofax/release/spoofax-releng release \\ spoofax-release 2 .6.0 \\ master 2 .6.0-SNAPSHOT \\ --next-develop-version 2 .7.0-SNAPSHOT \\ --non-interactive \\ --maven-deploy \\ --maven-deploy-identifier metaborg-nexus \\ --maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\ --nexus-deploy \\ --nexus-username myusername \\ --nexus-password mypassword \\ --nexus-repo releases Unfortunately, it is currently not possible to encrypt the artifact server password passed to the build script.","title":"Instructions"},{"location":"howtos/development/releasing/#new-spoofax-releng-submodules","text":"When adding a new submodule to the spoofax-releng repository, the following steps must be performed before starting the automated release process: Add a spoofax-release branch to the submodule (pointing to the current master branch), and push that branch. Add the submodule to the .gitmodule file in the spoofax-release branch of the spoofax-releng repository. Make sure that the branch of the submodule is set to spoofax-release , and that the remote is using an https URL. Commit and push this change.","title":"New spoofax-releng Submodules"},{"location":"howtos/development/releasing/#updating-the-release-archive","text":"To update the release archive of this documentation site, perform the following steps after a release: Update include files: Copy include/hyperlink/download-<current-release-version>.rst to new file include/hyperlink/download-<release-version>.rst , replace all instances of <current-release-version> in that new file with <release-version> , and update the date to the current date. In include/hyperlink/download-rel.rst , replace all instances of <current-release-version> with <release-version> . In include/hyperlink/download-dev.rst , update the development version to <next-development-version> . In include/_all.rst , add a new line to include the newly copied file: .. include:: /include/hyperlink/download-<release-version>.rst. Update source/release/migrate/<release-version>.rst (only if migrations are necessary): Remove stub notice. Update source/release/note/<release-version>.rst : Remove stub notice. Add small summary of the release as an introduction. Include download links, which can be copied and have their versions replaced from a previous release. Create new stub files for the next release: Create a new migration guide stub file. Create a new release notes stub file. Update source/release/note/index.rst : Move stub for this release to the top of the notes. Add new stub file at the bottom of the notes. Update source/release/migrate/index.rst : Move stub for this release to the top of the migration guides. Add new stub file at the bottom of the migration guides. Update conf.py : Update version variable. Update copyright variable with new year, if needed.","title":"Updating the Release Archive"},{"location":"howtos/development/requirements/","text":"Spoofax Development Requirements \u00b6 This how-to will instruct you which requirements you need to install to do Spoofax 2 development. Spoofax can be run on macOS, Linux, and Windows. Building is directly supported on macOS and Linux. Building on Windows is supported through the Windows Subsystem for Linux (Bash on Windows) . The following tools are required to build and develop Spoofax: Git 1.8.2 or newer Required to check out the source code from our GitHub repositories. Instructions on how to install Git for your platform can be found here: https://git-scm.com/downloads . If you run macOs and have Homebrew installed, you can install Git by executing brew install git . Confirm your Git installation by executing git version . Java JDK 8 or newer Required to build and run Java components. The latest JDK can be downloaded and installed from: https://www.oracle.com/technetwork/java/javase/downloads/index.html . On macOs, it can be a bit tricky to use the installed JDK, because Apple by default installs JRE 6. To check which version of Java you are running, execute the java -version command. If this tells you that the Java version is 1.8 or newer, or Java 9 or newer, everything is fine. If not, you can either install a newer Java version through Homebrew ( brew install --cask adoptopenjdk8 ), or use a JDK manager such as SDKMAN! . Python 3.4 or newer Python scripts are used to orchestrate the build. Instructions on how to install Python for your platform can be found here: https://www.python.org/downloads/ . If you run macOs and have Homebrew installed, you can install Python by executing brew install python3 . Confirm your Python installation by executing python3 --version or python --version , depending on how your package manager sets up Python. During a build of Spoofax, Pip will install some Python dependencies into a virtual environment. No extra Python dependencies are required for this (with one small exception, see the note below). The latest version of Pip will automatically be installed inside the virtual environment. Debian and derivatives (like Ubuntu) do not include the full standard library when installing Python ( bug 1290847 ), so you will need to install python3-venv to ensure the virtual environment can be created. Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2) Maven is required to build most components of Spoofax. Our Maven artifact server must also be registered with Maven since the build depends on artifacts from previous builds for bootstrapping purposes. We explain how to install and set up Maven in this how-to . Spoofax cannot be built using Maven 3.6.1 or 3.6.2 due to bugs MNG-6642 and MNG-6765 . Docker Required on macOS Catalina, Big Sur, and newer to be able to run the sdf2table and implodePT legacy binaries. On macOS, install it though the Docker for Mac website. Coreutils Required on macOS to be able to run the sdf2table and implodePT legacy binaries. On macOS with Homebrew installed, you can install them by running brew install coreutils .","title":"Requirements"},{"location":"howtos/development/requirements/#spoofax-development-requirements","text":"This how-to will instruct you which requirements you need to install to do Spoofax 2 development. Spoofax can be run on macOS, Linux, and Windows. Building is directly supported on macOS and Linux. Building on Windows is supported through the Windows Subsystem for Linux (Bash on Windows) . The following tools are required to build and develop Spoofax: Git 1.8.2 or newer Required to check out the source code from our GitHub repositories. Instructions on how to install Git for your platform can be found here: https://git-scm.com/downloads . If you run macOs and have Homebrew installed, you can install Git by executing brew install git . Confirm your Git installation by executing git version . Java JDK 8 or newer Required to build and run Java components. The latest JDK can be downloaded and installed from: https://www.oracle.com/technetwork/java/javase/downloads/index.html . On macOs, it can be a bit tricky to use the installed JDK, because Apple by default installs JRE 6. To check which version of Java you are running, execute the java -version command. If this tells you that the Java version is 1.8 or newer, or Java 9 or newer, everything is fine. If not, you can either install a newer Java version through Homebrew ( brew install --cask adoptopenjdk8 ), or use a JDK manager such as SDKMAN! . Python 3.4 or newer Python scripts are used to orchestrate the build. Instructions on how to install Python for your platform can be found here: https://www.python.org/downloads/ . If you run macOs and have Homebrew installed, you can install Python by executing brew install python3 . Confirm your Python installation by executing python3 --version or python --version , depending on how your package manager sets up Python. During a build of Spoofax, Pip will install some Python dependencies into a virtual environment. No extra Python dependencies are required for this (with one small exception, see the note below). The latest version of Pip will automatically be installed inside the virtual environment. Debian and derivatives (like Ubuntu) do not include the full standard library when installing Python ( bug 1290847 ), so you will need to install python3-venv to ensure the virtual environment can be created. Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2) Maven is required to build most components of Spoofax. Our Maven artifact server must also be registered with Maven since the build depends on artifacts from previous builds for bootstrapping purposes. We explain how to install and set up Maven in this how-to . Spoofax cannot be built using Maven 3.6.1 or 3.6.2 due to bugs MNG-6642 and MNG-6765 . Docker Required on macOS Catalina, Big Sur, and newer to be able to run the sdf2table and implodePT legacy binaries. On macOS, install it though the Docker for Mac website. Coreutils Required on macOS to be able to run the sdf2table and implodePT legacy binaries. On macOS with Homebrew installed, you can install them by running brew install coreutils .","title":"Spoofax Development Requirements"},{"location":"howtos/editor-services/rename-refactoring/","text":"Add Rename Refactoring to an Existing Project \u00b6 Rename Refactoring is the ability for the user to select a reference or declaration and rename it to across the whole program while not introducing errors and not touching syntactically equal names. Renaming in Statix \u00b6 To enable the Rename Refactoring for an existing Spoofax Language project that uses Statix, create an action that calls the rename-action strategy from the statixruntime library. The parameters are explained in the reference . For example: module renaming imports statixruntime statix / runtime / renaming pp analysis rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id ) Renaming in NaBL2 \u00b6 There also exists a version of the Rename refactoring that works with languages using NaBL2. It can be added with a Stratego module like this: module renaming imports nabl2 / runtime pp analysis rules rename-menu-action = nabl2-rename-action ( construct-textual-change , editor-analyze , id ) Menu Action \u00b6 The rename refactoring is triggered from an entry in the Spoofax menu. To add it to an existing project a menu like the following can be implemented in an ESV file : module Refactoring menus menu : \"Refactoring\" action : \"Rename\" = re name - menu - action See Also \u00b6 Reference: Rename Refactoring","title":"Add Rename Refactoring to an Existing Project"},{"location":"howtos/editor-services/rename-refactoring/#add-rename-refactoring-to-an-existing-project","text":"Rename Refactoring is the ability for the user to select a reference or declaration and rename it to across the whole program while not introducing errors and not touching syntactically equal names.","title":"Add Rename Refactoring to an Existing Project"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-statix","text":"To enable the Rename Refactoring for an existing Spoofax Language project that uses Statix, create an action that calls the rename-action strategy from the statixruntime library. The parameters are explained in the reference . For example: module renaming imports statixruntime statix / runtime / renaming pp analysis rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id )","title":"Renaming in Statix"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-nabl2","text":"There also exists a version of the Rename refactoring that works with languages using NaBL2. It can be added with a Stratego module like this: module renaming imports nabl2 / runtime pp analysis rules rename-menu-action = nabl2-rename-action ( construct-textual-change , editor-analyze , id )","title":"Renaming in NaBL2"},{"location":"howtos/editor-services/rename-refactoring/#menu-action","text":"The rename refactoring is triggered from an entry in the Spoofax menu. To add it to an existing project a menu like the following can be implemented in an ESV file : module Refactoring menus menu : \"Refactoring\" action : \"Rename\" = re name - menu - action","title":"Menu Action"},{"location":"howtos/editor-services/rename-refactoring/#see-also","text":"Reference: Rename Refactoring","title":"See Also"},{"location":"howtos/installation/install-eclipse-bundle/","text":"Install the Eclipse with Spoofax Plugin Bundle \u00b6 Install an Eclipse instance with the latest stable release of the Spoofax plugin pre-installed for your platform: Eclipse with JRE (recommended) Eclipse bundle including the Spoofax plugin with embedded Java Runtime Environment (JRE) (recommended): + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Eclipse Eclipse bundle including the Spoofax plugin ( no embedded JRE ): macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Development releases . Troubleshooting \u00b6 macOS: \"Eclipse\" cannot be opened because the developer could not be verified \u00b6 macOS puts unverified binaries in 'quarantine' and disallows their execution. To remove the com.apple.quarantine attribute, do: xattr -rc Eclipse.app Eclipse does not start, or complains about missing Java \u00b6 Download the Eclipse bundle with embedded JRE . Otherwise, ensure you have a distribution of Java installed. Then in eclipse.ini , add a -vm line at the top of the file, followed by the path to the Java installation. For example, with SDKMan! on macOS: -vm /Users/myusername/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib","title":"Install the Eclipse with Spoofax Plugin Bundle"},{"location":"howtos/installation/install-eclipse-bundle/#install-the-eclipse-with-spoofax-plugin-bundle","text":"Install an Eclipse instance with the latest stable release of the Spoofax plugin pre-installed for your platform: Eclipse with JRE (recommended) Eclipse bundle including the Spoofax plugin with embedded Java Runtime Environment (JRE) (recommended): + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Eclipse Eclipse bundle including the Spoofax plugin ( no embedded JRE ): macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Development releases .","title":"Install the Eclipse with Spoofax Plugin Bundle"},{"location":"howtos/installation/install-eclipse-bundle/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"howtos/installation/install-eclipse-bundle/#macos-eclipse-cannot-be-opened-because-the-developer-could-not-be-verified","text":"macOS puts unverified binaries in 'quarantine' and disallows their execution. To remove the com.apple.quarantine attribute, do: xattr -rc Eclipse.app","title":" macOS: \"Eclipse\" cannot be opened because the developer could not be verified"},{"location":"howtos/installation/install-eclipse-bundle/#eclipse-does-not-start-or-complains-about-missing-java","text":"Download the Eclipse bundle with embedded JRE . Otherwise, ensure you have a distribution of Java installed. Then in eclipse.ini , add a -vm line at the top of the file, followed by the path to the Java installation. For example, with SDKMan! on macOS: -vm /Users/myusername/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib","title":"Eclipse does not start, or complains about missing Java"},{"location":"howtos/installation/install-eclipse-plugin-manually/","text":"Install the Spoofax Eclipse Plugin Manually \u00b6 Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer. In Eclipse, go to menu Help \u2192 Install New Software . In the Work with: text area, type: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ ( Development releases ). Uncheck Group items by category to make the plugin visible. Check Spoofax Eclipse meta-tooling , Spoofax Eclipse meta-tooling M2E integration and Spoofax Eclipse runtime . Click Install and go through the remaining steps. Restart Eclipse.","title":"Install the Spoofax Eclipse Plugin Manually"},{"location":"howtos/installation/install-eclipse-plugin-manually/#install-the-spoofax-eclipse-plugin-manually","text":"Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer. In Eclipse, go to menu Help \u2192 Install New Software . In the Work with: text area, type: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ ( Development releases ). Uncheck Group items by category to make the plugin visible. Check Spoofax Eclipse meta-tooling , Spoofax Eclipse meta-tooling M2E integration and Spoofax Eclipse runtime . Click Install and go through the remaining steps. Restart Eclipse.","title":"Install the Spoofax Eclipse Plugin Manually"},{"location":"howtos/installation/install-from-source/","text":"Install Spoofax from Source \u00b6 Perform a manual build and installation of cutting-edge Spoofax from source, by first cloning the Git repository: HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Then: Using a terminal, navigate to the root of the spoofax-releng repository. (Optional.) Generate a new Maven ~/.m2/settings.xml with the Spoofax repository information. ./b gen-mvn-settings This will overwrite your existing ~/.m2/settings.xml file! Invoke the following command to build Spoofax and its submodules and meta-languages: ./b build all (Optional.) Generate a new Eclipse instance with the Spoofax plugin embedded into it: ./b gen-eclipse --destination Spoofax.app","title":"Install Spoofax from Source"},{"location":"howtos/installation/install-from-source/#install-spoofax-from-source","text":"Perform a manual build and installation of cutting-edge Spoofax from source, by first cloning the Git repository: HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Then: Using a terminal, navigate to the root of the spoofax-releng repository. (Optional.) Generate a new Maven ~/.m2/settings.xml with the Spoofax repository information. ./b gen-mvn-settings This will overwrite your existing ~/.m2/settings.xml file! Invoke the following command to build Spoofax and its submodules and meta-languages: ./b build all (Optional.) Generate a new Eclipse instance with the Spoofax plugin embedded into it: ./b gen-eclipse --destination Spoofax.app","title":"Install Spoofax from Source"},{"location":"howtos/stratego/concrete-syntax/","text":"Concrete Syntax \u00b6 When writing language-to-language transformations in Stratego, it is possible to use different approaches, for example, writing AST-to-AST transformations. However, to write such transformations, the language engineer needs to know the constructors of both languages. Moreover, AST nodes in rules that define such transformations may contain many nested children, making the work of writing such rules cumbersome and error-prone. Note that Stratego only statically checks the name and arity of constructors, thus, errors would only be detected when pretty-printing the generated AST to the target language. As an example of this approach, the rule below specifies a transformation of a Calc program to a Java program. program-to-java : Program ( stats ) - > CompilationUnit ( None () , [] , [ ClassDeclaration ( [ Public ()] , Id ( \"Program\" ) , None () , None () , None () , [ MethodDecl ( [ Public (), Static ()] , MethodHeader ( java-type , Id ( \"eval\" ) , NoParams () , [] , None () ) , Block ( [ java-stats * ] ) ) ] ) ] ) with java-type := ... java-stats * := ... An alternative approach consists of using string interpolation. Instead of generating abstract terms of the target language, transformations generate source code directly, interpolating strings with boilerplate code of the target language and variables defined in the transformation itself. The problem with this approach is that syntax errors in the string fragments of the target language are not detected statically. Consider the rule shown previously, rewritten below using string interpolation (the code between $[ and ]). Note that if the fragment would contain a typo, the syntax error would only be detected after the code had been generated. Note also that one can interpolate Stratego variables with the fragment of the target language by escaping them between [ and ]. program-to-java : Program ( stats ) - > $ [ public class Program { public static [ java-type ] eval () { [ java-stats ] } } ] with java-type := ... java-stats := ... The third option is to use concrete syntax. When using concrete syntax, the transformation is still AST-to-AST but the AST of the target language is abstracted over using the concrete syntax of the language instead. That is, the concrete syntax fragment is parsed internally producing an AST, and that AST is resulted from the transformation. The same rule defined using concrete syntax is shown below. Note that any syntax error in the fragment would in fact, be detected by the editor, as the fragment is being parsed internally. Moreover, the fragment also has the syntax highlighting of the target language when shown by the editor. program-to-java : Program ( stats ) - > compilation-unit |[ public class Program { public static ~ type : java-type eval () { ~ bstm * : java-stats * } } ]| with java-type := ... java-stats * := ... There are two aspects to consider when enabling concrete syntax inside Spoofax. The first one is being able to write Stratego transformations with fragments of a target (or source) language. In other words, the first aspect consists of generating a mixed parse table that embeds the desired target language inside Stratego. The second aspect consists of including the parse table inside an Spoofax project, adding an additional .meta file to then enable concrete syntax for a specific Stratego file. Below, we describe both aspects with more detail. Mixing Grammars \u00b6 To generate a mixed parse table that embeds a language inside Stratego, it is necessary to modify the original Stratego grammar, extending it with the desired language. One problem that may occur when combining the grammars of two different languages is name clashing, i.e., non-terminals that have the same name in Stratego and the embedded language. For that reason, the embedding occurs using a modified Stratego grammar, which renames all Stratego context-free non-terminals using by prefixing it with StrategoLang , avoiding name clashes. Inside Spoofax, you can add a source dependency on the org.metaborg:stratego.lang:${metaborgVersion} project in you metaborg.yaml file, then you can import the so-called namespaced grammar. Once you have access to the namespaced grammar, the next step consists of defining the embedding grammar, the grammar that actually mixes the two languages. A grammar that embeds one language into another may contain three types of productions: productions that define quotations for elements of the target language in the host language, productions that define anti-quotations back to the host language from the target language, and variables, which are shortcuts to anti-quotations, and may appear inside the target language fragments. When embedding a language into Stratego, it is common to allow fragments of the host language as Stratego terms. For that reason, quotation productions are injected into Stratego terms. For example, the productions below, written in SDF3, indicates that a Java compilation unit can occur in Stratego in a place where a Stratego term can occur. imports StrategoLang / sugar / terms-namespaced java / packages / CompilationUnits context-free syntax StrategoLang-PreTerm . ToTerm = < compilation-unit |[ < CompilationUnit > ]|> StrategoLang-PreTerm . ToTerm = <|[ < CompilationUnit > ]|> Anti-quotation productions define points to insert elements of the host language inside fragments of the target language. For example, with the production below, we allow Stratego terms to occur in a Java fragment whenever a non-terminal Type can occur. imports java / types / Main context-free syntax Type . FromTerm = [ ~ [ StrategoLang-Term ]] Type . FromTerm = [ ~ type :[ StrategoLang-Term ]] Note that the constructor FromTerm indicates that productions represent anti-quotations. Furthermore, note that anti-quotations may also be named after the non-terminal being referenced (e.g., ~type: ). Using anti-quotations might make the fragment of the target language quite verbose. Therefore, it is also possible to define variables as shortcuts to anti-quotations. For example, the productions below define variables to reference anti-quotations to Type fragments. That is, instead of reference to a Stratego variable X by using ~type:X , one may name this variable t_1 which corresponds to a variable for a non-terminal Type . variables Type = \"t_\" [ 0 -9 \\' ] * { prefer } The prefer annotation indicates that in case of an ambiguity, the variable production should be preferred. Using the three types of productions above, it is possible to specify which fragments one wants to write using concrete syntax and which symbols may appear inside these fragments as Stratego variables (using anti-quotation or variables with a specific name). Finally, it is necessary to define a module Stratego-<LanguageName> that should import the Stratego grammar and the embedding grammar. This module should be defined in a file named Stratego-<LanguageName>.sdf3 and put in the syntax folder so that Spoofax can locate it and build the mixed table. That is, if we define the module for our Stratego-Java mixed grammar: module Stratego-Java imports EmbeddedJava StrategoLang / import-namespaced context-free start-symbols StrategoLang-Module Note that it is necessary to define the start symbol of the mixed grammar as StrategoLang-Module . After defining the embedding grammar and the Stratego-<LanguageName> module, Spoofax generates the mixed table inside the trans folder when rebuilding the project. Using Mixed Parse Tables to Allow Concrete Syntax \u00b6 Assuming a mixed parse table has been successfully generated or already exists, the next step is to allow concrete syntax in transformations using that table. The table needs to be in a folder that can be discovered by the Stratego compiler. By default it will be generated in the trans folder of the project that defines the mixed grammar, to be used within the project. If you wish to use the mixed grammar in another project, make sure to export the generate table by adding an entry for it in the metaborg.yaml file. Then any other project that depends on your mixed grammar project with a source dependency will also provide the table file to the Stratego compiler. Next, together with the file in which we would like to enable concrete syntax, it is necessary to create a .meta file with the same name. That is, to enable concrete syntax in a file generate.str , it is necessary to create, in the same directory, an addition file generate.meta . This file should indicate which mixed table should be used to parse generate.str . For that reason it should contain: Meta ([ Syntax ( \"<ParseTableName>\" )]) where <ParseTableName> is the filename of the parse table without extension, Stratego-Java in our example. With the configuration above, Spoofax automatically detects that the file contains concrete syntax and use that table to parse it. In that file, one may write rules containing concrete syntax as defined by the productions in the mixed grammar.","title":"Concrete Syntax"},{"location":"howtos/stratego/concrete-syntax/#concrete-syntax","text":"When writing language-to-language transformations in Stratego, it is possible to use different approaches, for example, writing AST-to-AST transformations. However, to write such transformations, the language engineer needs to know the constructors of both languages. Moreover, AST nodes in rules that define such transformations may contain many nested children, making the work of writing such rules cumbersome and error-prone. Note that Stratego only statically checks the name and arity of constructors, thus, errors would only be detected when pretty-printing the generated AST to the target language. As an example of this approach, the rule below specifies a transformation of a Calc program to a Java program. program-to-java : Program ( stats ) - > CompilationUnit ( None () , [] , [ ClassDeclaration ( [ Public ()] , Id ( \"Program\" ) , None () , None () , None () , [ MethodDecl ( [ Public (), Static ()] , MethodHeader ( java-type , Id ( \"eval\" ) , NoParams () , [] , None () ) , Block ( [ java-stats * ] ) ) ] ) ] ) with java-type := ... java-stats * := ... An alternative approach consists of using string interpolation. Instead of generating abstract terms of the target language, transformations generate source code directly, interpolating strings with boilerplate code of the target language and variables defined in the transformation itself. The problem with this approach is that syntax errors in the string fragments of the target language are not detected statically. Consider the rule shown previously, rewritten below using string interpolation (the code between $[ and ]). Note that if the fragment would contain a typo, the syntax error would only be detected after the code had been generated. Note also that one can interpolate Stratego variables with the fragment of the target language by escaping them between [ and ]. program-to-java : Program ( stats ) - > $ [ public class Program { public static [ java-type ] eval () { [ java-stats ] } } ] with java-type := ... java-stats := ... The third option is to use concrete syntax. When using concrete syntax, the transformation is still AST-to-AST but the AST of the target language is abstracted over using the concrete syntax of the language instead. That is, the concrete syntax fragment is parsed internally producing an AST, and that AST is resulted from the transformation. The same rule defined using concrete syntax is shown below. Note that any syntax error in the fragment would in fact, be detected by the editor, as the fragment is being parsed internally. Moreover, the fragment also has the syntax highlighting of the target language when shown by the editor. program-to-java : Program ( stats ) - > compilation-unit |[ public class Program { public static ~ type : java-type eval () { ~ bstm * : java-stats * } } ]| with java-type := ... java-stats * := ... There are two aspects to consider when enabling concrete syntax inside Spoofax. The first one is being able to write Stratego transformations with fragments of a target (or source) language. In other words, the first aspect consists of generating a mixed parse table that embeds the desired target language inside Stratego. The second aspect consists of including the parse table inside an Spoofax project, adding an additional .meta file to then enable concrete syntax for a specific Stratego file. Below, we describe both aspects with more detail.","title":"Concrete Syntax"},{"location":"howtos/stratego/concrete-syntax/#mixing-grammars","text":"To generate a mixed parse table that embeds a language inside Stratego, it is necessary to modify the original Stratego grammar, extending it with the desired language. One problem that may occur when combining the grammars of two different languages is name clashing, i.e., non-terminals that have the same name in Stratego and the embedded language. For that reason, the embedding occurs using a modified Stratego grammar, which renames all Stratego context-free non-terminals using by prefixing it with StrategoLang , avoiding name clashes. Inside Spoofax, you can add a source dependency on the org.metaborg:stratego.lang:${metaborgVersion} project in you metaborg.yaml file, then you can import the so-called namespaced grammar. Once you have access to the namespaced grammar, the next step consists of defining the embedding grammar, the grammar that actually mixes the two languages. A grammar that embeds one language into another may contain three types of productions: productions that define quotations for elements of the target language in the host language, productions that define anti-quotations back to the host language from the target language, and variables, which are shortcuts to anti-quotations, and may appear inside the target language fragments. When embedding a language into Stratego, it is common to allow fragments of the host language as Stratego terms. For that reason, quotation productions are injected into Stratego terms. For example, the productions below, written in SDF3, indicates that a Java compilation unit can occur in Stratego in a place where a Stratego term can occur. imports StrategoLang / sugar / terms-namespaced java / packages / CompilationUnits context-free syntax StrategoLang-PreTerm . ToTerm = < compilation-unit |[ < CompilationUnit > ]|> StrategoLang-PreTerm . ToTerm = <|[ < CompilationUnit > ]|> Anti-quotation productions define points to insert elements of the host language inside fragments of the target language. For example, with the production below, we allow Stratego terms to occur in a Java fragment whenever a non-terminal Type can occur. imports java / types / Main context-free syntax Type . FromTerm = [ ~ [ StrategoLang-Term ]] Type . FromTerm = [ ~ type :[ StrategoLang-Term ]] Note that the constructor FromTerm indicates that productions represent anti-quotations. Furthermore, note that anti-quotations may also be named after the non-terminal being referenced (e.g., ~type: ). Using anti-quotations might make the fragment of the target language quite verbose. Therefore, it is also possible to define variables as shortcuts to anti-quotations. For example, the productions below define variables to reference anti-quotations to Type fragments. That is, instead of reference to a Stratego variable X by using ~type:X , one may name this variable t_1 which corresponds to a variable for a non-terminal Type . variables Type = \"t_\" [ 0 -9 \\' ] * { prefer } The prefer annotation indicates that in case of an ambiguity, the variable production should be preferred. Using the three types of productions above, it is possible to specify which fragments one wants to write using concrete syntax and which symbols may appear inside these fragments as Stratego variables (using anti-quotation or variables with a specific name). Finally, it is necessary to define a module Stratego-<LanguageName> that should import the Stratego grammar and the embedding grammar. This module should be defined in a file named Stratego-<LanguageName>.sdf3 and put in the syntax folder so that Spoofax can locate it and build the mixed table. That is, if we define the module for our Stratego-Java mixed grammar: module Stratego-Java imports EmbeddedJava StrategoLang / import-namespaced context-free start-symbols StrategoLang-Module Note that it is necessary to define the start symbol of the mixed grammar as StrategoLang-Module . After defining the embedding grammar and the Stratego-<LanguageName> module, Spoofax generates the mixed table inside the trans folder when rebuilding the project.","title":"Mixing Grammars"},{"location":"howtos/stratego/concrete-syntax/#using-mixed-parse-tables-to-allow-concrete-syntax","text":"Assuming a mixed parse table has been successfully generated or already exists, the next step is to allow concrete syntax in transformations using that table. The table needs to be in a folder that can be discovered by the Stratego compiler. By default it will be generated in the trans folder of the project that defines the mixed grammar, to be used within the project. If you wish to use the mixed grammar in another project, make sure to export the generate table by adding an entry for it in the metaborg.yaml file. Then any other project that depends on your mixed grammar project with a source dependency will also provide the table file to the Stratego compiler. Next, together with the file in which we would like to enable concrete syntax, it is necessary to create a .meta file with the same name. That is, to enable concrete syntax in a file generate.str , it is necessary to create, in the same directory, an addition file generate.meta . This file should indicate which mixed table should be used to parse generate.str . For that reason it should contain: Meta ([ Syntax ( \"<ParseTableName>\" )]) where <ParseTableName> is the filename of the parse table without extension, Stratego-Java in our example. With the configuration above, Spoofax automatically detects that the file contains concrete syntax and use that table to parse it. In that file, one may write rules containing concrete syntax as defined by the productions in the mixed grammar.","title":"Using Mixed Parse Tables to Allow Concrete Syntax"},{"location":"howtos/stratego/debug-stratego/","text":"Debug Stratego Programs \u00b6 Debugging Stratego programs can be frustrating. In strategic programming failure is a first-class citizen and the language supports dynamically typed programming. Thes are useful features for realizing generic and modular programming. However, this may mean that that errors may show up late in the game. A program fails much later then where the error occurs. Often during pretty-printing. Here we discuss some remedies for finding the problem. Signatures \u00b6 signature sorts Exp constructors Add : Exp * Exp - > Exp Define a good signature for your terms. Ideally define the syntax of your language in a syntax definition in SDF3, and declare all sorts explicitly, and avoid injections. This will ensure that a signature and matching pretty-printer are generated automatically, as well as a signature for Statix. Types \u00b6 translate :: Exp - > List ( Instr ) Define type signatures for transformations. Starting with Stratego2, the language supports the definition of type signatures for transformations . This will catch many obvious errors. Use With instead of Where \u00b6 translate : Add ( e1 , e2 ) - > < concat >[ instrs1 , instrs2 , [ Add ()]] with < translate > e1 => instrs1 with < translate > e2 => instrs2 The with clause expresses that you expect a premisse of a rewrite rule to succeed in all cases. When this expectation is violated, the rule will throw an exception and display a stack trace, instead of silently failing. Define SPT tests \u00b6 test translate [[ 1 + 2 ]] run translate Define unit tests in the SPT testing language. Debug \u00b6 dbg (| \"translate/Add: \" ) In case the measures above fail, use dbg to figure out where the error is in your program.","title":"Debug Stratego Programs"},{"location":"howtos/stratego/debug-stratego/#debug-stratego-programs","text":"Debugging Stratego programs can be frustrating. In strategic programming failure is a first-class citizen and the language supports dynamically typed programming. Thes are useful features for realizing generic and modular programming. However, this may mean that that errors may show up late in the game. A program fails much later then where the error occurs. Often during pretty-printing. Here we discuss some remedies for finding the problem.","title":"Debug Stratego Programs"},{"location":"howtos/stratego/debug-stratego/#signatures","text":"signature sorts Exp constructors Add : Exp * Exp - > Exp Define a good signature for your terms. Ideally define the syntax of your language in a syntax definition in SDF3, and declare all sorts explicitly, and avoid injections. This will ensure that a signature and matching pretty-printer are generated automatically, as well as a signature for Statix.","title":"Signatures"},{"location":"howtos/stratego/debug-stratego/#types","text":"translate :: Exp - > List ( Instr ) Define type signatures for transformations. Starting with Stratego2, the language supports the definition of type signatures for transformations . This will catch many obvious errors.","title":"Types"},{"location":"howtos/stratego/debug-stratego/#use-with-instead-of-where","text":"translate : Add ( e1 , e2 ) - > < concat >[ instrs1 , instrs2 , [ Add ()]] with < translate > e1 => instrs1 with < translate > e2 => instrs2 The with clause expresses that you expect a premisse of a rewrite rule to succeed in all cases. When this expectation is violated, the rule will throw an exception and display a stack trace, instead of silently failing.","title":"Use With instead of Where"},{"location":"howtos/stratego/debug-stratego/#define-spt-tests","text":"test translate [[ 1 + 2 ]] run translate Define unit tests in the SPT testing language.","title":"Define SPT tests"},{"location":"howtos/stratego/debug-stratego/#debug","text":"dbg (| \"translate/Add: \" ) In case the measures above fail, use dbg to figure out where the error is in your program.","title":"Debug"},{"location":"howtos/stratego/exchange-terms/","text":"Exchange Terms \u00b6 The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.","title":"Exchange Terms"},{"location":"howtos/stratego/exchange-terms/#exchange-terms","text":"The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.","title":"Exchange Terms"},{"location":"howtos/stratego/generate-pretty-printer/","text":"How to Generate a Pretty-Printer \u00b6 A pretty-printer is a mapping from abstract syntax trees (terms) to text. The resulting text should observe the syntactic rules Production Templates \u00b6 Generate Pretty-Printer \u00b6 automatically in build generates rules for translation from AST to Box Example. Generate pretty-print rules Use Pretty-Printer \u00b6 Define Builder \u00b6 for interactive use Define Menu Action \u00b6 to invoke the builder","title":"How to Generate a Pretty-Printer"},{"location":"howtos/stratego/generate-pretty-printer/#how-to-generate-a-pretty-printer","text":"A pretty-printer is a mapping from abstract syntax trees (terms) to text. The resulting text should observe the syntactic rules","title":"How to Generate a Pretty-Printer"},{"location":"howtos/stratego/generate-pretty-printer/#production-templates","text":"","title":"Production Templates"},{"location":"howtos/stratego/generate-pretty-printer/#generate-pretty-printer","text":"automatically in build generates rules for translation from AST to Box Example. Generate pretty-print rules","title":"Generate Pretty-Printer"},{"location":"howtos/stratego/generate-pretty-printer/#use-pretty-printer","text":"","title":"Use Pretty-Printer"},{"location":"howtos/stratego/generate-pretty-printer/#define-builder","text":"for interactive use","title":"Define Builder"},{"location":"howtos/stratego/generate-pretty-printer/#define-menu-action","text":"to invoke the builder","title":"Define Menu Action"},{"location":"howtos/stratego/generate-signature/","text":"How to Generate a Stratego Signature \u00b6 It is tedious to write a signature that is in sync with a syntax definition. Therefore, Spoofax automatically generates a signature from a syntax definition for the abstract syntax trees that the parser for that syntax definition produces. Write a Syntax Definition \u00b6 In the /syntax/ directory in your language project for language lang write a syntax definition in file lang.sdf3 . Possibly write additional syntax defininitions modules and import the in lang.sdf3 . Example. Consider the following SDF3 syntax definition: module lang imports Base lexical sorts IntConst lexical syntax IntConst = [ 0 -9 ] + sorts Exp context-free syntax Exp . Int = IntConst Exp . Plus = [[ Exp ] + [ Exp ]] { left } Exp . Minus = [[ Exp ] - [ Exp ]] { left } Exp = [([ Exp ])] { bracket } context-free priorities { left : Exp . Plus Exp . Minus } Generate Signature \u00b6 The build for your language project will invoke the SDF3 compiler to generate a signature file for each SDF3 file in your project in directory /src-gen/signatures/ with suffix -sig and extension .str . The build should be invoked as soon as you save a file. Thus lang.sdf3 generates /src-gen/signatures/lang-sig.str . Example. For the SDF3 file above, the following signature is automatically generated: module signatures / lang-sig imports signatures / Base-sig signature sorts IntConst sorts Exp constructors : string - > IntConst Int : IntConst - > Exp Plus : Exp * Exp - > Exp Minus : Exp * Exp - > Exp IntConst-Plhdr : IntConst Exp-Plhdr : Exp IntConst-Plhdr : COMPLETION-INSERTION - > IntConst Exp-Plhdr : COMPLETION-INSERTION - > Exp The injection from strings into the lexical IntConst sort reflects the fact that tokens are represented as strings in ASTs. The placeholder constructors generated for the sorts are used to represent incomplete programs and syntactic code completion 1 . Use Signature \u00b6 To use the signature, import it into the Stratego module that uses its constructors. Example. To use the signature for the example import it as follows: module desugar imports signatures / lang-sig rules // ... References \u00b6 Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016 , 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374 , doi:10.1145/2997364.2997374 . \u21a9","title":"How to Generate a Stratego Signature"},{"location":"howtos/stratego/generate-signature/#how-to-generate-a-stratego-signature","text":"It is tedious to write a signature that is in sync with a syntax definition. Therefore, Spoofax automatically generates a signature from a syntax definition for the abstract syntax trees that the parser for that syntax definition produces.","title":"How to Generate a Stratego Signature"},{"location":"howtos/stratego/generate-signature/#write-a-syntax-definition","text":"In the /syntax/ directory in your language project for language lang write a syntax definition in file lang.sdf3 . Possibly write additional syntax defininitions modules and import the in lang.sdf3 . Example. Consider the following SDF3 syntax definition: module lang imports Base lexical sorts IntConst lexical syntax IntConst = [ 0 -9 ] + sorts Exp context-free syntax Exp . Int = IntConst Exp . Plus = [[ Exp ] + [ Exp ]] { left } Exp . Minus = [[ Exp ] - [ Exp ]] { left } Exp = [([ Exp ])] { bracket } context-free priorities { left : Exp . Plus Exp . Minus }","title":"Write a Syntax Definition"},{"location":"howtos/stratego/generate-signature/#generate-signature","text":"The build for your language project will invoke the SDF3 compiler to generate a signature file for each SDF3 file in your project in directory /src-gen/signatures/ with suffix -sig and extension .str . The build should be invoked as soon as you save a file. Thus lang.sdf3 generates /src-gen/signatures/lang-sig.str . Example. For the SDF3 file above, the following signature is automatically generated: module signatures / lang-sig imports signatures / Base-sig signature sorts IntConst sorts Exp constructors : string - > IntConst Int : IntConst - > Exp Plus : Exp * Exp - > Exp Minus : Exp * Exp - > Exp IntConst-Plhdr : IntConst Exp-Plhdr : Exp IntConst-Plhdr : COMPLETION-INSERTION - > IntConst Exp-Plhdr : COMPLETION-INSERTION - > Exp The injection from strings into the lexical IntConst sort reflects the fact that tokens are represented as strings in ASTs. The placeholder constructors generated for the sorts are used to represent incomplete programs and syntactic code completion 1 .","title":"Generate Signature"},{"location":"howtos/stratego/generate-signature/#use-signature","text":"To use the signature, import it into the Stratego module that uses its constructors. Example. To use the signature for the example import it as follows: module desugar imports signatures / lang-sig rules // ...","title":"Use Signature"},{"location":"howtos/stratego/generate-signature/#references","text":"Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016 , 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374 , doi:10.1145/2997364.2997374 . \u21a9","title":"References"},{"location":"howtos/stratego/inspect-terms/","text":"Inspect Terms \u00b6 As a Stratego programmer you will be looking a lot at raw ATerms. Stratego pioneers did this by opening an ATerm file in emacs and trying to get a sense of the structure by parenthesis highlighting and inserting newlines here and there. These days your life is much more pleasant through pretty-printing ATerms, which adds layout to a term to make it readable. For example, parsing the following program let function fact(n : int) : int = if n < 1 then 1 else (n * fact(n - 1)) in printint(fact(10)) end produces the following ATerm: Let([FunDecs([FunDec(\"fact\",[FArg(\"n\",Tp(Tid(\"int\")))],Tp(Tid(\"int\")), If(Lt(Var(\"n\"),Int(\"1\")),Int(\"1\"),Seq([Times(Var(\"n\"),Call(Var(\"fact\"), [Minus(Var(\"n\"),Int(\"1\"))]))])))])],[Call(Var(\"printint\"),[Call(Var( \"fact\"),[Int(\"10\")])])]) By pretty-printing the term we get a much more readable term: Let( [ FunDecs( [ FunDec( \"fact\" , [FArg(\"n\", Tp(Tid(\"int\")))] , Tp(Tid(\"int\")) , If( Lt(Var(\"n\"), Int(\"1\")) , Int(\"1\") , Seq([ Times(Var(\"n\"), Call(Var(\"fact\"), [Minus(Var(\"n\"), Int(\"1\"))])) ]) ) ) ] ) ] , [ Call(Var(\"printint\"), [Call(Var(\"fact\"), [Int(\"10\")])]) ] ) In Spoofax/Eclipse, you will find that in some contexts ATerms are automatically pretty-printed, whereas in others they are simply printed linearly. However, you can obtain assistance with perceiving the structure of any ATerm by writing it into a file with the \".aterm\" extension and opening it in the Spoofax Editor in Eclipse. On the right there will be a convenient Outline Navigator which allows you to select any node in the ATerm and see the entire subtree below it highlighted in the editor.","title":"Inspect Terms"},{"location":"howtos/stratego/inspect-terms/#inspect-terms","text":"As a Stratego programmer you will be looking a lot at raw ATerms. Stratego pioneers did this by opening an ATerm file in emacs and trying to get a sense of the structure by parenthesis highlighting and inserting newlines here and there. These days your life is much more pleasant through pretty-printing ATerms, which adds layout to a term to make it readable. For example, parsing the following program let function fact(n : int) : int = if n < 1 then 1 else (n * fact(n - 1)) in printint(fact(10)) end produces the following ATerm: Let([FunDecs([FunDec(\"fact\",[FArg(\"n\",Tp(Tid(\"int\")))],Tp(Tid(\"int\")), If(Lt(Var(\"n\"),Int(\"1\")),Int(\"1\"),Seq([Times(Var(\"n\"),Call(Var(\"fact\"), [Minus(Var(\"n\"),Int(\"1\"))]))])))])],[Call(Var(\"printint\"),[Call(Var( \"fact\"),[Int(\"10\")])])]) By pretty-printing the term we get a much more readable term: Let( [ FunDecs( [ FunDec( \"fact\" , [FArg(\"n\", Tp(Tid(\"int\")))] , Tp(Tid(\"int\")) , If( Lt(Var(\"n\"), Int(\"1\")) , Int(\"1\") , Seq([ Times(Var(\"n\"), Call(Var(\"fact\"), [Minus(Var(\"n\"), Int(\"1\"))])) ]) ) ) ] ) ] , [ Call(Var(\"printint\"), [Call(Var(\"fact\"), [Int(\"10\")])]) ] ) In Spoofax/Eclipse, you will find that in some contexts ATerms are automatically pretty-printed, whereas in others they are simply printed linearly. However, you can obtain assistance with perceiving the structure of any ATerm by writing it into a file with the \".aterm\" extension and opening it in the Spoofax Editor in Eclipse. On the right there will be a convenient Outline Navigator which allows you to select any node in the ATerm and see the entire subtree below it highlighted in the editor.","title":"Inspect Terms"},{"location":"howtos/stratego/run-stratego-programs/","text":"How to Run Stratego Programs \u00b6 Stratego programs that are part of a language project in Spoofax/Eclipse are run by creating a menu entry that invokes a strategy in your program. Extend Spoofax Menu \u00b6 module $ModuleName menus menu : \"$Menu\" ( openeditor ) action : \"$MenuEntry\" = $Id Add a new ESV file in the editor/ directory of your project or use an existing one. In the menus section, create a menu with an appropriate name. Adding the attribute openeditor ensures that the result of running the program will be opened in an editor. Add an action entry to the menu with the name of the menu entry and the name of the builder strategy to invoke. This should add a menu entry Spoofax > Menu > Action to the editor for your language. Define Builder \u00b6 $ Id : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| $ Extension )> path with result := < $ Strategy > node In your Stratego program, probably in some top-level file in the trans/ directory of your project, add a 'builder' rewrite rule. Such a rewrite rule defines the interface between the user-interface (action menu entry) and your program. A builder has the interface shown above. When invoking the builder, Spoofax takes care of parsing the program and converting it to abstract syntax term. It takes a quintuple of the selected AST node , the entire ast , the file path , and the project-path and returns a pair of the filename and result . The results are computed in the conditions of the builder rule. The new filename is typically derived from the old file name in path The result is computed by invoking a strategy on the selected node or on the entire ast . Example: Parser \u00b6 module Syntax //... menus menu : \"Syntax\" ( openeditor ) action : \"Show parsed AST\" = debug-show-aterm ( source ) debug-show-aterm : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"aterm\" )> path ; result := node The debug-show-aterm provided with new Spoofax projects returns the selected node as result. Since Spoofax ensures that the content of the editor is parsed, this returns the AST of the editor content as a (pretty-printed) term. Example: Term Builder \u00b6 module Compilation menus menu : \"Compilation\" ( openeditor ) action : \"Desugar (AST)\" = desugar-aterm rules desugar-aterm : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"d.aterm\" )> path with result := < desugar > node The Desugar (AST) menu action calls the desugar-aterm builder, which in turn uses the desugar strategy to transform the selected node . The result is returned in a file with extension d.aterm . Example: Pretty Printing Builder \u00b6 module Compilation menus menu : \"Compilation\" ( openeditor ) action : \"Desugar\" = desugar-pp rules desugar-pp : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"d.tig\" )> path with result := < desugar ; pp-tiger-string > node The Desugar menu action calls the desugar-pp builder. That strategy transforms the selected node with desugar and pretty-prints the resulting term with pp-tiger-string . The result is returned in a file with extension d.tig . Define SPT Tests \u00b6 An alternative way to run transformations is to test them using SPT tests. This allows you to systematically run a transformation on a number of typical cases. Run On Save \u00b6 When a Stratego program is applied in production, a transformation can be applied automatically whenever a program in your language is saved.","title":"How to Run Stratego Programs"},{"location":"howtos/stratego/run-stratego-programs/#how-to-run-stratego-programs","text":"Stratego programs that are part of a language project in Spoofax/Eclipse are run by creating a menu entry that invokes a strategy in your program.","title":"How to Run Stratego Programs"},{"location":"howtos/stratego/run-stratego-programs/#extend-spoofax-menu","text":"module $ModuleName menus menu : \"$Menu\" ( openeditor ) action : \"$MenuEntry\" = $Id Add a new ESV file in the editor/ directory of your project or use an existing one. In the menus section, create a menu with an appropriate name. Adding the attribute openeditor ensures that the result of running the program will be opened in an editor. Add an action entry to the menu with the name of the menu entry and the name of the builder strategy to invoke. This should add a menu entry Spoofax > Menu > Action to the editor for your language.","title":"Extend Spoofax Menu"},{"location":"howtos/stratego/run-stratego-programs/#define-builder","text":"$ Id : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| $ Extension )> path with result := < $ Strategy > node In your Stratego program, probably in some top-level file in the trans/ directory of your project, add a 'builder' rewrite rule. Such a rewrite rule defines the interface between the user-interface (action menu entry) and your program. A builder has the interface shown above. When invoking the builder, Spoofax takes care of parsing the program and converting it to abstract syntax term. It takes a quintuple of the selected AST node , the entire ast , the file path , and the project-path and returns a pair of the filename and result . The results are computed in the conditions of the builder rule. The new filename is typically derived from the old file name in path The result is computed by invoking a strategy on the selected node or on the entire ast .","title":"Define Builder"},{"location":"howtos/stratego/run-stratego-programs/#example-parser","text":"module Syntax //... menus menu : \"Syntax\" ( openeditor ) action : \"Show parsed AST\" = debug-show-aterm ( source ) debug-show-aterm : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"aterm\" )> path ; result := node The debug-show-aterm provided with new Spoofax projects returns the selected node as result. Since Spoofax ensures that the content of the editor is parsed, this returns the AST of the editor content as a (pretty-printed) term.","title":"Example: Parser"},{"location":"howtos/stratego/run-stratego-programs/#example-term-builder","text":"module Compilation menus menu : \"Compilation\" ( openeditor ) action : \"Desugar (AST)\" = desugar-aterm rules desugar-aterm : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"d.aterm\" )> path with result := < desugar > node The Desugar (AST) menu action calls the desugar-aterm builder, which in turn uses the desugar strategy to transform the selected node . The result is returned in a file with extension d.aterm .","title":"Example: Term Builder"},{"location":"howtos/stratego/run-stratego-programs/#example-pretty-printing-builder","text":"module Compilation menus menu : \"Compilation\" ( openeditor ) action : \"Desugar\" = desugar-pp rules desugar-pp : ( node , _ , _ , path , project-path ) - > ( filename , result ) with filename := < guarantee-extension (| \"d.tig\" )> path with result := < desugar ; pp-tiger-string > node The Desugar menu action calls the desugar-pp builder. That strategy transforms the selected node with desugar and pretty-prints the resulting term with pp-tiger-string . The result is returned in a file with extension d.tig .","title":"Example: Pretty Printing Builder"},{"location":"howtos/stratego/run-stratego-programs/#define-spt-tests","text":"An alternative way to run transformations is to test them using SPT tests. This allows you to systematically run a transformation on a number of typical cases.","title":"Define SPT Tests"},{"location":"howtos/stratego/run-stratego-programs/#run-on-save","text":"When a Stratego program is applied in production, a transformation can be applied automatically whenever a program in your language is saved.","title":"Run On Save"},{"location":"references/","text":"References \u00b6 This are the Spoofax and meta-language references. For more background information on the ideas, architecture, and design decisions behind Spoofax and its meta-languages, see the Background section. The reference section should explain language constructs (syntax, statics, dynamics) and be structured following a taxonomy of the language Table of Contents \u00b6 SDF3 (Jasper) Statix (Aron) FlowSpec (Matthijs, Jeff) Stratego (Eelco, Jeff) PIE (Ivo, Gabri\u00ebl) MkDocs (Dani\u00ebl) bibtex syntax highlighting ESV / editor services Reviewing Peter Toine","title":"References"},{"location":"references/#references","text":"This are the Spoofax and meta-language references. For more background information on the ideas, architecture, and design decisions behind Spoofax and its meta-languages, see the Background section. The reference section should explain language constructs (syntax, statics, dynamics) and be structured following a taxonomy of the language","title":"References"},{"location":"references/#table-of-contents","text":"SDF3 (Jasper) Statix (Aron) FlowSpec (Matthijs, Jeff) Stratego (Eelco, Jeff) PIE (Ivo, Gabri\u00ebl) MkDocs (Dani\u00ebl) bibtex syntax highlighting ESV / editor services Reviewing Peter Toine","title":"Table of Contents"},{"location":"references/config/","text":"Language Configuration \u00b6 metaborg.yaml","title":"Language Configuration"},{"location":"references/config/#language-configuration","text":"metaborg.yaml","title":"Language Configuration"},{"location":"references/editor-services/","text":"Editor Services \u00b6 Most editor services are configured in an ESV file . This way the following editor services can be defined: Action Menus Analysis File Extensions Hover Tooltips On-Save Handlers Outline View Parsing Reference Resolution Stratego Strategies Syntax Highlighting Additionally, the following editor services are configured in a different way: Rename Refactoring","title":"Editor Services"},{"location":"references/editor-services/#editor-services","text":"Most editor services are configured in an ESV file . This way the following editor services can be defined: Action Menus Analysis File Extensions Hover Tooltips On-Save Handlers Outline View Parsing Reference Resolution Stratego Strategies Syntax Highlighting Additionally, the following editor services are configured in a different way: Rename Refactoring","title":"Editor Services"},{"location":"references/editor-services/analysis/","text":"Analysis \u00b6 The analyzer strategy is used to perform static analyses such as name and type analysis, on the AST that a parser produces. An analysis context provides a project-wide store to facilitate multi-file analysis and incrementality. There are four ways to configure the analysis, which set the analyzer strategy with the observer and context keys in an ESV file . language context : $Context observer : $Strategy No Analysis \u00b6 To completely disable analysis, do not set an observer and set the context to none: language context : none Stratego \u00b6 Stratego-based analysis allows you to implement your analysis in Stratego: language context : legacy observer : editor-analyze The identifier after the colon refers to the Stratego strategy that performs the analysis. It must take as input a 3-tuple (ast, path, projectPath) . As output it must produce a 4-tuple (ast, error*, warning*, note*) . The following Stratego code is an example of a strategy that implements this signature: editor-analyze : ( ast , path , projectPath ) - > ( ast ' , errors , warnings , notes ) with ast ' := < analyze > ast ; errors := < collect-all ( check-error )> ast ' ; warnings := < collect-all ( check-warning )> ast ' ; notes := < collect-all ( check-note )> ast ' Statix \u00b6 To use Statix as the meta-language for name and type analysis, use the editor-analyze strategy defined in trans/analysis.str , annotate it with the (constraint) modifier, and set no context: language observer : editor-analyze ( constraint ) By default, the Statix analyzer works in single-file mode and does not consider multi-file name resolution. To enable that, add the (multifile) modifier: language observer : editor-analyze ( constraint ) ( multifile )","title":"Analysis"},{"location":"references/editor-services/analysis/#analysis","text":"The analyzer strategy is used to perform static analyses such as name and type analysis, on the AST that a parser produces. An analysis context provides a project-wide store to facilitate multi-file analysis and incrementality. There are four ways to configure the analysis, which set the analyzer strategy with the observer and context keys in an ESV file . language context : $Context observer : $Strategy","title":"Analysis"},{"location":"references/editor-services/analysis/#no-analysis","text":"To completely disable analysis, do not set an observer and set the context to none: language context : none","title":"No Analysis"},{"location":"references/editor-services/analysis/#stratego","text":"Stratego-based analysis allows you to implement your analysis in Stratego: language context : legacy observer : editor-analyze The identifier after the colon refers to the Stratego strategy that performs the analysis. It must take as input a 3-tuple (ast, path, projectPath) . As output it must produce a 4-tuple (ast, error*, warning*, note*) . The following Stratego code is an example of a strategy that implements this signature: editor-analyze : ( ast , path , projectPath ) - > ( ast ' , errors , warnings , notes ) with ast ' := < analyze > ast ; errors := < collect-all ( check-error )> ast ' ; warnings := < collect-all ( check-warning )> ast ' ; notes := < collect-all ( check-note )> ast '","title":"Stratego"},{"location":"references/editor-services/analysis/#statix","text":"To use Statix as the meta-language for name and type analysis, use the editor-analyze strategy defined in trans/analysis.str , annotate it with the (constraint) modifier, and set no context: language observer : editor-analyze ( constraint ) By default, the Statix analyzer works in single-file mode and does not consider multi-file name resolution. To enable that, add the (multifile) modifier: language observer : editor-analyze ( constraint ) ( multifile )","title":"Statix"},{"location":"references/editor-services/esv/","text":"ESV \u00b6 The Editor Service (ESV) language is a declarative meta-language for configuring the editor services of a language. For example, the following ESV code fragment configures the syntax highlighting for a language, based on the types of tokens: module color colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic Structure \u00b6 ESV files end with the .esv extension, and are by convention placed in the editor/ folder of a language project. Each ESV file defines a module for the file, followed by import statements and then the main configuration sections. Each section consists of a number of keys and values. Main File By convention, the main ESV file of a language project must live at editor/Main.esv (default) or editor/main.esv . Other ESV files can be (transitively) imported from the main ESV file. Module Definition \u00b6 An ESV file starts with a module definition at the top of the file: module $ModuleName The module name is the filename of the ESV file without the exttension, and relative to the editor/ directory. For example, the module editor/mylang/Syntax.esv would have the following module name: module mylang/Syntax Module names can only contains the alphanumeric characters and dash, underscore, and period, and use the forward slash ( / ) as the path separator. Module names cannot be in parent directories, so ../Syntax is not allowed. Imports \u00b6 The imports section is an optional section immediately following the module definition. When specified it is given as: imports $Imports For example, to import editor/Syntax.esv and editor/Analysis.esv : imports Syntax Analysis Imports are transitive. At most one imports section is permitted. When specified, the imports section cannot be empty. Configuration Sections \u00b6 The main body of an ESV file consists of any number of configuration sections. An example of a configuration section is: language line comment : \"//\" block comment : \"/*\" \"*/\" The configuration sections are hard-coded in the ESV language, but mostly use a consistent syntax for the keys and values. The following configuration sections are currently defined: colorer Syntax Highlighting language Language File Extensions Parsing Analysis On-Save Handlers Stratego Strategies menus Action menus references Hover Tooltips Reference Resolutions views Outline View The following sections have been deprecated: analysis builders completions folding outliner refactorings","title":"ESV"},{"location":"references/editor-services/esv/#esv","text":"The Editor Service (ESV) language is a declarative meta-language for configuring the editor services of a language. For example, the following ESV code fragment configures the syntax highlighting for a language, based on the types of tokens: module color colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"ESV"},{"location":"references/editor-services/esv/#structure","text":"ESV files end with the .esv extension, and are by convention placed in the editor/ folder of a language project. Each ESV file defines a module for the file, followed by import statements and then the main configuration sections. Each section consists of a number of keys and values. Main File By convention, the main ESV file of a language project must live at editor/Main.esv (default) or editor/main.esv . Other ESV files can be (transitively) imported from the main ESV file.","title":"Structure"},{"location":"references/editor-services/esv/#module-definition","text":"An ESV file starts with a module definition at the top of the file: module $ModuleName The module name is the filename of the ESV file without the exttension, and relative to the editor/ directory. For example, the module editor/mylang/Syntax.esv would have the following module name: module mylang/Syntax Module names can only contains the alphanumeric characters and dash, underscore, and period, and use the forward slash ( / ) as the path separator. Module names cannot be in parent directories, so ../Syntax is not allowed.","title":"Module Definition"},{"location":"references/editor-services/esv/#imports","text":"The imports section is an optional section immediately following the module definition. When specified it is given as: imports $Imports For example, to import editor/Syntax.esv and editor/Analysis.esv : imports Syntax Analysis Imports are transitive. At most one imports section is permitted. When specified, the imports section cannot be empty.","title":"Imports"},{"location":"references/editor-services/esv/#configuration-sections","text":"The main body of an ESV file consists of any number of configuration sections. An example of a configuration section is: language line comment : \"//\" block comment : \"/*\" \"*/\" The configuration sections are hard-coded in the ESV language, but mostly use a consistent syntax for the keys and values. The following configuration sections are currently defined: colorer Syntax Highlighting language Language File Extensions Parsing Analysis On-Save Handlers Stratego Strategies menus Action menus references Hover Tooltips Reference Resolutions views Outline View The following sections have been deprecated: analysis builders completions folding outliner refactorings","title":"Configuration Sections"},{"location":"references/editor-services/file-extensions/","text":"Language File Extensions \u00b6 The file extensions that the editor should recognize as files belonging to the language definition, are configured in the language section extensions key of an ESV file . They are specified without a leading dot: language extensions : ent Multiple extensions can be set with a comma-separated list: language extensions : ent , entity , entities This will assign for example foo.ent , foo.entity , and foo.entities to the language.","title":"Language File Extensions"},{"location":"references/editor-services/file-extensions/#language-file-extensions","text":"The file extensions that the editor should recognize as files belonging to the language definition, are configured in the language section extensions key of an ESV file . They are specified without a leading dot: language extensions : ent Multiple extensions can be set with a comma-separated list: language extensions : ent , entity , entities This will assign for example foo.ent , foo.entity , and foo.entities to the language.","title":"Language File Extensions"},{"location":"references/editor-services/hover/","text":"Hover Tooltips \u00b6 Hover tooltips show a textual tooltip with extra information, when hovering part of the text. Hover tooltips are created by a Stratego strategy, but are configured in an ESV file under the references section: references hover _ : $Strategy For example: references hover _ : editor-hover The identifier after the colon refers to the Stratego strategy that creates the hover tooltip. The Stratego strategy takes an AST node, and either fails if no tooltip should be produced, or returns a tooltip string. The string may contain a few simple HTML tag to style the output. The following tags are supported: <br/> \u2014 line break <b>text</b> \u2014 bold <i>text</i> \u2014 italic <pre>code</pre> \u2014 preformatted (code) text Unrecognized HTML tags are stripped from the hover tooltip. Escape angled brackets and ampersands to show them verbatim in the tooltip.","title":"Hover Tooltips"},{"location":"references/editor-services/hover/#hover-tooltips","text":"Hover tooltips show a textual tooltip with extra information, when hovering part of the text. Hover tooltips are created by a Stratego strategy, but are configured in an ESV file under the references section: references hover _ : $Strategy For example: references hover _ : editor-hover The identifier after the colon refers to the Stratego strategy that creates the hover tooltip. The Stratego strategy takes an AST node, and either fails if no tooltip should be produced, or returns a tooltip string. The string may contain a few simple HTML tag to style the output. The following tags are supported: <br/> \u2014 line break <b>text</b> \u2014 bold <i>text</i> \u2014 italic <pre>code</pre> \u2014 preformatted (code) text Unrecognized HTML tags are stripped from the hover tooltip. Escape angled brackets and ampersands to show them verbatim in the tooltip.","title":"Hover Tooltips"},{"location":"references/editor-services/menus/","text":"Action Menus \u00b6 Menus are used to bind actions of your language, such as transformations, to a menu in the IDE. Menus are defined using the menu keyword under a menus section in an ESV file , and can themselves contain submenus, actions, and separators. menu : $String $MenuOptions $MenuContribs Menu Contributions \u00b6 A menu has zero or more $MenuContrib , which are: action , submenu , or separator . Actions \u00b6 Actions (sometimes called builders ) are defined under a menu or submenu with syntax: action : $String = $StrategoCall $MenuOptions Submenus \u00b6 Submenus allow grouping of actions in nested menus. Their syntax is: sub menu : $String $MenuOptions $MenuContribs end Separators \u00b6 Separators allow inserting a separator in a menu list using the syntax: separator Menu Options \u00b6 The menu options specify the behavior of the menu item. The following modifiers are supported: Modifier Description (source) Action is performed on the parsed AST instead of the default analyzed AST. (openeditor) The result should be opened in a new editor. (realtime) (meta) Example \u00b6 An example menu: menus menu : \"Generate\" action : \"To normal form\" = to-normal-form ( source ) sub menu : \"To Java\" action : \"Abstract\" = to-java-abstract ( openeditor ) action : \"Concrete\" = to-java-concrete end","title":"Action Menus"},{"location":"references/editor-services/menus/#action-menus","text":"Menus are used to bind actions of your language, such as transformations, to a menu in the IDE. Menus are defined using the menu keyword under a menus section in an ESV file , and can themselves contain submenus, actions, and separators. menu : $String $MenuOptions $MenuContribs","title":"Action Menus"},{"location":"references/editor-services/menus/#menu-contributions","text":"A menu has zero or more $MenuContrib , which are: action , submenu , or separator .","title":"Menu Contributions"},{"location":"references/editor-services/menus/#actions","text":"Actions (sometimes called builders ) are defined under a menu or submenu with syntax: action : $String = $StrategoCall $MenuOptions","title":"Actions"},{"location":"references/editor-services/menus/#submenus","text":"Submenus allow grouping of actions in nested menus. Their syntax is: sub menu : $String $MenuOptions $MenuContribs end","title":"Submenus"},{"location":"references/editor-services/menus/#separators","text":"Separators allow inserting a separator in a menu list using the syntax: separator","title":"Separators"},{"location":"references/editor-services/menus/#menu-options","text":"The menu options specify the behavior of the menu item. The following modifiers are supported: Modifier Description (source) Action is performed on the parsed AST instead of the default analyzed AST. (openeditor) The result should be opened in a new editor. (realtime) (meta)","title":"Menu Options"},{"location":"references/editor-services/menus/#example","text":"An example menu: menus menu : \"Generate\" action : \"To normal form\" = to-normal-form ( source ) sub menu : \"To Java\" action : \"Abstract\" = to-java-abstract ( openeditor ) action : \"Concrete\" = to-java-concrete end","title":"Example"},{"location":"references/editor-services/on-save/","text":"On-Save Handlers \u00b6 The on-save handler (also known as the compiler strategy) is used to transform files when they are saved in an editor. In an IDE, when a new project is opened, the compiler strategy is also executed on each file in the project, as well as when files change in the background. In a command-line batch compiler setting, it is used to transform all files. The compiler strategy is configured in an ESV file with the on save key: language on save : $Strategy The identifier after the colon refers to the Stratego strategy that performs the transformation. This strategy must have the exact same signature as the one for actions . For example: language on save : compile-file","title":"On-Save Handlers"},{"location":"references/editor-services/on-save/#on-save-handlers","text":"The on-save handler (also known as the compiler strategy) is used to transform files when they are saved in an editor. In an IDE, when a new project is opened, the compiler strategy is also executed on each file in the project, as well as when files change in the background. In a command-line batch compiler setting, it is used to transform all files. The compiler strategy is configured in an ESV file with the on save key: language on save : $Strategy The identifier after the colon refers to the Stratego strategy that performs the transformation. This strategy must have the exact same signature as the one for actions . For example: language on save : compile-file","title":"On-Save Handlers"},{"location":"references/editor-services/outline/","text":"Outline View \u00b6 An outline is a summary of the structure of a file, shown in a separate view next to a textual editor. An outline is created by a Stratego strategy, but is configured in an ESV file under the views section: views outline view : $Strategy expand to level : $Int The Stratego strategy specified as $Strategy must have the following signature: signature constructors Node : Label * Children - > Node rules editor-outline : ( node , position , ast , path , project-path ) - > outline Where the input is the default tuple used for builders , and the result is a list of Node terms, each carrying a label and a (possibly empty) list of child nodes. Preserve origins on the node's label to allow navigating to the corresponding code from the outline. For example: views outline view : editor-outline expand to level : 3 This configures the editor-outline Stratego strategy to be used to create outlines, and that outline nodes should be expanded 3 levels deep by default.","title":"Outline View"},{"location":"references/editor-services/outline/#outline-view","text":"An outline is a summary of the structure of a file, shown in a separate view next to a textual editor. An outline is created by a Stratego strategy, but is configured in an ESV file under the views section: views outline view : $Strategy expand to level : $Int The Stratego strategy specified as $Strategy must have the following signature: signature constructors Node : Label * Children - > Node rules editor-outline : ( node , position , ast , path , project-path ) - > outline Where the input is the default tuple used for builders , and the result is a list of Node terms, each carrying a label and a (possibly empty) list of child nodes. Preserve origins on the node's label to allow navigating to the corresponding code from the outline. For example: views outline view : editor-outline expand to level : 3 This configures the editor-outline Stratego strategy to be used to create outlines, and that outline nodes should be expanded 3 levels deep by default.","title":"Outline View"},{"location":"references/editor-services/parsing/","text":"Parsing \u00b6 Parsing language files in an editor is configured in the language section of an ESV file . The syntax is as follows: language table : $Path start symbols : $Sorts line comment : $String block comment : $String * $String fences : $Fences For example: language table : target/metaborg/sdf . tbl start symbols : File line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { } Parse Table \u00b6 The parse table of your language is set with the table key. By default, the parse table of an SDF specification is always produced at target/metaborg/sdf.tbl . It is only necessary to change this configuration when a custom parse table is used. Start Symbols \u00b6 The start symbols key determine which start symbols to use when an editor is opened. This must be a subset of the start symbols defined in the SDF3 specification of your language. Multiple start symbols can be set with a comma-separated list: language start symbols : Start , Program Comments \u00b6 The syntax for comments is: language line comment : $String block comment : $String * $String For example, Java comments are specified as: language line comment : \"//\" block comment : \"/*\" * \"*/\" The line comment key determines how single-line comments are created. It is used by editors to toggle the comment for a single line. For example, in Eclipse, pressing Ctrl + / ( Cmd + / on macOS), respectively comments or uncomments the line. The block comment key determines how multi-line comments are created. It is used when a whole block needs to be commented or uncommented. A block comment is described by the two strings denoting the start and end symbols of the block comment respectively. Fences \u00b6 Fences for bracket matching are set as follows: language fences : $Fences The fences key determines which symbols to use and match for bracket matching. A single fence is defined by a starting and closing symbol. Multiple fences can be set with a space-separated list. Fences are used to do bracket matching in text editors. For example, the default fences in a new Spoofax language project are: language fences : [ ] ( ) { } Multi-Character Fences Fences can contain multiple characters, but some implementations may not handle bracket matching with multiple fence characters. For example, Eclipse does not handle this case and ignores multi-character fences.","title":"Parsing"},{"location":"references/editor-services/parsing/#parsing","text":"Parsing language files in an editor is configured in the language section of an ESV file . The syntax is as follows: language table : $Path start symbols : $Sorts line comment : $String block comment : $String * $String fences : $Fences For example: language table : target/metaborg/sdf . tbl start symbols : File line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { }","title":"Parsing"},{"location":"references/editor-services/parsing/#parse-table","text":"The parse table of your language is set with the table key. By default, the parse table of an SDF specification is always produced at target/metaborg/sdf.tbl . It is only necessary to change this configuration when a custom parse table is used.","title":"Parse Table"},{"location":"references/editor-services/parsing/#start-symbols","text":"The start symbols key determine which start symbols to use when an editor is opened. This must be a subset of the start symbols defined in the SDF3 specification of your language. Multiple start symbols can be set with a comma-separated list: language start symbols : Start , Program","title":"Start Symbols"},{"location":"references/editor-services/parsing/#comments","text":"The syntax for comments is: language line comment : $String block comment : $String * $String For example, Java comments are specified as: language line comment : \"//\" block comment : \"/*\" * \"*/\" The line comment key determines how single-line comments are created. It is used by editors to toggle the comment for a single line. For example, in Eclipse, pressing Ctrl + / ( Cmd + / on macOS), respectively comments or uncomments the line. The block comment key determines how multi-line comments are created. It is used when a whole block needs to be commented or uncommented. A block comment is described by the two strings denoting the start and end symbols of the block comment respectively.","title":"Comments"},{"location":"references/editor-services/parsing/#fences","text":"Fences for bracket matching are set as follows: language fences : $Fences The fences key determines which symbols to use and match for bracket matching. A single fence is defined by a starting and closing symbol. Multiple fences can be set with a space-separated list. Fences are used to do bracket matching in text editors. For example, the default fences in a new Spoofax language project are: language fences : [ ] ( ) { } Multi-Character Fences Fences can contain multiple characters, but some implementations may not handle bracket matching with multiple fence characters. For example, Eclipse does not handle this case and ignores multi-character fences.","title":"Fences"},{"location":"references/editor-services/reference-resolution/","text":"Reference Resolution \u00b6 Reference resolution takes an AST node containing a reference, and tries to resolve it to its definition. The resolution is performed by a Stratego strategy, but is configured in an ESV file under the references section: references reference _ : $Strategy The identifier after the colon refers to the Stratego strategy that performs the resolution. The Stratego strategy takes an AST node, and either fails if it could not be resolved, or returns an AST node that has an origin location pointing to the definition site. For example: references reference _ : editor-resolve","title":"Reference Resolution"},{"location":"references/editor-services/reference-resolution/#reference-resolution","text":"Reference resolution takes an AST node containing a reference, and tries to resolve it to its definition. The resolution is performed by a Stratego strategy, but is configured in an ESV file under the references section: references reference _ : $Strategy The identifier after the colon refers to the Stratego strategy that performs the resolution. The Stratego strategy takes an AST node, and either fails if it could not be resolved, or returns an AST node that has an origin location pointing to the definition site. For example: references reference _ : editor-resolve","title":"Reference Resolution"},{"location":"references/editor-services/renaming/","text":"Rename Refactoring \u00b6 Spoofax provides an automated rename refactoring as an editor service for every language developed with it that has the static semantics defined with Statix or NaBL2. Strategy \u00b6 Rename refactoring is enabled by default for new Spoofax language projects. This works by registering the rename-action strategy from the statixruntime library as an action in a menu. This strategy takes three parameters: a layout-preserving pretty-printing strategy ( construct-textual-change by default), the editor analyze strategy ( editor-analyze by default), and a strategy that should succeed when renaming in multi-file mode. The default rename refactoring strategy looks like this: rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , fail ) To enable multi-file mode, change the last argument to id : rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id ) Statix \u00b6 For the renaming to work correctly in all cases when using Statix, terms that represent a declaration of a program entity, such as a function or a variable, need to set the @decl property on the name of the entity. For example, when declaring a type: declareType ( scope , name , T ) : - scope -> Type { name } with typeOfDecl T , @ name . decl := name , typeOfDecl of Type { name } in scope |-> [ ( _ , ( _ , T )) ] . See Also \u00b6 How-To: Add Rename Refactoring to an Existing Project","title":"Rename Refactoring"},{"location":"references/editor-services/renaming/#rename-refactoring","text":"Spoofax provides an automated rename refactoring as an editor service for every language developed with it that has the static semantics defined with Statix or NaBL2.","title":"Rename Refactoring"},{"location":"references/editor-services/renaming/#strategy","text":"Rename refactoring is enabled by default for new Spoofax language projects. This works by registering the rename-action strategy from the statixruntime library as an action in a menu. This strategy takes three parameters: a layout-preserving pretty-printing strategy ( construct-textual-change by default), the editor analyze strategy ( editor-analyze by default), and a strategy that should succeed when renaming in multi-file mode. The default rename refactoring strategy looks like this: rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , fail ) To enable multi-file mode, change the last argument to id : rules rename-menu-action = rename-action ( construct-textual-change , editor-analyze , id )","title":"Strategy"},{"location":"references/editor-services/renaming/#statix","text":"For the renaming to work correctly in all cases when using Statix, terms that represent a declaration of a program entity, such as a function or a variable, need to set the @decl property on the name of the entity. For example, when declaring a type: declareType ( scope , name , T ) : - scope -> Type { name } with typeOfDecl T , @ name . decl := name , typeOfDecl of Type { name } in scope |-> [ ( _ , ( _ , T )) ] .","title":"Statix"},{"location":"references/editor-services/renaming/#see-also","text":"How-To: Add Rename Refactoring to an Existing Project","title":"See Also"},{"location":"references/editor-services/stratego/","text":"Stratego \u00b6 The Java JAR and CTree files that will be loaded into the Stratego runtime for your language can be configured with the provider key in an ESV file : language provider : $Path The path is a path to a .jar or .ctree file, relative to the root of the project. For example: language provider : target/metaborg/stratego . ctree The extension of the provider should match the format in the metaborg.yaml file of your language. Multiple files can be set by setting the key multiple times: ``esv language provider : target/metaborg/stratego.ctree provider : target/custom1.jar provider : target/custom2.ctree ```","title":"Stratego"},{"location":"references/editor-services/stratego/#stratego","text":"The Java JAR and CTree files that will be loaded into the Stratego runtime for your language can be configured with the provider key in an ESV file : language provider : $Path The path is a path to a .jar or .ctree file, relative to the root of the project. For example: language provider : target/metaborg/stratego . ctree The extension of the provider should match the format in the metaborg.yaml file of your language. Multiple files can be set by setting the key multiple times: ``esv language provider : target/metaborg/stratego.ctree provider : target/custom1.jar provider : target/custom2.ctree ```","title":"Stratego"},{"location":"references/editor-services/syntax-highlighting/","text":"Syntax Highlighting \u00b6 Token-based syntax highlighting is configured in a colorer section of an ESV file . Such a section can contain style definitions and styling rules. Style Definitions \u00b6 Style definitions bind an identifier to a style for later reuse, using the syntax: $ID = $Style Styles \u00b6 A style specifies a combination of a foreground color, optional background color, and optional font style. Colors are specified as Red-Green-Blue values ranging from 0 (none) to 255 (full). The possible font attributes are: Font attribute Description (none) Normal font. bold Bold font. italic Italic font. bold italic Bond and italic font. italic bold Same as bold italic . For example, the following style definitions bind the red , green , and blue colors: colorer red = 255 0 0 green = 0 255 0 blue = 0 0 255 An optional background color can be set by adding another RGB value: colorer redWithGreenBackground = 255 0 0 0 255 0 The font attributes can be used to make the font bold or italic: colorer redWithBold = 255 0 0 bold redWithItalic = 255 0 0 italic redWithGreenBackgroundWithBoldItalic = 255 0 0 0 255 0 bold italic Style Rules \u00b6 Style rules assign a style to matched tokens with syntax: $Matcher : $Style Or assigns a previously defined style definition: $Matcher : $Ref The left hand side of style rules matches a token, whereas the right hand side assigns a style by referring to a previously defined style definition, or by directly assigning a style. For example, the following matches a token type and references a style definition: colorer operator : black whereas the following matches a token with a sort and constructor, and directly assigns a style: colorer ClassBodyDec . MethodDec : 0 255 0 Matchers \u00b6 There are several ways in which the matcher on the left-hand side of a style rule can be specified: by type, by sort, by constructor, or by sort and constructor. Match by Sort and Constructor \u00b6 The combination of a token sort and constructor can be matched by specifying the $Sort.$Constructor . For example: colorer ClassBodyDec.MethodDec : yellow ClassBodyDec.FieldDec : red Match by Constructor \u00b6 It is also possible to match constructors, regardless of their token sorts, using _ in place of the sort name. For example: colorer _ . Str : blue _ . StrCong : blue _ . QStr : blue _ . QDollar : blue _ . QBr : gray Match by Sort \u00b6 Additionally, it is possible to match any constructor for a specific sort. For this, just specify the name of the sort, $Sort . For example: colorer ID : darkblue TYPEID : blue JQTYPEID : blue PQTYPEID : blue FUNCID : 153 51 0 JFUNCID : 153 51 0 STRING : 177 47 2 Match by Type \u00b6 Finally, the following built-in token types can be matched on: identifier \u2014 matches identifiers, found by lexical non-terminals without numbers; keyword \u2014 matches keywords, found by terminals in the syntax definition; layout \u2014 matches layout, such as whitespace and comments, found by layout definition; number \u2014 matches numbers, found by lexical non-terminals with numbers; operator \u2014 matches operations, found by terminals that contain just symbols (no characters); string \u2014 matches strings, found by lexical non-terminals that include quotation marks; unknown \u2014 matches tokens which the parser was unable to infer a type for. var error For example, the following code defines a simple highlighting with token types: colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"Syntax Highlighting"},{"location":"references/editor-services/syntax-highlighting/#syntax-highlighting","text":"Token-based syntax highlighting is configured in a colorer section of an ESV file . Such a section can contain style definitions and styling rules.","title":"Syntax Highlighting"},{"location":"references/editor-services/syntax-highlighting/#style-definitions","text":"Style definitions bind an identifier to a style for later reuse, using the syntax: $ID = $Style","title":"Style Definitions"},{"location":"references/editor-services/syntax-highlighting/#styles","text":"A style specifies a combination of a foreground color, optional background color, and optional font style. Colors are specified as Red-Green-Blue values ranging from 0 (none) to 255 (full). The possible font attributes are: Font attribute Description (none) Normal font. bold Bold font. italic Italic font. bold italic Bond and italic font. italic bold Same as bold italic . For example, the following style definitions bind the red , green , and blue colors: colorer red = 255 0 0 green = 0 255 0 blue = 0 0 255 An optional background color can be set by adding another RGB value: colorer redWithGreenBackground = 255 0 0 0 255 0 The font attributes can be used to make the font bold or italic: colorer redWithBold = 255 0 0 bold redWithItalic = 255 0 0 italic redWithGreenBackgroundWithBoldItalic = 255 0 0 0 255 0 bold italic","title":"Styles"},{"location":"references/editor-services/syntax-highlighting/#style-rules","text":"Style rules assign a style to matched tokens with syntax: $Matcher : $Style Or assigns a previously defined style definition: $Matcher : $Ref The left hand side of style rules matches a token, whereas the right hand side assigns a style by referring to a previously defined style definition, or by directly assigning a style. For example, the following matches a token type and references a style definition: colorer operator : black whereas the following matches a token with a sort and constructor, and directly assigns a style: colorer ClassBodyDec . MethodDec : 0 255 0","title":"Style Rules"},{"location":"references/editor-services/syntax-highlighting/#matchers","text":"There are several ways in which the matcher on the left-hand side of a style rule can be specified: by type, by sort, by constructor, or by sort and constructor.","title":"Matchers"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort-and-constructor","text":"The combination of a token sort and constructor can be matched by specifying the $Sort.$Constructor . For example: colorer ClassBodyDec.MethodDec : yellow ClassBodyDec.FieldDec : red","title":"Match by Sort and Constructor"},{"location":"references/editor-services/syntax-highlighting/#match-by-constructor","text":"It is also possible to match constructors, regardless of their token sorts, using _ in place of the sort name. For example: colorer _ . Str : blue _ . StrCong : blue _ . QStr : blue _ . QDollar : blue _ . QBr : gray","title":"Match by Constructor"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort","text":"Additionally, it is possible to match any constructor for a specific sort. For this, just specify the name of the sort, $Sort . For example: colorer ID : darkblue TYPEID : blue JQTYPEID : blue PQTYPEID : blue FUNCID : 153 51 0 JFUNCID : 153 51 0 STRING : 177 47 2","title":"Match by Sort"},{"location":"references/editor-services/syntax-highlighting/#match-by-type","text":"Finally, the following built-in token types can be matched on: identifier \u2014 matches identifiers, found by lexical non-terminals without numbers; keyword \u2014 matches keywords, found by terminals in the syntax definition; layout \u2014 matches layout, such as whitespace and comments, found by layout definition; number \u2014 matches numbers, found by lexical non-terminals with numbers; operator \u2014 matches operations, found by terminals that contain just symbols (no characters); string \u2014 matches strings, found by lexical non-terminals that include quotation marks; unknown \u2014 matches tokens which the parser was unable to infer a type for. var error For example, the following code defines a simple highlighting with token types: colorer keyword : 153 51 153 identifier : black string : 177 47 2 number : 17 131 22 operator : black layout : 63 127 95 italic","title":"Match by Type"},{"location":"references/flowspec/Stratego_API/","text":"Setup \u00b6 Using the Stratego API requires a dependency on the FlowSpec Stratego code (source dependency), and an import of flowspec/api . Example. A Stratego module importing the FlowSpec API. module example imports flowspec/api Running the analysis \u00b6 There are strategies to integrate FlowSpec analysis in the NaBL2 analysis, and strategies for doing both NaBL2 analysis and FlowSpec analysis on an AST. Integrated into NaBL2 analysis \u00b6 These can be used in the final phase of the NaBL2 analysis process using the Stratego hooks . /** * Analyze the given AST with FlowSpec. * The FlowSpec analysis is added to given NaBL2 analysis result and returned. * * @param analysis:Analysis * @param propnames:String or List(String) * @type ast:Term -> Analysis */ flowspec-analyze(|analysis) /** * Analyze the given AST with FlowSpec, but only the given FlowSpec properties. * The FlowSpec analysis is added to given NaBL2 analysis result and returned. * * @param analysis:Analysis * @param propnames:String or List(String) * @type ast:Term -> Analysis */ flowspec-analyze(|analysis, propnames) The analysis results are also usable at that point for generating editor messages. Integration with NaBL2 is done by giving the FlowSpec analysis result as the \u201ccustom final analysis result\u201d: nabl2-custom-analysis-unit-hook: (resource, ast, custom-initial-result) -> (resource, ast) nabl2-custom-analysis-final-hook(|a): (resource, custom-initial-result, custom-unit-results) -> (errors, warnings, notes, custom-final-result) with asts := <map(\\(ast-resource, ast) -> <nabl2--index-ast(|ast-resource)> ast\\)> custom-unit-results ; // workaround for https://yellowgrass.org/issue/NaBL2/54 custom-final-result := <flowspec-analyze(|a)> asts ; errors := ... ; warnings := ... ; notes := ... This propagates the AST of each unit from the unit phase, and analyzes all of them together in the final phase. The custom-final-result is returned so that NaBL2 preserves it for later usage. FlowSpec provides convenience functions that request the custom final result again later: Running the analysis manually \u00b6 Sometimes you need data-flow analysis between transformations which change the program. That means you need to run the analysis just before a transformation to have analysis results corresponding to the current program. The following strategies execute the analysis and help with consuming the resulting tuple. /** * Analyze the given AST with NaBL2 and FlowSpec * * @param resource:String * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(|resource) /** * Analyze the given AST with NaBL2 and FlowSpec. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * * @param pre:Term -> Term * @param post:Term -> Term * @param resource:String * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(pre,post|resource) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(|resource, propname) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * * @param pre:Term -> Term * @param post:Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(pre,post|resource, propnames) /** * Take the analyze-ast 5-tuple output and return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param s(|Analysis): Term -> Term * @type ast: (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) -> Term */ flowspec-then(s) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Then return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param s(|Analysis): Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> Term */ flowspec-analyze-ast-then(s|resource, propnames) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * Then return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param pre:Term -> Term * @param post:Term -> Term * @param s(|Analysis): Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> Term */ flowspec-analyze-ast-then(pre, post, s|resource, propnames) Querying analysis \u00b6 The NaBL2 API defines several strategies to get an analysis term by resource name or from an AST node . This analysis term can then be passed to the querying strategies that give access to the data flow properties, if you hooked FlowSpec into the NaBL2 analysis process. The other way to get the analysis term is to execute the analysis with the flowspec-analyze-ast* variants. Control-flow graph \u00b6 There are a number of strategies to get the control-flow graph nodes associated with an AST fragment, as well as control-flow graph navigation strategies and AST search strategies to get back to the AST from a control-flow graph node. Note that querying the control-flow graph is cheap but finding the way back from the control-flow graph to the AST is more expensive. /** * Get the control flow graph node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-start-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-end-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-entry-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-exit-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-prev-nodes(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-next-nodes(|a) /** * Find AST node corresponding to the CFGNode back again * * @param ast : Term * @type node:CFGNode -> Term */ flowspec-cfg-node-ast(|ast) /** * Find AST node corresponding to the CFGNode back again * * @param ast : Term * @type pos:Position -> Term */ flowspec-pos-ast(|ast) /** * Find parent of AST node corresponding to the CFGNode back again by matching the parent with * the parent argument and giving back the child that is likely to be a match to the CFG node. * * @param parent : Term -> Term * @param ast : Term * @type node:CFGNode -> Term */ flowspec-cfg-node-ast(parent|ast) /** * Find parent of AST node corresponding to the CFGNode back again by matching the parent with * the parent argument and giving back the child that is likely to be a match to the CFG node. * * @param parent : Term -> Term * @param ast : Term * @type pos:Position -> Term */ flowspec-pos-ast(parent|ast) /** * Get the position of an AST node. * * @type Term -> Position */ flowspec-get-position Data flow properties \u00b6 FlowSpec properties can be read in two versions, pre and post. These indicate whether the effect of the cfg node has been applied yet. Whether or not it is applied depends on the direction of the analysis. pre for a forward analysis is without the effect of the node, but pre for a backward analysis includes the effect of the node. Note that each strategy can simply take the term that\u2019s associated with the control-flow graph node. But the control-flow graph node itself is also an accepted input. /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _before_ the effect of the control flow graph node. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-pre(|a, propname) /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _after_ the effect of the control flow graph node. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-post(|a, propname) /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _after_ the effect of the control flow graph node. If no node * is found the exit control flow graph node of the AST node is * queried for its post-effect property value. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-post-or-exit-post(|analysis-result, analysis-name) FlowSpec data helpers \u00b6 FlowSpec sets and maps are passed back to Stratego as lists wrapped in Set and Map constructors. As a convenience, the most common operations are lifted and added to the flowspec API: /** * Check if a FlowSpec Set contains an element. Succeeds if the given strategy succeeds for at * least one element. * * @param s: Term -?> * @type FlowSpecSet -?> FlowSpecSet */ flowspec-set-contains(s) /** * Look up elements in a FlowSpec Set of pairs. Returns the right elements of all pairs where * the given strategy succeeds on the left element. * * @param s: Term -?> * @type FlowSpecSet -?> List(Term) */ flowspec-set-lookup(s) /** * Look up a key in a FlowSpec Map. Returns the element if the given key exists in the map. * * @param k: Term * @type FlowSpecMap -?> Term */ flowspec-map-lookup(|k) Hover text \u00b6 For a hover implementation that displays name, type and FlowSpec properties use: /** * Provides a strategy for a hover message with as much information as possible about name, type * (from NaBl2) and FlowSpec properties. */ flowspec-editor-hover(language-pp) Profiling information \u00b6 /** * If flowspec-debug-profile is extended to succeed, some timing information will be printed in * stderr when using flowspec-analyze*. */ flowspec-debug-profile","title":"Stratego API"},{"location":"references/flowspec/Stratego_API/#setup","text":"Using the Stratego API requires a dependency on the FlowSpec Stratego code (source dependency), and an import of flowspec/api . Example. A Stratego module importing the FlowSpec API. module example imports flowspec/api","title":"Setup"},{"location":"references/flowspec/Stratego_API/#running-the-analysis","text":"There are strategies to integrate FlowSpec analysis in the NaBL2 analysis, and strategies for doing both NaBL2 analysis and FlowSpec analysis on an AST.","title":"Running the analysis"},{"location":"references/flowspec/Stratego_API/#integrated-into-nabl2-analysis","text":"These can be used in the final phase of the NaBL2 analysis process using the Stratego hooks . /** * Analyze the given AST with FlowSpec. * The FlowSpec analysis is added to given NaBL2 analysis result and returned. * * @param analysis:Analysis * @param propnames:String or List(String) * @type ast:Term -> Analysis */ flowspec-analyze(|analysis) /** * Analyze the given AST with FlowSpec, but only the given FlowSpec properties. * The FlowSpec analysis is added to given NaBL2 analysis result and returned. * * @param analysis:Analysis * @param propnames:String or List(String) * @type ast:Term -> Analysis */ flowspec-analyze(|analysis, propnames) The analysis results are also usable at that point for generating editor messages. Integration with NaBL2 is done by giving the FlowSpec analysis result as the \u201ccustom final analysis result\u201d: nabl2-custom-analysis-unit-hook: (resource, ast, custom-initial-result) -> (resource, ast) nabl2-custom-analysis-final-hook(|a): (resource, custom-initial-result, custom-unit-results) -> (errors, warnings, notes, custom-final-result) with asts := <map(\\(ast-resource, ast) -> <nabl2--index-ast(|ast-resource)> ast\\)> custom-unit-results ; // workaround for https://yellowgrass.org/issue/NaBL2/54 custom-final-result := <flowspec-analyze(|a)> asts ; errors := ... ; warnings := ... ; notes := ... This propagates the AST of each unit from the unit phase, and analyzes all of them together in the final phase. The custom-final-result is returned so that NaBL2 preserves it for later usage. FlowSpec provides convenience functions that request the custom final result again later:","title":"Integrated into NaBL2 analysis"},{"location":"references/flowspec/Stratego_API/#running-the-analysis-manually","text":"Sometimes you need data-flow analysis between transformations which change the program. That means you need to run the analysis just before a transformation to have analysis results corresponding to the current program. The following strategies execute the analysis and help with consuming the resulting tuple. /** * Analyze the given AST with NaBL2 and FlowSpec * * @param resource:String * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(|resource) /** * Analyze the given AST with NaBL2 and FlowSpec. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * * @param pre:Term -> Term * @param post:Term -> Term * @param resource:String * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(pre,post|resource) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(|resource, propname) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * * @param pre:Term -> Term * @param post:Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) */ flowspec-analyze-ast(pre,post|resource, propnames) /** * Take the analyze-ast 5-tuple output and return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param s(|Analysis): Term -> Term * @type ast: (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) -> Term */ flowspec-then(s) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Then return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param s(|Analysis): Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> Term */ flowspec-analyze-ast-then(s|resource, propnames) /** * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties. * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis. * Then return the result of applying the given strategy to the AST. * Note that the strategy takes the analysis object as a term argument. * * @param pre:Term -> Term * @param post:Term -> Term * @param s(|Analysis): Term -> Term * @param resource:String * @param propnames:String or List(String) * @type ast:Term -> Term */ flowspec-analyze-ast-then(pre, post, s|resource, propnames)","title":"Running the analysis manually"},{"location":"references/flowspec/Stratego_API/#querying-analysis","text":"The NaBL2 API defines several strategies to get an analysis term by resource name or from an AST node . This analysis term can then be passed to the querying strategies that give access to the data flow properties, if you hooked FlowSpec into the NaBL2 analysis process. The other way to get the analysis term is to execute the analysis with the flowspec-analyze-ast* variants.","title":"Querying analysis"},{"location":"references/flowspec/Stratego_API/#control-flow-graph","text":"There are a number of strategies to get the control-flow graph nodes associated with an AST fragment, as well as control-flow graph navigation strategies and AST search strategies to get back to the AST from a control-flow graph node. Note that querying the control-flow graph is cheap but finding the way back from the control-flow graph to the AST is more expensive. /** * Get the control flow graph node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-start-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-end-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-entry-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-exit-node(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-prev-nodes(|a) /** * Get the control flow graph start node associated with the given term. * * @param a : Analysis * @type term:Term -> CFGNode */ flowspec-get-cfg-next-nodes(|a) /** * Find AST node corresponding to the CFGNode back again * * @param ast : Term * @type node:CFGNode -> Term */ flowspec-cfg-node-ast(|ast) /** * Find AST node corresponding to the CFGNode back again * * @param ast : Term * @type pos:Position -> Term */ flowspec-pos-ast(|ast) /** * Find parent of AST node corresponding to the CFGNode back again by matching the parent with * the parent argument and giving back the child that is likely to be a match to the CFG node. * * @param parent : Term -> Term * @param ast : Term * @type node:CFGNode -> Term */ flowspec-cfg-node-ast(parent|ast) /** * Find parent of AST node corresponding to the CFGNode back again by matching the parent with * the parent argument and giving back the child that is likely to be a match to the CFG node. * * @param parent : Term -> Term * @param ast : Term * @type pos:Position -> Term */ flowspec-pos-ast(parent|ast) /** * Get the position of an AST node. * * @type Term -> Position */ flowspec-get-position","title":"Control-flow graph"},{"location":"references/flowspec/Stratego_API/#data-flow-properties","text":"FlowSpec properties can be read in two versions, pre and post. These indicate whether the effect of the cfg node has been applied yet. Whether or not it is applied depends on the direction of the analysis. pre for a forward analysis is without the effect of the node, but pre for a backward analysis includes the effect of the node. Note that each strategy can simply take the term that\u2019s associated with the control-flow graph node. But the control-flow graph node itself is also an accepted input. /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _before_ the effect of the control flow graph node. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-pre(|a, propname) /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _after_ the effect of the control flow graph node. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-post(|a, propname) /** * Get the property of the control flow graph node associated with * the given term. The value returned is the value of the property * _after_ the effect of the control flow graph node. If no node * is found the exit control flow graph node of the AST node is * queried for its post-effect property value. * * @param a : Analysis * @param prop : String * @type term:Term -> Term */ flowspec-get-property-post-or-exit-post(|analysis-result, analysis-name)","title":"Data flow properties"},{"location":"references/flowspec/Stratego_API/#flowspec-data-helpers","text":"FlowSpec sets and maps are passed back to Stratego as lists wrapped in Set and Map constructors. As a convenience, the most common operations are lifted and added to the flowspec API: /** * Check if a FlowSpec Set contains an element. Succeeds if the given strategy succeeds for at * least one element. * * @param s: Term -?> * @type FlowSpecSet -?> FlowSpecSet */ flowspec-set-contains(s) /** * Look up elements in a FlowSpec Set of pairs. Returns the right elements of all pairs where * the given strategy succeeds on the left element. * * @param s: Term -?> * @type FlowSpecSet -?> List(Term) */ flowspec-set-lookup(s) /** * Look up a key in a FlowSpec Map. Returns the element if the given key exists in the map. * * @param k: Term * @type FlowSpecMap -?> Term */ flowspec-map-lookup(|k)","title":"FlowSpec data helpers"},{"location":"references/flowspec/Stratego_API/#hover-text","text":"For a hover implementation that displays name, type and FlowSpec properties use: /** * Provides a strategy for a hover message with as much information as possible about name, type * (from NaBl2) and FlowSpec properties. */ flowspec-editor-hover(language-pp)","title":"Hover text"},{"location":"references/flowspec/Stratego_API/#profiling-information","text":"/** * If flowspec-debug-profile is extended to succeed, some timing information will be printed in * stderr when using flowspec-analyze*. */ flowspec-debug-profile","title":"Profiling information"},{"location":"references/flowspec/configuration/","text":"We will show you how to prepare your project for use with FlowSpec, and write your first small specification. Prepare your project \u00b6 You can start using FlowSpec by creating a new project, or by modifying an existing project. See below for the steps for your case. Start a new project \u00b6 If you have not done this already, install Spoofax Eclipse, by following the installation instructions . Create a new project by selecting New > Project... from the menu. Selecting Spoofax > Spoofax language project from the list, and click Next . After filling in a project name, an identifier, name etc will be automatically suggested. Select NaBL2 as the analysis type, FlowSpec builds on top of NaBL2\u2019s analysis infrastructure. Click Finish to create the project. Add the following dependencies in the metaborg.yaml file: --- # ... dependencies: compile: - org.metaborg:flowspec.lang:${metaborgVersion} source: - org.metaborg:flowspec.lang:${metaborgVersion} Add menus to access the result of analysis, by adding the following import to editor/Main.esv. module Main imports flowspec/Menus Convert an existing project \u00b6 If you have an existing project, and you want to start using FlowSpec, there are a few changes you need to make. First of all, make sure the metaborg.yaml file contains at least the following dependencies. --- # ... dependencies: compile: - org.metaborg:org.metaborg.meta.nabl2.lang:${metaborgVersion} - org.metaborg:flowspec.lang:${metaborgVersion} source: - org.metaborg:org.metaborg.meta.nabl2.shared:${metaborgVersion} - org.metaborg:org.metaborg.meta.nabl2.runtime:${metaborgVersion} - org.metaborg:flowspec.lang:${metaborgVersion} We will set things up, such that analysis rules will be grouped together in the directory trans/analysis . Create a file trans/analysis/main.str that contains the following. module analysis/main imports nabl2shared nabl2runtime analysis/- Add the following lines to your main trans/LANGUAGE.str . module LANGUAGE imports analysis/main rules editor-analyze = nabl2-analyze(desugar-pre) If your language does not have a desugaring step, use nabl2-analyze(id) instead. Add an NaBL2 specification. The most minimal one is the following. module analysis/minimal rules init. [[ _ ]]. Running and integrating the FlowSpec analysis is explained on the Stratego API page . Finally, we will add reference resolution and menus to access the result of analysis, by adding the following lines to editor/Main.esv . module Main imports nabl2/References nabl2/Menus flowspec/Menus You can now continue to the example specification here , or directly to the language reference . Inspecting analysis results \u00b6 You can debug your specification by inspecting the result of analysis. The result of analysis can be inspected, by selecting elements from the Spoofax > FlowSpec Analysis the menu. For multi-file projects, use the Project results, or the File results for single-file projects. The result is given as a control-flow graph annotated with data-flow properties in the DOT format used by GraphViz. If you have GraphViz installed, you can set the dot executable in the settings of the graphviz editor to allow you to jump straight from Eclipse to the rendered graph.","title":"Configuration"},{"location":"references/flowspec/configuration/#prepare-your-project","text":"You can start using FlowSpec by creating a new project, or by modifying an existing project. See below for the steps for your case.","title":"Prepare your project"},{"location":"references/flowspec/configuration/#start-a-new-project","text":"If you have not done this already, install Spoofax Eclipse, by following the installation instructions . Create a new project by selecting New > Project... from the menu. Selecting Spoofax > Spoofax language project from the list, and click Next . After filling in a project name, an identifier, name etc will be automatically suggested. Select NaBL2 as the analysis type, FlowSpec builds on top of NaBL2\u2019s analysis infrastructure. Click Finish to create the project. Add the following dependencies in the metaborg.yaml file: --- # ... dependencies: compile: - org.metaborg:flowspec.lang:${metaborgVersion} source: - org.metaborg:flowspec.lang:${metaborgVersion} Add menus to access the result of analysis, by adding the following import to editor/Main.esv. module Main imports flowspec/Menus","title":"Start a new project"},{"location":"references/flowspec/configuration/#convert-an-existing-project","text":"If you have an existing project, and you want to start using FlowSpec, there are a few changes you need to make. First of all, make sure the metaborg.yaml file contains at least the following dependencies. --- # ... dependencies: compile: - org.metaborg:org.metaborg.meta.nabl2.lang:${metaborgVersion} - org.metaborg:flowspec.lang:${metaborgVersion} source: - org.metaborg:org.metaborg.meta.nabl2.shared:${metaborgVersion} - org.metaborg:org.metaborg.meta.nabl2.runtime:${metaborgVersion} - org.metaborg:flowspec.lang:${metaborgVersion} We will set things up, such that analysis rules will be grouped together in the directory trans/analysis . Create a file trans/analysis/main.str that contains the following. module analysis/main imports nabl2shared nabl2runtime analysis/- Add the following lines to your main trans/LANGUAGE.str . module LANGUAGE imports analysis/main rules editor-analyze = nabl2-analyze(desugar-pre) If your language does not have a desugaring step, use nabl2-analyze(id) instead. Add an NaBL2 specification. The most minimal one is the following. module analysis/minimal rules init. [[ _ ]]. Running and integrating the FlowSpec analysis is explained on the Stratego API page . Finally, we will add reference resolution and menus to access the result of analysis, by adding the following lines to editor/Main.esv . module Main imports nabl2/References nabl2/Menus flowspec/Menus You can now continue to the example specification here , or directly to the language reference .","title":"Convert an existing project"},{"location":"references/flowspec/configuration/#inspecting-analysis-results","text":"You can debug your specification by inspecting the result of analysis. The result of analysis can be inspected, by selecting elements from the Spoofax > FlowSpec Analysis the menu. For multi-file projects, use the Project results, or the File results for single-file projects. The result is given as a control-flow graph annotated with data-flow properties in the DOT format used by GraphViz. If you have GraphViz installed, you can set the dot executable in the settings of the graphviz editor to allow you to jump straight from Eclipse to the rendered graph.","title":"Inspecting analysis results"},{"location":"references/flowspec/glossary/","text":"Glossary \u00b6","title":"Glossary"},{"location":"references/flowspec/glossary/#glossary","text":"","title":"Glossary"},{"location":"references/flowspec/introduction/","text":"Introduction \u00b6 Programs that are syntactically well-formed are not necessarily valid programs. Programming languages typically impose additional context-sensitive requirements on programs that cannot be captured in a syntax definition. Languages use data and control flow to check certain extra properties that fall outside of names and type systems. The FlowSpec \u2018Flow Analysis Specification Language\u2019 supports the specification of rules to define the static control flow of a language, and data flow analysis over that control flow. FlowSpec supports flow-sensitive intra-procedural data flow analysis. Control Flow Graphs \u00b6 Control-flow represents the execution order of a program. Depending on the input given to the program, or other things the program may observe of its execution environment (e.g. network communication, or a source of noise used to generate pseudo-random numbers), a program may execute a different trace of instructions. Since in general programs may not terminate at all, and humans are not very adapt at reasoning about possible infinities, we use a finite representation of possibly infinite program traces using control-flow graphs. Control-flow graphs are similarly finite as program text and are usually very similar, giving rise to a visual representation of the program. Loops in the program are represented as cycles in the control-flow graph, conditional code is represented by a split in control-flow which is merged again automatically after the conditional code. Data Flow Analysis over Control Flow Graphs \u00b6 Data-flow analysis propagates information either forward or backward along the control-flow graph. This can be information that approximates the data that is handled by the program, or the way in which the program interacts with memory, or something else altogether. Examples of data-flow analysis include constant analysis which checks when variables that are used in the program are guaranteed to have the same value regardless of the execution circumstances of the program, or live variables analysis which identifies if values in variables are actually observable by the program.","title":"Introduction"},{"location":"references/flowspec/introduction/#introduction","text":"Programs that are syntactically well-formed are not necessarily valid programs. Programming languages typically impose additional context-sensitive requirements on programs that cannot be captured in a syntax definition. Languages use data and control flow to check certain extra properties that fall outside of names and type systems. The FlowSpec \u2018Flow Analysis Specification Language\u2019 supports the specification of rules to define the static control flow of a language, and data flow analysis over that control flow. FlowSpec supports flow-sensitive intra-procedural data flow analysis.","title":"Introduction"},{"location":"references/flowspec/introduction/#control-flow-graphs","text":"Control-flow represents the execution order of a program. Depending on the input given to the program, or other things the program may observe of its execution environment (e.g. network communication, or a source of noise used to generate pseudo-random numbers), a program may execute a different trace of instructions. Since in general programs may not terminate at all, and humans are not very adapt at reasoning about possible infinities, we use a finite representation of possibly infinite program traces using control-flow graphs. Control-flow graphs are similarly finite as program text and are usually very similar, giving rise to a visual representation of the program. Loops in the program are represented as cycles in the control-flow graph, conditional code is represented by a split in control-flow which is merged again automatically after the conditional code.","title":"Control Flow Graphs"},{"location":"references/flowspec/introduction/#data-flow-analysis-over-control-flow-graphs","text":"Data-flow analysis propagates information either forward or backward along the control-flow graph. This can be information that approximates the data that is handled by the program, or the way in which the program interacts with memory, or something else altogether. Examples of data-flow analysis include constant analysis which checks when variables that are used in the program are guaranteed to have the same value regardless of the execution circumstances of the program, or live variables analysis which identifies if values in variables are actually observable by the program.","title":"Data Flow Analysis over Control Flow Graphs"},{"location":"references/flowspec/references/","text":"References \u00b6","title":"References"},{"location":"references/flowspec/references/#references","text":"","title":"References"},{"location":"references/flowspec/structure/","text":"Modules \u00b6 A module is defined by a single flowspec file. A module can contain several sections, for defining control-flow, data flow, types, and functions. Modules can import other modules. module $module-id imports $module-ref* $section* Terms and Patterns \u00b6 FlowSpec defines various data types, including terms, tuples, sets, and maps. These can be constructed by the user, or introduced by matching on the AST. term = ctor-id \"(\" {term \",\"}* \")\" | \"(\" {term \",\"}* \")\" | \"{\" {term \",\"}* \"}\" | \"{\" term \"|\" {term \",\"}* \"}\" | \"{\" {(term \"|->\" term) \",\"}* \"}\" | \"{\" term \"|->\" term \"|\" {(term \"|->\" term) \",\"}* \"}\" Control flow and data flow rules can use patterns to define which rules apply to which AST nodes. pattern = ctor-id \"(\" {pattern \",\"}* \")\" | \"(\" {pattern \",\"}* \")\" | var-id \"@\" pattern | \"_\" | var-id Control Flow \u00b6 The control-flow section contains the rules that define the control-flow for the subject language. control-flow rules $control-flow-rule* Control Flow Rules \u00b6 A control-flow rule consists of a pattern and a corresponding list of control-flow chains. control-flow-rule = \"root\"? pattern \"=\" {cfg-chain \",\"}+ | \"node\" pattern cfg-chain = {cfg-chain-elem \"->\"}+ cfg-chain-elem = \"entry\" | \"exit\" | variable | \"node\" variable | \"this\" Example. Module that specifies how the control-flow for the Add AST node goes from the lhs, the rhs, and then to the Add itself. It also specifies that Int must have a node in the control-flow graph. module control control-flow rules node Int(_) Add(l, r) = entry -> l -> r -> this -> exit Root Rules \u00b6 A root of the control-flow defines the start and end nodes of a control-flow graph. You can have multiple control-flow graphs in the same AST, but not nested ones. Each control-flow graph has a unique start and end node. A root control-flow rule introduces the start and end node. In other control-flow rules these nodes can be referred to for abrupt termination. cfg-chain-elem = ... | \"start\" | \"end\" Example. Module that defines control-flow for a procedure, and the return statement that goes straight to the end of the procedure. module control control-flow rules root Procedure(args, _, body) = start -> args -> body -> end Return(_) = entry -> this -> end Data Flow \u00b6 Properties \u00b6 The data flow section contains definitions of the properties to compute, and the rules that define how these properties are computed. properties property-definition* A property has a name, and a corresponding lattice type. The result after analysis will be a lattice of this type for each node in the control-flow graph. property-definition = name \":\" lattice Example. Lattice definition for a constant-value analysis. properties values: Map[name, Value] Rules \u00b6 The data flow rules specify how data should flow across the control-flow graph. property rules property-rule* property-rule = name \"(\" prop-pattern \")\" \"=\" expr prop-pattern = name \"->\" pattern | pattern \"->\" name | pattern \".\" \"start\" | pattern \".\" \"end\" Example. A simple specification for a constant-value analysis. property rules values(_.end) = Map[string, Value].bottom values(prev -> VarDec(n, _, Int(i))) = { k |-> v | (k |-> v) <- values(prev), k != n } \\/ {n |-> Const(i)} values(prev -> VarDec(n, _, _)) = { k |-> v | (k |-> v) <- values(prev), k != n } \\/ {n |-> Top()} values(prev -> _) = values(prev) Lattices \u00b6 Lattices are the main data type used in data-flow analysis, because of their desirable properties. Properties (the analysis results) must always be of type lattice. FlowSpec contains some builtin lattice types, but users can also specify their own. lattices lattice-definition* Lattice definitions must include the following: the underlying datatype, a join operator (either least-upper bound or greatest-lower bound), a top, and a bottom. name where type = type lub([name], name) = expr top = expr bottom = expr Types \u00b6 Aside from lattices, algebraic datatypes can be defined for use within lattices definitions. Users can directly match these datatypes, or construct new values. types type-definition* An algebraic datatype consists of a constructor and zero or more arguments. name = (\"|\" ctor-id \"(\" {type \",\"}* \")\")+ Example. The definition for an algebraic type used in constant value analysis. types ConstProp = | Top() | Const(int) | Bottom() Functions \u00b6 Functions make it possible to reuse functionality and avoid duplication of logic. functions function-definition* name([{(name \":\" type) \",\"}+]) = expr Expressions \u00b6 Integers \u00b6 Integer literals are written with an optional minus sign followed by one or more decimals. Supported integer operations are: Addition [ + ] Subtraction [ - ] Multiplication [ * ] Division [ / ] Modulo [ % ] Negate [ - ] Comparison [ < , <= , > , >= , == , != ] Booleans \u00b6 Boolean literals true and false are available as well as the usual boolean operations: And [ && ] Or [ || ] Not [ ! ] Sets and Maps \u00b6 Set and map literals are both denoted with curly braces. A set literal contains a comma-separated list of elements: {elem1, elem2, elem3} . A map literal contains a comma-separated list of bindings of the form key |-> value: { key1 |-> value1, key2 |-> value2 } . Operations on sets and maps include Union [ \\/ ] Intersection [ /\\ ] Set/map minus [ \\ ] Containment/lookup [ in ] There are also comprehensions of the form { new | old <- set, conditions } or { newkey |-> newvalue | oldkey |-> oldvalue <- map, condition } , where new elements or bindings are gathered based on old ones from a set or map, as long as the boolean condition expressions hold. Such a condition expression may also be a match expression without a body for the arms. This is commonly used to filter maps or sets. Match \u00b6 Pattern matching can be done with a match expression: match expr with | pattern1 => expr2 | pattern2 => expr2 , where expr are expressions and pattern are patterns. Terms and patterns are defined at the start of the reference. Variables and References \u00b6 Pattern matching can introduce variables. Other references include values in the lattice, such as MaySet.bottom or MustSet.top . Functions and Lattice Operations \u00b6 User defined functions are invoked with functionname(arg1, arg2) . Lattice operations can be similarly invoked, requiring the type name: MaySet.lub(s1, s2) . Property Lookup \u00b6 Property lookup is similar to a function call, although property lookup only ever has a single argument. Term Positions \u00b6 FlowSpec provides a builtin function that returns the position of a term: position(term) . This can be used to differentiate two terms from an AST that are otherwise the same. Lexical Grammar \u00b6 Identifiers \u00b6 Most identifiers in FlowSpec fall into one of two categories, which we will refer to as: Lowercase identifiers, that start with a lowercase character, and must match the regular expression [a-z][a-zA-Z0-9]*. Uppercase identifiers, that start with an uppercase character, and must match the regular expression [A-Z][a-zA-Z0-9]*. Comments \u00b6 Comments in FlowSpec follow C-style comments: // ... single line ... for single-line comments /* ... multiple lines ... */ for multi-line comments Multi-line comments can be nested, and run until the end of the file when the closing */ is omitted.","title":"Structure"},{"location":"references/flowspec/structure/#modules","text":"A module is defined by a single flowspec file. A module can contain several sections, for defining control-flow, data flow, types, and functions. Modules can import other modules. module $module-id imports $module-ref* $section*","title":"Modules"},{"location":"references/flowspec/structure/#terms-and-patterns","text":"FlowSpec defines various data types, including terms, tuples, sets, and maps. These can be constructed by the user, or introduced by matching on the AST. term = ctor-id \"(\" {term \",\"}* \")\" | \"(\" {term \",\"}* \")\" | \"{\" {term \",\"}* \"}\" | \"{\" term \"|\" {term \",\"}* \"}\" | \"{\" {(term \"|->\" term) \",\"}* \"}\" | \"{\" term \"|->\" term \"|\" {(term \"|->\" term) \",\"}* \"}\" Control flow and data flow rules can use patterns to define which rules apply to which AST nodes. pattern = ctor-id \"(\" {pattern \",\"}* \")\" | \"(\" {pattern \",\"}* \")\" | var-id \"@\" pattern | \"_\" | var-id","title":"Terms and Patterns"},{"location":"references/flowspec/structure/#control-flow","text":"The control-flow section contains the rules that define the control-flow for the subject language. control-flow rules $control-flow-rule*","title":"Control Flow"},{"location":"references/flowspec/structure/#control-flow-rules","text":"A control-flow rule consists of a pattern and a corresponding list of control-flow chains. control-flow-rule = \"root\"? pattern \"=\" {cfg-chain \",\"}+ | \"node\" pattern cfg-chain = {cfg-chain-elem \"->\"}+ cfg-chain-elem = \"entry\" | \"exit\" | variable | \"node\" variable | \"this\" Example. Module that specifies how the control-flow for the Add AST node goes from the lhs, the rhs, and then to the Add itself. It also specifies that Int must have a node in the control-flow graph. module control control-flow rules node Int(_) Add(l, r) = entry -> l -> r -> this -> exit","title":"Control Flow Rules"},{"location":"references/flowspec/structure/#root-rules","text":"A root of the control-flow defines the start and end nodes of a control-flow graph. You can have multiple control-flow graphs in the same AST, but not nested ones. Each control-flow graph has a unique start and end node. A root control-flow rule introduces the start and end node. In other control-flow rules these nodes can be referred to for abrupt termination. cfg-chain-elem = ... | \"start\" | \"end\" Example. Module that defines control-flow for a procedure, and the return statement that goes straight to the end of the procedure. module control control-flow rules root Procedure(args, _, body) = start -> args -> body -> end Return(_) = entry -> this -> end","title":"Root Rules"},{"location":"references/flowspec/structure/#data-flow","text":"","title":"Data Flow"},{"location":"references/flowspec/structure/#properties","text":"The data flow section contains definitions of the properties to compute, and the rules that define how these properties are computed. properties property-definition* A property has a name, and a corresponding lattice type. The result after analysis will be a lattice of this type for each node in the control-flow graph. property-definition = name \":\" lattice Example. Lattice definition for a constant-value analysis. properties values: Map[name, Value]","title":"Properties"},{"location":"references/flowspec/structure/#rules","text":"The data flow rules specify how data should flow across the control-flow graph. property rules property-rule* property-rule = name \"(\" prop-pattern \")\" \"=\" expr prop-pattern = name \"->\" pattern | pattern \"->\" name | pattern \".\" \"start\" | pattern \".\" \"end\" Example. A simple specification for a constant-value analysis. property rules values(_.end) = Map[string, Value].bottom values(prev -> VarDec(n, _, Int(i))) = { k |-> v | (k |-> v) <- values(prev), k != n } \\/ {n |-> Const(i)} values(prev -> VarDec(n, _, _)) = { k |-> v | (k |-> v) <- values(prev), k != n } \\/ {n |-> Top()} values(prev -> _) = values(prev)","title":"Rules"},{"location":"references/flowspec/structure/#lattices","text":"Lattices are the main data type used in data-flow analysis, because of their desirable properties. Properties (the analysis results) must always be of type lattice. FlowSpec contains some builtin lattice types, but users can also specify their own. lattices lattice-definition* Lattice definitions must include the following: the underlying datatype, a join operator (either least-upper bound or greatest-lower bound), a top, and a bottom. name where type = type lub([name], name) = expr top = expr bottom = expr","title":"Lattices"},{"location":"references/flowspec/structure/#types","text":"Aside from lattices, algebraic datatypes can be defined for use within lattices definitions. Users can directly match these datatypes, or construct new values. types type-definition* An algebraic datatype consists of a constructor and zero or more arguments. name = (\"|\" ctor-id \"(\" {type \",\"}* \")\")+ Example. The definition for an algebraic type used in constant value analysis. types ConstProp = | Top() | Const(int) | Bottom()","title":"Types"},{"location":"references/flowspec/structure/#functions","text":"Functions make it possible to reuse functionality and avoid duplication of logic. functions function-definition* name([{(name \":\" type) \",\"}+]) = expr","title":"Functions"},{"location":"references/flowspec/structure/#expressions","text":"","title":"Expressions"},{"location":"references/flowspec/structure/#integers","text":"Integer literals are written with an optional minus sign followed by one or more decimals. Supported integer operations are: Addition [ + ] Subtraction [ - ] Multiplication [ * ] Division [ / ] Modulo [ % ] Negate [ - ] Comparison [ < , <= , > , >= , == , != ]","title":"Integers"},{"location":"references/flowspec/structure/#booleans","text":"Boolean literals true and false are available as well as the usual boolean operations: And [ && ] Or [ || ] Not [ ! ]","title":"Booleans"},{"location":"references/flowspec/structure/#sets-and-maps","text":"Set and map literals are both denoted with curly braces. A set literal contains a comma-separated list of elements: {elem1, elem2, elem3} . A map literal contains a comma-separated list of bindings of the form key |-> value: { key1 |-> value1, key2 |-> value2 } . Operations on sets and maps include Union [ \\/ ] Intersection [ /\\ ] Set/map minus [ \\ ] Containment/lookup [ in ] There are also comprehensions of the form { new | old <- set, conditions } or { newkey |-> newvalue | oldkey |-> oldvalue <- map, condition } , where new elements or bindings are gathered based on old ones from a set or map, as long as the boolean condition expressions hold. Such a condition expression may also be a match expression without a body for the arms. This is commonly used to filter maps or sets.","title":"Sets and Maps"},{"location":"references/flowspec/structure/#match","text":"Pattern matching can be done with a match expression: match expr with | pattern1 => expr2 | pattern2 => expr2 , where expr are expressions and pattern are patterns. Terms and patterns are defined at the start of the reference.","title":"Match"},{"location":"references/flowspec/structure/#variables-and-references","text":"Pattern matching can introduce variables. Other references include values in the lattice, such as MaySet.bottom or MustSet.top .","title":"Variables and References"},{"location":"references/flowspec/structure/#functions-and-lattice-operations","text":"User defined functions are invoked with functionname(arg1, arg2) . Lattice operations can be similarly invoked, requiring the type name: MaySet.lub(s1, s2) .","title":"Functions and Lattice Operations"},{"location":"references/flowspec/structure/#property-lookup","text":"Property lookup is similar to a function call, although property lookup only ever has a single argument.","title":"Property Lookup"},{"location":"references/flowspec/structure/#term-positions","text":"FlowSpec provides a builtin function that returns the position of a term: position(term) . This can be used to differentiate two terms from an AST that are otherwise the same.","title":"Term Positions"},{"location":"references/flowspec/structure/#lexical-grammar","text":"","title":"Lexical Grammar"},{"location":"references/flowspec/structure/#identifiers","text":"Most identifiers in FlowSpec fall into one of two categories, which we will refer to as: Lowercase identifiers, that start with a lowercase character, and must match the regular expression [a-z][a-zA-Z0-9]*. Uppercase identifiers, that start with an uppercase character, and must match the regular expression [A-Z][a-zA-Z0-9]*.","title":"Identifiers"},{"location":"references/flowspec/structure/#comments","text":"Comments in FlowSpec follow C-style comments: // ... single line ... for single-line comments /* ... multiple lines ... */ for multi-line comments Multi-line comments can be nested, and run until the end of the file when the closing */ is omitted.","title":"Comments"},{"location":"references/flowspec/testing/","text":"Testing \u00b6","title":"Testing"},{"location":"references/flowspec/testing/#testing","text":"","title":"Testing"},{"location":"references/pipelines/","text":"Pipelines for Interactive Environments \u00b6 Pipelines for interactive Environments (PIE) is the build system for Spoofax 3. PIE consists of two parts: a Java framework, a Java runtime and the PIE Domain Specific Language (DSL). This reference documentation is for the PIE DSL and will only provide some high level information about the framework and runtime to provide context. PIE uses tasks to compose pipelines. Each task has 0 or more inputs and one output. Each task can depend on files or on other tasks. Tasks can be marked as explicitly observed to indicate that we want the output of these tasks to stay up to date. The PIE runtime executes tasks incrementally, which means that it only executes tasks that are no longer up to date and that are required for a task which is explicitly observed. Tasks can be written in Java, but this involves a lot of boilerplate. Tasks can also be written in the PIE DSL. The PIE DSL is specifically made for PIE, so it has little boilerplate. Tasks written in the PIE DSL are compiled to Java. The PIE DSL \u00b6 PIE models a pipeline as tasks that call each other. The PIE DSL calls these tasks \"functions\", because each task has inputs and an output. A PIE DSL program consists of one or more files. File structure \u00b6 module fully:qualified:moduleName import fully:qualified:name:of:another:module import org:example:multipleDefs:{func1, func2 as other, aDataTypeAsWell} import org:example:languages:{java, cpp, sql}:spoofax:{parse, analyze, compile} data coolDataType = foreign java org.example.MyFirstJavaClass { func aMethod(int) -> bool } func greetWorld() -> string = \"Hello world!\" PIE DSL files contain a module statement, imports, and data and function definitions. The module statement declares the fully qualified name of the module. Imports are optional and import datatypes and function from other modules. They can import multiple functions or datatypes at the same time, and they can rename elements. Data and function definitions define functions and datatypes. Directory structure and module system \u00b6 PIE files have the extension .pie . Each PIE file forms a module. Modules can define functions and datatypes, and can import functions and datatypes from other modules. It is recommended to use the same name for the module as the path and filename, but this is not required. As such, the PIE DSL does not place any restrictions on paths and file names besides the standard restrictions for Spoofax languages. The module system is described in Modules . Types and data definitions \u00b6 The PIE DSL is a statically typed language. There are a few built-in types, such as int and path . Built-in types use lowercase characters. Custom datatypes can currently only be imported from Java as foreign definitions. The types in the PIE DSL are described in Types . The PIE DSL also supports generic datatypes. These follow Java semantics. The semantics of generics can be found in Generics . Function definitions \u00b6 Functions express task definitions. Functions consist of a head and an implementation. func $FuncHead = $FuncImpl func greet(name: string) -> string = \"Hello ${name}!\" func doSomethingDifficult() -> path = foreign org.example.DoSomethingDifficult func callJavaStaticFunction() -> bool = foreign java fully.qualified.java.ClassName#staticMethodName func createCustomType() -> CustomType = foreign java constructor org.example.CustomType The function head describes the signature of the function: the name, the input parameter types and the output type. All functions can be called the same way regardless of their implementation. The function implementation describes the way a function is implemented. A function can be implemented in PIE by providing an expression, as can be seen with greet Expressions are described in Expressions . A function can also be implemented in Java. The three ways this can be done are shown in the example as well. A complete overview of functions is given in Functions . Misc information. \u00b6 Java and C use the function called main with a certain signature as the entry point to the program. A PIE program does not have a set entry point. The entry point is whatever function is called from the PIE runtime.","title":"Pipelines for Interactive Environments"},{"location":"references/pipelines/#pipelines-for-interactive-environments","text":"Pipelines for interactive Environments (PIE) is the build system for Spoofax 3. PIE consists of two parts: a Java framework, a Java runtime and the PIE Domain Specific Language (DSL). This reference documentation is for the PIE DSL and will only provide some high level information about the framework and runtime to provide context. PIE uses tasks to compose pipelines. Each task has 0 or more inputs and one output. Each task can depend on files or on other tasks. Tasks can be marked as explicitly observed to indicate that we want the output of these tasks to stay up to date. The PIE runtime executes tasks incrementally, which means that it only executes tasks that are no longer up to date and that are required for a task which is explicitly observed. Tasks can be written in Java, but this involves a lot of boilerplate. Tasks can also be written in the PIE DSL. The PIE DSL is specifically made for PIE, so it has little boilerplate. Tasks written in the PIE DSL are compiled to Java.","title":"Pipelines for Interactive Environments"},{"location":"references/pipelines/#the-pie-dsl","text":"PIE models a pipeline as tasks that call each other. The PIE DSL calls these tasks \"functions\", because each task has inputs and an output. A PIE DSL program consists of one or more files.","title":"The PIE DSL"},{"location":"references/pipelines/#file-structure","text":"module fully:qualified:moduleName import fully:qualified:name:of:another:module import org:example:multipleDefs:{func1, func2 as other, aDataTypeAsWell} import org:example:languages:{java, cpp, sql}:spoofax:{parse, analyze, compile} data coolDataType = foreign java org.example.MyFirstJavaClass { func aMethod(int) -> bool } func greetWorld() -> string = \"Hello world!\" PIE DSL files contain a module statement, imports, and data and function definitions. The module statement declares the fully qualified name of the module. Imports are optional and import datatypes and function from other modules. They can import multiple functions or datatypes at the same time, and they can rename elements. Data and function definitions define functions and datatypes.","title":"File structure"},{"location":"references/pipelines/#directory-structure-and-module-system","text":"PIE files have the extension .pie . Each PIE file forms a module. Modules can define functions and datatypes, and can import functions and datatypes from other modules. It is recommended to use the same name for the module as the path and filename, but this is not required. As such, the PIE DSL does not place any restrictions on paths and file names besides the standard restrictions for Spoofax languages. The module system is described in Modules .","title":"Directory structure and module system"},{"location":"references/pipelines/#types-and-data-definitions","text":"The PIE DSL is a statically typed language. There are a few built-in types, such as int and path . Built-in types use lowercase characters. Custom datatypes can currently only be imported from Java as foreign definitions. The types in the PIE DSL are described in Types . The PIE DSL also supports generic datatypes. These follow Java semantics. The semantics of generics can be found in Generics .","title":"Types and data definitions"},{"location":"references/pipelines/#function-definitions","text":"Functions express task definitions. Functions consist of a head and an implementation. func $FuncHead = $FuncImpl func greet(name: string) -> string = \"Hello ${name}!\" func doSomethingDifficult() -> path = foreign org.example.DoSomethingDifficult func callJavaStaticFunction() -> bool = foreign java fully.qualified.java.ClassName#staticMethodName func createCustomType() -> CustomType = foreign java constructor org.example.CustomType The function head describes the signature of the function: the name, the input parameter types and the output type. All functions can be called the same way regardless of their implementation. The function implementation describes the way a function is implemented. A function can be implemented in PIE by providing an expression, as can be seen with greet Expressions are described in Expressions . A function can also be implemented in Java. The three ways this can be done are shown in the example as well. A complete overview of functions is given in Functions .","title":"Function definitions"},{"location":"references/pipelines/#misc-information","text":"Java and C use the function called main with a certain signature as the entry point to the program. A PIE program does not have a set entry point. The entry point is whatever function is called from the PIE runtime.","title":"Misc information."},{"location":"references/pipelines/expressions/","text":"Expressions \u00b6 This section describes expressions in the PIE DSL. Todo Write documentation","title":"Expressions"},{"location":"references/pipelines/expressions/#expressions","text":"This section describes expressions in the PIE DSL. Todo Write documentation","title":"Expressions"},{"location":"references/pipelines/functions/","text":"Functions \u00b6 This section describes functions in the PIE DSL. Note A task is a function with some special semantics in regards to runtime behavior. The PIE DSL does not differentiate between functions and tasks. In the DSL, both are called functions. Todo Write documentation","title":"Functions"},{"location":"references/pipelines/functions/#functions","text":"This section describes functions in the PIE DSL. Note A task is a function with some special semantics in regards to runtime behavior. The PIE DSL does not differentiate between functions and tasks. In the DSL, both are called functions. Todo Write documentation","title":"Functions"},{"location":"references/pipelines/generics/","text":"Generics \u00b6 This section describes generics in the PIE DSL. In a nutshell, it just follows the Java semantics. Todo Write documentation","title":"Generics"},{"location":"references/pipelines/generics/#generics","text":"This section describes generics in the PIE DSL. In a nutshell, it just follows the Java semantics. Todo Write documentation","title":"Generics"},{"location":"references/pipelines/modules/","text":"Module system \u00b6 This section describes the module system of the PIE DSL. Todo document the module system","title":"Module system"},{"location":"references/pipelines/modules/#module-system","text":"This section describes the module system of the PIE DSL. Todo document the module system","title":"Module system"},{"location":"references/pipelines/types/","text":"Types \u00b6 There are several built-in types in the PIE DSL. The PIE DSL also allows defining custom types. Todo write about the types in PIE The type system \u00b6 Built-in types \u00b6 unit \u00b6 bool \u00b6 int \u00b6 string \u00b6 path \u00b6 null \u00b6 top \u00b6 bottom \u00b6 Nullable types \u00b6 Lists \u00b6 (todo: also discuss empty lists) Tuples \u00b6 Suppliers \u00b6 Function types \u00b6 Datatypes \u00b6 Wildcards \u00b6 Custom datatypes \u00b6","title":"Types"},{"location":"references/pipelines/types/#types","text":"There are several built-in types in the PIE DSL. The PIE DSL also allows defining custom types. Todo write about the types in PIE","title":"Types"},{"location":"references/pipelines/types/#the-type-system","text":"","title":"The type system"},{"location":"references/pipelines/types/#built-in-types","text":"","title":"Built-in types"},{"location":"references/pipelines/types/#unit","text":"","title":"unit"},{"location":"references/pipelines/types/#bool","text":"","title":"bool"},{"location":"references/pipelines/types/#int","text":"","title":"int"},{"location":"references/pipelines/types/#string","text":"","title":"string"},{"location":"references/pipelines/types/#path","text":"","title":"path"},{"location":"references/pipelines/types/#null","text":"","title":"null"},{"location":"references/pipelines/types/#top","text":"","title":"top"},{"location":"references/pipelines/types/#bottom","text":"","title":"bottom"},{"location":"references/pipelines/types/#nullable-types","text":"","title":"Nullable types"},{"location":"references/pipelines/types/#lists","text":"(todo: also discuss empty lists)","title":"Lists"},{"location":"references/pipelines/types/#tuples","text":"","title":"Tuples"},{"location":"references/pipelines/types/#suppliers","text":"","title":"Suppliers"},{"location":"references/pipelines/types/#function-types","text":"","title":"Function types"},{"location":"references/pipelines/types/#datatypes","text":"","title":"Datatypes"},{"location":"references/pipelines/types/#wildcards","text":"","title":"Wildcards"},{"location":"references/pipelines/types/#custom-datatypes","text":"","title":"Custom datatypes"},{"location":"references/statix/","text":"Statix \u00b6 Statix is a Meta-language for the Specification of Static Semantics. Statix specifications are organised in modules . In Statix, programs, types and all other data are represented using terms . Type-checking a program is performed by solving a set of constraints over terms. In addition to these built-in constraints, specification writers can define their own constraints . Type-checking is closely related to, and strongly intertwined with, name resolution. For that reason, Statix has built-in support for modelling name binding patterns in the form of scope graphs . During type-checking, names can be resolved using queries . When transforming programs using in Stratego , Statix specifications can be executed, and the results accesssed using the Stratego API for Statix . Statix has a special test format , which can be used for isolating issues in a specification, or in the Statix ecosystem. Tip Readers with little or no familiarity with Statix are recommended to read the Language Concepts section first. Sources \u00b6 The sources of the different Statix components can be found at: https://github.com/metaborg/nabl/tree/master/statix.lang : The Statix Language https://github.com/metaborg/nabl/tree/master/statix.runtime : The Statix Runtime https://github.com/metaborg/nabl/tree/master/statix.solver : The Statix Solver","title":"Statix"},{"location":"references/statix/#statix","text":"Statix is a Meta-language for the Specification of Static Semantics. Statix specifications are organised in modules . In Statix, programs, types and all other data are represented using terms . Type-checking a program is performed by solving a set of constraints over terms. In addition to these built-in constraints, specification writers can define their own constraints . Type-checking is closely related to, and strongly intertwined with, name resolution. For that reason, Statix has built-in support for modelling name binding patterns in the form of scope graphs . During type-checking, names can be resolved using queries . When transforming programs using in Stratego , Statix specifications can be executed, and the results accesssed using the Stratego API for Statix . Statix has a special test format , which can be used for isolating issues in a specification, or in the Statix ecosystem. Tip Readers with little or no familiarity with Statix are recommended to read the Language Concepts section first.","title":"Statix"},{"location":"references/statix/#sources","text":"The sources of the different Statix components can be found at: https://github.com/metaborg/nabl/tree/master/statix.lang : The Statix Language https://github.com/metaborg/nabl/tree/master/statix.runtime : The Statix Runtime https://github.com/metaborg/nabl/tree/master/statix.solver : The Statix Solver","title":"Sources"},{"location":"references/statix/basic-constraints/","text":"Basic Constraints \u00b6 As mentioned in the Language Concepts section, the core idea of Statix is to see a type-checking problem as a constraint solving problem. Therefore, it is crucial to be able to express constraints in a specification. In this section, we discuss all constraints that are note related to scope graphs. These constraints are explained in-depth in the sections on Scope Graph Construction and Queries . True \u00b6 true The true constraint is the constraint that is trivially satisfied. False \u00b6 false $ Message ? The false constraint is the constraint that will always fail. Just as all other constraints that can fail, it is possible to add a message . Conjunction \u00b6 $ Constraint , $ Constraint A conjunction of constraints is satisfied when both conjuncts are satisfied. Note that the solving order of the conjuncts is undefined. Equality \u00b6 $ Term == $ Term $ Message ? Asserts that two terms are equal. When necessary, this constraint infers values for free variables in the terms. Statically, both terms should have the same type. Disequality \u00b6 $ Term != $ Term $ Message ? Asserts that two terms are not equal. Statically, both terms should have the same type. Statix treats free variables as different from each other, and as different from concrete terms. Therefore, when any of both terms is not ground (i.e. contains free variables), the constraint will not fail. Exists \u00b6 { $ Var * } $ Constraint An exists constraint introduces new existentially quantified variables in the scope of its subconstraint. The names of the variables in an exists constraint should be unique (i.e. {x x} true is not allowed), but are allowed to shadow outer variables. Try \u00b6 try { $ Constraint } $ Message ? The try constraint validates whether the outer context implies that the inner constraint holds. That is: any model for the outer context (all other constraints than $Constraint ) is also a (not necessarily minimal) model for $Constraint . In order to implement these semantics, the $Constraint is handled differently than regular constraints in two ways. The $Constraint is not allowed to refine the outer context. Therefore, equality constraints will not infer values for variable that were introduced outside the try . Likewise, scopes can not be instantiated, nor edges/declarations added to scopes from outside the try . This behavior also implies that values constructed within a try construct will never escape the try context. Disequalities in $Constraint that involve free variables cause the try to fail, because appearently the disequality does not hold for all models of the outer context. Todo Explain the design choices for try in a background section. AST Identifiers \u00b6 astId ( $ Term , $ Term ) The astId constraint asserts that its second argument is the term index of the first argument. The type of the first argument may be anything, but the type of the second argument is astId . Tip Often, using an astId term will read more natural. AST Property \u00b6 @$ Term . $ Prop $ Op $ Term Statix allows to set properties on AST nodes. These properties can be used to communicate typing results to the outside world, for example to be used in a transformation. For more information on reading these properties, please refer to the Stratego API documentation . The first term is the term (usually an AST node) on which the property is set. Next $Prop specifies which property is set. This property can be any string of the form [a-zA-Z] [a-zA-Z0-9\\_]* . It is not required to declare properties. There are two special properties: ref and type . ref properties are set on (syntactic) variable references, and point to the term they are referencing. The Spoofax reference resolution service uses these properties to offer reference resolution in the editor. The type property contains the type of a term. This type is shown when hovering over a term in an editor. The $Op specifies the operator with which a property is set. There are two possible operators: := : The assignment operator. This operator requires a property to have only a single unique value (although, since Spoofax 2.5.17, that value may be set multiple times). += : The bag insertion operator. Properties using this operator can be set multiple times, and will be aggregated in the eventual property value. Note that using both operators for a single property on a particular node will result in a failed constraint. However, it is allowed to use different operators for a property, as long as the terms on which these operators are used are different. Finally, the last $Term denotes the value of the property. Warning Failing property constraints are ignored (i.e. no error for them is reported). Arithmetic Constraints \u00b6 $ Term $ Op $ ArithExp $ Message ? Statix supports several arithmetic constraints. These constraints consist of a term, an operator and an arithmetic expression. The $Term should have type int , while the $ArithExp is syntactically guaranteed to have type int , given that all variable references have type int . At the $Op position, several comparison operators can be used: #= asserts that both terms are equal #\\\\= asserts that both terms are not equal #>= asserts that the left term is equal or bigger that the left term #=< asserts that the left term is equal or smaller that the left term #> asserts that the left term is strictly bigger that the left term #< asserts that the left term is strictly smaller that the left term Arithmetic expressions can be integer literals, variables and bracketed arithmetic expressions. Variables in an arithmetic expression must have type int . Additionally, the following arithmetic operations can be used: $ArithExp + $ArithExp : computes integer addition $ArithExp - $ArithExp : computes integer subtraction $ArithExp * $ArithExp : computes integer multiplication min($ArithExp, $ArithExp) : computes the minimum of both arguments max($ArithExp, $ArithExp) : computes the maximum of both arguments $ArithExp div $ArithExp : computes the integer divisor (i.e. rounded down regular division). $ArithExp mod $ArithExp : computes the modulus of its arguments. Unlike other constraints, arithmetic constraint do no inference of values in the $ArithExp . Hence, having any free variables in this expression will cause the constraint to fail. Separate Arithmetic Expression Syntax As discussed, Statix has a special syntactic category for arithmetic expressions. Therefore, arithmetic expressions cannot be used at regular term positions. Instead, arithmetic expressions can be embedded in terms using the Arithmetic Expressions term syntax. Java Integers Arithmetic Expressions are implemented using standard Java integers, and hence have the same size limitations. Messages \u00b6 | $ Severity $ MessageBody $ Position ? Constraints that might possibly fail can be provided with a customized message. Such message carry three parameters. First, the $Severity indicates the severity of a message. It may be either error , warning or note . Note however that warnings and notes can only be issued for failing try constraints. Second, the error message string is provided. This message string may be a regular string literal or a template literal. Template literals look as follows: $[$ ContentPart *] Content parts are either message string literals or interpolated terms. The escaping rules for string literals in templates are slightly different than for regular string literals. Message string literals can contain any character, where square brackets and backslashes must be escaped with a backslash. Just as regular string literals, tabs, newlines and carriage returns can be encoded with \\t , \\n and \\r , respectively. Terms can be inserted in a message template by surrounding them with (unescaped) square brackets: [$Term] . The term may have any type, but must be well-formed according to the regular typing rules for terms. Bug Using functional predicates inside message templates will cause an exception when loading the specification. Thirdly, a position can be assigned to the message: @ $ Var Here, the $Var is assumed to be an AST node. When the constraint on which this message is placed fails, the message will be shown inline at the AST node pointed to by this variable. When no message position is provided, or the assigned position is invalid, Statix will scan the the arguments to user-defined constraints on the call trace that led to the failed constraint from left to right for an AST argument, and put the message on the first valid node found. When no AST node could be found (for example when the project constraint fails), the error is positioned at the project resource. Warning Messages on projects are often overlooked by users. Hence it is recommended that project constraints are designed in a way they can never fail. When message is provided for a failed constraint, Statix will scan the call trace for constraints that have a message provided, and use the message it encounters. If no message is found, a rendering of the failed constraint is used as a message.","title":"Basic Constraints"},{"location":"references/statix/basic-constraints/#basic-constraints","text":"As mentioned in the Language Concepts section, the core idea of Statix is to see a type-checking problem as a constraint solving problem. Therefore, it is crucial to be able to express constraints in a specification. In this section, we discuss all constraints that are note related to scope graphs. These constraints are explained in-depth in the sections on Scope Graph Construction and Queries .","title":"Basic Constraints"},{"location":"references/statix/basic-constraints/#true","text":"true The true constraint is the constraint that is trivially satisfied.","title":"True"},{"location":"references/statix/basic-constraints/#false","text":"false $ Message ? The false constraint is the constraint that will always fail. Just as all other constraints that can fail, it is possible to add a message .","title":"False"},{"location":"references/statix/basic-constraints/#conjunction","text":"$ Constraint , $ Constraint A conjunction of constraints is satisfied when both conjuncts are satisfied. Note that the solving order of the conjuncts is undefined.","title":"Conjunction"},{"location":"references/statix/basic-constraints/#equality","text":"$ Term == $ Term $ Message ? Asserts that two terms are equal. When necessary, this constraint infers values for free variables in the terms. Statically, both terms should have the same type.","title":"Equality"},{"location":"references/statix/basic-constraints/#disequality","text":"$ Term != $ Term $ Message ? Asserts that two terms are not equal. Statically, both terms should have the same type. Statix treats free variables as different from each other, and as different from concrete terms. Therefore, when any of both terms is not ground (i.e. contains free variables), the constraint will not fail.","title":"Disequality"},{"location":"references/statix/basic-constraints/#exists","text":"{ $ Var * } $ Constraint An exists constraint introduces new existentially quantified variables in the scope of its subconstraint. The names of the variables in an exists constraint should be unique (i.e. {x x} true is not allowed), but are allowed to shadow outer variables.","title":"Exists"},{"location":"references/statix/basic-constraints/#try","text":"try { $ Constraint } $ Message ? The try constraint validates whether the outer context implies that the inner constraint holds. That is: any model for the outer context (all other constraints than $Constraint ) is also a (not necessarily minimal) model for $Constraint . In order to implement these semantics, the $Constraint is handled differently than regular constraints in two ways. The $Constraint is not allowed to refine the outer context. Therefore, equality constraints will not infer values for variable that were introduced outside the try . Likewise, scopes can not be instantiated, nor edges/declarations added to scopes from outside the try . This behavior also implies that values constructed within a try construct will never escape the try context. Disequalities in $Constraint that involve free variables cause the try to fail, because appearently the disequality does not hold for all models of the outer context. Todo Explain the design choices for try in a background section.","title":"Try"},{"location":"references/statix/basic-constraints/#ast-identifiers","text":"astId ( $ Term , $ Term ) The astId constraint asserts that its second argument is the term index of the first argument. The type of the first argument may be anything, but the type of the second argument is astId . Tip Often, using an astId term will read more natural.","title":"AST Identifiers"},{"location":"references/statix/basic-constraints/#ast-property","text":"@$ Term . $ Prop $ Op $ Term Statix allows to set properties on AST nodes. These properties can be used to communicate typing results to the outside world, for example to be used in a transformation. For more information on reading these properties, please refer to the Stratego API documentation . The first term is the term (usually an AST node) on which the property is set. Next $Prop specifies which property is set. This property can be any string of the form [a-zA-Z] [a-zA-Z0-9\\_]* . It is not required to declare properties. There are two special properties: ref and type . ref properties are set on (syntactic) variable references, and point to the term they are referencing. The Spoofax reference resolution service uses these properties to offer reference resolution in the editor. The type property contains the type of a term. This type is shown when hovering over a term in an editor. The $Op specifies the operator with which a property is set. There are two possible operators: := : The assignment operator. This operator requires a property to have only a single unique value (although, since Spoofax 2.5.17, that value may be set multiple times). += : The bag insertion operator. Properties using this operator can be set multiple times, and will be aggregated in the eventual property value. Note that using both operators for a single property on a particular node will result in a failed constraint. However, it is allowed to use different operators for a property, as long as the terms on which these operators are used are different. Finally, the last $Term denotes the value of the property. Warning Failing property constraints are ignored (i.e. no error for them is reported).","title":"AST Property"},{"location":"references/statix/basic-constraints/#arithmetic-constraints","text":"$ Term $ Op $ ArithExp $ Message ? Statix supports several arithmetic constraints. These constraints consist of a term, an operator and an arithmetic expression. The $Term should have type int , while the $ArithExp is syntactically guaranteed to have type int , given that all variable references have type int . At the $Op position, several comparison operators can be used: #= asserts that both terms are equal #\\\\= asserts that both terms are not equal #>= asserts that the left term is equal or bigger that the left term #=< asserts that the left term is equal or smaller that the left term #> asserts that the left term is strictly bigger that the left term #< asserts that the left term is strictly smaller that the left term Arithmetic expressions can be integer literals, variables and bracketed arithmetic expressions. Variables in an arithmetic expression must have type int . Additionally, the following arithmetic operations can be used: $ArithExp + $ArithExp : computes integer addition $ArithExp - $ArithExp : computes integer subtraction $ArithExp * $ArithExp : computes integer multiplication min($ArithExp, $ArithExp) : computes the minimum of both arguments max($ArithExp, $ArithExp) : computes the maximum of both arguments $ArithExp div $ArithExp : computes the integer divisor (i.e. rounded down regular division). $ArithExp mod $ArithExp : computes the modulus of its arguments. Unlike other constraints, arithmetic constraint do no inference of values in the $ArithExp . Hence, having any free variables in this expression will cause the constraint to fail. Separate Arithmetic Expression Syntax As discussed, Statix has a special syntactic category for arithmetic expressions. Therefore, arithmetic expressions cannot be used at regular term positions. Instead, arithmetic expressions can be embedded in terms using the Arithmetic Expressions term syntax. Java Integers Arithmetic Expressions are implemented using standard Java integers, and hence have the same size limitations.","title":"Arithmetic Constraints"},{"location":"references/statix/basic-constraints/#messages","text":"| $ Severity $ MessageBody $ Position ? Constraints that might possibly fail can be provided with a customized message. Such message carry three parameters. First, the $Severity indicates the severity of a message. It may be either error , warning or note . Note however that warnings and notes can only be issued for failing try constraints. Second, the error message string is provided. This message string may be a regular string literal or a template literal. Template literals look as follows: $[$ ContentPart *] Content parts are either message string literals or interpolated terms. The escaping rules for string literals in templates are slightly different than for regular string literals. Message string literals can contain any character, where square brackets and backslashes must be escaped with a backslash. Just as regular string literals, tabs, newlines and carriage returns can be encoded with \\t , \\n and \\r , respectively. Terms can be inserted in a message template by surrounding them with (unescaped) square brackets: [$Term] . The term may have any type, but must be well-formed according to the regular typing rules for terms. Bug Using functional predicates inside message templates will cause an exception when loading the specification. Thirdly, a position can be assigned to the message: @ $ Var Here, the $Var is assumed to be an AST node. When the constraint on which this message is placed fails, the message will be shown inline at the AST node pointed to by this variable. When no message position is provided, or the assigned position is invalid, Statix will scan the the arguments to user-defined constraints on the call trace that led to the failed constraint from left to right for an AST argument, and put the message on the first valid node found. When no AST node could be found (for example when the project constraint fails), the error is positioned at the project resource. Warning Messages on projects are often overlooked by users. Hence it is recommended that project constraints are designed in a way they can never fail. When message is provided for a failed constraint, Statix will scan the call trace for constraints that have a message provided, and use the message it encounters. If no message is found, a rendering of the failed constraint is used as a message.","title":"Messages"},{"location":"references/statix/concepts/","text":"Language Concepts \u00b6 In this section, a brief description of the main concepts of the Statix language is provided. Terms \u00b6 The data model that underlies all Statix specifications is algebraic data. Besides several built-in primitives, such as integer and string literals, users can build composite terms using term constructors, tuples and lists. Statix is a sorted logic, in the sense that all runtime data should adhere to a multi-sorted signature. Constraints \u00b6 Key to the Statix design philosophy is to view a type-checking problem as a constraint problem. When solving the constraint problem, a minimal model is inferred from the constraints. This model represents a principal typing for the original program. In order to express such constraint problems, a versatile set of built-in constraints is provided by the Statix language. For more information on constraints, see the Basic Constraints section. Rules \u00b6 Besides using built-in constraints, users can define their own constraints using constraint handling rules. Rules consist of a head and a body. The head specifies the arguments to the constraint, and (optionally) a guard, which indicates when to apply the rule. The body is a regular constraint, which, when proven, asserts that the constraint holds. More detailed information about user-defined constraints can be found in the Rules section. Scope Graphs \u00b6 Since Statix is especially designed for type-checking, and type-checking is heavily intertwined with name binding, special support for name binding is integrated in the language. Name binding is modelled using scope graphs , in which scopes are represented as nodes, visibility is modelled using labelled edges between nodes, and declarations using special terminal nodes that are associated with a particular datum. References are modelled using scope graph queries . For more information on scope graph construction and querying, see sections Scope Graph Constraints and Queries , respectively.","title":"Language Concepts"},{"location":"references/statix/concepts/#language-concepts","text":"In this section, a brief description of the main concepts of the Statix language is provided.","title":"Language Concepts"},{"location":"references/statix/concepts/#terms","text":"The data model that underlies all Statix specifications is algebraic data. Besides several built-in primitives, such as integer and string literals, users can build composite terms using term constructors, tuples and lists. Statix is a sorted logic, in the sense that all runtime data should adhere to a multi-sorted signature.","title":"Terms"},{"location":"references/statix/concepts/#constraints","text":"Key to the Statix design philosophy is to view a type-checking problem as a constraint problem. When solving the constraint problem, a minimal model is inferred from the constraints. This model represents a principal typing for the original program. In order to express such constraint problems, a versatile set of built-in constraints is provided by the Statix language. For more information on constraints, see the Basic Constraints section.","title":"Constraints"},{"location":"references/statix/concepts/#rules","text":"Besides using built-in constraints, users can define their own constraints using constraint handling rules. Rules consist of a head and a body. The head specifies the arguments to the constraint, and (optionally) a guard, which indicates when to apply the rule. The body is a regular constraint, which, when proven, asserts that the constraint holds. More detailed information about user-defined constraints can be found in the Rules section.","title":"Rules"},{"location":"references/statix/concepts/#scope-graphs","text":"Since Statix is especially designed for type-checking, and type-checking is heavily intertwined with name binding, special support for name binding is integrated in the language. Name binding is modelled using scope graphs , in which scopes are represented as nodes, visibility is modelled using labelled edges between nodes, and declarations using special terminal nodes that are associated with a particular datum. References are modelled using scope graph queries . For more information on scope graph construction and querying, see sections Scope Graph Constraints and Queries , respectively.","title":"Scope Graphs"},{"location":"references/statix/modules/","text":"Modules \u00b6 A Statix Specification is organised as a collection of modules. Each module corresponds to a file with a .stx extension. Module Structure \u00b6 The structure of a Statix module looks as follows: module $ ModuleName $ Section * Each module declares its name, and subsequently contains a number of sections. The module name should coincide with the relative path of the module with respect to the closest source root. Todo Link to documentation on source roots. Imports \u00b6 In an imports section, definitions from other modules can be brought in scope. imports $ ModuleName * Modules can only be imported with their fully qualified name. That is, for each $ModuleName in an imports section, a module with exactly the same name must exist. Imports of sorts, constructors and predicates are transitive, while imports of labels and relations are non-transitive. Furthermore, overloading by type, shadowing of top-level definitions, and duplicate imports of specification entities are not allowed. Signatures \u00b6 In a signature section, type definitions are located. signature $ Signature * Examples of signatures are: sort and constructor declarations or label and relation declarations. Each of these will be explained in the appropriate subsection. Rules \u00b6 In a rules section, the rules of a specification are defined. For more information on rules, see the Rules section. rules $ RuleDeclaration *","title":"Modules"},{"location":"references/statix/modules/#modules","text":"A Statix Specification is organised as a collection of modules. Each module corresponds to a file with a .stx extension.","title":"Modules"},{"location":"references/statix/modules/#module-structure","text":"The structure of a Statix module looks as follows: module $ ModuleName $ Section * Each module declares its name, and subsequently contains a number of sections. The module name should coincide with the relative path of the module with respect to the closest source root. Todo Link to documentation on source roots.","title":"Module Structure"},{"location":"references/statix/modules/#imports","text":"In an imports section, definitions from other modules can be brought in scope. imports $ ModuleName * Modules can only be imported with their fully qualified name. That is, for each $ModuleName in an imports section, a module with exactly the same name must exist. Imports of sorts, constructors and predicates are transitive, while imports of labels and relations are non-transitive. Furthermore, overloading by type, shadowing of top-level definitions, and duplicate imports of specification entities are not allowed.","title":"Imports"},{"location":"references/statix/modules/#signatures","text":"In a signature section, type definitions are located. signature $ Signature * Examples of signatures are: sort and constructor declarations or label and relation declarations. Each of these will be explained in the appropriate subsection.","title":"Signatures"},{"location":"references/statix/modules/#rules","text":"In a rules section, the rules of a specification are defined. For more information on rules, see the Rules section. rules $ RuleDeclaration *","title":"Rules"},{"location":"references/statix/queries/","text":"Queries \u00b6 Scope Graphs, as introduced in the previous section can be queried. Scope graph queries always start in a particular scope, and traverse the scope graph in order to find declarations under a particular relation. The syntax for queries is as follows: query $ QueryTarget filter $ LabelRE and $ DataWF min $ LabelOrder * and $ DataLeq in $ Scope |-> $ Result The $Scope parameter is a term with type scope . In this scope, the query starts. All other query arguments are explained in the following subsections. Query Targets \u00b6 The query target is the 'thing' that is looked for in the query. This can be one of: $Relation : A relation identifier . In this case, the query will return data that is declared under that relation. () : the end of path query target. In this case, the query will return all paths that match the appropriate filters. () as relation The () query target can be thought of as a regular relation if one assumes #1 |-()-> #1 to exist for every scope #1 in the scope graph. Filters \u00b6 Query results can be filtered using two different filters. First, a regular expression on labels ( $LabelRE ) defines a filter on the paths that the query resolution algorithm will explore. This regular expression can be build from the following components: $Label : Matches paths that travers a single edge with the label $Label . Requires the label to be declared in a signature section, as explained in the section on edges . e : epsilon . Matches the empty path. Queries using this filter will only return declarations in the scope where the query started. 0 : empty set . Matches no path. $LabelRE $LabelRE : concatenation . Matches paths that can be split in two segments p1 and p2 , such that p1 matches the first regular expression, and p2 matches the second. $LabelRE | $LabelRE : disjunction . Matches paths that match either the first or the second regular expression. $LabelRE & $LabelRE : conjunction . Matches paths that match both the first and the second regular expression. ~$LabelRE : negation . Matches all paths that do not match the inner regular expression. $LabelRE* : closure . Matches paths that can be split into zero or more segments that each match the inner regular expression. $LabelRE+ : one or more . Matches paths that can be split into one or more segments that each match the inner regular expression. Equivalent to $LabelRE $LabelRE* $LabelRE? : zero or one . Matches paths that are matched by the inner regular expression, or empty paths. Equivalent to $LabelRE | e . Additionally, regular expression can be grouped by brackets. Second, data well-formedness filters ( $DataWF ) can be applied. These filters restrict which datums are included in the query result. They are expressed as anonymous lambda rules: { $ Pattern : - $ Constraint } This rule is instantiated for every declaration that is reachable according to the path well-formedness expression. When the instantiated body constraint holds, the declaration is included in the query answer. Lambda Instantiation Lambda constraint instantiation is similar to rule instantiation. For more information on rule instantiation, see the section about rule definitions . Entailment semantics Data well-formedness conditions are treated as entailment/implied conditions. Hence, they are not allowed to extend or refine the outer context. For more information on this evaluation mode, see the documentation of the try construct . The type of the predicate that is expected depends on the kind of relation that is used. For predicative relations, all arguments in the relation are provided to the data well-formedness constraint. However, for functional relations, the 'output value' (i.e. the value that the relation maps to) is not provided to the filter. When multiple arguments are provided to a data-wellformedness predicate (when there are multiple 'input' arguments to the queried relation), these arguments must be wrapped in a tuple. When the end-of-path query target () is used, the data-wellformedness constraint expects a single scope as argument. Example of filters A simple query for variables illustrates both filters. Suppose the relation var is in scope with type string -> TYPE . Then a rule (with type ascriptions ) that looks up a variable definition can be defined as follows. resolveVar ( s : scope , name : string ) = R : - query var filter P * I ? and { name' : string : - name' == name } in s |-> R . In this example, the path well-formedness expression P* I? indicates that any number of P edges may be traversed, and then, optionally, a single I edge. This resolution policy excludes e.g. transitive imports, and the traversal of P edges in an imported module. The anonymous data well-formedness condition states that a declaration with name name' may only be included in the query result if name' is equal to name from the enclosing scope. Suppose that resolveVar is instantiated for name |-> \"x\" , and declarations with name \"x\" and \"y\" are in scope. Now the anonymous inner rule is instantiated for both \"x\" and \"y\" . For \"x\" , the constraint \"x\" == \"x\" is generated, which can be solved successfully. For \"y\" however, the constraint \"y\" == \"x\" is generated, which cannot be solved successfully. Hence, only the declaration for \"x\" is included in the eventual query answer. There are three shorthands for common data well-formedness predicates: true , which is equivalent to { _ :- true } . This shorthand will thus include all encountered declaration in the query result. false , which is equivalent to { _ :- false } . This shorthand will include no declarations in the query answer. eq($Term) , is equivalent to { x :- x == $Term } and hence will include all declarations that are equal to $Term . Syntactically, the query filter can be omitted entirely, or the data well-formedness predicate can be omitted, even if a path filter is provided. By default, the path filter is ~0 , meaning that every path is considered valid, and the data well-formedness predicate is true , meaning that every datum will be returned in the query answer. Shadowing \u00b6 For many languages, name resolution involves dealing with shadowing correctly. In Statix queries, it is possible to encode shadowing policies using label orders and data comparison predicates. A declaration shadows another declaration iff its path is 'smaller than' the other path by a prefix order defined over a label comparison relation, and when the declaration data is smaller than or equal to the data of the other declaration according to a data comparison predicate. Label orders ( $LabelOrder ) are expressed as less-than relations on labels. $ Label < $ Label Here, a label is either a declared label symbol , or $ , which denotes the 'end-of-path' label. This label can be used to express orders on path length. For example, $ < P expresses that paths with fewer P labels are preferred over paths with more P labels. Strict Partial Order Label orders must be strict partial orders . That is, they are implicitly transitive, but may not be reflexive or symmetric. Label order specifications that are not strict partial orders will be rejected at specification loading time. Prefix order Note that the label order is a prefix order , not a lexicographical full-path order . That is, paths that diverged by traversing different edges with the same label are not ordered by this relation. In addition to a label ordering relation, a data comparison predicate ( $DataLeq ) can be provided. This predicate can be written as follows: { $ Pattern , $ Pattern : - $ Constraint } This constraint indicates that the left argument is smaller than the right argument, given that the constraint can be satisfied. The types of each patterns is similar to the type of the data-wellformedness predicate. When the queried relation is predicative (i.e. has no 'output'), the pattern is a tuple containing arguments of the declaration that is compared. If the queried relation is functional, a tuple with only the 'input' arguments must be provided. When there is only one declaration argument, the tuple may be omitted. There are several shorthands available for the data comparison constraint: true is equivalent to { _, _ :- true } , and hence ensures that declarations are shadowed based on the label order only. false is equivalent to { _, _ :- false } , and hence ensures that no shadowing is applied, even when paths can be ordered using the label order. $ConstraintName is equivalent to { d1, d2 :- $ConstraintName(d1, d2) } , which means that d1 shadows d2 when $ConstraintName(d1, d2) can be satisfied. { $Pattern, $Pattern } is equivalent to { $Pattern, $Pattern :- true } , which means that the first argument shadows the second if they match the patterns. Non-linear Patterns The data comparison shorthand is mostly used with non-linear patterns. For example, to encode that declarations with equal names shadow each other, the data comparison shorthand { x, x } can be used. When using this pattern however, please ensure that variable names are fresh, because the behavior of shadowing names is planned to change in the future. Partial Order Data comparison functions orders must be (non-strict) partial orders . That is, they are implicitly transitive and reflexive, but may not be symmetric. However, this is not validated for tractability reasons. Therefore, for any predicate that is not a partial order (other than true ), shadowing behavior is undefined. Syntactically, the shadowing parameters can be omitted altogether, or the data comparison predicate can be omitted, even when an label order is specified. The default value of the label order is an empty relation, while the default value of the data comparison predicate is true . On the one hand, this ensures that no shadowing is applied when no shadowing parameters are provided. On the other hand, when a label order, but no data comparison predicate is provided, all declarations shadow each other based on a path comparison only. Operationally, the label order and the data comparison constraints are applied conjunctively . For any declaration d and d' , if the path to d is smaller than the path to d' according to the label order, and the application of the data comparison constraint to d, d' can be satisfied, d' will be excluded from the query answer. Result Pattern \u00b6 When the query resolution is completed, the query result will be unified with the $Result term. This term is a list that contains path-datum entries. Therefore, the type of this term is list((path * R)) , where R is a tuple type with the argument types of the relation that is queried. In case the relation is functional, the 'output' type is included in the result. When the relation is unary, the tuple is omitted. When the query target is () , R is the scope type. For the syntactic structure of the paths, please refer to the section on path terms . Semantically, for any query answer pair (p, d) , the path p represents the path followed from the scope in which the query started to the scope in which the declaration of d was found. Top-level Destination scope Since path terms are left-recursive , have the source scope at the left side, and the destination scope (i.e. the scope in which the paired datum was declared) on the right, it turns out that the target scope is in the third argument of the top-level constructor. This is convenient, since it allows to access the target scope without destructuring the whole path. (Direct access to the source scope is not really important, since it is already available as an argument to the query constraint). On the other side, it is sometimes perceived as not completely intuitive to have the target scope in the top level constructor. When multiple results are returned by the query, Statix has no guarantees on the order of their appearence in the list. Query Sugar \u00b6 Warning Since Spoofax 2.5.15, the query sugar constructs are deprecated.","title":"Queries"},{"location":"references/statix/queries/#queries","text":"Scope Graphs, as introduced in the previous section can be queried. Scope graph queries always start in a particular scope, and traverse the scope graph in order to find declarations under a particular relation. The syntax for queries is as follows: query $ QueryTarget filter $ LabelRE and $ DataWF min $ LabelOrder * and $ DataLeq in $ Scope |-> $ Result The $Scope parameter is a term with type scope . In this scope, the query starts. All other query arguments are explained in the following subsections.","title":"Queries"},{"location":"references/statix/queries/#query-targets","text":"The query target is the 'thing' that is looked for in the query. This can be one of: $Relation : A relation identifier . In this case, the query will return data that is declared under that relation. () : the end of path query target. In this case, the query will return all paths that match the appropriate filters. () as relation The () query target can be thought of as a regular relation if one assumes #1 |-()-> #1 to exist for every scope #1 in the scope graph.","title":"Query Targets"},{"location":"references/statix/queries/#filters","text":"Query results can be filtered using two different filters. First, a regular expression on labels ( $LabelRE ) defines a filter on the paths that the query resolution algorithm will explore. This regular expression can be build from the following components: $Label : Matches paths that travers a single edge with the label $Label . Requires the label to be declared in a signature section, as explained in the section on edges . e : epsilon . Matches the empty path. Queries using this filter will only return declarations in the scope where the query started. 0 : empty set . Matches no path. $LabelRE $LabelRE : concatenation . Matches paths that can be split in two segments p1 and p2 , such that p1 matches the first regular expression, and p2 matches the second. $LabelRE | $LabelRE : disjunction . Matches paths that match either the first or the second regular expression. $LabelRE & $LabelRE : conjunction . Matches paths that match both the first and the second regular expression. ~$LabelRE : negation . Matches all paths that do not match the inner regular expression. $LabelRE* : closure . Matches paths that can be split into zero or more segments that each match the inner regular expression. $LabelRE+ : one or more . Matches paths that can be split into one or more segments that each match the inner regular expression. Equivalent to $LabelRE $LabelRE* $LabelRE? : zero or one . Matches paths that are matched by the inner regular expression, or empty paths. Equivalent to $LabelRE | e . Additionally, regular expression can be grouped by brackets. Second, data well-formedness filters ( $DataWF ) can be applied. These filters restrict which datums are included in the query result. They are expressed as anonymous lambda rules: { $ Pattern : - $ Constraint } This rule is instantiated for every declaration that is reachable according to the path well-formedness expression. When the instantiated body constraint holds, the declaration is included in the query answer. Lambda Instantiation Lambda constraint instantiation is similar to rule instantiation. For more information on rule instantiation, see the section about rule definitions . Entailment semantics Data well-formedness conditions are treated as entailment/implied conditions. Hence, they are not allowed to extend or refine the outer context. For more information on this evaluation mode, see the documentation of the try construct . The type of the predicate that is expected depends on the kind of relation that is used. For predicative relations, all arguments in the relation are provided to the data well-formedness constraint. However, for functional relations, the 'output value' (i.e. the value that the relation maps to) is not provided to the filter. When multiple arguments are provided to a data-wellformedness predicate (when there are multiple 'input' arguments to the queried relation), these arguments must be wrapped in a tuple. When the end-of-path query target () is used, the data-wellformedness constraint expects a single scope as argument. Example of filters A simple query for variables illustrates both filters. Suppose the relation var is in scope with type string -> TYPE . Then a rule (with type ascriptions ) that looks up a variable definition can be defined as follows. resolveVar ( s : scope , name : string ) = R : - query var filter P * I ? and { name' : string : - name' == name } in s |-> R . In this example, the path well-formedness expression P* I? indicates that any number of P edges may be traversed, and then, optionally, a single I edge. This resolution policy excludes e.g. transitive imports, and the traversal of P edges in an imported module. The anonymous data well-formedness condition states that a declaration with name name' may only be included in the query result if name' is equal to name from the enclosing scope. Suppose that resolveVar is instantiated for name |-> \"x\" , and declarations with name \"x\" and \"y\" are in scope. Now the anonymous inner rule is instantiated for both \"x\" and \"y\" . For \"x\" , the constraint \"x\" == \"x\" is generated, which can be solved successfully. For \"y\" however, the constraint \"y\" == \"x\" is generated, which cannot be solved successfully. Hence, only the declaration for \"x\" is included in the eventual query answer. There are three shorthands for common data well-formedness predicates: true , which is equivalent to { _ :- true } . This shorthand will thus include all encountered declaration in the query result. false , which is equivalent to { _ :- false } . This shorthand will include no declarations in the query answer. eq($Term) , is equivalent to { x :- x == $Term } and hence will include all declarations that are equal to $Term . Syntactically, the query filter can be omitted entirely, or the data well-formedness predicate can be omitted, even if a path filter is provided. By default, the path filter is ~0 , meaning that every path is considered valid, and the data well-formedness predicate is true , meaning that every datum will be returned in the query answer.","title":"Filters"},{"location":"references/statix/queries/#shadowing","text":"For many languages, name resolution involves dealing with shadowing correctly. In Statix queries, it is possible to encode shadowing policies using label orders and data comparison predicates. A declaration shadows another declaration iff its path is 'smaller than' the other path by a prefix order defined over a label comparison relation, and when the declaration data is smaller than or equal to the data of the other declaration according to a data comparison predicate. Label orders ( $LabelOrder ) are expressed as less-than relations on labels. $ Label < $ Label Here, a label is either a declared label symbol , or $ , which denotes the 'end-of-path' label. This label can be used to express orders on path length. For example, $ < P expresses that paths with fewer P labels are preferred over paths with more P labels. Strict Partial Order Label orders must be strict partial orders . That is, they are implicitly transitive, but may not be reflexive or symmetric. Label order specifications that are not strict partial orders will be rejected at specification loading time. Prefix order Note that the label order is a prefix order , not a lexicographical full-path order . That is, paths that diverged by traversing different edges with the same label are not ordered by this relation. In addition to a label ordering relation, a data comparison predicate ( $DataLeq ) can be provided. This predicate can be written as follows: { $ Pattern , $ Pattern : - $ Constraint } This constraint indicates that the left argument is smaller than the right argument, given that the constraint can be satisfied. The types of each patterns is similar to the type of the data-wellformedness predicate. When the queried relation is predicative (i.e. has no 'output'), the pattern is a tuple containing arguments of the declaration that is compared. If the queried relation is functional, a tuple with only the 'input' arguments must be provided. When there is only one declaration argument, the tuple may be omitted. There are several shorthands available for the data comparison constraint: true is equivalent to { _, _ :- true } , and hence ensures that declarations are shadowed based on the label order only. false is equivalent to { _, _ :- false } , and hence ensures that no shadowing is applied, even when paths can be ordered using the label order. $ConstraintName is equivalent to { d1, d2 :- $ConstraintName(d1, d2) } , which means that d1 shadows d2 when $ConstraintName(d1, d2) can be satisfied. { $Pattern, $Pattern } is equivalent to { $Pattern, $Pattern :- true } , which means that the first argument shadows the second if they match the patterns. Non-linear Patterns The data comparison shorthand is mostly used with non-linear patterns. For example, to encode that declarations with equal names shadow each other, the data comparison shorthand { x, x } can be used. When using this pattern however, please ensure that variable names are fresh, because the behavior of shadowing names is planned to change in the future. Partial Order Data comparison functions orders must be (non-strict) partial orders . That is, they are implicitly transitive and reflexive, but may not be symmetric. However, this is not validated for tractability reasons. Therefore, for any predicate that is not a partial order (other than true ), shadowing behavior is undefined. Syntactically, the shadowing parameters can be omitted altogether, or the data comparison predicate can be omitted, even when an label order is specified. The default value of the label order is an empty relation, while the default value of the data comparison predicate is true . On the one hand, this ensures that no shadowing is applied when no shadowing parameters are provided. On the other hand, when a label order, but no data comparison predicate is provided, all declarations shadow each other based on a path comparison only. Operationally, the label order and the data comparison constraints are applied conjunctively . For any declaration d and d' , if the path to d is smaller than the path to d' according to the label order, and the application of the data comparison constraint to d, d' can be satisfied, d' will be excluded from the query answer.","title":"Shadowing"},{"location":"references/statix/queries/#result-pattern","text":"When the query resolution is completed, the query result will be unified with the $Result term. This term is a list that contains path-datum entries. Therefore, the type of this term is list((path * R)) , where R is a tuple type with the argument types of the relation that is queried. In case the relation is functional, the 'output' type is included in the result. When the relation is unary, the tuple is omitted. When the query target is () , R is the scope type. For the syntactic structure of the paths, please refer to the section on path terms . Semantically, for any query answer pair (p, d) , the path p represents the path followed from the scope in which the query started to the scope in which the declaration of d was found. Top-level Destination scope Since path terms are left-recursive , have the source scope at the left side, and the destination scope (i.e. the scope in which the paired datum was declared) on the right, it turns out that the target scope is in the third argument of the top-level constructor. This is convenient, since it allows to access the target scope without destructuring the whole path. (Direct access to the source scope is not really important, since it is already available as an argument to the query constraint). On the other side, it is sometimes perceived as not completely intuitive to have the target scope in the top level constructor. When multiple results are returned by the query, Statix has no guarantees on the order of their appearence in the list.","title":"Result Pattern"},{"location":"references/statix/queries/#query-sugar","text":"Warning Since Spoofax 2.5.15, the query sugar constructs are deprecated.","title":"Query Sugar"},{"location":"references/statix/rules/","text":"Rules \u00b6 User-defined constraints and their rules make up the main part of a Statix specification. In this section, we describe the definition and usage of user-defined constraints and their rules. Constraint Definitions \u00b6 In order to define a custom constraint, its type must be declared first. A constraint can be declared in a rules section, or in a constraints subsection of a signature section. A constraint is declared by specifying its name and argument type. For more information on types, please refer to the Terms section. Note that the name of the constraint must be unique within a specification. $ ConstraintName : { $ Type \"*\" } * Terminology In this reference manual, we consistently use the term 'constraint declaration' for the introduction of new user-defined constraints. However, in practise, these are sometimes also referred to as 'predicate' or just simply 'constraint'. When a constraint declaration is provided this way, it can be used as a constraint by providing concrete arguments, separated by comma's. $ ConstraintName ({ $ Term \",\" } * ) $ Message ? The sorts of the argument terms should be equal to the sorts in the constraint declaration. Rule Definitions \u00b6 When solving a user-defined constraint, a rule for that constraint is unfolded in order to infer a model satisfying the constraint. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) : - $ Constraint . The part before the turnstile ( :- ) is often referred to as the head of the rule, while the $Constraint after the turnstile is denoted as body . When applying a rule, each head pattern (which is just a term) will be matched with its corresponding actual argument. Statically, the sorts of the terms in $Patterns are type-checked based on the constraint declaration. Any variables in patterns are implicitly introduced in the scope of the rule. Patterns can be non-linear. That is, a variable may occur multiple times in a pattern. Operationally, the subterms at these positions are then required to be structurally equal. Note that multiple rules for a single constraint can, and often will, be provided. For each constraint, the rule that is used for simplification is determined by the guard of the rule. This guard is derived from the head pattern: a rule can only be applied when the constraint arguments match the patterns. During constraint solving, Statix will try at most one rule for each constraint. The appropriate rule is selected by applying the following heuristics in order: 1. Rules with a smaller domain are preferred over rules with a larger domain. 2. When pairwise comparing rules, the rule for which, in left-to-right order, a more specific pattern is encountered first is preferred over the other. For all cases where these heuristics do not decide which rule to use for a constraint, compile time \"Overlapping patterns\" errors will be emitted. The $RuleName is just a name that can be used for documentation purposes. It cannot be referenced from any position in the specification, and may be omitted altogether. Axiom rules \u00b6 In some cases, a constraint trivially holds for particular inputs. For such constraints, an axiom rule can be specified. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ). This rule is similar to a regular rule, but lacks a body. When applying such a rule, no new constraints are introduced, reflecting the fact that the constraint trivially holds for these arguments. Functional Rules \u00b6 Some user-defined constraints can be thought of more naturally as a function: a constraint where a particular term is inferred by the constraint, rather than validated. Statix allows to write constraints in a functional idiom as follows: First, a constraint declaration for such 'functional constraints' must be provided as follows: $ ConstraintName : { $ Type \"*\" } * -> $ Type In addition to the regular list of input sorts, a sort for the output term is provided to the constraint declaration. Rule definitions for a functional constraint look as follows: [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) = $ Term : - $ Constraint . Compared to predicative rule definitions as introduced earlier in this section, an additional term after an equality-sign is appended to the rule head. This term denotes the output term (the term inferred by the rule). A functional constraint can be used in a term position, as opposed to a constraint position for predicative rules. Otherwise, their syntax is the same. $ ConstraintName ({ $ Term \",\" } * ) Semantically, the output term of applying the constraint is substituted at the position of the application of the functional predicate. Terminology: Functional vs. Predicative When we want to make the distinction between these two forms of constraints explicit, we usually refer to either groups with 'predicative constraint declarations' and 'predicative constraints', versus 'functional constraint declarations' and 'functional constraints', respectively. Normalization Every specification with functional predicates is normalized to a form with only regular predicates. To show the normal form of a specification in Eclipse, use the Spoofax > Syntax > Format normalized AST menu action. Mapping rules \u00b6 Another common pattern in Statix is defining a predicate that instantiates a predicate for all elements in a list. Statix allows derive such mapping rules using the maps keyword as follows: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) A lift specifier ( $Lift ) can be one of the following: * : The identity lift . This lift specifier indicates that this argument is passed to the mapped constraint unchanged. list(*) : The list lift : This lift specifier indicates that the mapped constraint will be instantiated for each element in the list at that argument position. Each constraint defined with maps , must contain at least one list lift. Otherwise, the mapping would be a no-op. ({$Lift \",\"}+) : The tuple lift : This lift specifier indicates that arguments are extracted from a tuple. For each tuple argument, a corresponding lifting is applied afterwards. The type of $MappingConstraintName is inferred by inverse application of the lift specifiers to the type of $MappedConstraintName . Therefore, no explicit declaration of the type of the mapping constraint is required. Similar to predicative constraints, functional mapping constraints can be derived: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) = $ Lift In addition to lift specifiers of the input arguments, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred terms from the mapped constraints are aggregated and returned by the mapping constraint. Example. A common example where mapping rules are used is when type-checking a list of declarations. A specification snippet for that could look as follows: rules declOk : scope * Decl declsOk maps declOk ( * , list ( * )) // rules for declOk In this snippet, the declsOk constraint instantiates declOk for each declaration in a list of declaration. Its inferred type is scope * list(Decl) . When mapping functional constraints, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred values of the mapped constraint are returned by the mapping constraint. When using multiple list lifts in the input, the resulting constraint will zip the arguments. This implicitly requires the input lists to be of equal length. The creation of a cartesian product can be achieved by repeated application of the maps construct for each argument. Normalization Similar to functional constraints, constraints derived using the maps construct are normalized to regular predicative constraints. This normalization can be inspected using the Spoofax > Syntax > Format normalized AST menu action. Injections of Namespaces and Relations \u00b6 For convenience, it is possible to declare namespaces, namespace queries (both deprecated) and relations in a rules section as well. rules namespace Var : string resolve Var filter P * I * relation var : string -> TYPE","title":"Rules"},{"location":"references/statix/rules/#rules","text":"User-defined constraints and their rules make up the main part of a Statix specification. In this section, we describe the definition and usage of user-defined constraints and their rules.","title":"Rules"},{"location":"references/statix/rules/#constraint-definitions","text":"In order to define a custom constraint, its type must be declared first. A constraint can be declared in a rules section, or in a constraints subsection of a signature section. A constraint is declared by specifying its name and argument type. For more information on types, please refer to the Terms section. Note that the name of the constraint must be unique within a specification. $ ConstraintName : { $ Type \"*\" } * Terminology In this reference manual, we consistently use the term 'constraint declaration' for the introduction of new user-defined constraints. However, in practise, these are sometimes also referred to as 'predicate' or just simply 'constraint'. When a constraint declaration is provided this way, it can be used as a constraint by providing concrete arguments, separated by comma's. $ ConstraintName ({ $ Term \",\" } * ) $ Message ? The sorts of the argument terms should be equal to the sorts in the constraint declaration.","title":"Constraint Definitions"},{"location":"references/statix/rules/#rule-definitions","text":"When solving a user-defined constraint, a rule for that constraint is unfolded in order to infer a model satisfying the constraint. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) : - $ Constraint . The part before the turnstile ( :- ) is often referred to as the head of the rule, while the $Constraint after the turnstile is denoted as body . When applying a rule, each head pattern (which is just a term) will be matched with its corresponding actual argument. Statically, the sorts of the terms in $Patterns are type-checked based on the constraint declaration. Any variables in patterns are implicitly introduced in the scope of the rule. Patterns can be non-linear. That is, a variable may occur multiple times in a pattern. Operationally, the subterms at these positions are then required to be structurally equal. Note that multiple rules for a single constraint can, and often will, be provided. For each constraint, the rule that is used for simplification is determined by the guard of the rule. This guard is derived from the head pattern: a rule can only be applied when the constraint arguments match the patterns. During constraint solving, Statix will try at most one rule for each constraint. The appropriate rule is selected by applying the following heuristics in order: 1. Rules with a smaller domain are preferred over rules with a larger domain. 2. When pairwise comparing rules, the rule for which, in left-to-right order, a more specific pattern is encountered first is preferred over the other. For all cases where these heuristics do not decide which rule to use for a constraint, compile time \"Overlapping patterns\" errors will be emitted. The $RuleName is just a name that can be used for documentation purposes. It cannot be referenced from any position in the specification, and may be omitted altogether.","title":"Rule Definitions"},{"location":"references/statix/rules/#axiom-rules","text":"In some cases, a constraint trivially holds for particular inputs. For such constraints, an axiom rule can be specified. [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ). This rule is similar to a regular rule, but lacks a body. When applying such a rule, no new constraints are introduced, reflecting the fact that the constraint trivially holds for these arguments.","title":"Axiom rules"},{"location":"references/statix/rules/#functional-rules","text":"Some user-defined constraints can be thought of more naturally as a function: a constraint where a particular term is inferred by the constraint, rather than validated. Statix allows to write constraints in a functional idiom as follows: First, a constraint declaration for such 'functional constraints' must be provided as follows: $ ConstraintName : { $ Type \"*\" } * -> $ Type In addition to the regular list of input sorts, a sort for the output term is provided to the constraint declaration. Rule definitions for a functional constraint look as follows: [$ RuleName ]$ ConstraintName ({ $ Pattern \",\" } * ) = $ Term : - $ Constraint . Compared to predicative rule definitions as introduced earlier in this section, an additional term after an equality-sign is appended to the rule head. This term denotes the output term (the term inferred by the rule). A functional constraint can be used in a term position, as opposed to a constraint position for predicative rules. Otherwise, their syntax is the same. $ ConstraintName ({ $ Term \",\" } * ) Semantically, the output term of applying the constraint is substituted at the position of the application of the functional predicate. Terminology: Functional vs. Predicative When we want to make the distinction between these two forms of constraints explicit, we usually refer to either groups with 'predicative constraint declarations' and 'predicative constraints', versus 'functional constraint declarations' and 'functional constraints', respectively. Normalization Every specification with functional predicates is normalized to a form with only regular predicates. To show the normal form of a specification in Eclipse, use the Spoofax > Syntax > Format normalized AST menu action.","title":"Functional Rules"},{"location":"references/statix/rules/#mapping-rules","text":"Another common pattern in Statix is defining a predicate that instantiates a predicate for all elements in a list. Statix allows derive such mapping rules using the maps keyword as follows: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) A lift specifier ( $Lift ) can be one of the following: * : The identity lift . This lift specifier indicates that this argument is passed to the mapped constraint unchanged. list(*) : The list lift : This lift specifier indicates that the mapped constraint will be instantiated for each element in the list at that argument position. Each constraint defined with maps , must contain at least one list lift. Otherwise, the mapping would be a no-op. ({$Lift \",\"}+) : The tuple lift : This lift specifier indicates that arguments are extracted from a tuple. For each tuple argument, a corresponding lifting is applied afterwards. The type of $MappingConstraintName is inferred by inverse application of the lift specifiers to the type of $MappedConstraintName . Therefore, no explicit declaration of the type of the mapping constraint is required. Similar to predicative constraints, functional mapping constraints can be derived: $ MappingConstraintName maps $ MappedConstraintName ({ $ Lift \",\" }) = $ Lift In addition to lift specifiers of the input arguments, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred terms from the mapped constraints are aggregated and returned by the mapping constraint. Example. A common example where mapping rules are used is when type-checking a list of declarations. A specification snippet for that could look as follows: rules declOk : scope * Decl declsOk maps declOk ( * , list ( * )) // rules for declOk In this snippet, the declsOk constraint instantiates declOk for each declaration in a list of declaration. Its inferred type is scope * list(Decl) . When mapping functional constraints, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred values of the mapped constraint are returned by the mapping constraint. When using multiple list lifts in the input, the resulting constraint will zip the arguments. This implicitly requires the input lists to be of equal length. The creation of a cartesian product can be achieved by repeated application of the maps construct for each argument. Normalization Similar to functional constraints, constraints derived using the maps construct are normalized to regular predicative constraints. This normalization can be inspected using the Spoofax > Syntax > Format normalized AST menu action.","title":"Mapping rules"},{"location":"references/statix/rules/#injections-of-namespaces-and-relations","text":"For convenience, it is possible to declare namespaces, namespace queries (both deprecated) and relations in a rules section as well. rules namespace Var : string resolve Var filter P * I * relation var : string -> TYPE","title":"Injections of Namespaces and Relations"},{"location":"references/statix/scope-graphs/","text":"Scope Graph Constraints \u00b6 One of the core concepts of Statix is modelling name binding structures using scope graphs . Scope graphs consist of three different components, summarized in the following table. Component Description Textual Notation Graphical notation Scope Region in a program with uniform behavior wrt. name resolution. Represented as nodes in a graph. #1 Circular node Edge Directed edges with upper-case labels model reachability between scopes. #1 -L-> #2 Labeled arrow Declaration Declarations associate data terms with a particular scope under a particular relation. #1 |-r-> d Labeled block arrow Using these components, and leveraging the fact that scopes are regular terms, many name-binding patterns can be modelled. In the remainder of this section, we will explain how scope graph constraints can be expressed in the Statix language. Scopes \u00b6 First, scopes can be created using the new keyword: new $ Var + For each var in the list of variables provided to the new constraint, a fresh scope is generated, and bound to that particular variable. Note that the $Var s are not introduced by this constraints, but rather have to be introduced earlier in a rule head or using an existential constraint . Statix guarantees that each scope has a unique identity. Scopes that are generated by different new constraints can never be equal under the equality constraint . Edges \u00b6 The existence of edges in a scope graph can be asserted using edge assertion constraints: $ Term - $ Label- > $ Term This constraint ensures that an edge from the first term argument to the last argument (which must have type scope ) with a label $Label exists. Edge Assertions not Idempotent Edge constraints are not idempotent. That is, repeated edge assertions will result in multiple equivalent edges in a scope graph. However, because query results have set semantics, and edges have structural identity, declarations reached via such a duplicated edge will not be duplicated in a query answer. For example (assuming familiarity with queries and tests ), the constraint: { R s1 s2 } new s1 s2 , s1 -P-> s2 , s1 -P-> s2 , query () filter P in s1 |-> R will give the following (slightly simplified) result: substitution R |-> [ ( PathStep ( PathEmpty ( # s1 ), P , # s2 ), # s2 ) ] analysis scope graph # s1 { edges { P : # s2 # s2 } } In this result, the P edge is duplicated in the scope graph, but there is still only a single query result. It is required to declare edge labels in a signature section: signature name-resolution labels $ Label + Label are just uppercase identifiers. They must adhere to the following regular expression: [A-Z] [A-Za-z0-9\\_] . It is not allowed to shadow label names, nor may modules import equivalent label names from different modules. Declarations \u00b6 Declarations in a scope graph can be asserted as follows: !$ Relation [$ Term *] in $ Scope This constraint asserts that the terms inside the square brackets are associated with scope $Scope under relation $Relation . Regarding the static semantics of this constraint, $Scope is a term which should have type scope . Additionally, the term arguments must adhere to the signature of the relation. The signature of a relation must be provided in a signature section: signature relation $ Relation : { $ Type \"*\" } * Just as rules , relations can alternatively be declared in a functional style: $ Relation : { $ Type \"*\" } * -> $ Type The style of declaration is importand when doing queries , but asserting declarations is similar for both types of relations. When asserting a declaration for a functional relation, the terms that the relation maps to should be provided as the last term in the square brackets. Instead of in a signature section, relations can be declared in a rules section as well. It is allowed to have multiple declaration assertions for a single relation in the same scope, even when the data of the different relations are equivalent. In the latter case, multiple equivalent declarations will be inserted in the scope graph. Permission to Extend \u00b6 In order to make query execution sound, Statix statically limits to which scopes new edges or declarations may be added (adding a edge or declaration is often called extending). Scope extension is only allowed in the following cases: Scopes that are freshly instantiated in a rule using new constraints may be extended by that rule, and any user-defined constraint that is instantiated by that rule. Scopes that are passed as direct argument to a rule may be extended by that rule, given that the scope may be extended by rule that instantiated that constraint. This property is validated at the instantiation site. Uninstantiated scope variables that are passed directly to a user-defined constraint in which they are instantiated may be extended by the outer constraint as well. However, this does not hold for input/output values of functional rules These rules prevent extension of scopes that are obtained by pattern matching/ deconstruction. Namespaces and Occurrences \u00b6 Warning Since Spoofax 2.5.15, namespaces and occurrences are deprecated.","title":"Scope Graph Constraints"},{"location":"references/statix/scope-graphs/#scope-graph-constraints","text":"One of the core concepts of Statix is modelling name binding structures using scope graphs . Scope graphs consist of three different components, summarized in the following table. Component Description Textual Notation Graphical notation Scope Region in a program with uniform behavior wrt. name resolution. Represented as nodes in a graph. #1 Circular node Edge Directed edges with upper-case labels model reachability between scopes. #1 -L-> #2 Labeled arrow Declaration Declarations associate data terms with a particular scope under a particular relation. #1 |-r-> d Labeled block arrow Using these components, and leveraging the fact that scopes are regular terms, many name-binding patterns can be modelled. In the remainder of this section, we will explain how scope graph constraints can be expressed in the Statix language.","title":"Scope Graph Constraints"},{"location":"references/statix/scope-graphs/#scopes","text":"First, scopes can be created using the new keyword: new $ Var + For each var in the list of variables provided to the new constraint, a fresh scope is generated, and bound to that particular variable. Note that the $Var s are not introduced by this constraints, but rather have to be introduced earlier in a rule head or using an existential constraint . Statix guarantees that each scope has a unique identity. Scopes that are generated by different new constraints can never be equal under the equality constraint .","title":"Scopes"},{"location":"references/statix/scope-graphs/#edges","text":"The existence of edges in a scope graph can be asserted using edge assertion constraints: $ Term - $ Label- > $ Term This constraint ensures that an edge from the first term argument to the last argument (which must have type scope ) with a label $Label exists. Edge Assertions not Idempotent Edge constraints are not idempotent. That is, repeated edge assertions will result in multiple equivalent edges in a scope graph. However, because query results have set semantics, and edges have structural identity, declarations reached via such a duplicated edge will not be duplicated in a query answer. For example (assuming familiarity with queries and tests ), the constraint: { R s1 s2 } new s1 s2 , s1 -P-> s2 , s1 -P-> s2 , query () filter P in s1 |-> R will give the following (slightly simplified) result: substitution R |-> [ ( PathStep ( PathEmpty ( # s1 ), P , # s2 ), # s2 ) ] analysis scope graph # s1 { edges { P : # s2 # s2 } } In this result, the P edge is duplicated in the scope graph, but there is still only a single query result. It is required to declare edge labels in a signature section: signature name-resolution labels $ Label + Label are just uppercase identifiers. They must adhere to the following regular expression: [A-Z] [A-Za-z0-9\\_] . It is not allowed to shadow label names, nor may modules import equivalent label names from different modules.","title":"Edges"},{"location":"references/statix/scope-graphs/#declarations","text":"Declarations in a scope graph can be asserted as follows: !$ Relation [$ Term *] in $ Scope This constraint asserts that the terms inside the square brackets are associated with scope $Scope under relation $Relation . Regarding the static semantics of this constraint, $Scope is a term which should have type scope . Additionally, the term arguments must adhere to the signature of the relation. The signature of a relation must be provided in a signature section: signature relation $ Relation : { $ Type \"*\" } * Just as rules , relations can alternatively be declared in a functional style: $ Relation : { $ Type \"*\" } * -> $ Type The style of declaration is importand when doing queries , but asserting declarations is similar for both types of relations. When asserting a declaration for a functional relation, the terms that the relation maps to should be provided as the last term in the square brackets. Instead of in a signature section, relations can be declared in a rules section as well. It is allowed to have multiple declaration assertions for a single relation in the same scope, even when the data of the different relations are equivalent. In the latter case, multiple equivalent declarations will be inserted in the scope graph.","title":"Declarations"},{"location":"references/statix/scope-graphs/#permission-to-extend","text":"In order to make query execution sound, Statix statically limits to which scopes new edges or declarations may be added (adding a edge or declaration is often called extending). Scope extension is only allowed in the following cases: Scopes that are freshly instantiated in a rule using new constraints may be extended by that rule, and any user-defined constraint that is instantiated by that rule. Scopes that are passed as direct argument to a rule may be extended by that rule, given that the scope may be extended by rule that instantiated that constraint. This property is validated at the instantiation site. Uninstantiated scope variables that are passed directly to a user-defined constraint in which they are instantiated may be extended by the outer constraint as well. However, this does not hold for input/output values of functional rules These rules prevent extension of scopes that are obtained by pattern matching/ deconstruction.","title":"Permission to Extend"},{"location":"references/statix/scope-graphs/#namespaces-and-occurrences","text":"Warning Since Spoofax 2.5.15, namespaces and occurrences are deprecated.","title":"Namespaces and Occurrences"},{"location":"references/statix/stratego-api/","text":"Stratego API \u00b6 Executing the Solver \u00b6 Querying the Analysis Result \u00b6","title":"Stratego API"},{"location":"references/statix/stratego-api/#stratego-api","text":"","title":"Stratego API"},{"location":"references/statix/stratego-api/#executing-the-solver","text":"","title":"Executing the Solver"},{"location":"references/statix/stratego-api/#querying-the-analysis-result","text":"","title":"Querying the Analysis Result"},{"location":"references/statix/terms/","text":"Terms \u00b6 In Statix, data is represented using terms. This data can be a program, a typing annotation, or anything else that the specification defines. Terms are built from atoms and composites, such as constructors, tuples and lists. Additionally, Statix allows to inline several constraint results in terms. In this section, we explain the various types of terms that Statix supports, and, when appropriate, how their types should be declared. Terminology: Sort vs. Type Throughout this reference manual, we use the term 'sort' for syntactic categories, and 'type' for all other types (such as lists, tuples, scopes, etc.). However, in practise, these terms are both used in both meanings. Numerals \u00b6 Numeric literals are literals of the form [0-9]+ . Negative literals are not supported directly. All integer literals have the built-in type int . Strings \u00b6 String literals are arbitrary, single-line sequences of characters enclosed in double quotes. String literals may not contain unescaped backslashes, double quotes, or tabs. Double quotes and backslashes can be used in a string literal by prefixing them with another backslashes ( \\\" and \\\\ , respectively), while tabs, newlines and carriage returns can be encoded using respectively \\t , \\n and \\r . Otherwise, no escaping is required. String literals have the built-in type string . Identifiers \u00b6 Variables are identifiers of values of the following form: [a-zA-Z] [a-zA-Z0-9\\_]* [\\']* . With respect to type-checking, variables can be handled in two ways. When a variable occurs in the head of a rule , it is implicitly brought into scope with the type inferred from the rule type. Otherwise, it is required that the variable is introduced earlier, with the correct type. Apart from introduction in rule heads, variables can be introduced by existential constraints . In that case, the type of the variable is derived from its usage. Wildcards \u00b6 Wildcards are represented as _ , and denote variables without identity. Every occurrence of a wildcard is interpreted as a new variable. Because wildcards cannot reference each other, it is not required that the types of multiple wildcard occurrences coincide. Composite terms \u00b6 Composite terms can be build using constructor applications : $ ConsId ({ $ Term \",\" } * ) Here a term with constructor $ConsId and some term arguments is built. Composite terms must adhere to a signature. A signature describes which term compositions are valid, and must be declared in a signature section: signature sorts $ SortID * constructors $ ConsId : { $ Type \"*\" } + -> $ SortID $ ConsId : $ SortID First, the syntactic categories (which closely correspond to type identifiers in other languages) must be declared in a sorts subsection. Then, the constructor symbols can be declared in a constructors section. For each constructor, the types of the arguments and its sort should be provided. For nullary constructors (constructors without arguments), the arrow preceding the sort should be omitted. When a composite term is built, it is validated that all arguments match the type declaration from the signature. The type of the whole composite term is equal to the sort of the constructor. Tuples \u00b6 A built-in composite data construction is tuples : ({ $ Term \",\" } * ) Tuples have a statically fixed length, but the types of the arguments may differ. The type of the tuple expression is just the product of its arguments. The arity of a tuple may be anything except one, because unary tuples cause syntactic ambiguities with bracketed expressions. Lists \u00b6 Another built-in composite data construction is lists : [ { $ Term \",\" } *] Lists are created by comma-separating terms, enclosing them in square brackets. All terms should have the same type. Given that the type of the terms is T , the type of the list expression will be list(T) . Alternatively, lists can have a variable tail: [ { $ Term \",\" } * | $ Term ] In this syntax, the tail of the list is another term. This term should have type list(T) , where T is again the type of the first terms. Name Ascription \u00b6 It is possible to assign names to terms by prefixing the term with a variable name: $ Var @$ Term Note that this does not introduce a new variable with name $Var (except in a rule head , where all variables are introduced implicitly), but rather requires that a variable with corresponding name and type is already introduced. Ascribe and Equality In terms of equality constraints , the ascribe is equal to $Var == $Term . It is used to prevent the duplication of $Term . Type Ascription \u00b6 Statix allows to add inline type annotations to terms as follows: $ Term : $ Type The type-checker will validate that the term actually has the specified type, but the runtime behavior in not influenced by these ascriptions. Complete Inference In general, the Statix type-checker should be able to infer all types. However, in case of a type error being reported at an incorrect position, these type ascriptions can help tracing the cause of the error. Arithmetic operations \u00b6 Arithmetic expressions can be inserted in terms as follows: # ( $ ArithExp ) Here, the type of the expression is int . For more information on arithmetic expressions, see Arithmetic Constraints Normalization In terms of existential constraints , inline arithmetic expressions have behavior equal to {v} v #= $ArithExp , where v is used at the position of the arithmetic expression. So, for example, {T} T == CONS(#(21 * 2)) is equal to {T v} v #= 21 * 2, T == CONS(v) . AST Identifier \u00b6 In Spoofax, all terms in an AST are assigned an unique identifier (the term index) before analysis. This term identifier can be isolated as follows: astId ( $ Term ) Here, the type of $Term can be anything, and the type of the whole term will be astId . AST Identifiers are used to assign properties . New \u00b6 Statix allows inline creation of scopes : new Statically, the new term has type scope . At runtime, this creates a fresh scope, and inserts that at the position of the new term. Normalization In terms of existential constraints , the inline new operator has behavior equal to {s} new s , where s is used at the position of the new term. So, for example, {T} T == CLASS(new) is equal to {T s} new s, T == CLASS(s) . Paths \u00b6 Part of a query result is the path from the resolved datum back to the scope where the query started. In order to represent paths, Statix has two built-in constructors: _PathEmpty : Unary constructor that carries a single scope. This constructor has type scope -> path . _PathStep : Ternary constructor that represents a traversed edge in a path. This constructor has type path * label * scope -> path . Label Constraints Although the labels in a _PathStep can be bound to a variable, and hence be compared with and included in other terms, no inspection, matching or comparison with label definitions is supported. Occurrences \u00b6 Warning Since Spoofax 2.5.15, namespaces and occurrences are deprecated. Statix has built-in support for namespaces. A term embedded in a particular namespace is called an occurrence . Occurrences can be written as follows: $ NamespaceId { $ SpaceTerms } $ NamespaceId { $ SpaceTerms @$ OccurrenceId } In this structure template, $SpaceTerms means a list of terms, separated by spaces. The occurrence identifier can be any term. In case the term has an AST identifier, that value will be used as the identity of the occurrence. Alternatively, the occurrence identifier can be left out: $ NamespaceId { $ SpaceTerms } The default occurrence identifier is - , which means that the occurrence has no identifier. The type of an occurrence literal is occurrence . For more information about namespaces, see the Queries section. Declaration Match \u00b6 Statix allows to query the current scope for declarations of a particular form: ?$ RelationId [ { $ Term \",\" } ] in $ Scope When using this expression, a functional relation $RelationId must be declared. The terms arguments must correspond to the argument of the relation, and the type of the term is the output type of the relation. For more information on querying the scope graph, see the Queries section. Declaration Match as Query In terms of regular queries , the declaration match is equal to a query with filter e , expecting a single output. E.g. T == ?var[\"x\"] in s is equal to query var filter e and { x' :- x' == \"x\" } in s |-> [(_, (_, T))] .","title":"Terms"},{"location":"references/statix/terms/#terms","text":"In Statix, data is represented using terms. This data can be a program, a typing annotation, or anything else that the specification defines. Terms are built from atoms and composites, such as constructors, tuples and lists. Additionally, Statix allows to inline several constraint results in terms. In this section, we explain the various types of terms that Statix supports, and, when appropriate, how their types should be declared. Terminology: Sort vs. Type Throughout this reference manual, we use the term 'sort' for syntactic categories, and 'type' for all other types (such as lists, tuples, scopes, etc.). However, in practise, these terms are both used in both meanings.","title":"Terms"},{"location":"references/statix/terms/#numerals","text":"Numeric literals are literals of the form [0-9]+ . Negative literals are not supported directly. All integer literals have the built-in type int .","title":"Numerals"},{"location":"references/statix/terms/#strings","text":"String literals are arbitrary, single-line sequences of characters enclosed in double quotes. String literals may not contain unescaped backslashes, double quotes, or tabs. Double quotes and backslashes can be used in a string literal by prefixing them with another backslashes ( \\\" and \\\\ , respectively), while tabs, newlines and carriage returns can be encoded using respectively \\t , \\n and \\r . Otherwise, no escaping is required. String literals have the built-in type string .","title":"Strings"},{"location":"references/statix/terms/#identifiers","text":"Variables are identifiers of values of the following form: [a-zA-Z] [a-zA-Z0-9\\_]* [\\']* . With respect to type-checking, variables can be handled in two ways. When a variable occurs in the head of a rule , it is implicitly brought into scope with the type inferred from the rule type. Otherwise, it is required that the variable is introduced earlier, with the correct type. Apart from introduction in rule heads, variables can be introduced by existential constraints . In that case, the type of the variable is derived from its usage.","title":"Identifiers"},{"location":"references/statix/terms/#wildcards","text":"Wildcards are represented as _ , and denote variables without identity. Every occurrence of a wildcard is interpreted as a new variable. Because wildcards cannot reference each other, it is not required that the types of multiple wildcard occurrences coincide.","title":"Wildcards"},{"location":"references/statix/terms/#composite-terms","text":"Composite terms can be build using constructor applications : $ ConsId ({ $ Term \",\" } * ) Here a term with constructor $ConsId and some term arguments is built. Composite terms must adhere to a signature. A signature describes which term compositions are valid, and must be declared in a signature section: signature sorts $ SortID * constructors $ ConsId : { $ Type \"*\" } + -> $ SortID $ ConsId : $ SortID First, the syntactic categories (which closely correspond to type identifiers in other languages) must be declared in a sorts subsection. Then, the constructor symbols can be declared in a constructors section. For each constructor, the types of the arguments and its sort should be provided. For nullary constructors (constructors without arguments), the arrow preceding the sort should be omitted. When a composite term is built, it is validated that all arguments match the type declaration from the signature. The type of the whole composite term is equal to the sort of the constructor.","title":"Composite terms"},{"location":"references/statix/terms/#tuples","text":"A built-in composite data construction is tuples : ({ $ Term \",\" } * ) Tuples have a statically fixed length, but the types of the arguments may differ. The type of the tuple expression is just the product of its arguments. The arity of a tuple may be anything except one, because unary tuples cause syntactic ambiguities with bracketed expressions.","title":"Tuples"},{"location":"references/statix/terms/#lists","text":"Another built-in composite data construction is lists : [ { $ Term \",\" } *] Lists are created by comma-separating terms, enclosing them in square brackets. All terms should have the same type. Given that the type of the terms is T , the type of the list expression will be list(T) . Alternatively, lists can have a variable tail: [ { $ Term \",\" } * | $ Term ] In this syntax, the tail of the list is another term. This term should have type list(T) , where T is again the type of the first terms.","title":"Lists"},{"location":"references/statix/terms/#name-ascription","text":"It is possible to assign names to terms by prefixing the term with a variable name: $ Var @$ Term Note that this does not introduce a new variable with name $Var (except in a rule head , where all variables are introduced implicitly), but rather requires that a variable with corresponding name and type is already introduced. Ascribe and Equality In terms of equality constraints , the ascribe is equal to $Var == $Term . It is used to prevent the duplication of $Term .","title":"Name Ascription"},{"location":"references/statix/terms/#type-ascription","text":"Statix allows to add inline type annotations to terms as follows: $ Term : $ Type The type-checker will validate that the term actually has the specified type, but the runtime behavior in not influenced by these ascriptions. Complete Inference In general, the Statix type-checker should be able to infer all types. However, in case of a type error being reported at an incorrect position, these type ascriptions can help tracing the cause of the error.","title":"Type Ascription"},{"location":"references/statix/terms/#arithmetic-operations","text":"Arithmetic expressions can be inserted in terms as follows: # ( $ ArithExp ) Here, the type of the expression is int . For more information on arithmetic expressions, see Arithmetic Constraints Normalization In terms of existential constraints , inline arithmetic expressions have behavior equal to {v} v #= $ArithExp , where v is used at the position of the arithmetic expression. So, for example, {T} T == CONS(#(21 * 2)) is equal to {T v} v #= 21 * 2, T == CONS(v) .","title":"Arithmetic operations"},{"location":"references/statix/terms/#ast-identifier","text":"In Spoofax, all terms in an AST are assigned an unique identifier (the term index) before analysis. This term identifier can be isolated as follows: astId ( $ Term ) Here, the type of $Term can be anything, and the type of the whole term will be astId . AST Identifiers are used to assign properties .","title":"AST Identifier"},{"location":"references/statix/terms/#new","text":"Statix allows inline creation of scopes : new Statically, the new term has type scope . At runtime, this creates a fresh scope, and inserts that at the position of the new term. Normalization In terms of existential constraints , the inline new operator has behavior equal to {s} new s , where s is used at the position of the new term. So, for example, {T} T == CLASS(new) is equal to {T s} new s, T == CLASS(s) .","title":"New"},{"location":"references/statix/terms/#paths","text":"Part of a query result is the path from the resolved datum back to the scope where the query started. In order to represent paths, Statix has two built-in constructors: _PathEmpty : Unary constructor that carries a single scope. This constructor has type scope -> path . _PathStep : Ternary constructor that represents a traversed edge in a path. This constructor has type path * label * scope -> path . Label Constraints Although the labels in a _PathStep can be bound to a variable, and hence be compared with and included in other terms, no inspection, matching or comparison with label definitions is supported.","title":"Paths"},{"location":"references/statix/terms/#occurrences","text":"Warning Since Spoofax 2.5.15, namespaces and occurrences are deprecated. Statix has built-in support for namespaces. A term embedded in a particular namespace is called an occurrence . Occurrences can be written as follows: $ NamespaceId { $ SpaceTerms } $ NamespaceId { $ SpaceTerms @$ OccurrenceId } In this structure template, $SpaceTerms means a list of terms, separated by spaces. The occurrence identifier can be any term. In case the term has an AST identifier, that value will be used as the identity of the occurrence. Alternatively, the occurrence identifier can be left out: $ NamespaceId { $ SpaceTerms } The default occurrence identifier is - , which means that the occurrence has no identifier. The type of an occurrence literal is occurrence . For more information about namespaces, see the Queries section.","title":"Occurrences"},{"location":"references/statix/terms/#declaration-match","text":"Statix allows to query the current scope for declarations of a particular form: ?$ RelationId [ { $ Term \",\" } ] in $ Scope When using this expression, a functional relation $RelationId must be declared. The terms arguments must correspond to the argument of the relation, and the type of the term is the output type of the relation. For more information on querying the scope graph, see the Queries section. Declaration Match as Query In terms of regular queries , the declaration match is equal to a query with filter e , expecting a single output. E.g. T == ?var[\"x\"] in s is equal to query var filter e and { x' :- x' == \"x\" } in s |-> [(_, (_, T))] .","title":"Declaration Match"},{"location":"references/statix/tests/","text":"Tests \u00b6 Test Format \u00b6 Test Output \u00b6 Substitution Scope Graph Messages","title":"Tests"},{"location":"references/statix/tests/#tests","text":"","title":"Tests"},{"location":"references/statix/tests/#test-format","text":"","title":"Test Format"},{"location":"references/statix/tests/#test-output","text":"Substitution Scope Graph Messages","title":"Test Output"},{"location":"references/stratego/","text":"Stratego \u00b6 The Stratego language caters for the definition of program transformations. Transformations operate on the abstract syntax trees of programs. Abstract syntax trees are represented by means of first-order terms . A program is structured as a collection of modules , which may import each other. Transformations are defined by means of named rewrite rules . Rules may explicitly invoke rules. Alternatively, rules may be invoked by strategies that define how to combine rules into a more complex transformation using strategy combinators . Context-sensitive transformations can be expressed using dynamic rewrite rules . Starting with Stratego 2, terms and transformation strategies are (gradually) typed . Placeholder Convention \u00b6 In this reference manual we use placeholders to indicate the syntactic structure of language constructs. For example, a rewrite rule has the form $ Label : $ Term - > $ Term in which the $Label is the name of the rule, the first $Term the left-hand side, and the second the right-hand side of the rule. This convention should give an indication of the formal structure of a construct, without going down to the precise details of the syntax definition. As a side effect, the schema also shows the preferred indentation of language constructs where that is applicable. Not in Reference Manual \u00b6 Concrete Syntax \u00b6 By using the concrete syntax of a language, transformations can be expressed in the native syntax of the language under transformation, rather than using abstract syntax. Library \u00b6 The Stratego standard library is a collection of modules that are available with each Stratego program and on which the runtime library relies. Find automatically generated documentation at the following sites: http://releases.strategoxt.org/docs/api/libstratego-lib/stable/docs/ https://stratego.martijndwars.nl/ Source \u00b6 The sources of the Stratego implementation can be found at https://github.com/metaborg/stratego : The Stratego language implementation https://github.com/metaborg/strategoxt : The Stratego/XT ecosystem","title":"Stratego"},{"location":"references/stratego/#stratego","text":"The Stratego language caters for the definition of program transformations. Transformations operate on the abstract syntax trees of programs. Abstract syntax trees are represented by means of first-order terms . A program is structured as a collection of modules , which may import each other. Transformations are defined by means of named rewrite rules . Rules may explicitly invoke rules. Alternatively, rules may be invoked by strategies that define how to combine rules into a more complex transformation using strategy combinators . Context-sensitive transformations can be expressed using dynamic rewrite rules . Starting with Stratego 2, terms and transformation strategies are (gradually) typed .","title":"Stratego"},{"location":"references/stratego/#placeholder-convention","text":"In this reference manual we use placeholders to indicate the syntactic structure of language constructs. For example, a rewrite rule has the form $ Label : $ Term - > $ Term in which the $Label is the name of the rule, the first $Term the left-hand side, and the second the right-hand side of the rule. This convention should give an indication of the formal structure of a construct, without going down to the precise details of the syntax definition. As a side effect, the schema also shows the preferred indentation of language constructs where that is applicable.","title":"Placeholder Convention"},{"location":"references/stratego/#not-in-reference-manual","text":"","title":"Not in Reference Manual"},{"location":"references/stratego/#concrete-syntax","text":"By using the concrete syntax of a language, transformations can be expressed in the native syntax of the language under transformation, rather than using abstract syntax.","title":"Concrete Syntax"},{"location":"references/stratego/#library","text":"The Stratego standard library is a collection of modules that are available with each Stratego program and on which the runtime library relies. Find automatically generated documentation at the following sites: http://releases.strategoxt.org/docs/api/libstratego-lib/stable/docs/ https://stratego.martijndwars.nl/","title":"Library"},{"location":"references/stratego/#source","text":"The sources of the Stratego implementation can be found at https://github.com/metaborg/stratego : The Stratego language implementation https://github.com/metaborg/strategoxt : The Stratego/XT ecosystem","title":"Source"},{"location":"references/stratego/dynamic-rules/","text":"Dynamic Rules \u00b6 Plain rewrite rules are context-free, i.e. do not take their context into account. Context-sensitive transformations can be defined by passing context information using additional arguments to rules and strategies. Alternatively, Stratego provides linguistic support to dynamically define rewrite rules based on context information 1 . Defining Dynamic Rules \u00b6 rules ( $ Id : $ Rule ... ) A dynamic rule definition is a regular (conditional) rewrite rule that is defined as part of a strategy rather than at top-level. The difference is that any variables that are bound in the context of the rule, take their binding from the context, rather then being universally quantified. Thus, a dynamic rule instance can be thought of as having the context variables replaced by the corresponding terms from the context. Example. The following strategy DefineInlineCall defines the dynamic rule InlineCall : DefineInlineCall = ? FunDef ( f , args , e ) ; rules ( InlineCall : Call ( f , es ) - > Let ( dec * , e ) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ( args , es ) => dec * ) The variables f , args , and e in the dynamic rule are bound in context, while the variables es and dec* are universally quantified. The variables x and e in the embedded lambda rule are local to that rule. Thus, the application < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) can be thought of to give rise to the definition InlineCall : Call ( \"inc\" , es ) - > Let ( dec * , Add ( Var ( \"x\" ), Int ( \"1\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"x\" ], es ) => dec * Invoking Dynamic Rules \u00b6 When $Id is defined as a dynamic rule it can be invoke like a regular rule or strategies. The invocation only succeeds when applied to a term that coincide with the left-hand side pattern variables bindings inherited from the context. Thus, in the example above InlineCall can be called to invoke a previously defined dynamic rule. For example, the following are calls to DefineInlineCall and InlineCall < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) < InlineCall > Call ( \"inc\" , [ Mul ( Var ( \"y\" ), Int ( \"3\" ))]) => Let ([ VarDec ( \"x\" , Mul ( Var ( \"y\" ), Int ( \"3\" )))], Add ( Var ( \"x\" ), Int ( \"1\" ))) < InlineCall > Call ( \"foo\" , []) // fails Note that the application to Call(\"foo\", []) fails since it does not match the dynamically defined rule. Parameterized Dynamic Rules \u00b6 Dynamic rules can be parameterized like regular rewrite rules and strategies. Multiple Definitions \u00b6 Dynamic rules can be defined for multiple contexts simultaneously. For example, the following applications of DefineInlineCall < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) < DefineInlineCall > FunDef ( \"twice\" , [ \"y\" ], Mul ( Var ( \"x\" ), Int ( \"2\" ))) can be thought of defining multiple top-level rewrite rules InlineCall : Call ( \"inc\" , es ) - > Let ( dec * , Add ( Var ( \"x\" ), Int ( \"1\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"x\" ], es ) => dec * InlineCall : Call ( \"twice\" , es ) - > Let ( dec * , Mul ( Var ( \"y\" ), Int ( \"2\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"y\" ], es ) => dec * Overriding Dynamic Rules \u00b6 A definition of a dynamic rule with the same left-hand side as a previous definition, overrides that previous definition. Thus, if after the applications of DefineInlineCall above, we apply < DefineInlineCall > FunDef ( \"twice\" , [ \"z\" ], Add ( Var ( \"z\" ), Var ( \"z\" ))) Then the dynamic rule for twice above is undefined , and instead the rule InlineCall : Call ( \"twice\" , es ) - > Let ( dec * , Add ( Var ( \"z\" ), Var ( \"z\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"z\" ], es ) => dec * is added to the collection of rules. Dynamic Rule Scope \u00b6 It is possible to limit the scope in which dynamic rule definitions are available. The dynamic rule scope {| $Id ... : $Strategy |} limits the availability of dynamic rules named $Id .. defined within the brackets to that scope. After exiting the scope, the state of the dynamic rule definitions before the scope is restored. For example, the following strategy defines inlining rules that are only available during the visit of the body of the Let : inline : Let ( dec1 * , e1 ) - > Let ( dec2 * , e2 ) with < inline > dec1 * => dec2 * with {| InlineCall : < map ( try ( DefineInlineCall ))> dec2 * ; < inline > e1 => e2 |} Application of this strategy to the program term Let ([ FunDef ( \"inc\" , [ .. ], .. ) , FunDef ( \"twice\" , [ .. ], .. )] , Add ( Let ([ FunDef ( \"twice\" , [ .. ], [ .. ])] , Call ( \"twice\" , [ .. ])) // inline second def of twice , Call ( \"twice\" , [ .. ]) // inline first def of twice ) ) will result in locally overriding the first dynamic rule for \"twice\" , but undoing that override at the end of the dynamic rule scope, such that it is available again at the second call to \"twice\" . While dynamic rule scopes can deal with lexical scope systems, the preferred way to deal with scope in programming languages is to perform name (and type) analysis using the Statix meta-language and perform a uniquify transformation to guarantee unique names. Multiple Right-Hand Sides \u00b6 In order to collect multiple ways to rewrite a term use rules( $Id :+ $Rule) . For example, the following is a small API for for emitting nodes in a control-flow graph consisting of blocks. add-cfg-node :: CBlock - > CBlock all -cfg-nodes :: List ( CBlock ) - > List ( CBlock ) add-cfg-node = ? block ; rules ( CFGNode : + _ - > block ) all -cfg-nodes = < bagof-CFGNode < + ! []>() The bagof-$Id strategy is generated automatically and produces all right-hand sides corresponding to a left-hand side. Other Dynamic Rule Extensions \u00b6 The papers by Olmos and Visser 2 and Bravenboer et. al 1 describe more advanced features of dynamic rules, primarily inspired by data-flow transformations. For defining data-flow analyses, Spoofax now provides the FlowSpec meta-language. References \u00b6 Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69 \\(1\\-2\\) :123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 \u21a9 Karina Olmos and Eelco Visser. Composing source-to-source data-flow transformations with rewriting strategies and dependent dynamic rewrite rules. In Rastislav Bod\u00edk, editor, Compiler Construction, 14 th International Conference, CC 2005, Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2005, Edinburgh, UK, April 4-8, 2005, Proceedings , volume 3443 of Lecture Notes in Computer Science, 204\u2013220. Springer, 2005. URL: https://doi.org/10.1007/978-3-540-31985-6_14 , doi:10.1007/978-3-540-31985-6_14 . \u21a9","title":"Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#dynamic-rules","text":"Plain rewrite rules are context-free, i.e. do not take their context into account. Context-sensitive transformations can be defined by passing context information using additional arguments to rules and strategies. Alternatively, Stratego provides linguistic support to dynamically define rewrite rules based on context information 1 .","title":"Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#defining-dynamic-rules","text":"rules ( $ Id : $ Rule ... ) A dynamic rule definition is a regular (conditional) rewrite rule that is defined as part of a strategy rather than at top-level. The difference is that any variables that are bound in the context of the rule, take their binding from the context, rather then being universally quantified. Thus, a dynamic rule instance can be thought of as having the context variables replaced by the corresponding terms from the context. Example. The following strategy DefineInlineCall defines the dynamic rule InlineCall : DefineInlineCall = ? FunDef ( f , args , e ) ; rules ( InlineCall : Call ( f , es ) - > Let ( dec * , e ) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ( args , es ) => dec * ) The variables f , args , and e in the dynamic rule are bound in context, while the variables es and dec* are universally quantified. The variables x and e in the embedded lambda rule are local to that rule. Thus, the application < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) can be thought of to give rise to the definition InlineCall : Call ( \"inc\" , es ) - > Let ( dec * , Add ( Var ( \"x\" ), Int ( \"1\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"x\" ], es ) => dec *","title":"Defining Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#invoking-dynamic-rules","text":"When $Id is defined as a dynamic rule it can be invoke like a regular rule or strategies. The invocation only succeeds when applied to a term that coincide with the left-hand side pattern variables bindings inherited from the context. Thus, in the example above InlineCall can be called to invoke a previously defined dynamic rule. For example, the following are calls to DefineInlineCall and InlineCall < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) < InlineCall > Call ( \"inc\" , [ Mul ( Var ( \"y\" ), Int ( \"3\" ))]) => Let ([ VarDec ( \"x\" , Mul ( Var ( \"y\" ), Int ( \"3\" )))], Add ( Var ( \"x\" ), Int ( \"1\" ))) < InlineCall > Call ( \"foo\" , []) // fails Note that the application to Call(\"foo\", []) fails since it does not match the dynamically defined rule.","title":"Invoking Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#parameterized-dynamic-rules","text":"Dynamic rules can be parameterized like regular rewrite rules and strategies.","title":"Parameterized Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#multiple-definitions","text":"Dynamic rules can be defined for multiple contexts simultaneously. For example, the following applications of DefineInlineCall < DefineInlineCall > FunDef ( \"inc\" , [ \"x\" ], Add ( Var ( \"x\" ), Int ( \"1\" ))) < DefineInlineCall > FunDef ( \"twice\" , [ \"y\" ], Mul ( Var ( \"x\" ), Int ( \"2\" ))) can be thought of defining multiple top-level rewrite rules InlineCall : Call ( \"inc\" , es ) - > Let ( dec * , Add ( Var ( \"x\" ), Int ( \"1\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"x\" ], es ) => dec * InlineCall : Call ( \"twice\" , es ) - > Let ( dec * , Mul ( Var ( \"y\" ), Int ( \"2\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"y\" ], es ) => dec *","title":"Multiple Definitions"},{"location":"references/stratego/dynamic-rules/#overriding-dynamic-rules","text":"A definition of a dynamic rule with the same left-hand side as a previous definition, overrides that previous definition. Thus, if after the applications of DefineInlineCall above, we apply < DefineInlineCall > FunDef ( \"twice\" , [ \"z\" ], Add ( Var ( \"z\" ), Var ( \"z\" ))) Then the dynamic rule for twice above is undefined , and instead the rule InlineCall : Call ( \"twice\" , es ) - > Let ( dec * , Add ( Var ( \"z\" ), Var ( \"z\" ))) where < zip ( \\ ( x , e ) - > VarDec ( x , e ) \\ )> ([ \"z\" ], es ) => dec * is added to the collection of rules.","title":"Overriding Dynamic Rules"},{"location":"references/stratego/dynamic-rules/#dynamic-rule-scope","text":"It is possible to limit the scope in which dynamic rule definitions are available. The dynamic rule scope {| $Id ... : $Strategy |} limits the availability of dynamic rules named $Id .. defined within the brackets to that scope. After exiting the scope, the state of the dynamic rule definitions before the scope is restored. For example, the following strategy defines inlining rules that are only available during the visit of the body of the Let : inline : Let ( dec1 * , e1 ) - > Let ( dec2 * , e2 ) with < inline > dec1 * => dec2 * with {| InlineCall : < map ( try ( DefineInlineCall ))> dec2 * ; < inline > e1 => e2 |} Application of this strategy to the program term Let ([ FunDef ( \"inc\" , [ .. ], .. ) , FunDef ( \"twice\" , [ .. ], .. )] , Add ( Let ([ FunDef ( \"twice\" , [ .. ], [ .. ])] , Call ( \"twice\" , [ .. ])) // inline second def of twice , Call ( \"twice\" , [ .. ]) // inline first def of twice ) ) will result in locally overriding the first dynamic rule for \"twice\" , but undoing that override at the end of the dynamic rule scope, such that it is available again at the second call to \"twice\" . While dynamic rule scopes can deal with lexical scope systems, the preferred way to deal with scope in programming languages is to perform name (and type) analysis using the Statix meta-language and perform a uniquify transformation to guarantee unique names.","title":"Dynamic Rule Scope"},{"location":"references/stratego/dynamic-rules/#multiple-right-hand-sides","text":"In order to collect multiple ways to rewrite a term use rules( $Id :+ $Rule) . For example, the following is a small API for for emitting nodes in a control-flow graph consisting of blocks. add-cfg-node :: CBlock - > CBlock all -cfg-nodes :: List ( CBlock ) - > List ( CBlock ) add-cfg-node = ? block ; rules ( CFGNode : + _ - > block ) all -cfg-nodes = < bagof-CFGNode < + ! []>() The bagof-$Id strategy is generated automatically and produces all right-hand sides corresponding to a left-hand side.","title":"Multiple Right-Hand Sides"},{"location":"references/stratego/dynamic-rules/#other-dynamic-rule-extensions","text":"The papers by Olmos and Visser 2 and Bravenboer et. al 1 describe more advanced features of dynamic rules, primarily inspired by data-flow transformations. For defining data-flow analyses, Spoofax now provides the FlowSpec meta-language.","title":"Other Dynamic Rule Extensions"},{"location":"references/stratego/dynamic-rules/#references","text":"Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae , 69 \\(1\\-2\\) :123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06 . \u21a9 \u21a9 Karina Olmos and Eelco Visser. Composing source-to-source data-flow transformations with rewriting strategies and dependent dynamic rewrite rules. In Rastislav Bod\u00edk, editor, Compiler Construction, 14 th International Conference, CC 2005, Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2005, Edinburgh, UK, April 4-8, 2005, Proceedings , volume 3443 of Lecture Notes in Computer Science, 204\u2013220. Springer, 2005. URL: https://doi.org/10.1007/978-3-540-31985-6_14 , doi:10.1007/978-3-540-31985-6_14 . \u21a9","title":"References"},{"location":"references/stratego/lexical/","text":"Lexical \u00b6 Identifiers \u00b6 Identifiers used as names of constructors and transformations have the form ID = [ a-zA-Z ][ a-zA-Z0-9 \\ - \\ _ ] * In particular, hyphens can be part of identifiers. Identifiers cannot be followed by identifiers or keywords without intervening whitespace. Reserved Words \u00b6 Todo provide list of reserved words Module Names \u00b6 Module names can be sequences of identifiers separated by / . Integers \u00b6 INT = [ 0 -9 ] + Check syntax of integers Whitespace \u00b6 Spaces, tabs, and newlines are whitespace and can occur between any two tokens. Comments \u00b6 Comments follow the C/Java tradition. That is, the language supports single line comments after // // a single line comment and multi-line comments between /* and */ /* a multi-line comment can be spread over multiple lines */ Comments can occur anywhere. Multi-line comments cannot be nested currently. Todo but this should be changed so that multi-line comments can be nested","title":"Lexical"},{"location":"references/stratego/lexical/#lexical","text":"","title":"Lexical"},{"location":"references/stratego/lexical/#identifiers","text":"Identifiers used as names of constructors and transformations have the form ID = [ a-zA-Z ][ a-zA-Z0-9 \\ - \\ _ ] * In particular, hyphens can be part of identifiers. Identifiers cannot be followed by identifiers or keywords without intervening whitespace.","title":"Identifiers"},{"location":"references/stratego/lexical/#reserved-words","text":"Todo provide list of reserved words","title":"Reserved Words"},{"location":"references/stratego/lexical/#module-names","text":"Module names can be sequences of identifiers separated by / .","title":"Module Names"},{"location":"references/stratego/lexical/#integers","text":"INT = [ 0 -9 ] + Check syntax of integers","title":"Integers"},{"location":"references/stratego/lexical/#whitespace","text":"Spaces, tabs, and newlines are whitespace and can occur between any two tokens.","title":"Whitespace"},{"location":"references/stratego/lexical/#comments","text":"Comments follow the C/Java tradition. That is, the language supports single line comments after // // a single line comment and multi-line comments between /* and */ /* a multi-line comment can be spread over multiple lines */ Comments can occur anywhere. Multi-line comments cannot be nested currently. Todo but this should be changed so that multi-line comments can be nested","title":"Comments"},{"location":"references/stratego/modules/","text":"Modules \u00b6 A Stratego program is organised as a collection of modules, which are imported from a main module. Module Structure \u00b6 module $ ModuleName $ Imports * $ Section * A module starts with a module header followed by a list of imports . The name of a module in the header and imports should correspond to the file name, relative to a 'root' directory. The rest of a module consists of signature , rules , and strategies sections, in any order, and possibly repeated. File Name and File Extension \u00b6 A module coincides with the file it resides in. It is not possible to define more than one module in a file, which precludes nested modules. The name of a module coincides with the file name, which should be fully qualified relative to a root directory. A Stratego is a file with the extension .str2 for Stratego 2. Modules for the Stratego 1 version of the language have extension .str . The file extension does not feature in the module names used in the language. The following is example module header: module compilation / translation imports desugaring / desugar Module Names \u00b6 Module names can be hierarchical. For example, consider the following directory structure - trans - compilation - optimization.str2 - translation.str2 - desugaring - desugar.str2 A declaration of or reference to a module uses its fully qualified name, with / to indicate the directory structure, relative to a 'root' directory. For example, if trans is declared as a root , then the module names for the modules above are - compilation/optimization - compilation/translation - desugaring/desugar Imports \u00b6 imports $ ModuleName + A module should import all other modules from which it uses definitions. Imports are non-transitive and may be mutually recursive. Modules can extend rule and strategy definitions from other modules. This allows the modular extension of a language. When imported, all definitions in a module are visible. There are currently no mechanisms for hiding definitions. An imports can list multiple modules. The form imports A B is equivalent to imports A imports B Signatures \u00b6 A signature section introduces sorts, constructors, and overlays. signature sorts $ Sort * constructors $ ConstructorDef * overlays $ OverlayDef * Rules and Strategies \u00b6 Rule definitions and strategy definitions introduce named transformations. rules $ RuleDef * strategies $ StrategyDef * The rules and strategies section headers are indicative only; rule and strategy definitions can actually be mixed. Libraries \u00b6 A Stratego library is a closed collection of modules. A library can be pre-compiled since client programs may not extend its definitions. A library is used by importing a collection of external definitions of the signatures of constructors and transformations it defines. Even if definitions in a library are not included in a libraries external definition, they cannot be redefined, as that produces link errors. Source Inclusion \u00b6 Todo Concrete Syntax \u00b6 When using concrete syntax in a module, a .meta file accompanying the module indicates the parse table to use.","title":"Modules"},{"location":"references/stratego/modules/#modules","text":"A Stratego program is organised as a collection of modules, which are imported from a main module.","title":"Modules"},{"location":"references/stratego/modules/#module-structure","text":"module $ ModuleName $ Imports * $ Section * A module starts with a module header followed by a list of imports . The name of a module in the header and imports should correspond to the file name, relative to a 'root' directory. The rest of a module consists of signature , rules , and strategies sections, in any order, and possibly repeated.","title":"Module Structure"},{"location":"references/stratego/modules/#file-name-and-file-extension","text":"A module coincides with the file it resides in. It is not possible to define more than one module in a file, which precludes nested modules. The name of a module coincides with the file name, which should be fully qualified relative to a root directory. A Stratego is a file with the extension .str2 for Stratego 2. Modules for the Stratego 1 version of the language have extension .str . The file extension does not feature in the module names used in the language. The following is example module header: module compilation / translation imports desugaring / desugar","title":"File Name and File Extension"},{"location":"references/stratego/modules/#module-names","text":"Module names can be hierarchical. For example, consider the following directory structure - trans - compilation - optimization.str2 - translation.str2 - desugaring - desugar.str2 A declaration of or reference to a module uses its fully qualified name, with / to indicate the directory structure, relative to a 'root' directory. For example, if trans is declared as a root , then the module names for the modules above are - compilation/optimization - compilation/translation - desugaring/desugar","title":"Module Names"},{"location":"references/stratego/modules/#imports","text":"imports $ ModuleName + A module should import all other modules from which it uses definitions. Imports are non-transitive and may be mutually recursive. Modules can extend rule and strategy definitions from other modules. This allows the modular extension of a language. When imported, all definitions in a module are visible. There are currently no mechanisms for hiding definitions. An imports can list multiple modules. The form imports A B is equivalent to imports A imports B","title":"Imports"},{"location":"references/stratego/modules/#signatures","text":"A signature section introduces sorts, constructors, and overlays. signature sorts $ Sort * constructors $ ConstructorDef * overlays $ OverlayDef *","title":"Signatures"},{"location":"references/stratego/modules/#rules-and-strategies","text":"Rule definitions and strategy definitions introduce named transformations. rules $ RuleDef * strategies $ StrategyDef * The rules and strategies section headers are indicative only; rule and strategy definitions can actually be mixed.","title":"Rules and Strategies"},{"location":"references/stratego/modules/#libraries","text":"A Stratego library is a closed collection of modules. A library can be pre-compiled since client programs may not extend its definitions. A library is used by importing a collection of external definitions of the signatures of constructors and transformations it defines. Even if definitions in a library are not included in a libraries external definition, they cannot be redefined, as that produces link errors.","title":"Libraries"},{"location":"references/stratego/modules/#source-inclusion","text":"Todo","title":"Source Inclusion"},{"location":"references/stratego/modules/#concrete-syntax","text":"When using concrete syntax in a module, a .meta file accompanying the module indicates the parse table to use.","title":"Concrete Syntax"},{"location":"references/stratego/rewrite-rules/","text":"Rewrite Rules \u00b6 $ Id ( $ StrategyArg , ... | $ TermArg , ... ) : $ Term - > $ Term $ Condition * A rewrite rule has a name, zero or more strategy argumuents, zero or more term arguments, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions. A rewrite rule application $Id($StrategExp, ... | $Term) to a subject term binds the strategy and term arguments and matches the term pattern in the left-hand side to the term. If the pattern match succeeds, the conditions are applied in turn to the subject term, accumulating bindings to term variables. When all conditions succeed, the right-hand side term pattern is instantiated with the accumulated variable bindings. When the pattern match to the left-hand side or one of the conditions fails, the rule fails. Where Condition \u00b6 where $ StrategyExp A where condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables. If the strategy expression fails, the enclosing rule fails. Failure of a where clause is expected. The strategy expression is expected to be discrimating and only succeed in those cases that the rule should be applied. With Condition \u00b6 with $ StrategyExp A with condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables. A with condition expresses the expectation that the strategy expression succeeds in all cases. When a with condition fails, this is an indication of a programming error, and the enclosing rule throws a fatal exception, and the program terminates with a stack trace. Simple Rewrite Rules \u00b6 $ Id : $ Term - > $ Term $ Condition * A simple (unparameterized) rewrite rule consists of a name that identifies the rule, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions. Example DeMorgan : Not ( And ( e1 , e2 )) - > Or ( Not ( e1 ), Not ( e2 )) Rules with the Same Name \u00b6 Multiple rewrite rules may have the same name. When a (simple) rewrite rule fails to apply to a term, the next rule with the same name is tried. For examples, the following rules define desugarings of expressions. rules desugar-exp :: Exp - > Exp desugar-exp : Seq ([], e ) - > e desugar-exp : Seq ([ e ], Unit ()) - > e desugar-exp : Seq ([ e1 , e2 | e * ], e3 ) - > Seq ([ e1 ], Seq ([ e2 | e * ], e3 )) desugar-exp : Seq ([ Seq ( e1 * , e1 ) | e2 * ], e2 ) - > Seq ([ e1 * , e1 | e2 * ], e2 ) desugar-exp : Let ( dec * , [ e1 , e2 | e * ]) - > Let ( dec * , [ Seq ([ e1 , e2 | e * ], Unit ())]) When one rule fails to apply, the next rule is tried. When the left-hand sides are non-overlapping, the order of the rules does not matter. In case of overlap, the rules are tried in textual order. When overlapping rules are defined in separate modules, the order is undefined. Note Consider specificity ordering in the future. Parameterized Rewrite Rules \u00b6 Rewrite rules can be parameterized with transformation strategies and with terms. Example. The following rules define reversal of a list with an accumulator: rules reverse :: List ( a ) - > List ( a ) reverse (| List ( a )) :: List ( a ) - > List ( a ) s reverse : xs - > < reverse (|[])> xs reverse (| xs ) : [] - > xs reverse (| xs ) : [ y | ys ] - > < reverse-acc (|[ y | xs ])> ys When leaving out the term parameters, the bar can be left out $ Id ( $ StrategyArg ) : $ Term - > $ Term $ Condition * Example. The map(s) strategy applies transformation s to each element of a list: map ( a - > b ) :: List ( a ) - > List ( b ) map ( s ) : [] - > [] map ( s ) : [ hd | tl ] - > [< s > hd | < map ( s )> tl ] Note In the absence of a type system, the distinction between strategy arguments and term arguments was made based on the syntactic distinction. In a future version of the language, this syntactic distiction may no longer be necessary based on types. Desugaring \u00b6 A conditional rewrite rule can be desugared to a strategy definition using basic strategy combinators . A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules. A conditional rule L: p1 -> p2 where s is a simple rule extended with an additional computation s which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side. For example, the EvalPlus rule in the following session uses a condition to compute the sum of i and j : EvalPlus : Plus ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k < EvalPlus > Plus ( Int ( \"14\" ), Int ( \"3\" )) => Int ( \"17\" ) A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form L : p1 - > p2 where s is syntactic sugar for L = ? p1 ; where ( s ); ! p2 Thus, after the match with p1 succeeds the strategy s is applied to the subject term. Only if the application of s succeeds, is the right-hand side p2 built. Note that since s is applied within a where, the build !p2 is applied to the original subject term; only variable bindings computed within s can be used in p2 . As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition. EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k The addition is computed by applying the primitive strategy addS to the pair of integers (i,j) and matching the result against the variable k , which is then used in the right-hand side. This rule is desugared to EvalPlus = ? Add ( Int ( i ), Int ( j )); where ( ! ( i , j ); addS ; ? k ); ! Int ( k )","title":"Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#rewrite-rules","text":"$ Id ( $ StrategyArg , ... | $ TermArg , ... ) : $ Term - > $ Term $ Condition * A rewrite rule has a name, zero or more strategy argumuents, zero or more term arguments, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions. A rewrite rule application $Id($StrategExp, ... | $Term) to a subject term binds the strategy and term arguments and matches the term pattern in the left-hand side to the term. If the pattern match succeeds, the conditions are applied in turn to the subject term, accumulating bindings to term variables. When all conditions succeed, the right-hand side term pattern is instantiated with the accumulated variable bindings. When the pattern match to the left-hand side or one of the conditions fails, the rule fails.","title":"Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#where-condition","text":"where $ StrategyExp A where condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables. If the strategy expression fails, the enclosing rule fails. Failure of a where clause is expected. The strategy expression is expected to be discrimating and only succeed in those cases that the rule should be applied.","title":"Where Condition"},{"location":"references/stratego/rewrite-rules/#with-condition","text":"with $ StrategyExp A with condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables. A with condition expresses the expectation that the strategy expression succeeds in all cases. When a with condition fails, this is an indication of a programming error, and the enclosing rule throws a fatal exception, and the program terminates with a stack trace.","title":"With Condition"},{"location":"references/stratego/rewrite-rules/#simple-rewrite-rules","text":"$ Id : $ Term - > $ Term $ Condition * A simple (unparameterized) rewrite rule consists of a name that identifies the rule, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions. Example DeMorgan : Not ( And ( e1 , e2 )) - > Or ( Not ( e1 ), Not ( e2 ))","title":"Simple Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#rules-with-the-same-name","text":"Multiple rewrite rules may have the same name. When a (simple) rewrite rule fails to apply to a term, the next rule with the same name is tried. For examples, the following rules define desugarings of expressions. rules desugar-exp :: Exp - > Exp desugar-exp : Seq ([], e ) - > e desugar-exp : Seq ([ e ], Unit ()) - > e desugar-exp : Seq ([ e1 , e2 | e * ], e3 ) - > Seq ([ e1 ], Seq ([ e2 | e * ], e3 )) desugar-exp : Seq ([ Seq ( e1 * , e1 ) | e2 * ], e2 ) - > Seq ([ e1 * , e1 | e2 * ], e2 ) desugar-exp : Let ( dec * , [ e1 , e2 | e * ]) - > Let ( dec * , [ Seq ([ e1 , e2 | e * ], Unit ())]) When one rule fails to apply, the next rule is tried. When the left-hand sides are non-overlapping, the order of the rules does not matter. In case of overlap, the rules are tried in textual order. When overlapping rules are defined in separate modules, the order is undefined. Note Consider specificity ordering in the future.","title":"Rules with the Same Name"},{"location":"references/stratego/rewrite-rules/#parameterized-rewrite-rules","text":"Rewrite rules can be parameterized with transformation strategies and with terms. Example. The following rules define reversal of a list with an accumulator: rules reverse :: List ( a ) - > List ( a ) reverse (| List ( a )) :: List ( a ) - > List ( a ) s reverse : xs - > < reverse (|[])> xs reverse (| xs ) : [] - > xs reverse (| xs ) : [ y | ys ] - > < reverse-acc (|[ y | xs ])> ys When leaving out the term parameters, the bar can be left out $ Id ( $ StrategyArg ) : $ Term - > $ Term $ Condition * Example. The map(s) strategy applies transformation s to each element of a list: map ( a - > b ) :: List ( a ) - > List ( b ) map ( s ) : [] - > [] map ( s ) : [ hd | tl ] - > [< s > hd | < map ( s )> tl ] Note In the absence of a type system, the distinction between strategy arguments and term arguments was made based on the syntactic distinction. In a future version of the language, this syntactic distiction may no longer be necessary based on types.","title":"Parameterized Rewrite Rules"},{"location":"references/stratego/rewrite-rules/#desugaring","text":"A conditional rewrite rule can be desugared to a strategy definition using basic strategy combinators . A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules. A conditional rule L: p1 -> p2 where s is a simple rule extended with an additional computation s which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side. For example, the EvalPlus rule in the following session uses a condition to compute the sum of i and j : EvalPlus : Plus ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k < EvalPlus > Plus ( Int ( \"14\" ), Int ( \"3\" )) => Int ( \"17\" ) A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form L : p1 - > p2 where s is syntactic sugar for L = ? p1 ; where ( s ); ! p2 Thus, after the match with p1 succeeds the strategy s is applied to the subject term. Only if the application of s succeeds, is the right-hand side p2 built. Note that since s is applied within a where, the build !p2 is applied to the original subject term; only variable bindings computed within s can be used in p2 . As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition. EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k The addition is computed by applying the primitive strategy addS to the pair of integers (i,j) and matching the result against the variable k , which is then used in the right-hand side. This rule is desugared to EvalPlus = ? Add ( Int ( i ), Int ( j )); where ( ! ( i , j ); addS ; ? k ); ! Int ( k )","title":"Desugaring"},{"location":"references/stratego/strategy-combinators/","text":"Strategy Combinators \u00b6 A strategy expression combines the application of rules using strategy combinators . Sequential Combinators \u00b6 Identity and Failure \u00b6 id fail The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects. Sequential Composition \u00b6 $ StrategyExp ; $ StrategyExp The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails. Properties. Sequential composition is associative. Identity is a left and right unit for sequential composition; since id always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since fail always fails the next strategy will never be reached. This leads to the following equations: ( s1 ; s2 ) ; s3 = s1 ; ( s2 ; s3 ) id ; s = s s ; id = s fail ; s = fail However, not for all strategies s we have that failure is a right zero for sequential composition: s ; fail = fail // is not a law Although the composition s; fail will always fail, the execution of s may have side effects that are not performed by fail . For example, consider printing a term in s . Example. Consider the following rewrite rules. A : P ( Z (), x ) - > x B : P ( S ( x ), y ) - > P ( x , S ( y )) The following applications shows the effect of first applying B and then A : < B > ! P ( S ( Z ()), Z ()) => P ( S ( Z ), Z ) < A > P ( Z , S ( Z )) => S ( Z ) Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019: < B ; A > ! P ( S ( Z ()), Z ()) => S ( Z ) The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first: < B ; B > ! P ( S ( Z ()), Z ()) // fails Left Choice \u00b6 $ StrategyExp < + $ StrategyExp The left choice or deterministic choice s1 <+ s2 tries to apply s1 and s2 in that order. That is, it first tries to apply s1 , and if that succeeds the choice succeeds. However, if the application of s1 fails, s2 is applied to the original term. Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless. ( s1 < + s2 ) < + s3 = s1 < + ( s2 < + s3 ) id < + s = id fail < + s = s s < + fail = s However, identity is not a right zero for left choice. That is, not for all strategies s we have that s < + id = s // is not a law The expression s <+ id always succeeds, even (especially) in the case that s fails, in which case the right-hand side of the equation fails of course. Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property ( s1 < + s2 ); s3 = ( s1 ; s3 ) < + ( s2 ; s3 ) // is not a law does not hold for all s1 , s2 , and s3 . The difference is illustrated by the following applications: <( B < + id ); B > P ( S ( Z ), Z ) // fails <( B ; B ) < + ( id ; B )> P ( S ( Z ()), Z ()) => P ( Z , S ( Z )) In the application of (B <+ id); B , the first application of B succeeds after which the choice is committed. The subsequent application of B then fails. This is equivalent to first applying (B <+ id) and then applying B to the result. The application of (B; B) <+ (id; B) , however, is successful; the application of B; B fails, after which the choice backtracks to id; B , which succeeds. Example. The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules: PlusAssoc : Plus ( Plus ( e1 , e2 ), e3 ) - > Plus ( e1 , Plus ( e2 , e3 )) PlusZero : Plus ( Int ( \"0\" ), e ) - > e These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into PlusAssoc <+ PlusZero creates a strategy that transforms terms matching both rules as illustrated by the following applications: < PlusAssoc > Plus ( Int ( \"0\" ), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Int ( \"0\" ), Int ( \"3\" )) => Int ( \"3\" ) < PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) => Plus ( Var ( \"x\" ), Plus ( Int ( \"42\" ), Int ( \"3\" ))) Example. An application of <+ in combination with id is the reflexive closure of a strategy s : try ( s ) = s < + id The user-defined strategy combinator try tries to apply its argument strategy s , but if that fails, just succeeds using id . Guarded Left Choice \u00b6 $ StrategyExp < $ StrategyExp + $ StrategyExp With the guarded left choice operator s1 < s2 + s3 , if s1 succeeds s2 is applied, else s3 is applied. If s2 fails, the complete expression fails; no backtracking to s3 takes place. Properties. This combinator is a generalization of the left choice combinator <+ . s1 < + s2 = s1 < id + s2 The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard: id < s2 + s3 = s2 fail < s2 + s3 = s3 If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch. s1 < s2 + fail = s1 ; s2 Guarded choice is not associative: ( s1 < s2 + s3 ) < s4 + s5 = s1 < s2 + ( s3 < s4 + s5 ) // not a law To see why consider the possible traces of these expressions. For example, when s1 and s2 succeed subsequently, the left-hand side expression calls s4 , while the right-hand side expression does not. However, sequential composition distributes over guarded choice from left and right: ( s1 < s2 + s3 ); s4 = s1 < ( s2 ; s4 ) + ( s3 ; s4 ) s0 ; ( s1 < s2 + s3 ) = ( s0 ; s1 ) < s2 + s3 Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation not(s) of a strategy s , succeeds if s fails, and fails when it succeeds: not ( s ) = s < fail + id Since failure discards the effect of a (successful) transformation, this has the effect of testing whether s succeeds. So we have the following laws for not: not ( id ) = fail not ( fail ) = id However, side effects performed by s are not undone, of course. Therefore, the following equation does not hold: not ( not ( s )) = s // not a law Another example of the use of guarded choice is the restore-always combinator: restore-always ( s , r ) = s < r + ( r ; fail ) It applies a \u2018restore\u2019 strategy r after applying a strategy s , even if s fails, and preserves the success/failure behavior of s . Since fail discards the transformation effect of r , this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying s . If-then-else \u00b6 if $ StrategyExp then $ StrategyExp else $ StrategyExp end The if s1 then s2 else s3 end construct is like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but its transformation effect is undone. However, the condition strategy s1 is still applied to the subject term. The if s1 then s2 end strategy is similar; if the condition fails, the strategy succeeds. The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator: if s1 then s2 else s3 end ==> // transforms to where ( s1 ) < s2 + s3 The strategy where(s) succeeds if s succeeds, but returns the original subject term. Properties. The following laws show that the branches are selected by success or failure of the condition: if id then s2 else s3 end = s2 if fail then s2 else s3 end = s3 The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch: if s1 then s2 end = where ( s1 ) < s2 + id Examples. The inclusive or or(s1, s2) succeeds if one of the strategies s1 or s2 succeeds, but guarantees that both are applied, in the order s1 first, then s2 : or ( s1 , s2 ) = if s1 then try ( where ( s2 )) else where ( s2 ) end This ensures that any side effects are always performed, in contrast to s1 <\\+ s2 , where s2 is only executed if s1 fails. (Thus, left choice implements a short circuit Boolean or.) Similarly, the following and(s1, s2) combinator is the non-short circuit version of Boolean conjunction: and ( s1 , s2 ) = if s1 then where ( s2 ) else where ( s2 ); fail end Switch \u00b6 switch s0 case s1 : s1 ' case s2 : s2 ' ... otherwise : sdef end The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice. The switch first applies the s0 strategy to the current term t resulting in a term t' . Then it tries the cases in turn applying each si to t' . As soon as this succeeds the corresponding case is selected and si' is applied to the t , the term to which the switch was applied. If none of the cases applies, the default strategy sdef from the otherwise is applied. The switch construct is syntactic sugar for a nested if-then-else: { x : where ( s0 => x ); if < s1 > x then s1 ' else if < s2 > x then s2 ' else if ... then ... else sdef end end end } Non-Deterministic Choice \u00b6 $ StrategyExp + $ StrategyExp The non-deterministic choice operator s1 + s2 chooses one of the two strategies s1 or s2 to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler or runtime system. The + combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with + . The following transformation illustrates this: module A f = s1 module B f = s2 module main imports A B => f = s2 + s1 This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters. While the + combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <+ to avoid surprises. Note. In the past, the + combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this: module A f = s1 f = s2 => f = s1 < + s2 Fixpoint Recursion \u00b6 rec $ Id ( $ StrategyExp ) The fixpoint operator rec x(s) , which recurses on applications of x within s . The rec operator allows the definition of an unnamed strategy expression to be recursive. For example, in the definition g ( s ) = foo ; rec x ( ... x ... ); bar the strategy between foo and bar is a recursive strategy that does not recurse to g(s) . Alternative. Originally, the rec operator was the only way to define recursive strategies. Currently, a recursive definition is a normal strategy definition with a recursive call in its body. f ( s ) = ... f ( s ) ... The rec operator is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope. Example. The repeat strategy applies a transformation s until it fails. It is defined as a recursive definition using try as follows: try ( s ) = s < + id repeat ( s ) = try ( s ; repeat ( s )) An equivalent definition using rec is: repeat ( s ) = rec x ( try ( s ; x )) Term Combinators \u00b6 Building Terms \u00b6 ! $ Term The build operation !p replaces the subject term with the instantiation of the pattern p using the bindings from the environment to the variables occurring in p . Example. The strategy !Or(And(x, z), And(y, z)) replaces the subject term with the instantiation of Or(And(x, z), And(y, z)) using bindings to variables x , y and z . ! Int ( \"10\" ) => Int ( \"10\" ) ! Plus ( Var ( \"a\" ), Int ( \"10\" )) => Plus ( Var ( \"a\" ), Int ( \"10\" )) It is possible to build terms with variables. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern p . Example. In a context where e is bound to Var(\"b\") ! Plus ( Var ( \"a\" ), e ) => Plus ( Var ( \"a\" ), Var ( \"b\" )) Matching Terms \u00b6 ? $ Term The match operation ?t matches the subject term against the term t . < ? Plus ( Var ( \"a\" ), Int ( \"3\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // succeeds < ? Plus ( Int ( \"3\" ), Var ( \"b\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy ?x compares the current term ( t ) to variable x . It binds variable x to term t in the environment. A variable can only be bound once, or to the same term. < ? e > Plus ( Var ( \"a\" ), Int ( \"3\" )) // binds e to Plus(Var(\"a\"),Int(\"3\")) < ? e > ! Int ( \"17\" ) // fails The general case is matching against an arbitrary term pattern. The match strategy ?p compares the current term to a pattern p . It will add bindings for the variables in pattern p to the environment. The wildcard _ in a match will match any term. < ? Plus ( e , _ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // e is bound to Var(\"a\") Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term. < ? Plus ( e , e )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails < ? Plus ( e , e )> ! Plus ( Var ( \"a\" ), Var ( \"a\" )) // e is bound to Var(\"a\") Example. Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching: equal = ? ( x , x ) equal (| x ) = ? x The equal strategy tests whether the current term is a a pair of the same terms. The equal(|x) strategy tests whether the current term is equal to the argument term. < equal >( \"a\" , \"a\" ) // succeeds < equal >( \"a\" , \"b\" ) // fails < equal (| Foo ( Baz ()))> Foo ( Bar ()) // fails < equal (| Foo ( Bar ()))> Foo ( Bar ()) // succeeds Term Variable Scope \u00b6 { $ Id , ... : $ StrategyExp } Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because e2 is bound to Int(\"3\") and does not match with Var(\"b\") . < ? Plus ( e1 , e2 ) ! Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) // e1 is bound to Var(\"a\") // e2 is bound to Int(\"3\") < ? Plus ( e1 , e2 ) ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Var ( \"b\" )) // fails To use a variable name more than once Stratego provides term variable scope. A scope {x1,...,xn : s} locally undefines the variables xi . That is, the binding to a variable xi outside the scope is not visible inside it, nor is the binding to xi inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times. <{ e3 , e4 : ? Plus ( e3 , e4 ); ! Plus ( e4 , e3 )}> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) // e3 is not bound to a term <{ e3 , e4 : ? Plus ( e3 , e4 ); ! Plus ( e4 , e3 )}> Plus ( Var ( \"a\" ), Var ( \"b\" )) => Plus ( Var ( \"b\" ), Var ( \"a\" )) Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name: SwapArgs = { e1 , e2 : ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )} < SwapArgs > Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) Implicit Variable Scope \u00b6 When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write SwapArgs = { e1 , e2 : ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )} However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as let SwapArgs = ? Plus ( e1 , e2 ); Plus ( e2 , e1 ) in ... end While the variables are bound in the enclosing definition, they are not restricted to SwapArgs in this case, since in a let one typically wants to use bindings to variables in the enclosing code. Combining Match and Build \u00b6 Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build: < ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build. Stratego provides syntactic sugar for various combinations of match and build. Anonymous Rewrite Rule \u00b6 ( $ Pattern - > $ Pattern ) An anonymous rewrite rule (p1 -> p2) transforms a term matching p1 into an instantiation of p2 . Such a rule is equivalent to the sequence ?p1; !p2 . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) Where \u00b6 where ( $ StrategyExp ) The where(s) combinator applies s to the current term, but restores that term afterwards. Any bindings to variables are kept, however. The where(s) construct is syntactic sugar for {x: ?x; s; !x} with x a fresh variable not occurring in s . Thus, the current subject term is saved by binding it to a new variable x , then the strategy s is applied, and finally, the original term is restored by building x . Example < where ( ? Plus ( Int ( i ), Int ( j )); < addS >( i , j ) => k )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Int ( \"14\" ), Int ( \"3\" )) // i is bound to \"14\" // k is bound to \"17\" With \u00b6 with ( s ) The strategy with(s) applies s on the current subject term and then restores the current subject term. In other words, s is executed solely for its side effects, such as binding variables. In this respect, with is like where . However, with(s) differs in a key way: if the strategy s fails, Stratego stops with an error, reporting the strategy that failed. Lambda Rules \u00b6 \\ $ Term - > $ Term where $ Condition \\ A lambda rule of the form \\ p1 -> p2 where s \\ is an anonymous rewrite rule for which the variables in the left-hand side p1 are local to the rule, that is, it is equivalent to an expression of the form { x1 , ... , xn : ( p1 - > p2 where s )} with x1 ,\u2026, xn the variables of p1 . This means that any variables used in s and p2 that do not occur in p1 are bound in the context of the rule. Example. < map ( \\ ( x , y ) - > x \\ )> [( 1 , 2 ),( 3 , 4 ),( 5 , 6 )] => [ 1 , 3 , 5 ] Apply and Match \u00b6 $ StrategyExp => $ Term < $ StrategyExp > $ Term < $ StrategyExp > $ Term => $ Term The operation <s> p captures the notion of applying a strategy to a term, i.e., the scenario !p; s . The operation s => p capture the notion of applying a strategy to the current subject term and then matching the result against the pattern p , i.e., s; ?p . The combined operation <s> p1 => p2 thus captures the notion of applying a strategy to a term p1 and matching the result against p2 , i.e, !p1; s; ?p2 . Example. The conditional rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k can be reformulated as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k Assignment \u00b6 $ Term := $ Term The strategy p1 := p2 builds p2 and matches the result against p1 , i.e. it is equivalent to !p2; ?p1 . The strategy is often combined with strategy application into p1 := <s>p2 , which is equivalent to <s>p2 => p1 (but more familiar to an audience with an imperative mindset). For example, consider the following rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with k := < addS >( i , j ) Applying Strategies in Build \u00b6 < $ StrategyExp > $ Term // in build pattern In a build pattern, the application <s>t applies the strategy s to the term t , returning the resulting term. Example. The constant folding rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k can be simplified by directly applying the addition in the right-hand side: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int (< addS >( i , j )) Example. The following definition of the map(s) strategy applies a strategy to each term in a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ] Term Wrap \u00b6 < $ StrategyExp > // in build pattern A term wrap is a build strategy !p[<s>] containing one or more strategy applications <s> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <s> is replaced with the term resulting from applying s to the current subject term, i.e., the one that is being replaced by the build. Motivation. One often write rules of the form x -> Foo(Bar(x)) , i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as !Foo(Bar(<id>)) . Example. The following applications illustrate some uses of term wraps: < ! (< id >,< id >)> 3 => ( 3 , 3 ) <(< Fst ; inc >,< Snd >)> ( 3 , 3 ) => ( 4 , 3 ) < ! Call (< id >, [])> \"foobar\" => Call ( \"foobar\" , []) mod2 = < mod >(< id >, 2 ) < mod2 > 6 => 0 Desugaring. Term wraps are implemented by translation to a combination of match and build expressions. Thus, a term wrap !p[<s>] is translated to a strategy expression { x : where ( s => x ); ! p [ x ]} where x is a fresh variable not occurring in s . In other words, the strategy s is applied to the current subject term, i.e., the term to which the build is applied. As an example, the term wrap !Foo(Bar(<id>)) is desugared to the strategy { x : where ( id => x ); ! Foo ( Bar ( x ))} which after simplification is equivalent to {x: ?x; !Foo(Bar(x))} , i.e., exactly the original lambda rule \\x -> Foo(Bar(x))\\ . Term Project \u00b6 < $ StrategyExp > // in match pattern Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern. Examples. For example, the expression ?And(<id>,x) matches terms of the form And(t1,t2) and reduces them to the first subterm t1 . Another example is the strategy map ( ? FunDec (< id >, _ , _ )) which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the FunDec constructor. Here are some more examples: < ? [ _ |< id >]> [ 1 , 2 , 3 ] => [ 2 , 3 ] < ? Call (< id >, [])> Call ( \"foobar\" , []) => \"foobar\" Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, ?Call(x, <?args; length => 3>) matches only with function calls with three arguments. Desugaring. A match expression ?p[<s>] is desugared as { x : ? p [ x ]; < s > x } That is, after the pattern p[x] matches, it is reduced to the subterm bound to x to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on. Traversal Combinators \u00b6 Traversal combinators apply strategies to direct subterms of a term and can be combined with other combinators to define full term traversal strategies. Congruence Operators \u00b6 $ Constructor ( $ StrategyExp , ... , $ StrategyExp ) A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor c declared in a signature, there is a corresponding congruence operator c(s1 , ..., sn) , which applies to terms of the form c(t1 , ..., tn) by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match. Example. Consider the following signature of expressions: module expressions signature sorts Exp constructors Plus : Exp * Exp - > Exp Times : Exp * Exp - > Exp The following applications apply the congruence operators Plus and Times to a term: < Plus ( ! Var ( \"a\" ), id )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < Times ( id , ! Int ( \"42\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor. Tuple and List Congruences \u00b6 [ $ StrategExp , ... , $ StrategyExp ] [ $ StrategExp , ... , $ StrategyExp | $ StrategyExp ] ( $ StrategExp , ... , $ StrategyExp ) Congruences can also be applied to tuples, (s1,s2,...,sn) , and lists, [s1,s2,...,sn] . Example. The definition of a map(s) strategy using list congruences: map ( s ) = [] < + [ s | map ( s )] Visiting All Subterms \u00b6 all ( $ StrategyExp ) The all(s) strategy transforms a constructor application by applying the parameter strategy s to each direct subterm. An application of all(s) fails if the application to one of the subterms fails. The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms. < all ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Var ( \"a\" )) < all ( ! Var ( \"z\" ))> Times ( Var ( \"b\" ), Int ( \"3\" )) => Times ( Var ( \"z\" ), Var ( \"z\" )) Example. The bottomup(s) is defined as bottomup ( s ) = all ( bottomup ( s )); s and defines a full traversal over the subject term. Visiting One Subterm \u00b6 one ( $ StrategyExp ) The one(s) strategy transforms a constructor application by applying the parameter strategy s to exactly one direct subterm. An application of one(s) fails if the application to all of the subterms fails. The following applications illustrate the behavior of the combinator: < one ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < one ( \\ Int ( x ) - > Int (< addS >( x , \"1\" )) \\ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"4\" )) < one ( ? Plus ( _ , _ ))> Plus ( Var ( \"a\" ), Int ( \"4\" )) // fails Example. A frequently used application of one is the oncetd(s) traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied. oncetd ( s ) = s < + one ( oncetd ( s )) Thus, s is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to oncetd(s) . An application of oncetd is the contains(|t) strategy, which checks whether the subject term contains a subterm that is equal to t. contains (| t ) = oncetd ( ? t ) Through the depth first search of oncetd , either an occurrence of t is found, or all subterms are verified to be unequal to t . Visiting Some Subterms \u00b6 some ( $ StrategyExp ) The some(s) strategy transforms a constructor application by applying the parameter strategy s to as many direct subterms as possible and at least one. An application of some(s) fails if the application to all of the subterms fails. Some one-pass traversals based on some: sometd ( s ) = s < + some ( sometd ( s )) somebu ( s ) = some ( somebu ( s )) < + s A fixed-point traversal with some: reduce-par ( s ) = repeat ( rec x ( some ( x ) + s )) Generic Term Deconstruction \u00b6 $ Term # ( $ Term ) // in a match pattern The term pattern expression c#(ts) used in a match pattern succeeds when applied to a constructor application and matches the constructor name (as a string) to c and the list of term arguments to ts . Generic Term Construction \u00b6 $ Term # ( $ Term ) // in a build pattern The term pattern expression c#(ts) used in a build pattern succeeds when c constructs a string and ts constructs a list of terms. It then builds the corresponding constructor application c(ts) . References \u00b6 Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined 1 . Thus, Stratego consists of a core language 2 and a 'sugar' language defined by reduction to the core language. Warning While it useful to understand the constructs defined in this section, their use should be avoided in favour of the higher-level language constructs, such as rewrite rules , where possible. Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9","title":"Strategy Combinators"},{"location":"references/stratego/strategy-combinators/#strategy-combinators","text":"A strategy expression combines the application of rules using strategy combinators .","title":"Strategy Combinators"},{"location":"references/stratego/strategy-combinators/#sequential-combinators","text":"","title":"Sequential Combinators"},{"location":"references/stratego/strategy-combinators/#identity-and-failure","text":"id fail The identity strategy id always succeeds and behaves as the identity function on terms. The failure strategy fail always fails. The operations have no side effects.","title":"Identity and Failure"},{"location":"references/stratego/strategy-combinators/#sequential-composition","text":"$ StrategyExp ; $ StrategyExp The sequential composition s1 ; s2 of the strategies s1 and s2 first applies the strategy s1 to the subject term and then s2 to the result of that first application. The strategy fails if either s1 or s2 fails. Properties. Sequential composition is associative. Identity is a left and right unit for sequential composition; since id always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since fail always fails the next strategy will never be reached. This leads to the following equations: ( s1 ; s2 ) ; s3 = s1 ; ( s2 ; s3 ) id ; s = s s ; id = s fail ; s = fail However, not for all strategies s we have that failure is a right zero for sequential composition: s ; fail = fail // is not a law Although the composition s; fail will always fail, the execution of s may have side effects that are not performed by fail . For example, consider printing a term in s . Example. Consider the following rewrite rules. A : P ( Z (), x ) - > x B : P ( S ( x ), y ) - > P ( x , S ( y )) The following applications shows the effect of first applying B and then A : < B > ! P ( S ( Z ()), Z ()) => P ( S ( Z ), Z ) < A > P ( Z , S ( Z )) => S ( Z ) Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019: < B ; A > ! P ( S ( Z ()), Z ()) => S ( Z ) The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first: < B ; B > ! P ( S ( Z ()), Z ()) // fails","title":"Sequential Composition"},{"location":"references/stratego/strategy-combinators/#left-choice","text":"$ StrategyExp < + $ StrategyExp The left choice or deterministic choice s1 <+ s2 tries to apply s1 and s2 in that order. That is, it first tries to apply s1 , and if that succeeds the choice succeeds. However, if the application of s1 fails, s2 is applied to the original term. Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless. ( s1 < + s2 ) < + s3 = s1 < + ( s2 < + s3 ) id < + s = id fail < + s = s s < + fail = s However, identity is not a right zero for left choice. That is, not for all strategies s we have that s < + id = s // is not a law The expression s <+ id always succeeds, even (especially) in the case that s fails, in which case the right-hand side of the equation fails of course. Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property ( s1 < + s2 ); s3 = ( s1 ; s3 ) < + ( s2 ; s3 ) // is not a law does not hold for all s1 , s2 , and s3 . The difference is illustrated by the following applications: <( B < + id ); B > P ( S ( Z ), Z ) // fails <( B ; B ) < + ( id ; B )> P ( S ( Z ()), Z ()) => P ( Z , S ( Z )) In the application of (B <+ id); B , the first application of B succeeds after which the choice is committed. The subsequent application of B then fails. This is equivalent to first applying (B <+ id) and then applying B to the result. The application of (B; B) <+ (id; B) , however, is successful; the application of B; B fails, after which the choice backtracks to id; B , which succeeds. Example. The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules: PlusAssoc : Plus ( Plus ( e1 , e2 ), e3 ) - > Plus ( e1 , Plus ( e2 , e3 )) PlusZero : Plus ( Int ( \"0\" ), e ) - > e These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into PlusAssoc <+ PlusZero creates a strategy that transforms terms matching both rules as illustrated by the following applications: < PlusAssoc > Plus ( Int ( \"0\" ), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Int ( \"0\" ), Int ( \"3\" )) => Int ( \"3\" ) < PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) // fails < PlusAssoc < + PlusZero > Plus ( Plus ( Var ( \"x\" ), Int ( \"42\" )), Int ( \"3\" )) => Plus ( Var ( \"x\" ), Plus ( Int ( \"42\" ), Int ( \"3\" ))) Example. An application of <+ in combination with id is the reflexive closure of a strategy s : try ( s ) = s < + id The user-defined strategy combinator try tries to apply its argument strategy s , but if that fails, just succeeds using id .","title":"Left Choice"},{"location":"references/stratego/strategy-combinators/#guarded-left-choice","text":"$ StrategyExp < $ StrategyExp + $ StrategyExp With the guarded left choice operator s1 < s2 + s3 , if s1 succeeds s2 is applied, else s3 is applied. If s2 fails, the complete expression fails; no backtracking to s3 takes place. Properties. This combinator is a generalization of the left choice combinator <+ . s1 < + s2 = s1 < id + s2 The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard: id < s2 + s3 = s2 fail < s2 + s3 = s3 If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch. s1 < s2 + fail = s1 ; s2 Guarded choice is not associative: ( s1 < s2 + s3 ) < s4 + s5 = s1 < s2 + ( s3 < s4 + s5 ) // not a law To see why consider the possible traces of these expressions. For example, when s1 and s2 succeed subsequently, the left-hand side expression calls s4 , while the right-hand side expression does not. However, sequential composition distributes over guarded choice from left and right: ( s1 < s2 + s3 ); s4 = s1 < ( s2 ; s4 ) + ( s3 ; s4 ) s0 ; ( s1 < s2 + s3 ) = ( s0 ; s1 ) < s2 + s3 Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation not(s) of a strategy s , succeeds if s fails, and fails when it succeeds: not ( s ) = s < fail + id Since failure discards the effect of a (successful) transformation, this has the effect of testing whether s succeeds. So we have the following laws for not: not ( id ) = fail not ( fail ) = id However, side effects performed by s are not undone, of course. Therefore, the following equation does not hold: not ( not ( s )) = s // not a law Another example of the use of guarded choice is the restore-always combinator: restore-always ( s , r ) = s < r + ( r ; fail ) It applies a \u2018restore\u2019 strategy r after applying a strategy s , even if s fails, and preserves the success/failure behavior of s . Since fail discards the transformation effect of r , this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying s .","title":"Guarded Left Choice"},{"location":"references/stratego/strategy-combinators/#if-then-else","text":"if $ StrategyExp then $ StrategyExp else $ StrategyExp end The if s1 then s2 else s3 end construct is like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but its transformation effect is undone. However, the condition strategy s1 is still applied to the subject term. The if s1 then s2 end strategy is similar; if the condition fails, the strategy succeeds. The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator: if s1 then s2 else s3 end ==> // transforms to where ( s1 ) < s2 + s3 The strategy where(s) succeeds if s succeeds, but returns the original subject term. Properties. The following laws show that the branches are selected by success or failure of the condition: if id then s2 else s3 end = s2 if fail then s2 else s3 end = s3 The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch: if s1 then s2 end = where ( s1 ) < s2 + id Examples. The inclusive or or(s1, s2) succeeds if one of the strategies s1 or s2 succeeds, but guarantees that both are applied, in the order s1 first, then s2 : or ( s1 , s2 ) = if s1 then try ( where ( s2 )) else where ( s2 ) end This ensures that any side effects are always performed, in contrast to s1 <\\+ s2 , where s2 is only executed if s1 fails. (Thus, left choice implements a short circuit Boolean or.) Similarly, the following and(s1, s2) combinator is the non-short circuit version of Boolean conjunction: and ( s1 , s2 ) = if s1 then where ( s2 ) else where ( s2 ); fail end","title":"If-then-else"},{"location":"references/stratego/strategy-combinators/#switch","text":"switch s0 case s1 : s1 ' case s2 : s2 ' ... otherwise : sdef end The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice. The switch first applies the s0 strategy to the current term t resulting in a term t' . Then it tries the cases in turn applying each si to t' . As soon as this succeeds the corresponding case is selected and si' is applied to the t , the term to which the switch was applied. If none of the cases applies, the default strategy sdef from the otherwise is applied. The switch construct is syntactic sugar for a nested if-then-else: { x : where ( s0 => x ); if < s1 > x then s1 ' else if < s2 > x then s2 ' else if ... then ... else sdef end end end }","title":"Switch"},{"location":"references/stratego/strategy-combinators/#non-deterministic-choice","text":"$ StrategyExp + $ StrategyExp The non-deterministic choice operator s1 + s2 chooses one of the two strategies s1 or s2 to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler or runtime system. The + combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with + . The following transformation illustrates this: module A f = s1 module B f = s2 module main imports A B => f = s2 + s1 This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters. While the + combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <+ to avoid surprises. Note. In the past, the + combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this: module A f = s1 f = s2 => f = s1 < + s2","title":"Non-Deterministic Choice"},{"location":"references/stratego/strategy-combinators/#fixpoint-recursion","text":"rec $ Id ( $ StrategyExp ) The fixpoint operator rec x(s) , which recurses on applications of x within s . The rec operator allows the definition of an unnamed strategy expression to be recursive. For example, in the definition g ( s ) = foo ; rec x ( ... x ... ); bar the strategy between foo and bar is a recursive strategy that does not recurse to g(s) . Alternative. Originally, the rec operator was the only way to define recursive strategies. Currently, a recursive definition is a normal strategy definition with a recursive call in its body. f ( s ) = ... f ( s ) ... The rec operator is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope. Example. The repeat strategy applies a transformation s until it fails. It is defined as a recursive definition using try as follows: try ( s ) = s < + id repeat ( s ) = try ( s ; repeat ( s )) An equivalent definition using rec is: repeat ( s ) = rec x ( try ( s ; x ))","title":"Fixpoint Recursion"},{"location":"references/stratego/strategy-combinators/#term-combinators","text":"","title":"Term Combinators"},{"location":"references/stratego/strategy-combinators/#building-terms","text":"! $ Term The build operation !p replaces the subject term with the instantiation of the pattern p using the bindings from the environment to the variables occurring in p . Example. The strategy !Or(And(x, z), And(y, z)) replaces the subject term with the instantiation of Or(And(x, z), And(y, z)) using bindings to variables x , y and z . ! Int ( \"10\" ) => Int ( \"10\" ) ! Plus ( Var ( \"a\" ), Int ( \"10\" )) => Plus ( Var ( \"a\" ), Int ( \"10\" )) It is possible to build terms with variables. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern p . Example. In a context where e is bound to Var(\"b\") ! Plus ( Var ( \"a\" ), e ) => Plus ( Var ( \"a\" ), Var ( \"b\" ))","title":"Building Terms"},{"location":"references/stratego/strategy-combinators/#matching-terms","text":"? $ Term The match operation ?t matches the subject term against the term t . < ? Plus ( Var ( \"a\" ), Int ( \"3\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // succeeds < ? Plus ( Int ( \"3\" ), Var ( \"b\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy ?x compares the current term ( t ) to variable x . It binds variable x to term t in the environment. A variable can only be bound once, or to the same term. < ? e > Plus ( Var ( \"a\" ), Int ( \"3\" )) // binds e to Plus(Var(\"a\"),Int(\"3\")) < ? e > ! Int ( \"17\" ) // fails The general case is matching against an arbitrary term pattern. The match strategy ?p compares the current term to a pattern p . It will add bindings for the variables in pattern p to the environment. The wildcard _ in a match will match any term. < ? Plus ( e , _ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // e is bound to Var(\"a\") Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term. < ? Plus ( e , e )> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails < ? Plus ( e , e )> ! Plus ( Var ( \"a\" ), Var ( \"a\" )) // e is bound to Var(\"a\") Example. Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching: equal = ? ( x , x ) equal (| x ) = ? x The equal strategy tests whether the current term is a a pair of the same terms. The equal(|x) strategy tests whether the current term is equal to the argument term. < equal >( \"a\" , \"a\" ) // succeeds < equal >( \"a\" , \"b\" ) // fails < equal (| Foo ( Baz ()))> Foo ( Bar ()) // fails < equal (| Foo ( Bar ()))> Foo ( Bar ()) // succeeds","title":"Matching Terms"},{"location":"references/stratego/strategy-combinators/#term-variable-scope","text":"{ $ Id , ... : $ StrategyExp } Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because e2 is bound to Int(\"3\") and does not match with Var(\"b\") . < ? Plus ( e1 , e2 ) ! Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) // e1 is bound to Var(\"a\") // e2 is bound to Int(\"3\") < ? Plus ( e1 , e2 ) ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Var ( \"b\" )) // fails To use a variable name more than once Stratego provides term variable scope. A scope {x1,...,xn : s} locally undefines the variables xi . That is, the binding to a variable xi outside the scope is not visible inside it, nor is the binding to xi inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times. <{ e3 , e4 : ? Plus ( e3 , e4 ); ! Plus ( e4 , e3 )}> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) // e3 is not bound to a term <{ e3 , e4 : ? Plus ( e3 , e4 ); ! Plus ( e4 , e3 )}> Plus ( Var ( \"a\" ), Var ( \"b\" )) => Plus ( Var ( \"b\" ), Var ( \"a\" )) Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name: SwapArgs = { e1 , e2 : ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )} < SwapArgs > Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" ))","title":"Term Variable Scope"},{"location":"references/stratego/strategy-combinators/#implicit-variable-scope","text":"When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write SwapArgs = { e1 , e2 : ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )} However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write SwapArgs = ( Plus ( e1 , e2 ) - > Plus ( e2 , e1 )) instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as let SwapArgs = ? Plus ( e1 , e2 ); Plus ( e2 , e1 ) in ... end While the variables are bound in the enclosing definition, they are not restricted to SwapArgs in this case, since in a let one typically wants to use bindings to variables in the enclosing code.","title":"Implicit Variable Scope"},{"location":"references/stratego/strategy-combinators/#combining-match-and-build","text":"Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build: < ? Plus ( e1 , e2 ); ! Plus ( e2 , e1 )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" )) This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build. Stratego provides syntactic sugar for various combinations of match and build.","title":"Combining Match and Build"},{"location":"references/stratego/strategy-combinators/#anonymous-rewrite-rule","text":"( $ Pattern - > $ Pattern ) An anonymous rewrite rule (p1 -> p2) transforms a term matching p1 into an instantiation of p2 . Such a rule is equivalent to the sequence ?p1; !p2 . <( Plus ( e1 , e2 ) - > Plus ( e2 , e1 ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Int ( \"3\" ), Var ( \"a\" ))","title":"Anonymous Rewrite Rule"},{"location":"references/stratego/strategy-combinators/#where","text":"where ( $ StrategyExp ) The where(s) combinator applies s to the current term, but restores that term afterwards. Any bindings to variables are kept, however. The where(s) construct is syntactic sugar for {x: ?x; s; !x} with x a fresh variable not occurring in s . Thus, the current subject term is saved by binding it to a new variable x , then the strategy s is applied, and finally, the original term is restored by building x . Example < where ( ? Plus ( Int ( i ), Int ( j )); < addS >( i , j ) => k )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Int ( \"14\" ), Int ( \"3\" )) // i is bound to \"14\" // k is bound to \"17\"","title":"Where"},{"location":"references/stratego/strategy-combinators/#with","text":"with ( s ) The strategy with(s) applies s on the current subject term and then restores the current subject term. In other words, s is executed solely for its side effects, such as binding variables. In this respect, with is like where . However, with(s) differs in a key way: if the strategy s fails, Stratego stops with an error, reporting the strategy that failed.","title":"With"},{"location":"references/stratego/strategy-combinators/#lambda-rules","text":"\\ $ Term - > $ Term where $ Condition \\ A lambda rule of the form \\ p1 -> p2 where s \\ is an anonymous rewrite rule for which the variables in the left-hand side p1 are local to the rule, that is, it is equivalent to an expression of the form { x1 , ... , xn : ( p1 - > p2 where s )} with x1 ,\u2026, xn the variables of p1 . This means that any variables used in s and p2 that do not occur in p1 are bound in the context of the rule. Example. < map ( \\ ( x , y ) - > x \\ )> [( 1 , 2 ),( 3 , 4 ),( 5 , 6 )] => [ 1 , 3 , 5 ]","title":"Lambda Rules"},{"location":"references/stratego/strategy-combinators/#apply-and-match","text":"$ StrategyExp => $ Term < $ StrategyExp > $ Term < $ StrategyExp > $ Term => $ Term The operation <s> p captures the notion of applying a strategy to a term, i.e., the scenario !p; s . The operation s => p capture the notion of applying a strategy to the current subject term and then matching the result against the pattern p , i.e., s; ?p . The combined operation <s> p1 => p2 thus captures the notion of applying a strategy to a term p1 and matching the result against p2 , i.e, !p1; s; ?p2 . Example. The conditional rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where ! ( i , j ); addS ; ? k can be reformulated as EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k","title":"Apply and Match"},{"location":"references/stratego/strategy-combinators/#assignment","text":"$ Term := $ Term The strategy p1 := p2 builds p2 and matches the result against p1 , i.e. it is equivalent to !p2; ?p1 . The strategy is often combined with strategy application into p1 := <s>p2 , which is equivalent to <s>p2 => p1 (but more familiar to an audience with an imperative mindset). For example, consider the following rewrite rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) with k := < addS >( i , j )","title":"Assignment"},{"location":"references/stratego/strategy-combinators/#applying-strategies-in-build","text":"< $ StrategyExp > $ Term // in build pattern In a build pattern, the application <s>t applies the strategy s to the term t , returning the resulting term. Example. The constant folding rule EvalPlus : Add ( Int ( i ), Int ( j )) - > Int ( k ) where < addS >( i , j ) => k can be simplified by directly applying the addition in the right-hand side: EvalPlus : Add ( Int ( i ), Int ( j )) - > Int (< addS >( i , j )) Example. The following definition of the map(s) strategy applies a strategy to each term in a list: map ( s ) : [] - > [] map ( s ) : [ x | xs ] - > [< s > x | < map ( s )> xs ]","title":"Applying Strategies in Build"},{"location":"references/stratego/strategy-combinators/#term-wrap","text":"< $ StrategyExp > // in build pattern A term wrap is a build strategy !p[<s>] containing one or more strategy applications <s> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <s> is replaced with the term resulting from applying s to the current subject term, i.e., the one that is being replaced by the build. Motivation. One often write rules of the form x -> Foo(Bar(x)) , i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as !Foo(Bar(<id>)) . Example. The following applications illustrate some uses of term wraps: < ! (< id >,< id >)> 3 => ( 3 , 3 ) <(< Fst ; inc >,< Snd >)> ( 3 , 3 ) => ( 4 , 3 ) < ! Call (< id >, [])> \"foobar\" => Call ( \"foobar\" , []) mod2 = < mod >(< id >, 2 ) < mod2 > 6 => 0 Desugaring. Term wraps are implemented by translation to a combination of match and build expressions. Thus, a term wrap !p[<s>] is translated to a strategy expression { x : where ( s => x ); ! p [ x ]} where x is a fresh variable not occurring in s . In other words, the strategy s is applied to the current subject term, i.e., the term to which the build is applied. As an example, the term wrap !Foo(Bar(<id>)) is desugared to the strategy { x : where ( id => x ); ! Foo ( Bar ( x ))} which after simplification is equivalent to {x: ?x; !Foo(Bar(x))} , i.e., exactly the original lambda rule \\x -> Foo(Bar(x))\\ .","title":"Term Wrap"},{"location":"references/stratego/strategy-combinators/#term-project","text":"< $ StrategyExp > // in match pattern Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern. Examples. For example, the expression ?And(<id>,x) matches terms of the form And(t1,t2) and reduces them to the first subterm t1 . Another example is the strategy map ( ? FunDec (< id >, _ , _ )) which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the FunDec constructor. Here are some more examples: < ? [ _ |< id >]> [ 1 , 2 , 3 ] => [ 2 , 3 ] < ? Call (< id >, [])> Call ( \"foobar\" , []) => \"foobar\" Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, ?Call(x, <?args; length => 3>) matches only with function calls with three arguments. Desugaring. A match expression ?p[<s>] is desugared as { x : ? p [ x ]; < s > x } That is, after the pattern p[x] matches, it is reduced to the subterm bound to x to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on.","title":"Term Project"},{"location":"references/stratego/strategy-combinators/#traversal-combinators","text":"Traversal combinators apply strategies to direct subterms of a term and can be combined with other combinators to define full term traversal strategies.","title":"Traversal Combinators"},{"location":"references/stratego/strategy-combinators/#congruence-operators","text":"$ Constructor ( $ StrategyExp , ... , $ StrategyExp ) A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor c declared in a signature, there is a corresponding congruence operator c(s1 , ..., sn) , which applies to terms of the form c(t1 , ..., tn) by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match. Example. Consider the following signature of expressions: module expressions signature sorts Exp constructors Plus : Exp * Exp - > Exp Times : Exp * Exp - > Exp The following applications apply the congruence operators Plus and Times to a term: < Plus ( ! Var ( \"a\" ), id )> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < Times ( id , ! Int ( \"42\" ))> Plus ( Var ( \"a\" ), Int ( \"3\" )) // fails The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor.","title":"Congruence Operators"},{"location":"references/stratego/strategy-combinators/#tuple-and-list-congruences","text":"[ $ StrategExp , ... , $ StrategyExp ] [ $ StrategExp , ... , $ StrategyExp | $ StrategyExp ] ( $ StrategExp , ... , $ StrategyExp ) Congruences can also be applied to tuples, (s1,s2,...,sn) , and lists, [s1,s2,...,sn] . Example. The definition of a map(s) strategy using list congruences: map ( s ) = [] < + [ s | map ( s )]","title":"Tuple and List Congruences"},{"location":"references/stratego/strategy-combinators/#visiting-all-subterms","text":"all ( $ StrategyExp ) The all(s) strategy transforms a constructor application by applying the parameter strategy s to each direct subterm. An application of all(s) fails if the application to one of the subterms fails. The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms. < all ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Var ( \"a\" )) < all ( ! Var ( \"z\" ))> Times ( Var ( \"b\" ), Int ( \"3\" )) => Times ( Var ( \"z\" ), Var ( \"z\" )) Example. The bottomup(s) is defined as bottomup ( s ) = all ( bottomup ( s )); s and defines a full traversal over the subject term.","title":"Visiting All Subterms"},{"location":"references/stratego/strategy-combinators/#visiting-one-subterm","text":"one ( $ StrategyExp ) The one(s) strategy transforms a constructor application by applying the parameter strategy s to exactly one direct subterm. An application of one(s) fails if the application to all of the subterms fails. The following applications illustrate the behavior of the combinator: < one ( ! Var ( \"a\" ))> Plus ( Int ( \"14\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"3\" )) < one ( \\ Int ( x ) - > Int (< addS >( x , \"1\" )) \\ )> Plus ( Var ( \"a\" ), Int ( \"3\" )) => Plus ( Var ( \"a\" ), Int ( \"4\" )) < one ( ? Plus ( _ , _ ))> Plus ( Var ( \"a\" ), Int ( \"4\" )) // fails Example. A frequently used application of one is the oncetd(s) traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied. oncetd ( s ) = s < + one ( oncetd ( s )) Thus, s is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to oncetd(s) . An application of oncetd is the contains(|t) strategy, which checks whether the subject term contains a subterm that is equal to t. contains (| t ) = oncetd ( ? t ) Through the depth first search of oncetd , either an occurrence of t is found, or all subterms are verified to be unequal to t .","title":"Visiting One Subterm"},{"location":"references/stratego/strategy-combinators/#visiting-some-subterms","text":"some ( $ StrategyExp ) The some(s) strategy transforms a constructor application by applying the parameter strategy s to as many direct subterms as possible and at least one. An application of some(s) fails if the application to all of the subterms fails. Some one-pass traversals based on some: sometd ( s ) = s < + some ( sometd ( s )) somebu ( s ) = some ( somebu ( s )) < + s A fixed-point traversal with some: reduce-par ( s ) = repeat ( rec x ( some ( x ) + s ))","title":"Visiting Some Subterms"},{"location":"references/stratego/strategy-combinators/#generic-term-deconstruction","text":"$ Term # ( $ Term ) // in a match pattern The term pattern expression c#(ts) used in a match pattern succeeds when applied to a constructor application and matches the constructor name (as a string) to c and the list of term arguments to ts .","title":"Generic Term Deconstruction"},{"location":"references/stratego/strategy-combinators/#generic-term-construction","text":"$ Term # ( $ Term ) // in a build pattern The term pattern expression c#(ts) used in a build pattern succeeds when c constructs a string and ts constructs a list of terms. It then builds the corresponding constructor application c(ts) .","title":"Generic Term Construction"},{"location":"references/stratego/strategy-combinators/#references","text":"Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined 1 . Thus, Stratego consists of a core language 2 and a 'sugar' language defined by reduction to the core language. Warning While it useful to understand the constructs defined in this section, their use should be avoided in favour of the higher-level language constructs, such as rewrite rules , where possible. Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming , 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425 , doi:10.1145/289423.289425 . \u21a9 Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science , 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661 \\(05\\) 80027-1 , doi:10.1016/S1571-0661 \\(05\\) 80027-1 . \u21a9","title":"References"},{"location":"references/stratego/strategy-definitions/","text":"Strategy Definitions \u00b6 $ Id ( $ StrategyArg , ... | $ TermArg , ... ) = $ StrategyExp A strategy definition gives a name to a strategy expression, has zero or more strategy arguments, and zero or more term arguments. Simple Definitions \u00b6 A simple strategy definition gaves a name to a strategy expression . $ Id = s For example, the following definition defines desugar as an application of the innermost strategy to the rewrite rule(s) desugar-exp . strategies desugar :: Module - > Module desugar = innermost ( desugar-exp ) Parameterized Definitions \u00b6 Just like rewrite rules , strategy definitions can be parameterized with strategies and terms. $ Id ( $ StrategyArg , ... | $ TermArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... | t1 , ... ) = s When a strategy has no term arguments, the bar can be left out: $ Id ( $ StrategyArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... ) = s Simple strategy definitions are the special case in which a strategy does not have strategy and term arguments. For example, the following definition defines topdown(s) in terms of sequential composition and generic traversal: topdown ( TP ) :: TP topdown ( s ) = s ; all ( topdown ( s )) Extending Definitions \u00b6 Just like rewrite rules, strategy definitions can have multiple definitions. In case a strategy expression fails to apply, the next definition is applied. When definitions are in the same module, definitions are applied in the textual order they are defined in. When definitions are defined in separate modules, the order is undefined. External Definitions \u00b6 external definitions libraries Todo finish this section on external definitions Local Definitions \u00b6 Todo finish this section on local definitions","title":"Strategy Definitions"},{"location":"references/stratego/strategy-definitions/#strategy-definitions","text":"$ Id ( $ StrategyArg , ... | $ TermArg , ... ) = $ StrategyExp A strategy definition gives a name to a strategy expression, has zero or more strategy arguments, and zero or more term arguments.","title":"Strategy Definitions"},{"location":"references/stratego/strategy-definitions/#simple-definitions","text":"A simple strategy definition gaves a name to a strategy expression . $ Id = s For example, the following definition defines desugar as an application of the innermost strategy to the rewrite rule(s) desugar-exp . strategies desugar :: Module - > Module desugar = innermost ( desugar-exp )","title":"Simple Definitions"},{"location":"references/stratego/strategy-definitions/#parameterized-definitions","text":"Just like rewrite rules , strategy definitions can be parameterized with strategies and terms. $ Id ( $ StrategyArg , ... | $ TermArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... | t1 , ... ) = s When a strategy has no term arguments, the bar can be left out: $ Id ( $ StrategyArg , ... ) :: $ Type - > $ Type $ Id ( s1 , ... ) = s Simple strategy definitions are the special case in which a strategy does not have strategy and term arguments. For example, the following definition defines topdown(s) in terms of sequential composition and generic traversal: topdown ( TP ) :: TP topdown ( s ) = s ; all ( topdown ( s ))","title":"Parameterized Definitions"},{"location":"references/stratego/strategy-definitions/#extending-definitions","text":"Just like rewrite rules, strategy definitions can have multiple definitions. In case a strategy expression fails to apply, the next definition is applied. When definitions are in the same module, definitions are applied in the textual order they are defined in. When definitions are defined in separate modules, the order is undefined.","title":"Extending Definitions"},{"location":"references/stratego/strategy-definitions/#external-definitions","text":"external definitions libraries Todo finish this section on external definitions","title":"External Definitions"},{"location":"references/stratego/strategy-definitions/#local-definitions","text":"Todo finish this section on local definitions","title":"Local Definitions"},{"location":"references/stratego/terms/","text":"Terms \u00b6 Stratego programs transform terms. For example, the code 4 + f(5 * x) might be represented in a term as: Plus ( Int ( \"4\" ), Call ( \"f\" , [ Mul ( Int ( \"5\" ), Var ( \"x\" ))])) Term Forms \u00b6 Terms are constructed from the following forms. Integer \u00b6 $ Digit + An integer constant, that is a list of decimal digits, is an ATerm. Examples: 1 , 12343 . String \u00b6 \"$Char*\" A string constant, that is a list of characters between double quotes is an ATerm. Special characters such as double quotes and newlines should be escaped using a backslash. The backslash character itself should be escaped as well. Examples: \"foobar\" , \"string with quotes\\\"\" , \"escaped escape character\\\\ and a newline\\n\" . String Templates \u00b6 $ [ $ TemplateChar * ] Multiline strings can be constructed using string templates. $ [ if [ code1 ] then [ code2 ]] The indentation will be computed relative to the start of the template. String templates can also include escapes to term expressions producing strings or integers. For example, the string above includes escapes to include code1 and code2 and the following error message $ [ error : variable [ x ] is not defined ] includes the name of the variable x . Constructor application \u00b6 $ Constructor ( $ Term , ... , $ Term ) A constructor is an identifier, that is an alphanumeric string starting with a letter, or a double quoted string. A constructor application c(t1,...,tn) creates a term by applying a constructor to a sequence of zero or more terms. For example, the term Plus(Int(\"4\"),Var(\"x\")) uses the constructors Plus , Int , and Var to create a nested term from the strings \"4\" and \"x\" . The parentheses are needed even when a constructor has no subterms, in order to avoid ambiguity with variables . Thus, True() is a constructor application, but True is a variable. List \u00b6 [ $ Term , ... , $ Term ] A list is a term of the form [t1,...,tn] , that is a list of zero or more terms between square brackets. While all applications of a specific constructor typically have the same number of subterms, lists can have a variable number of subterms. The elements of a list are typically of the same type, while the subterms of a constructor application can vary in type. Example: The second argument of the call to \"f\" in the term Call(\"f\",[Int(\"5\"),Var(\"x\")]) is a list of expressions. Tuple \u00b6 ( $ Term , ... , $ Term ) A tuple (t1,...,tn) is a constructor application without a constructor. Example: (Var(\"x\"), Type(\"int\")) Annotation \u00b6 $ PreTerm { $ Term , ... , $ Term } Any of the term forms above can be annotated with a list of terms. Example: Lt(Var(\"n\"),Int(\"1\")){Type(\"bool\")} . Only 'preterms', i.e. terms without annotations, can be annotated. The form Var(\"a\"){Type(\"bool\")}{Value(3)} is syntactically incorrect. Term Patterns \u00b6 A term pattern , is a term extended with variables . In the term pattern Plus ( e , Int ( \"0\" )) the identifier e is a variable that stands for any term. Linear vs Non-Linear \u00b6 A pattern is linear if each variable occurs at most once, non-linear otherwise. The non-linear pattern Plus ( e , e ) stands for a Plus term with identical arguments. A term pattern without variables (aka term) is ground . Substitution \u00b6 Substitution is the process of applying a map from variables to terms to a term pattern, replacing occurrence of variables in the domain of the map with the corresponding terms in the codomain of the map. Substitution is also the name for the mapping of variables to terms. Pattern Matching \u00b6 Pattern matching is the process of matching a ground term against a term pattern. A term t matches a term pattern p iff there is a substition S such that applying the substitution to the pattern S(p) yields the term t . Persistent Representation \u00b6 The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer. Todo API for reading, writing terms? Namespaces \u00b6 Currently, the constructors of terms live in a global namespace. In the future, we want to support qualified names. References \u00b6 Terms in Stratego are inspired by terms in the Annotated Term Format , or ATerms for short 1 . The ATerm format provides a set of constructs for representing trees, comparable to XML or abstract data types in functional programming languages. Mark G. J. van den Brand, H. A. de Jong, Paul Klint, and Pieter A. Olivier. Efficient annotated terms. Software: Practice and Experience , 30 \\(3\\) :259\u2013291, 2000. \u21a9","title":"Terms"},{"location":"references/stratego/terms/#terms","text":"Stratego programs transform terms. For example, the code 4 + f(5 * x) might be represented in a term as: Plus ( Int ( \"4\" ), Call ( \"f\" , [ Mul ( Int ( \"5\" ), Var ( \"x\" ))]))","title":"Terms"},{"location":"references/stratego/terms/#term-forms","text":"Terms are constructed from the following forms.","title":"Term Forms"},{"location":"references/stratego/terms/#integer","text":"$ Digit + An integer constant, that is a list of decimal digits, is an ATerm. Examples: 1 , 12343 .","title":"Integer"},{"location":"references/stratego/terms/#string","text":"\"$Char*\" A string constant, that is a list of characters between double quotes is an ATerm. Special characters such as double quotes and newlines should be escaped using a backslash. The backslash character itself should be escaped as well. Examples: \"foobar\" , \"string with quotes\\\"\" , \"escaped escape character\\\\ and a newline\\n\" .","title":"String"},{"location":"references/stratego/terms/#string-templates","text":"$ [ $ TemplateChar * ] Multiline strings can be constructed using string templates. $ [ if [ code1 ] then [ code2 ]] The indentation will be computed relative to the start of the template. String templates can also include escapes to term expressions producing strings or integers. For example, the string above includes escapes to include code1 and code2 and the following error message $ [ error : variable [ x ] is not defined ] includes the name of the variable x .","title":"String Templates"},{"location":"references/stratego/terms/#constructor-application","text":"$ Constructor ( $ Term , ... , $ Term ) A constructor is an identifier, that is an alphanumeric string starting with a letter, or a double quoted string. A constructor application c(t1,...,tn) creates a term by applying a constructor to a sequence of zero or more terms. For example, the term Plus(Int(\"4\"),Var(\"x\")) uses the constructors Plus , Int , and Var to create a nested term from the strings \"4\" and \"x\" . The parentheses are needed even when a constructor has no subterms, in order to avoid ambiguity with variables . Thus, True() is a constructor application, but True is a variable.","title":"Constructor application"},{"location":"references/stratego/terms/#list","text":"[ $ Term , ... , $ Term ] A list is a term of the form [t1,...,tn] , that is a list of zero or more terms between square brackets. While all applications of a specific constructor typically have the same number of subterms, lists can have a variable number of subterms. The elements of a list are typically of the same type, while the subterms of a constructor application can vary in type. Example: The second argument of the call to \"f\" in the term Call(\"f\",[Int(\"5\"),Var(\"x\")]) is a list of expressions.","title":"List"},{"location":"references/stratego/terms/#tuple","text":"( $ Term , ... , $ Term ) A tuple (t1,...,tn) is a constructor application without a constructor. Example: (Var(\"x\"), Type(\"int\"))","title":"Tuple"},{"location":"references/stratego/terms/#annotation","text":"$ PreTerm { $ Term , ... , $ Term } Any of the term forms above can be annotated with a list of terms. Example: Lt(Var(\"n\"),Int(\"1\")){Type(\"bool\")} . Only 'preterms', i.e. terms without annotations, can be annotated. The form Var(\"a\"){Type(\"bool\")}{Value(3)} is syntactically incorrect.","title":"Annotation"},{"location":"references/stratego/terms/#term-patterns","text":"A term pattern , is a term extended with variables . In the term pattern Plus ( e , Int ( \"0\" )) the identifier e is a variable that stands for any term.","title":"Term Patterns"},{"location":"references/stratego/terms/#linear-vs-non-linear","text":"A pattern is linear if each variable occurs at most once, non-linear otherwise. The non-linear pattern Plus ( e , e ) stands for a Plus term with identical arguments. A term pattern without variables (aka term) is ground .","title":"Linear vs Non-Linear"},{"location":"references/stratego/terms/#substitution","text":"Substitution is the process of applying a map from variables to terms to a term pattern, replacing occurrence of variables in the domain of the map with the corresponding terms in the codomain of the map. Substitution is also the name for the mapping of variables to terms.","title":"Substitution"},{"location":"references/stratego/terms/#pattern-matching","text":"Pattern matching is the process of matching a ground term against a term pattern. A term t matches a term pattern p iff there is a substition S such that applying the substitution to the pattern S(p) yields the term t .","title":"Pattern Matching"},{"location":"references/stratego/terms/#persistent-representation","text":"The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer. Todo API for reading, writing terms?","title":"Persistent Representation"},{"location":"references/stratego/terms/#namespaces","text":"Currently, the constructors of terms live in a global namespace. In the future, we want to support qualified names.","title":"Namespaces"},{"location":"references/stratego/terms/#references","text":"Terms in Stratego are inspired by terms in the Annotated Term Format , or ATerms for short 1 . The ATerm format provides a set of constructs for representing trees, comparable to XML or abstract data types in functional programming languages. Mark G. J. van den Brand, H. A. de Jong, Paul Klint, and Pieter A. Olivier. Efficient annotated terms. Software: Practice and Experience , 30 \\(3\\) :259\u2013291, 2000. \u21a9","title":"References"},{"location":"references/stratego/types/","text":"Types \u00b6 Terms provide a generic, untyped format to represent tree-structured data. Stratego transformations can transform such data, but require at least that the arities of term constructors that are used in rules are declared. Starting with Stratego 2, the types of terms and term transformations may be declared and checked in more detail 1 . Signatures \u00b6 signature $ SigSection * A signature declares the shape of well-formed terms using sort declarations, constructor declarations, and overlays. Sorts \u00b6 sorts $ Sort * A sort is determined by an identifier and optionally has arguments. A sort (or type ) identifies a collection of well-formed terms. Convention: Sort identifiers start with a capital letter. Constructors \u00b6 constructors $ ConstructorDecl A constructor declaration has the form $ Constructor : $ Sort * ... * $ Sort - > Decl and declares a constructor name, the sorts of the argument terms, and the sort of the constructed term. Convention: Constructor identifiers start with a capital letter. Example: The constructor declaration Assign : ID * Exp - > Stmt defines the constructor Assign with input sorts ID and Exp and output sort Stmt . Thus, if x and e are terms of sort ID and Exp , respectively, then Assign(x, e) is a term of sort Stmt . When the list of argument sorts is empty the arrow can be omitted: $ Constructor : Decl Example: The constructor declaration True : Bool defines that True() is a term of sort Bool . Note that the parentheses are required. The term True is a variable. The Stratego1 compiler only checks the arity of constructor applications against the signature. The Stratego2 compiler uses signature definitions to type check code if it has been given a type signature. Injections \u00b6 An injection is a constructor without name and with a single argument. : $ Sort - > $ Sort Injections include an entire type as a subtype of another type without cluttering the tree structure. List Type \u00b6 List ( $ Sort ) The type constructor List(_) is for typing homogenous lists. Exmample. The type List(Exp) represents lists of expressions Exp . Polymorphic Types \u00b6 Stratego2 supports user-defined polymorphic types. That is, sorts can have parameters. For example, the following signature defines the type of priority queues, polymorphic in the carrier type, in which the priority is determined by the length of the list. signature sorts PrioQ ( * ) constructors NilQ : PrioQ ( a ) ConsQ : a * int * List ( a ) * PrioQ ( a ) - > PrioQ ( a ) Tuple Type \u00b6 ( $ TermType * ... * $ TermType ) Tuple terms can be typed in strategy types. Currently, tuple types cannot be used in term signatures. Overlays \u00b6 overlays $ OverlayDef An overlay defines a term abbreviation. An overlay definition has the form $ Constructor ( $ ID , ... , $ ID ) = $ Term and defines that applications of the constructor should be expanded to the term. Transformation Types \u00b6 $ Id ( $ StrategyType , ... | $ TermType , ... ) :: $ TermType - > $ TermType A transformation type defines the signature of a transformation with name $Id with the types of its strategy arguments and term arguments, the type of the 'current term' to which the transformation is applied, and the type of the term that is returned, if the transformation succeeds. Transformation types are declared in rules or strategies sections. $ Id ( $ StrategyType , ... ) :: $ TermType - > $ TermType When a transformation only has strategy parameters, the bar can be left out. $ Id :: $ TermType - > $ TermType When a transformation also has no strategy parameters, the parentheses can be left out as well. Strategy Type \u00b6 $ TermType - > $ TermType The type of a transformation/strategy argument is an arrow from a term type to a term type. Note that transformation strategies cannot be reified as terms. Type Dynamic \u00b6 ? Type dynamic , written ? , represents the unknown type. Stratego2 is a gradually typed language in order to facilitate the migration from (mostly) untyped Stratego1 code to typed Stratego2 code. Furthermore, some patterns in Stratego cannot be typed statically. When used as a strategy type ? represents ? -> ? . Type Casts \u00b6 ///syntax of casts Todo syntactic form Gradual type systems allow a term with the dynamic type to be used in any place where a static type is required. Stratego2 will insert a type cast at such a point to check at run time that the term is type-correct. This way, a Stratego program halts execution in predictable places when a run time type error occurs. There can be no run time type errors in fully statically typed code either, only at the boundary between dynamically and statically typed code. Type Preserving \u00b6 TP A type preserving transformation transforms any type to itself (or fails). In signatures, a type preserving transformation is indicated with TP . Example. The type declaration topdown ( s : TP ) :: TP declares that the topdown strategy is type preserving if its argument strategy is. The type-checking for a type preserving transformation is very strict. It should be in terms of other type preserving transformations, or match the input term to a specific type and return a term from that specific type. Is Type \u00b6 is ( $ Sort ) Given the definition of a term sort S , the is(S) strategy checks whether a term is of sort S and fails if that is not the case. Example. The strategy <is(Exp)>t checks that term t conforms to the signature of sort Exp . The is(S) strategy uses the same mechanism as type casts for checking a term type at run time. References \u00b6 Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"Types"},{"location":"references/stratego/types/#types","text":"Terms provide a generic, untyped format to represent tree-structured data. Stratego transformations can transform such data, but require at least that the arities of term constructors that are used in rules are declared. Starting with Stratego 2, the types of terms and term transformations may be declared and checked in more detail 1 .","title":"Types"},{"location":"references/stratego/types/#signatures","text":"signature $ SigSection * A signature declares the shape of well-formed terms using sort declarations, constructor declarations, and overlays.","title":"Signatures"},{"location":"references/stratego/types/#sorts","text":"sorts $ Sort * A sort is determined by an identifier and optionally has arguments. A sort (or type ) identifies a collection of well-formed terms. Convention: Sort identifiers start with a capital letter.","title":"Sorts"},{"location":"references/stratego/types/#constructors","text":"constructors $ ConstructorDecl A constructor declaration has the form $ Constructor : $ Sort * ... * $ Sort - > Decl and declares a constructor name, the sorts of the argument terms, and the sort of the constructed term. Convention: Constructor identifiers start with a capital letter. Example: The constructor declaration Assign : ID * Exp - > Stmt defines the constructor Assign with input sorts ID and Exp and output sort Stmt . Thus, if x and e are terms of sort ID and Exp , respectively, then Assign(x, e) is a term of sort Stmt . When the list of argument sorts is empty the arrow can be omitted: $ Constructor : Decl Example: The constructor declaration True : Bool defines that True() is a term of sort Bool . Note that the parentheses are required. The term True is a variable. The Stratego1 compiler only checks the arity of constructor applications against the signature. The Stratego2 compiler uses signature definitions to type check code if it has been given a type signature.","title":"Constructors"},{"location":"references/stratego/types/#injections","text":"An injection is a constructor without name and with a single argument. : $ Sort - > $ Sort Injections include an entire type as a subtype of another type without cluttering the tree structure.","title":"Injections"},{"location":"references/stratego/types/#list-type","text":"List ( $ Sort ) The type constructor List(_) is for typing homogenous lists. Exmample. The type List(Exp) represents lists of expressions Exp .","title":"List Type"},{"location":"references/stratego/types/#polymorphic-types","text":"Stratego2 supports user-defined polymorphic types. That is, sorts can have parameters. For example, the following signature defines the type of priority queues, polymorphic in the carrier type, in which the priority is determined by the length of the list. signature sorts PrioQ ( * ) constructors NilQ : PrioQ ( a ) ConsQ : a * int * List ( a ) * PrioQ ( a ) - > PrioQ ( a )","title":"Polymorphic Types"},{"location":"references/stratego/types/#tuple-type","text":"( $ TermType * ... * $ TermType ) Tuple terms can be typed in strategy types. Currently, tuple types cannot be used in term signatures.","title":"Tuple Type"},{"location":"references/stratego/types/#overlays","text":"overlays $ OverlayDef An overlay defines a term abbreviation. An overlay definition has the form $ Constructor ( $ ID , ... , $ ID ) = $ Term and defines that applications of the constructor should be expanded to the term.","title":"Overlays"},{"location":"references/stratego/types/#transformation-types","text":"$ Id ( $ StrategyType , ... | $ TermType , ... ) :: $ TermType - > $ TermType A transformation type defines the signature of a transformation with name $Id with the types of its strategy arguments and term arguments, the type of the 'current term' to which the transformation is applied, and the type of the term that is returned, if the transformation succeeds. Transformation types are declared in rules or strategies sections. $ Id ( $ StrategyType , ... ) :: $ TermType - > $ TermType When a transformation only has strategy parameters, the bar can be left out. $ Id :: $ TermType - > $ TermType When a transformation also has no strategy parameters, the parentheses can be left out as well.","title":"Transformation Types"},{"location":"references/stratego/types/#strategy-type","text":"$ TermType - > $ TermType The type of a transformation/strategy argument is an arrow from a term type to a term type. Note that transformation strategies cannot be reified as terms.","title":"Strategy Type"},{"location":"references/stratego/types/#type-dynamic","text":"? Type dynamic , written ? , represents the unknown type. Stratego2 is a gradually typed language in order to facilitate the migration from (mostly) untyped Stratego1 code to typed Stratego2 code. Furthermore, some patterns in Stratego cannot be typed statically. When used as a strategy type ? represents ? -> ? .","title":"Type Dynamic"},{"location":"references/stratego/types/#type-casts","text":"///syntax of casts Todo syntactic form Gradual type systems allow a term with the dynamic type to be used in any place where a static type is required. Stratego2 will insert a type cast at such a point to check at run time that the term is type-correct. This way, a Stratego program halts execution in predictable places when a run time type error occurs. There can be no run time type errors in fully statically typed code either, only at the boundary between dynamically and statically typed code.","title":"Type Casts"},{"location":"references/stratego/types/#type-preserving","text":"TP A type preserving transformation transforms any type to itself (or fails). In signatures, a type preserving transformation is indicated with TP . Example. The type declaration topdown ( s : TP ) :: TP declares that the topdown strategy is type preserving if its argument strategy is. The type-checking for a type preserving transformation is very strict. It should be in terms of other type preserving transformations, or match the input term to a specific type and return a term from that specific type.","title":"Type Preserving"},{"location":"references/stratego/types/#is-type","text":"is ( $ Sort ) Given the definition of a term sort S , the is(S) strategy checks whether a term is of sort S and fails if that is not the case. Example. The strategy <is(Exp)>t checks that term t conforms to the signature of sort Exp . The is(S) strategy uses the same mechanism as type casts for checking a term type at run time.","title":"Is Type"},{"location":"references/stratego/types/#references","text":"Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13 th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020 , 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928 , doi:10.1145/3426425.3426928 . \u21a9","title":"References"},{"location":"references/syntax/","text":"SDF3 \u00b6 SDF3 is the meta-language in Spoofax for syntax definition. A syntax definition is structured as a collection of modules , which may import each other. Symbols are the building blocks of productions . Productions are defined for lexical , context-free , or kernel syntax. Start symbols indicate the entry point of a syntax definition. SDF3 automatically generates a pretty-printer for template -based productions. Grammars can be disambiguated by means of rejects, priorities, associativity, and restrictions. SDF3 provides additional constructs for the definition of layout-sensitivite languages. Permissive grammars are automatically generated for error-recovery parsing. Handwritten recovery rules can be added to tweak recovery behavior. Several aspects related to syntax definition and parsing can be configured in the metaborg.yaml. file. Source \u00b6 The sources of the SDF3 implementation can be found at https://github.com/metaborg/sdf/tree/master/org.metaborg.meta.lang.template : The SDF3 language implementation (SDF3 was called TemplateLang before and it has not been renamed everywhere yet)","title":"SDF3"},{"location":"references/syntax/#sdf3","text":"SDF3 is the meta-language in Spoofax for syntax definition. A syntax definition is structured as a collection of modules , which may import each other. Symbols are the building blocks of productions . Productions are defined for lexical , context-free , or kernel syntax. Start symbols indicate the entry point of a syntax definition. SDF3 automatically generates a pretty-printer for template -based productions. Grammars can be disambiguated by means of rejects, priorities, associativity, and restrictions. SDF3 provides additional constructs for the definition of layout-sensitivite languages. Permissive grammars are automatically generated for error-recovery parsing. Handwritten recovery rules can be added to tweak recovery behavior. Several aspects related to syntax definition and parsing can be configured in the metaborg.yaml. file.","title":"SDF3"},{"location":"references/syntax/#source","text":"The sources of the SDF3 implementation can be found at https://github.com/metaborg/sdf/tree/master/org.metaborg.meta.lang.template : The SDF3 language implementation (SDF3 was called TemplateLang before and it has not been renamed everywhere yet)","title":"Source"},{"location":"references/syntax/configuration/","text":"Configuration \u00b6 When using SDF3 inside Spoofax, several configuration options are relevant. They allow using the new parser generator, specifying the shape of completion placeholders, or disable SDF altogether. These options should be specified in the metaborg.yaml file. For example, to disable SDF for the current project, use: language : sdf : enabled : false SDF3 allows generating placeholders for code completion. The default \"shape\" of placeholders is $Symbol . However, it is possible to tweak this shape using the configuration below (the configuration for suffix is optional): language : sdf : placeholder : prefix : \"$\" suffix : \"$\" Currently, the path to the parse table is specified in the Syntax.esv file, commonly as table: target/metaborg/sdf.tbl . When the ESV file does not contain this entry, it is also possible to specify the path to the parse table in the metaborg.yaml file. This is useful when testing an external parse table, or using a parse table different from the one being generated in the project. In the example below, the table is loaded from the path tables/sdf.tbl . The same can be applied to the parse table used for code completion. language : sdf : parse-table : \"tables/sdf.tbl\" completion-parse-table : \"tables/sdf-completions.tbl\" In a Spoofax project, it is also possible to use SDF2 instead of SDF3. This enables SDF2 tools such as the SDF2 parenthesizer, signature generator, etc. For example: language : sdf : version : sdf2 By default SDF3 compilation works by generating SDF2 files, and depending on the SDF2 toolchain. However, a new (and experimental) parse table generator can be selected by writing: language : sdf : sdf2table : java This configuration disables the SDF2 generation, and may cause problems when defining grammars to use concrete syntax, since this feature is not supported yet by SDF3. However, the java parse table generator supports Unicode, whereas SDF2 generation does not. Furthermore, dynamic can be used instead of java , to enable lazy parse table generation, where the parse table is generated while the program is parsed. A namespaced grammar can be generated automatically from an SDF3 grammar. This namespacing is done by adding the language name to all module names and sort names. The generated grammar is put in src-gen/syntax . The configuration to enable this is: language : sdf : generate-namespaced : true Note that namespacing doesn't not handle imports of grammar files from other projects very well. JSGLR version \u00b6 An experimental new version of the SGLR parser implementation is available: JSGLR2. It supports parsing, imploding and syntax highlighting. Error reporting, recovery and completions are currently not supported. It can be enabled with: language : sdf : jsglr-version : v2 There are some extensions of JSGLR2 available. To use them, change the jsglr-version by replacing v2 with one of the following: data-dependent : Data-dependent JSGLR2 solves deep priority conflicts using data-dependent parsing, which does not require duplicating the grammar productions. incremental : Incremental JSGLR2 reuses previous parse results to speed up parsing. layout-sensitive : Layout-sensitive JSGLR2, see Layout Sensitivity . recovery : JSGLR2 with recovery tries to recover from parse errors. This extension is experimental. recovery-incremental : Incremental JSGLR2 with recovery. This extension is experimental. JSGLR2 logging \u00b6 Logging is available for JSGLR2. It can be enabled with: language : sdf : jsglr2-logging : all Since logging all parsing events is quite verbose, several other scopes are available in addition to the all option: none : Log nothing (default). minimal : Only log the start and end of a parse, including a measurement of total parse time (including imploding and tokenization). parsing : Log all standard parsing events (such as stack and parse forest operations, action execution, etc.) but no variant-specific events (e.g. related to recovery). recovery : Log the recovery iterations and the recovery productions that are applied.","title":"Configuration"},{"location":"references/syntax/configuration/#configuration","text":"When using SDF3 inside Spoofax, several configuration options are relevant. They allow using the new parser generator, specifying the shape of completion placeholders, or disable SDF altogether. These options should be specified in the metaborg.yaml file. For example, to disable SDF for the current project, use: language : sdf : enabled : false SDF3 allows generating placeholders for code completion. The default \"shape\" of placeholders is $Symbol . However, it is possible to tweak this shape using the configuration below (the configuration for suffix is optional): language : sdf : placeholder : prefix : \"$\" suffix : \"$\" Currently, the path to the parse table is specified in the Syntax.esv file, commonly as table: target/metaborg/sdf.tbl . When the ESV file does not contain this entry, it is also possible to specify the path to the parse table in the metaborg.yaml file. This is useful when testing an external parse table, or using a parse table different from the one being generated in the project. In the example below, the table is loaded from the path tables/sdf.tbl . The same can be applied to the parse table used for code completion. language : sdf : parse-table : \"tables/sdf.tbl\" completion-parse-table : \"tables/sdf-completions.tbl\" In a Spoofax project, it is also possible to use SDF2 instead of SDF3. This enables SDF2 tools such as the SDF2 parenthesizer, signature generator, etc. For example: language : sdf : version : sdf2 By default SDF3 compilation works by generating SDF2 files, and depending on the SDF2 toolchain. However, a new (and experimental) parse table generator can be selected by writing: language : sdf : sdf2table : java This configuration disables the SDF2 generation, and may cause problems when defining grammars to use concrete syntax, since this feature is not supported yet by SDF3. However, the java parse table generator supports Unicode, whereas SDF2 generation does not. Furthermore, dynamic can be used instead of java , to enable lazy parse table generation, where the parse table is generated while the program is parsed. A namespaced grammar can be generated automatically from an SDF3 grammar. This namespacing is done by adding the language name to all module names and sort names. The generated grammar is put in src-gen/syntax . The configuration to enable this is: language : sdf : generate-namespaced : true Note that namespacing doesn't not handle imports of grammar files from other projects very well.","title":"Configuration"},{"location":"references/syntax/configuration/#jsglr-version","text":"An experimental new version of the SGLR parser implementation is available: JSGLR2. It supports parsing, imploding and syntax highlighting. Error reporting, recovery and completions are currently not supported. It can be enabled with: language : sdf : jsglr-version : v2 There are some extensions of JSGLR2 available. To use them, change the jsglr-version by replacing v2 with one of the following: data-dependent : Data-dependent JSGLR2 solves deep priority conflicts using data-dependent parsing, which does not require duplicating the grammar productions. incremental : Incremental JSGLR2 reuses previous parse results to speed up parsing. layout-sensitive : Layout-sensitive JSGLR2, see Layout Sensitivity . recovery : JSGLR2 with recovery tries to recover from parse errors. This extension is experimental. recovery-incremental : Incremental JSGLR2 with recovery. This extension is experimental.","title":"JSGLR version"},{"location":"references/syntax/configuration/#jsglr2-logging","text":"Logging is available for JSGLR2. It can be enabled with: language : sdf : jsglr2-logging : all Since logging all parsing events is quite verbose, several other scopes are available in addition to the all option: none : Log nothing (default). minimal : Only log the start and end of a parse, including a measurement of total parse time (including imploding and tokenization). parsing : Log all standard parsing events (such as stack and parse forest operations, action execution, etc.) but no variant-specific events (e.g. related to recovery). recovery : Log the recovery iterations and the recovery productions that are applied.","title":"JSGLR2 logging"},{"location":"references/syntax/context-free-syntax/","text":"Context-Free Syntax \u00b6 The context-free syntax describes the more high-level syntactic structure of sentences in a language. A context-free syntax contains a list of productions. Elements of the right-hand side of a context-free production are pre-processed in a normalization step before parser generation that adds the LAYOUT? symbol between any two symbols. Context-free syntax has the form: context-free syntax $Production* An example production rule: context-free syntax Block.Block = \"{\" Statement* \"}\" SDF3 automatically allows for layout to be present between the symbols of a rule. This means that a fragment such as: { } will still be recognized as a block (assuming that the newline and line-feed characters are defined as layout).","title":"Context-Free Syntax"},{"location":"references/syntax/context-free-syntax/#context-free-syntax","text":"The context-free syntax describes the more high-level syntactic structure of sentences in a language. A context-free syntax contains a list of productions. Elements of the right-hand side of a context-free production are pre-processed in a normalization step before parser generation that adds the LAYOUT? symbol between any two symbols. Context-free syntax has the form: context-free syntax $Production* An example production rule: context-free syntax Block.Block = \"{\" Statement* \"}\" SDF3 automatically allows for layout to be present between the symbols of a rule. This means that a fragment such as: { } will still be recognized as a block (assuming that the newline and line-feed characters are defined as layout).","title":"Context-Free Syntax"},{"location":"references/syntax/disambiguation/","text":"Disambiguation \u00b6 The semantics of SDF3 can be seen as two-staged. First, the grammar generates all possible derivations. Second, the disambiguation constructs remove a number of derivations that are not valid. Note that SDF3 actually performs some disambiguation both when generating the parse table as during parsing. Rejections \u00b6 Rejections filter derivations. The semantics of a rejection is that the set of valid derivations for the left-hand side of the production will not contain the construction described on the right-hand side. In other words, the language defined by the sort on the left-hand side has become smaller, removing all the constructions generated by the rule on the right-hand side. Disambiguation by reject occurs at parse time (mostly). A rule can be marked as rejected by using the attribute {reject} after the rule: $Sort = ... {reject} The {reject} attribute works well for lexical rejections, especially keyword reservation in the form of productions like: ID = \"keyword\" {reject} Preferences \u00b6 The preferences mechanism is another disambiguation filter that provides a post parse filter to parse forests. The attributes prefer and avoid are the only disambiguation constructs that compare alternative derivations after parsing. Warning prefer and avoid are deprecated and will be removed in a future version of Spoofax. The following definition assumes that derivations are represented using parse forests with \"packaged ambiguity nodes\". This means that whenever in a derivation there is a choice for several sub-derivations, at that point a special choice node (ambiguity constructor) is placed with all alternatives as children. We assume here that the ambiguity constructor is always placed at the location where a choice is needed, and not higher (i.e. a minimal parse forest representation). The preference mechanism compares the top nodes of each alternative: All alternative derivations that have avoid at the top node will be removed, but only if other alternatives derivations are there that do not have avoid at the top node. If there are derivations that have prefer at the top node, all other derivations that do not have prefer at the top node will be removed. The preference attribute can be used to handle the case when two productions can parse the same input. Here is an example: Exp.FunctionApp = <<Expr> <Expr*>> Exp.Constructor = <<ID> <Expr>> {prefer} Priorities \u00b6 Priorities are one of SDF3's most often used disambiguation constructs. A priority section defines the relative priorities between productions. Priorities are a powerful disambiguation construct because it occurs at parse generation time. The idea behind the semantics of priorities is that productions with a higher priority \"bind stronger\" than productions with a lower priority. The essence of the priority disambiguation construct is that certain parse trees are removed from the \"forest\" (the set of all possible parse trees that can be derived from a segment of code). The basic priority syntax looks like this: context-free priorities $ProductionRef > $ProductionRef Where $ProductionRef> can either be $Sort.$Constructor or the entire production itself. Several priorities in a priority grammar are separated by commas. If more productions have the same priority they may be grouped between curly braces on each side of the > sign. context-free priorities {$ProductionRef $ProductionRef} > $ProductionRef, $ProductionRef > $ProductionRef By default, the priority relation is automatically transitively closed (i.e. if A > B and B > C then A > C). To specify a non-transitive priority relation it is necessary to include a dot before the > sign ( .> ). SDF3 provides safe disambiguation, meaning that priority relations only remove ambiguous derivations. Furthermore, SDF3 also allows tree filtering by means of indexed priorities such as: context-free priorities $ProductionRef $Index > $ProductionRef where the symbol at position $Index (starting with 0) in the first production should not derive the second production. An example defining priorities for the addition, subtraction and multiplication operators is listed below. Because addition and subtraction have the same priority, the are grouped together between brackets. context-free priorities {Exp.Times} > {Exp.Plus Exp.Minus} Associativity \u00b6 Like with priorities, the essence of the associativity attribute is that certain parse trees are removed from the \"forest\". The left associativity attribute on a production P filters all occurrences of P as a direct child of P in the right-most argument. This implies that left is only effective on productions that are recursive on the right (as in A B C -> C ). The right associativity attribute on a production P filters all occurrences of P as a direct child of P in the left-most argument. This implies that right is only effective on productions that are recursive on the left ( as in C A B -> C ). The non-assoc associativity attribute on a production P filters all occurrences of P as a direct child of P in any argument. This implement that non-assoc is only effective if a production is indeed recursive (as in A C B -> C ). The assoc attribute means the same as left Associativity declarations occur in two places in SDF3. The first is as production attributes. The second is as associativity declarations in priority groups. An example on how to mention associativity as a production attribute is given below: Exp.Plus = <<Exp> + <Exp>> {left} In priority groups, the associativity has the same semantics as the associativity attributes, except that the filter refers to more nested productions instead of a recursive nesting of one production. The group associativity attribute works pairwise and commutative on all combinations of productions in the group. If there is only one element in the group the attribute is reflexive, otherwise it is not reflexive. context-free priorities {left: Exp.Times} > {left: Exp.Plus Exp.Minus} Restrictions \u00b6 The notion of restrictions enables the formulation of lexical disambiguation strategies. Examples are \"shift before reduce\" and \"longest match\". A restriction filters applications of productions for certain non-terminals if the following character (lookahead) is in a certain class. The result is that specific symbols may not be followed by a character from a given character class. A lookahead may consist of more than one character class (multiple lookahead). Restrictions come in two flavors: lexical restrictions that apply to lexical non-terminals context-free restrictions that apply to context-free non-terminals. The general form of a restriction is: $Symbol+ -/- $Lookahead The semantics of a restriction is to remove all derivations that produce a certain $Symbol . The condition for this removal is that the derivation tree for that symbol is followed immediately by something that matches the lookahead declaration. Note that to be able to check this condition, one must look past derivations that produce the empty language, until the characters to the right of the filtered symbol are found. Also, for finding multiple lookahead matches, one must ignore nullable sub-trees that may occur in the middle of the matched lookahead. In case of lexical restrictions $Symbol may be either a literal or sort. In case of context-free restrictions only a sort or symbol is allowed. The restriction operator -/- should be read as may not be followed by. Before the restriction operator -/- a list of symbols is given for which the restriction holds. As an example, the following restriction rule implements the \u201clongest match\u201d policy: an identifier can not be followed by an alpha-numeric character. ID -/- [a-zA-Z0-9\\_]","title":"Disambiguation"},{"location":"references/syntax/disambiguation/#disambiguation","text":"The semantics of SDF3 can be seen as two-staged. First, the grammar generates all possible derivations. Second, the disambiguation constructs remove a number of derivations that are not valid. Note that SDF3 actually performs some disambiguation both when generating the parse table as during parsing.","title":"Disambiguation"},{"location":"references/syntax/disambiguation/#rejections","text":"Rejections filter derivations. The semantics of a rejection is that the set of valid derivations for the left-hand side of the production will not contain the construction described on the right-hand side. In other words, the language defined by the sort on the left-hand side has become smaller, removing all the constructions generated by the rule on the right-hand side. Disambiguation by reject occurs at parse time (mostly). A rule can be marked as rejected by using the attribute {reject} after the rule: $Sort = ... {reject} The {reject} attribute works well for lexical rejections, especially keyword reservation in the form of productions like: ID = \"keyword\" {reject}","title":"Rejections"},{"location":"references/syntax/disambiguation/#preferences","text":"The preferences mechanism is another disambiguation filter that provides a post parse filter to parse forests. The attributes prefer and avoid are the only disambiguation constructs that compare alternative derivations after parsing. Warning prefer and avoid are deprecated and will be removed in a future version of Spoofax. The following definition assumes that derivations are represented using parse forests with \"packaged ambiguity nodes\". This means that whenever in a derivation there is a choice for several sub-derivations, at that point a special choice node (ambiguity constructor) is placed with all alternatives as children. We assume here that the ambiguity constructor is always placed at the location where a choice is needed, and not higher (i.e. a minimal parse forest representation). The preference mechanism compares the top nodes of each alternative: All alternative derivations that have avoid at the top node will be removed, but only if other alternatives derivations are there that do not have avoid at the top node. If there are derivations that have prefer at the top node, all other derivations that do not have prefer at the top node will be removed. The preference attribute can be used to handle the case when two productions can parse the same input. Here is an example: Exp.FunctionApp = <<Expr> <Expr*>> Exp.Constructor = <<ID> <Expr>> {prefer}","title":"Preferences"},{"location":"references/syntax/disambiguation/#priorities","text":"Priorities are one of SDF3's most often used disambiguation constructs. A priority section defines the relative priorities between productions. Priorities are a powerful disambiguation construct because it occurs at parse generation time. The idea behind the semantics of priorities is that productions with a higher priority \"bind stronger\" than productions with a lower priority. The essence of the priority disambiguation construct is that certain parse trees are removed from the \"forest\" (the set of all possible parse trees that can be derived from a segment of code). The basic priority syntax looks like this: context-free priorities $ProductionRef > $ProductionRef Where $ProductionRef> can either be $Sort.$Constructor or the entire production itself. Several priorities in a priority grammar are separated by commas. If more productions have the same priority they may be grouped between curly braces on each side of the > sign. context-free priorities {$ProductionRef $ProductionRef} > $ProductionRef, $ProductionRef > $ProductionRef By default, the priority relation is automatically transitively closed (i.e. if A > B and B > C then A > C). To specify a non-transitive priority relation it is necessary to include a dot before the > sign ( .> ). SDF3 provides safe disambiguation, meaning that priority relations only remove ambiguous derivations. Furthermore, SDF3 also allows tree filtering by means of indexed priorities such as: context-free priorities $ProductionRef $Index > $ProductionRef where the symbol at position $Index (starting with 0) in the first production should not derive the second production. An example defining priorities for the addition, subtraction and multiplication operators is listed below. Because addition and subtraction have the same priority, the are grouped together between brackets. context-free priorities {Exp.Times} > {Exp.Plus Exp.Minus}","title":"Priorities"},{"location":"references/syntax/disambiguation/#associativity","text":"Like with priorities, the essence of the associativity attribute is that certain parse trees are removed from the \"forest\". The left associativity attribute on a production P filters all occurrences of P as a direct child of P in the right-most argument. This implies that left is only effective on productions that are recursive on the right (as in A B C -> C ). The right associativity attribute on a production P filters all occurrences of P as a direct child of P in the left-most argument. This implies that right is only effective on productions that are recursive on the left ( as in C A B -> C ). The non-assoc associativity attribute on a production P filters all occurrences of P as a direct child of P in any argument. This implement that non-assoc is only effective if a production is indeed recursive (as in A C B -> C ). The assoc attribute means the same as left Associativity declarations occur in two places in SDF3. The first is as production attributes. The second is as associativity declarations in priority groups. An example on how to mention associativity as a production attribute is given below: Exp.Plus = <<Exp> + <Exp>> {left} In priority groups, the associativity has the same semantics as the associativity attributes, except that the filter refers to more nested productions instead of a recursive nesting of one production. The group associativity attribute works pairwise and commutative on all combinations of productions in the group. If there is only one element in the group the attribute is reflexive, otherwise it is not reflexive. context-free priorities {left: Exp.Times} > {left: Exp.Plus Exp.Minus}","title":"Associativity"},{"location":"references/syntax/disambiguation/#restrictions","text":"The notion of restrictions enables the formulation of lexical disambiguation strategies. Examples are \"shift before reduce\" and \"longest match\". A restriction filters applications of productions for certain non-terminals if the following character (lookahead) is in a certain class. The result is that specific symbols may not be followed by a character from a given character class. A lookahead may consist of more than one character class (multiple lookahead). Restrictions come in two flavors: lexical restrictions that apply to lexical non-terminals context-free restrictions that apply to context-free non-terminals. The general form of a restriction is: $Symbol+ -/- $Lookahead The semantics of a restriction is to remove all derivations that produce a certain $Symbol . The condition for this removal is that the derivation tree for that symbol is followed immediately by something that matches the lookahead declaration. Note that to be able to check this condition, one must look past derivations that produce the empty language, until the characters to the right of the filtered symbol are found. Also, for finding multiple lookahead matches, one must ignore nullable sub-trees that may occur in the middle of the matched lookahead. In case of lexical restrictions $Symbol may be either a literal or sort. In case of context-free restrictions only a sort or symbol is allowed. The restriction operator -/- should be read as may not be followed by. Before the restriction operator -/- a list of symbols is given for which the restriction holds. As an example, the following restriction rule implements the \u201clongest match\u201d policy: an identifier can not be followed by an alpha-numeric character. ID -/- [a-zA-Z0-9\\_]","title":"Restrictions"},{"location":"references/syntax/kernel-syntax/","text":"Kernel Syntax \u00b6 The rules from context-free and lexical syntax are translated into kernel syntax by the SDF3 normalizer. When writing kernel syntax, one has more control over the layout between symbols of a production. As part of normalization, among other things, SDF3 renames each symbol in the lexical syntax to include the suffix -LEX and each symbol in the context-free syntax to include the suffix -CF . For example, the two productions lexical syntax BinaryConst = [0-1]+ context-free syntax Block.Block = \"{\" Statement* \"}\" written in kernel syntax look like syntax Block-CF.Block = \"{\" LAYOUT?-CF Statement*-CF LAYOUT?-CF \"}\" BinaryConst-LEX = [0-1]+ Literals and character classes are lexical by definition, thus they do not need any suffix. Note that each symbol in kernel syntax is uniquely identified by its full name including -CF and -LEX . That is, two symbols named Block-CF and Block are different, if both occur in kernel syntax. However, Block-CF is the same symbol as Block if the latter appears in a context-free syntax section. As mentioned before, layout can only occur in between symbols if explicitly specified. For example, the production syntax Block-CF.Block = \"{\" Statement*-CF LAYOUT?-CF \"}\" does not allow layout to occur in between the opening bracket and the list of statements. This means that a fragment such as: { x = 1; } would not be recognized as a block.","title":"Kernel Syntax"},{"location":"references/syntax/kernel-syntax/#kernel-syntax","text":"The rules from context-free and lexical syntax are translated into kernel syntax by the SDF3 normalizer. When writing kernel syntax, one has more control over the layout between symbols of a production. As part of normalization, among other things, SDF3 renames each symbol in the lexical syntax to include the suffix -LEX and each symbol in the context-free syntax to include the suffix -CF . For example, the two productions lexical syntax BinaryConst = [0-1]+ context-free syntax Block.Block = \"{\" Statement* \"}\" written in kernel syntax look like syntax Block-CF.Block = \"{\" LAYOUT?-CF Statement*-CF LAYOUT?-CF \"}\" BinaryConst-LEX = [0-1]+ Literals and character classes are lexical by definition, thus they do not need any suffix. Note that each symbol in kernel syntax is uniquely identified by its full name including -CF and -LEX . That is, two symbols named Block-CF and Block are different, if both occur in kernel syntax. However, Block-CF is the same symbol as Block if the latter appears in a context-free syntax section. As mentioned before, layout can only occur in between symbols if explicitly specified. For example, the production syntax Block-CF.Block = \"{\" Statement*-CF LAYOUT?-CF \"}\" does not allow layout to occur in between the opening bracket and the list of statements. This means that a fragment such as: { x = 1; } would not be recognized as a block.","title":"Kernel Syntax"},{"location":"references/syntax/layout-sensitivity/","text":"Layout Sensitivity \u00b6 SDF3 supports definition of layout sensitive syntax by means of low-level layout constraints and high-level layout declarations . Note If you want to use layout constraints or layout declarations, you should specify the jsglr-version: layout-sensitive parameter for SDF3, see configuration . Layout Constraints \u00b6 While we haven't covered layout constraints in this documentation, the paper of Erdweg et al. 1 describes the concepts. Layout Declarations \u00b6 In the paper of Erdweg et al. 1 , the authors describe layout constraints in terms of restrictions involving the position of the subtree involved in the constraint ( 0 , 1 , ...), token selectors ( first , left , last and right ), and position selectors as lines and columns ( line and col ). This mechanism allows writing layout constraints to express alignment, offside and indentation rules, but writing such constraints is rather cumbersome and error prone. Alternatively, one may write layout constraints using layout declarations , which are more declarative specifications and abstract over lines, columns and token selectors as the original layout constraints from the Erdweg et al. paper 1 . Tree selectors \u00b6 To specify which trees should be subject to a layout constraint, one may use: tree positions, SDF3 labeled non-terminals, or unique literals that occurs in the production. For example: context-free syntax Stmt.IfElse = \"if\" Exp \"then\" Stmts \"else\" else:Stmts {layout( indent \"if\" 3, else && align 3 else && align \"if\" \"else\" )} In the layout constraint for the production above, else refers to the tree for the labeled non-terminal else:Stmts , \"if\" refers to the tree corresponding to the \"if\" literal and the number 3 correspond to the tree at position 3 in the parse tree (starting at 0, ignoring trees for LAYOUT? ). align \u00b6 The layout constraint layout(align x y1, ..., yn) specifies that the trees indicated by the tree selectors yi should be aligned with the tree indicated by the tree selector x , i.e., all these trees should start in the same column. For example, if we consider the production above, the following program is correct according to the align constraints: if x < 0 then \u00b7\u00b7 x = 0 else \u00b7\u00b7 y = 1 Whereas, the following program is incorrect because neither the if and else keyword align ( align \"if\" \"else\" ), nor the statements in the branches ( align 3 else ): if x < 0 then \u00b7\u00b7 x = 0 \u00b7 else \u00b7\u00b7\u00b7 y = 1 align-list \u00b6 The constraint align-list can be used to indicate that all subtrees within a list should be aligned. That is, a constraint layout(align-list x) , where x is a tree selector for a list subtree, can be used to enforce such constraint. For example, consider the following production and its layout constraint: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( align-list then )} This constraint indicates that statements inside the list should be aligned. Therefore, the following program is correct according to this constraint: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 And the following program is invalid, as the second statement is misaligned: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 offside \u00b6 The offside rule is very common in layout-sensitive languages. It states that all lines after the first one should be further to the right compared to the first line. For a description of how the offside rule can be modelled with layout constraints, refer to Erdweg et al. 1 . An example of a declarative specification of the offside rule can be seen in the production below: context-free syntax Stmt.Assign = <<ID> = <Exp>> {layout(offside 3)} The layout constraint specifies that when the expression in the statement spams multiple lines, all following lines should be indented with respect to the column where the expression started. For example, the following program is valid according to this constraint: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7\u00b7 + 2 However, the following program is not valid, as the second line of the expression starts at the same column as the first line: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7 + 2 Note that if the expression is written on a single line, the constraint is also verified. That is, the following program successfully parses: x = 4 * 10 + 2 It is also possible to use the offside relation on different trees. For example, consider the constraint in the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( offside \"if\" then )} This constraint states that all lines (except the first) of the statements in the then branch should be indented with respect to the if literal. Thus, the following program is invalid according to this layout constraint, because the statement x = 2 should be indented with relation to the topmost if . if x < 0 then \u00b7\u00b7 if y < 0 then x = 2 In general, an offside constraint involving more than a single tree is combined with indent constraint to enforce that the column of the first and all subsequent lines should be indented. indent \u00b6 An indent constraint indicates that the column of the first line of a certain tree should be further to the right with respect to another tree. For example, consider the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then )} This constraint indicates that the first line of the list of statements should be indented with respect to the if literal. Thus, according to this constraint the following program is valid: if x < 0 then \u00b7\u00b7 x = 2 Note that if the list of statements in the then branch spams multiple lines, the constraint does not apply to its subsequent lines. For example, consider the following program: if x < 0 then \u00b7\u00b7 x = 2 + 10 * 4 y = 3 This program is still valid, since the column of the first line of the first assignment is indented with respect to the if literal. To indicate that the first and all subsequent lines should be indented, an offside constraint should also be included. context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then && offside \"if\" then )} With this constraint, the remainder of the expression * 4 should also be further to the right compared to the \"if\" literal. The following program is correct according to these two constraints, since the second line of the first assignment and the second assignment are also indented with respect to the if literal: if x < 0 then \u00b7\u00b7 x = 2 + 10 \u00b7 * 4 \u00b7 y = 3 Finally, all these layout declarations can be ignored by the parser and used only when generating the pretty-printer. To do that, prefix the constraint with pp- writing, for example, pp-offside or pp-align . Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14 . \u21a9 \u21a9 \u21a9 \u21a9","title":"Layout Sensitivity"},{"location":"references/syntax/layout-sensitivity/#layout-sensitivity","text":"SDF3 supports definition of layout sensitive syntax by means of low-level layout constraints and high-level layout declarations . Note If you want to use layout constraints or layout declarations, you should specify the jsglr-version: layout-sensitive parameter for SDF3, see configuration .","title":"Layout Sensitivity"},{"location":"references/syntax/layout-sensitivity/#layout-constraints","text":"While we haven't covered layout constraints in this documentation, the paper of Erdweg et al. 1 describes the concepts.","title":"Layout Constraints"},{"location":"references/syntax/layout-sensitivity/#layout-declarations","text":"In the paper of Erdweg et al. 1 , the authors describe layout constraints in terms of restrictions involving the position of the subtree involved in the constraint ( 0 , 1 , ...), token selectors ( first , left , last and right ), and position selectors as lines and columns ( line and col ). This mechanism allows writing layout constraints to express alignment, offside and indentation rules, but writing such constraints is rather cumbersome and error prone. Alternatively, one may write layout constraints using layout declarations , which are more declarative specifications and abstract over lines, columns and token selectors as the original layout constraints from the Erdweg et al. paper 1 .","title":"Layout Declarations"},{"location":"references/syntax/layout-sensitivity/#tree-selectors","text":"To specify which trees should be subject to a layout constraint, one may use: tree positions, SDF3 labeled non-terminals, or unique literals that occurs in the production. For example: context-free syntax Stmt.IfElse = \"if\" Exp \"then\" Stmts \"else\" else:Stmts {layout( indent \"if\" 3, else && align 3 else && align \"if\" \"else\" )} In the layout constraint for the production above, else refers to the tree for the labeled non-terminal else:Stmts , \"if\" refers to the tree corresponding to the \"if\" literal and the number 3 correspond to the tree at position 3 in the parse tree (starting at 0, ignoring trees for LAYOUT? ).","title":"Tree selectors"},{"location":"references/syntax/layout-sensitivity/#align","text":"The layout constraint layout(align x y1, ..., yn) specifies that the trees indicated by the tree selectors yi should be aligned with the tree indicated by the tree selector x , i.e., all these trees should start in the same column. For example, if we consider the production above, the following program is correct according to the align constraints: if x < 0 then \u00b7\u00b7 x = 0 else \u00b7\u00b7 y = 1 Whereas, the following program is incorrect because neither the if and else keyword align ( align \"if\" \"else\" ), nor the statements in the branches ( align 3 else ): if x < 0 then \u00b7\u00b7 x = 0 \u00b7 else \u00b7\u00b7\u00b7 y = 1","title":"align"},{"location":"references/syntax/layout-sensitivity/#align-list","text":"The constraint align-list can be used to indicate that all subtrees within a list should be aligned. That is, a constraint layout(align-list x) , where x is a tree selector for a list subtree, can be used to enforce such constraint. For example, consider the following production and its layout constraint: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( align-list then )} This constraint indicates that statements inside the list should be aligned. Therefore, the following program is correct according to this constraint: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2 And the following program is invalid, as the second statement is misaligned: if x < 0 then \u00b7\u00b7 x = 0 \u00b7\u00b7\u00b7 y = 4 \u00b7\u00b7 z = 2","title":"align-list"},{"location":"references/syntax/layout-sensitivity/#offside","text":"The offside rule is very common in layout-sensitive languages. It states that all lines after the first one should be further to the right compared to the first line. For a description of how the offside rule can be modelled with layout constraints, refer to Erdweg et al. 1 . An example of a declarative specification of the offside rule can be seen in the production below: context-free syntax Stmt.Assign = <<ID> = <Exp>> {layout(offside 3)} The layout constraint specifies that when the expression in the statement spams multiple lines, all following lines should be indented with respect to the column where the expression started. For example, the following program is valid according to this constraint: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7\u00b7 + 2 However, the following program is not valid, as the second line of the expression starts at the same column as the first line: x = 4 * 10 \u00b7\u00b7\u00b7\u00b7 + 2 Note that if the expression is written on a single line, the constraint is also verified. That is, the following program successfully parses: x = 4 * 10 + 2 It is also possible to use the offside relation on different trees. For example, consider the constraint in the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( offside \"if\" then )} This constraint states that all lines (except the first) of the statements in the then branch should be indented with respect to the if literal. Thus, the following program is invalid according to this layout constraint, because the statement x = 2 should be indented with relation to the topmost if . if x < 0 then \u00b7\u00b7 if y < 0 then x = 2 In general, an offside constraint involving more than a single tree is combined with indent constraint to enforce that the column of the first and all subsequent lines should be indented.","title":"offside"},{"location":"references/syntax/layout-sensitivity/#indent","text":"An indent constraint indicates that the column of the first line of a certain tree should be further to the right with respect to another tree. For example, consider the following production: context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then )} This constraint indicates that the first line of the list of statements should be indented with respect to the if literal. Thus, according to this constraint the following program is valid: if x < 0 then \u00b7\u00b7 x = 2 Note that if the list of statements in the then branch spams multiple lines, the constraint does not apply to its subsequent lines. For example, consider the following program: if x < 0 then \u00b7\u00b7 x = 2 + 10 * 4 y = 3 This program is still valid, since the column of the first line of the first assignment is indented with respect to the if literal. To indicate that the first and all subsequent lines should be indented, an offside constraint should also be included. context-free syntax Stmt.If = \"if\" Exp \"then\" then:Stmt* {layout( indent \"if\" then && offside \"if\" then )} With this constraint, the remainder of the expression * 4 should also be further to the right compared to the \"if\" literal. The following program is correct according to these two constraints, since the second line of the first assignment and the second assignment are also indented with respect to the if literal: if x < 0 then \u00b7\u00b7 x = 2 + 10 \u00b7 * 4 \u00b7 y = 3 Finally, all these layout declarations can be ignored by the parser and used only when generating the pretty-printer. To do that, prefix the constraint with pp- writing, for example, pp-offside or pp-align . Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5 th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers , volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14 . \u21a9 \u21a9 \u21a9 \u21a9","title":"indent"},{"location":"references/syntax/lexical-syntax/","text":"Lexical Syntax \u00b6 The lexical syntax usually describes the low level structure of programs (often referred to as lexical tokens). However, in SDF3, the token concept is not really relevant, since only character classes are terminals. The lexical syntax sections in SDF3 are simply a convenient notation for the low level syntax of a language. The LAYOUT symbol should also be defined in a lexical syntax section. A lexical syntax consists of a list of productions. Lexical syntax is described as follows: lexical syntax $Production* An example of a production in lexical syntax: lexical syntax BinaryConst = [0-1]+","title":"Lexical Syntax"},{"location":"references/syntax/lexical-syntax/#lexical-syntax","text":"The lexical syntax usually describes the low level structure of programs (often referred to as lexical tokens). However, in SDF3, the token concept is not really relevant, since only character classes are terminals. The lexical syntax sections in SDF3 are simply a convenient notation for the low level syntax of a language. The LAYOUT symbol should also be defined in a lexical syntax section. A lexical syntax consists of a list of productions. Lexical syntax is described as follows: lexical syntax $Production* An example of a production in lexical syntax: lexical syntax BinaryConst = [0-1]+","title":"Lexical Syntax"},{"location":"references/syntax/modules/","text":"Modules \u00b6 An SDF3 specification consists of a number of module declarations. Each module defines sections and may import other modules. Imports \u00b6 Modules may import other modules for reuse or separation of concerns. A module may extend the definition of a non-terminal in another module. A module may compose the definition of a language by importing the parts of the language. The structure of a module is as follows: module $ModuleName $ImportSection* $Section* The module keyword is followed by the module name, then a series of imports can be made, followed by sections that contain the actual definition of the syntax. An import section is structured as follows: imports $ModuleName* Note that SDF3 does not support parameterized modules. Sections \u00b6 An SDF3 module may constitute of zero or more sections. All sections contribute to the final grammar that defines a language: sorts , lexical sorts , context-free sorts (see Symbols#Sorts ) lexical syntax (see Lexical Syntax ) context-free syntax (see Context-Free Syntax ) syntax (see Kernel Syntax ) lexical start-symbols , context-free start-symbols , start-symbols (see Start Symbols ) context-free priorities , priorities (see Disambiguation ) template options (see Templates )","title":"Modules"},{"location":"references/syntax/modules/#modules","text":"An SDF3 specification consists of a number of module declarations. Each module defines sections and may import other modules.","title":"Modules"},{"location":"references/syntax/modules/#imports","text":"Modules may import other modules for reuse or separation of concerns. A module may extend the definition of a non-terminal in another module. A module may compose the definition of a language by importing the parts of the language. The structure of a module is as follows: module $ModuleName $ImportSection* $Section* The module keyword is followed by the module name, then a series of imports can be made, followed by sections that contain the actual definition of the syntax. An import section is structured as follows: imports $ModuleName* Note that SDF3 does not support parameterized modules.","title":"Imports"},{"location":"references/syntax/modules/#sections","text":"An SDF3 module may constitute of zero or more sections. All sections contribute to the final grammar that defines a language: sorts , lexical sorts , context-free sorts (see Symbols#Sorts ) lexical syntax (see Lexical Syntax ) context-free syntax (see Context-Free Syntax ) syntax (see Kernel Syntax ) lexical start-symbols , context-free start-symbols , start-symbols (see Start Symbols ) context-free priorities , priorities (see Disambiguation ) template options (see Templates )","title":"Sections"},{"location":"references/syntax/productions/","text":"Productions \u00b6 The basic building block of syntax sections is the production. The left-hand side of a regular production rule can be either just a symbol or a symbol followed by . and a constructor name. The right-hand side consists of zero or more symbols. Both sides are separated by = : $Symbol = $Symbol* $Symbol.$Constructor = $Symbol* A production is read as the definition. The symbol on the left-hand side is defined by the right-hand side of the production. Productions are used to describe lexical , context-free , and kernel syntax. Productions may also occur in priority sections , but might also be referred to by its $Symbol.$Constructor . All productions with the same symbol together define the alternatives for that symbol. Attributes \u00b6 The definition of productions may be followed by attributes that define additional (syntactic or semantic) properties of that production. The attributes are written between curly brackets after the right-hand side of a production. If a production has more than one attribute they are separated by commas. Attributes have thus the following form: $Sort = $Symbol* { $Attribute1, $Attribute2, ...} $Sort.$Constructor = $Symbol* { $Attribute1, $Attribute2, ...} The following syntax-related attributes exist: bracket is an important attribute in combination with priorities. The parenthesizer tool uses the bracket attribute to find productions to add to a parse tree before pretty printing (when the tree violates priority constraints). Note that most of these tools demand the production with a bracket attribute to have the shape: X = \"(\" X \")\" {bracket} with any kind of bracket syntax but the X being the same symbol on the left-hand side and the right-hand side. The connection with priorities and associativity is that when a non-terminal is disambiguated using either of them, a production rule with the bracket attribute is probably also needed. reject is a disambiguation construct that implements language difference. It is used for keyword reservation. See Disambiguation#Rejections . left , right , non-assoc , assoc are disambiguation constructs used to define the associativity of productions. See Disambiguation#Associativity . prefer and avoid are deprecated disambiguation constructs to define preference of one derivation over others. See Disambiguation#Preferences .","title":"Productions"},{"location":"references/syntax/productions/#productions","text":"The basic building block of syntax sections is the production. The left-hand side of a regular production rule can be either just a symbol or a symbol followed by . and a constructor name. The right-hand side consists of zero or more symbols. Both sides are separated by = : $Symbol = $Symbol* $Symbol.$Constructor = $Symbol* A production is read as the definition. The symbol on the left-hand side is defined by the right-hand side of the production. Productions are used to describe lexical , context-free , and kernel syntax. Productions may also occur in priority sections , but might also be referred to by its $Symbol.$Constructor . All productions with the same symbol together define the alternatives for that symbol.","title":"Productions"},{"location":"references/syntax/productions/#attributes","text":"The definition of productions may be followed by attributes that define additional (syntactic or semantic) properties of that production. The attributes are written between curly brackets after the right-hand side of a production. If a production has more than one attribute they are separated by commas. Attributes have thus the following form: $Sort = $Symbol* { $Attribute1, $Attribute2, ...} $Sort.$Constructor = $Symbol* { $Attribute1, $Attribute2, ...} The following syntax-related attributes exist: bracket is an important attribute in combination with priorities. The parenthesizer tool uses the bracket attribute to find productions to add to a parse tree before pretty printing (when the tree violates priority constraints). Note that most of these tools demand the production with a bracket attribute to have the shape: X = \"(\" X \")\" {bracket} with any kind of bracket syntax but the X being the same symbol on the left-hand side and the right-hand side. The connection with priorities and associativity is that when a non-terminal is disambiguated using either of them, a production rule with the bracket attribute is probably also needed. reject is a disambiguation construct that implements language difference. It is used for keyword reservation. See Disambiguation#Rejections . left , right , non-assoc , assoc are disambiguation constructs used to define the associativity of productions. See Disambiguation#Associativity . prefer and avoid are deprecated disambiguation constructs to define preference of one derivation over others. See Disambiguation#Preferences .","title":"Attributes"},{"location":"references/syntax/recovery/","text":"Recovery \u00b6 SDF3 automatically generates permissive grammars for supporting error-recovery parsing 1 . The permissive grammars contain recovery productions that can be used to recover from syntactic errors. The recovery productions are either deletions or insertions. Deletions can skip over an erroneous part of the input. Insertions recover from a missing part of the input, e.g. a missing closing bracket. Handwritten recovery rules can be added to tweak the automatically generated permissive grammar by using the recover attribute. For example, the following insertion enables recovery for missing if literals: lexical syntax \"if\" = {recover} The empty right-hand side makes sure that, in recovery mode, the if literal can be parsed even when it is not present in the input. Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems , 34 \\(4\\) :15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678 , doi:10.1145/2400676.2400678 . \u21a9","title":"Recovery"},{"location":"references/syntax/recovery/#recovery","text":"SDF3 automatically generates permissive grammars for supporting error-recovery parsing 1 . The permissive grammars contain recovery productions that can be used to recover from syntactic errors. The recovery productions are either deletions or insertions. Deletions can skip over an erroneous part of the input. Insertions recover from a missing part of the input, e.g. a missing closing bracket. Handwritten recovery rules can be added to tweak the automatically generated permissive grammar by using the recover attribute. For example, the following insertion enables recovery for missing if literals: lexical syntax \"if\" = {recover} The empty right-hand side makes sure that, in recovery mode, the if literal can be parsed even when it is not present in the input. Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems , 34 \\(4\\) :15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678 , doi:10.1145/2400676.2400678 . \u21a9","title":"Recovery"},{"location":"references/syntax/start-symbols/","text":"Start Symbols \u00b6 The lexical or context-free start symbols sections explicitly define the symbols which will serve as start symbols when parsing terms. If no start symbols are defined it is not possible to recognize terms. This has the effect that input sentences corresponding to these symbols can be parsed. So, if we want to recognize boolean terms we have to define explicitly the sort Boolean as a start symbol in the module Booleans . Any symbol and also lists, optionals, etc., can serve as a start-symbol. A definition of lexical start symbols looks like: lexical start-symbols $Symbol* While context-free start symbols are defined as: context-free start-symbols $Symbol* SDF3 also supports kernel start-symbols: start-symbols $Symbol* In contrast to lexical and kernel start-symbols, context-free start symbols can be surrounded by optional layout. A lexical start-symbol should have been defined by a production in the lexical syntax; a context-free symbol should have been defined in the context-free syntax. Both symbols can also be defined in kernel syntax using the suffix -LEX or -CF .","title":"Start Symbols"},{"location":"references/syntax/start-symbols/#start-symbols","text":"The lexical or context-free start symbols sections explicitly define the symbols which will serve as start symbols when parsing terms. If no start symbols are defined it is not possible to recognize terms. This has the effect that input sentences corresponding to these symbols can be parsed. So, if we want to recognize boolean terms we have to define explicitly the sort Boolean as a start symbol in the module Booleans . Any symbol and also lists, optionals, etc., can serve as a start-symbol. A definition of lexical start symbols looks like: lexical start-symbols $Symbol* While context-free start symbols are defined as: context-free start-symbols $Symbol* SDF3 also supports kernel start-symbols: start-symbols $Symbol* In contrast to lexical and kernel start-symbols, context-free start symbols can be surrounded by optional layout. A lexical start-symbol should have been defined by a production in the lexical syntax; a context-free symbol should have been defined in the context-free syntax. Both symbols can also be defined in kernel syntax using the suffix -LEX or -CF .","title":"Start Symbols"},{"location":"references/syntax/symbols/","text":"Symbols \u00b6 The building block of SDF3 productions is a symbol. SDF3 symbols can be compared to terminals and non-terminals in other grammar formalisms. The elementary symbols are character classes, literals, and sorts. Intrinsically, only character classes are real terminal symbols. All other symbols represent non-terminals. SDF3 also support symbols that capture BNF-like notation such as lists, optionals, alternatives, and sequences. Note that these symbols are also non-terminals, and are just shorthands for common structures present in context-free grammars. Character classes \u00b6 Character classes occur only in lexical syntax and are enclosed by [ and ] . A character class consists of a list of zero or more characters (which stand for themselves) such as [x] to represent the character x , or character ranges, as an abbreviation for all the characters in the range such as [0-9] representing 0 , 1 , ..., 9 . A valid range consists of [c1-c2] , where the character c2 has a higher ASCII code than c1 . Note that nested character classes can also be concatenated within the same character class symbol, for example [c1c2-c3c4-c5] includes the characters c1 and the ranges c2-c3 , c4-c5 . In this case, the nested character classes do not need to be ordered, as SDF3 orders them when performing a normalization step. Escaping \u00b6 SDF3 uses a backslash ( \\ ) as a escape for the quotingof special characters. One should use \\c whenever c is not a digit or a letter in a character class. Unicode \u00b6 Arbitrary Unicode code points can be included in a character class by writing an escaped integer, which is particularly useful for representing characters outside the printable ASCII range. The integer can be a binary, octal, decimal, or hexadecimal number, for example: \\0b101010 , \\052 , \\42 , and \\0x2A all represent the code point 42, or the '*' character. Special ASCII Characters \u00b6 Additionally, special ASCII characters are represented by: \\t : horizontal tabulation \\n : newline character \\v : vertical tabulation \\f : form feed \\r : carriage return Operators \u00b6 SDF3 provides the following operators for character classes: (complement) ~ : Accepts all the characters that are not in the original class. (difference) / : Accepts all the characters in the first class unless they are in a second class. (union) \\/ : Accepts all the characters in either character classes. (intersection) /\\ : Accepts all the characters that are accepted by both character classes. Note that the first operator is unary and the other ones are left associative binary operators. Furthermore, such operators are not applicable to other symbols in general. Literals \u00b6 A literal symbol defines a fixed length word. This usually corresponds to a terminal symbol in ordinary context-free grammars, for example \"true\" or \"+\" . Literals must always be quoted and consist of (possibly escaped) ASCII characters. As literals are also regular non-terminals, SDF3 automatically generates productions for them in terms of terminal symbols. \"definition\" = [d][e][f][i][n][i][t][i][o][n] Note that the production above defines a case-sensitive implementation of the defined literal. Case-insensitive literals are defined using single-quoted strings as in 'true' or 'else' . SDF3 generates a different production for case-insensitive literals as 'definition' = [dD][eE][fF][iI][nN][iI][tT][iI][oO][nN] The literal above accepts case-insensitive inputs such as definition , DEFINITION , DeFiNiTiOn or defINITION . Sorts \u00b6 A sort corresponds to a plain non-terminal, e.g. Statement or Exp . Sort names start with a capital letter and may be followed by letters, digits, hyphens, or underscores. Note that unlike SDF2, SDF3 does not support parameterized sorts (yet!). Sorts are declared by listing their name in the appropriate sorts section, which have the following forms. For context-free sorts: context-free sorts $Sort* For lexical sorts: lexical sorts $Sort* SDF3 also supports kernel sorts: sorts $Sort* Note Kernel sorts should be suffixed with -CF or -LEX , depending on whether they are context-free sorts or lexical sorts. When a sort in a sorts block does not have a suffix, it is treated as a context-free sort. Writing a sort in these sections only indicates that a sort has been declared, even if it does not have any explicit production visible. Optionals \u00b6 SDF3 provides a shorthand for describing zero or exactly one occurrence of a sort by appending the sort with ? . For example, the sort Extends? can be parsed as Extends or without consuming any input. Internally, SDF3 generates the following productions after normalizing the grammar:: Extends?.None = Extends?.Some = Extends Note that using ? adds the constructors None and Some to the final abstract syntax tree. Lists \u00b6 Lists symbols as the name says, indicate that a symbol should occur several times. In this way, it is also possible to construct flat structures to represent them. SDF3 provides support for two types of lists, with and without separators. Furthermore, it is also possible to indicate whether a list can be empty ( * ) or should have at least one element ( + ). For example, a list Statement* indicates zero or more Statement , whereas a list with separator {ID \",\"}+ indicates one or more ID separated by , . Note that SDF3 only supports literal symbols as separators. Again, SDF3 generates the following productions to represent lists, when normalizing the grammar: Statement* = Statement* = Statement+ Statement+ = Statement+ Statement Statement+ = Statement {ID \",\"}* = {ID \",\"}* = {ID \",\"}+ {ID \",\"}+ = {ID \",\"}+ \",\" {ID \",\"} {ID \",\"}+ = {ID \",\"} When parsing a context-free list, SDF3 produces a flattened list as an AST node such as [Statement, ..., Statement] or [ID, ..., ID] . Note that because the separator is a literal, it does not appear in the AST. Alternative \u00b6 Alternative symbols express the choice between two symbols, for example, ID | INT . That is, the symbol ID | INT can be parsed as either ID or INT . For that reason, SDF3 normalizes alternatives by generating the following productions: ID | INT = ID ID | INT = INT Note that SDF3 only allow alternative symbols to occur in lexical syntax. Furthermore, note that the alternative operator is right associative and binds stronger than any operator. That is, ID \",\" | ID \";\" expresses ID (\",\" | ID) \";\" . To express (ID \",\") | (ID \";\") , we can use a sequence symbol. Sequence \u00b6 A sequence operator allows grouping of two or more symbols. Sequences are useful when combined with other symbols such, lists or optionals, for example (\"e\" [0-9]+)? . Like alternative symbols, sequences can only occur in lexical syntax. A sequence symbol is normalized as: (\"e\" [0-9]+) = \"e\" [0-9]+ Labeled symbols \u00b6 SDF3 supports decorating symbols with labels, such as myList:{elem:Stmt \";\"}* . The labels can be used for layout constraints/declarations or by other tools that use SDF3 grammars as input. LAYOUT \u00b6 The LAYOUT symbol is a reserved sort name. It is used to indicate the whitespace that can appear in between context-free symbols. The user must define the symbol LAYOUT such as: LAYOUT = [\\ \\t\\n] Note that the production above should be defined in the lexical syntax.","title":"Symbols"},{"location":"references/syntax/symbols/#symbols","text":"The building block of SDF3 productions is a symbol. SDF3 symbols can be compared to terminals and non-terminals in other grammar formalisms. The elementary symbols are character classes, literals, and sorts. Intrinsically, only character classes are real terminal symbols. All other symbols represent non-terminals. SDF3 also support symbols that capture BNF-like notation such as lists, optionals, alternatives, and sequences. Note that these symbols are also non-terminals, and are just shorthands for common structures present in context-free grammars.","title":"Symbols"},{"location":"references/syntax/symbols/#character-classes","text":"Character classes occur only in lexical syntax and are enclosed by [ and ] . A character class consists of a list of zero or more characters (which stand for themselves) such as [x] to represent the character x , or character ranges, as an abbreviation for all the characters in the range such as [0-9] representing 0 , 1 , ..., 9 . A valid range consists of [c1-c2] , where the character c2 has a higher ASCII code than c1 . Note that nested character classes can also be concatenated within the same character class symbol, for example [c1c2-c3c4-c5] includes the characters c1 and the ranges c2-c3 , c4-c5 . In this case, the nested character classes do not need to be ordered, as SDF3 orders them when performing a normalization step.","title":"Character classes"},{"location":"references/syntax/symbols/#escaping","text":"SDF3 uses a backslash ( \\ ) as a escape for the quotingof special characters. One should use \\c whenever c is not a digit or a letter in a character class.","title":"Escaping"},{"location":"references/syntax/symbols/#unicode","text":"Arbitrary Unicode code points can be included in a character class by writing an escaped integer, which is particularly useful for representing characters outside the printable ASCII range. The integer can be a binary, octal, decimal, or hexadecimal number, for example: \\0b101010 , \\052 , \\42 , and \\0x2A all represent the code point 42, or the '*' character.","title":"Unicode"},{"location":"references/syntax/symbols/#special-ascii-characters","text":"Additionally, special ASCII characters are represented by: \\t : horizontal tabulation \\n : newline character \\v : vertical tabulation \\f : form feed \\r : carriage return","title":"Special ASCII Characters"},{"location":"references/syntax/symbols/#operators","text":"SDF3 provides the following operators for character classes: (complement) ~ : Accepts all the characters that are not in the original class. (difference) / : Accepts all the characters in the first class unless they are in a second class. (union) \\/ : Accepts all the characters in either character classes. (intersection) /\\ : Accepts all the characters that are accepted by both character classes. Note that the first operator is unary and the other ones are left associative binary operators. Furthermore, such operators are not applicable to other symbols in general.","title":"Operators"},{"location":"references/syntax/symbols/#literals","text":"A literal symbol defines a fixed length word. This usually corresponds to a terminal symbol in ordinary context-free grammars, for example \"true\" or \"+\" . Literals must always be quoted and consist of (possibly escaped) ASCII characters. As literals are also regular non-terminals, SDF3 automatically generates productions for them in terms of terminal symbols. \"definition\" = [d][e][f][i][n][i][t][i][o][n] Note that the production above defines a case-sensitive implementation of the defined literal. Case-insensitive literals are defined using single-quoted strings as in 'true' or 'else' . SDF3 generates a different production for case-insensitive literals as 'definition' = [dD][eE][fF][iI][nN][iI][tT][iI][oO][nN] The literal above accepts case-insensitive inputs such as definition , DEFINITION , DeFiNiTiOn or defINITION .","title":"Literals"},{"location":"references/syntax/symbols/#sorts","text":"A sort corresponds to a plain non-terminal, e.g. Statement or Exp . Sort names start with a capital letter and may be followed by letters, digits, hyphens, or underscores. Note that unlike SDF2, SDF3 does not support parameterized sorts (yet!). Sorts are declared by listing their name in the appropriate sorts section, which have the following forms. For context-free sorts: context-free sorts $Sort* For lexical sorts: lexical sorts $Sort* SDF3 also supports kernel sorts: sorts $Sort* Note Kernel sorts should be suffixed with -CF or -LEX , depending on whether they are context-free sorts or lexical sorts. When a sort in a sorts block does not have a suffix, it is treated as a context-free sort. Writing a sort in these sections only indicates that a sort has been declared, even if it does not have any explicit production visible.","title":"Sorts"},{"location":"references/syntax/symbols/#optionals","text":"SDF3 provides a shorthand for describing zero or exactly one occurrence of a sort by appending the sort with ? . For example, the sort Extends? can be parsed as Extends or without consuming any input. Internally, SDF3 generates the following productions after normalizing the grammar:: Extends?.None = Extends?.Some = Extends Note that using ? adds the constructors None and Some to the final abstract syntax tree.","title":"Optionals"},{"location":"references/syntax/symbols/#lists","text":"Lists symbols as the name says, indicate that a symbol should occur several times. In this way, it is also possible to construct flat structures to represent them. SDF3 provides support for two types of lists, with and without separators. Furthermore, it is also possible to indicate whether a list can be empty ( * ) or should have at least one element ( + ). For example, a list Statement* indicates zero or more Statement , whereas a list with separator {ID \",\"}+ indicates one or more ID separated by , . Note that SDF3 only supports literal symbols as separators. Again, SDF3 generates the following productions to represent lists, when normalizing the grammar: Statement* = Statement* = Statement+ Statement+ = Statement+ Statement Statement+ = Statement {ID \",\"}* = {ID \",\"}* = {ID \",\"}+ {ID \",\"}+ = {ID \",\"}+ \",\" {ID \",\"} {ID \",\"}+ = {ID \",\"} When parsing a context-free list, SDF3 produces a flattened list as an AST node such as [Statement, ..., Statement] or [ID, ..., ID] . Note that because the separator is a literal, it does not appear in the AST.","title":"Lists"},{"location":"references/syntax/symbols/#alternative","text":"Alternative symbols express the choice between two symbols, for example, ID | INT . That is, the symbol ID | INT can be parsed as either ID or INT . For that reason, SDF3 normalizes alternatives by generating the following productions: ID | INT = ID ID | INT = INT Note that SDF3 only allow alternative symbols to occur in lexical syntax. Furthermore, note that the alternative operator is right associative and binds stronger than any operator. That is, ID \",\" | ID \";\" expresses ID (\",\" | ID) \";\" . To express (ID \",\") | (ID \";\") , we can use a sequence symbol.","title":"Alternative"},{"location":"references/syntax/symbols/#sequence","text":"A sequence operator allows grouping of two or more symbols. Sequences are useful when combined with other symbols such, lists or optionals, for example (\"e\" [0-9]+)? . Like alternative symbols, sequences can only occur in lexical syntax. A sequence symbol is normalized as: (\"e\" [0-9]+) = \"e\" [0-9]+","title":"Sequence"},{"location":"references/syntax/symbols/#labeled-symbols","text":"SDF3 supports decorating symbols with labels, such as myList:{elem:Stmt \";\"}* . The labels can be used for layout constraints/declarations or by other tools that use SDF3 grammars as input.","title":"Labeled symbols"},{"location":"references/syntax/symbols/#layout","text":"The LAYOUT symbol is a reserved sort name. It is used to indicate the whitespace that can appear in between context-free symbols. The user must define the symbol LAYOUT such as: LAYOUT = [\\ \\t\\n] Note that the production above should be defined in the lexical syntax.","title":"LAYOUT"},{"location":"references/syntax/templates/","text":"Templates \u00b6 Templates are a major change in SDF3 when comparing to SDF2. They are essential when aiming to generate a nice pretty printer or generate proper syntactic code completion templates. When generating such artifacts, a general production simply introduces a whitespace in between symbols. For example, when writing a grammar rule Statement.If = \"if\" \"(\" Exp \")\" Exp \"else\" Exp and pretty printing a valid program, we would get the text in a single line separated by spaces, as: Furthermore, code completion would consider the same indentation when inserting code snippets. However, when using template productions such as Statement.If = < if ($Exp) $Exp else $Exp We would get the following program: Again, code completion would also consider this indentation for proposals. That is, in template productions, the surrounding layout is used to nicely pretty print programs and its code completion suggestions. Template Productions \u00b6 Template productions are an alternative way of defining productions. Similarly, they consist of a left-hand side and a right-hand side separated by = . The left-hand side is the same as for productive rules. The right-hand side is a template delimited by < and > . The template can contain zero or more symbols: $Sort = < $Symbol* > $Sort.$Constructor = < $Symbol* > Alternatively, square brackets can be used to delimit a template: $Sort = [ $Symbol* ] $Sort.$Constructor = [ $Symbol* ] The symbols in a template can either be placeholders or literal strings. It is worth noting that: placeholders need to be enclosed within the same delimiters (either <...> or [...] ) as the template; literal strings need not not be enclosed within quotation marks; literal strings are tokenized on space characters (whitespace, tab); additionally, literal strings are tokenized on boundaries between characters from the set given by the tokenize option, see the tokenize template option ; placeholders translate literally. If a separator containing any layout characters is given, the placeholder maps to a list with separator that strips the layout. An example of a template rule: Exp.Addition = < $Exp + $Exp > Here, the + symbol is a literal string and $Exp is a placeholder for sort Exp . Placeholders are of the form: $Sort? : optional placeholder $Sort* : repetition (0...n) $Sort+ : repetition (1...n) <{$Sort \",\"}*> : repetition with separator Case-insensitive Literals \u00b6 As we showed before, SDF3 allows defining case-insensitive literals as single-quoted strings in regular productions. For example: Exp.If = 'if' \"(\" Exp \")\" Exp 'else' Exp accepts case-insensitive keywords for if and else such as if , IF , If , else , ELSE or ELsE . However, to generate case-insensitive literals from template productions, it is necessary to add annotate these productions as case-insensitive. For example, a template production: Exp.If = < if($Exp) $Exp else $Exp > {case-insensitive} accepts the same input as the regular production mentioned before. Moreover, lexical symbols can also be annotated as case-insensitive to parse as such. The constructed abstract syntax tree contains lower-case symbols, but the original term is preserved via origin-tracking. For example: ID = [a-zA-z][a-zA-Z0-9]* {case-insensitive} can parse foo , Foo , FOo , fOo , foO , fOO or FOO . Whichever option generates a node \"foo\" in the abstract syntax tree. By consulting the origin information on this node, it is possible to know which term was used as input to the parser. Template options \u00b6 Template options are options that are applied to the current file. A template options section is structured as follows: template options $TemplateOption* Multiple template option sections are not supported. If multiple template option sections are specified, the last one is used. There are three kinds of template options. keyword \u00b6 Convenient way for setting up lexical follow restrictions for keywords. See the section on follow restrictions for more information. The structure of the keyword option is as follows: keyword -/- $Pattern This will add a follow restriction on the pattern for each keyword in the language. Keywords are automatically detected, any terminal that ends with an alphanumeric character is considered a keyword. Multiple keyword options are not supported. If multiple keyword options are specified, the last one is used. Note that this only sets up follow restrictions, rejection of keywords as identifiers still needs to be written manually. tokenize \u00b6 Specifies which characters may have layout around them. The structure of a tokenize option is as follows: tokenize : \"$Character*\" Consider the following grammar specification: template options tokenize : \"(\" context-free syntax Exp.Call = <<ID>();> Because layout is allowed around the ( and ) characters, there may be layout between () and ; in the template rule. If no tokenize option is specified, it defaults to the default value of () . Multiple tokenize options are not supported. If multiple tokenize options are specified, the last one is used. reject \u00b6 Convenient way for setting up reject rules for keywords. See the section on rejections for more information. The structure of the reject option is as follows: Symbol = keyword {attrs} where Symbol is the symbol to generate the rules for. Note that attrs can be include any attribute, but by using reject , reject rules such as ID = \"true\" {reject} are generated for all keywords that appear in the templates. Multiple reject template options are not supported. If multiple reject template options are specified, the last one is used.","title":"Templates"},{"location":"references/syntax/templates/#templates","text":"Templates are a major change in SDF3 when comparing to SDF2. They are essential when aiming to generate a nice pretty printer or generate proper syntactic code completion templates. When generating such artifacts, a general production simply introduces a whitespace in between symbols. For example, when writing a grammar rule Statement.If = \"if\" \"(\" Exp \")\" Exp \"else\" Exp and pretty printing a valid program, we would get the text in a single line separated by spaces, as: Furthermore, code completion would consider the same indentation when inserting code snippets. However, when using template productions such as Statement.If = < if ($Exp) $Exp else $Exp We would get the following program: Again, code completion would also consider this indentation for proposals. That is, in template productions, the surrounding layout is used to nicely pretty print programs and its code completion suggestions.","title":"Templates"},{"location":"references/syntax/templates/#template-productions","text":"Template productions are an alternative way of defining productions. Similarly, they consist of a left-hand side and a right-hand side separated by = . The left-hand side is the same as for productive rules. The right-hand side is a template delimited by < and > . The template can contain zero or more symbols: $Sort = < $Symbol* > $Sort.$Constructor = < $Symbol* > Alternatively, square brackets can be used to delimit a template: $Sort = [ $Symbol* ] $Sort.$Constructor = [ $Symbol* ] The symbols in a template can either be placeholders or literal strings. It is worth noting that: placeholders need to be enclosed within the same delimiters (either <...> or [...] ) as the template; literal strings need not not be enclosed within quotation marks; literal strings are tokenized on space characters (whitespace, tab); additionally, literal strings are tokenized on boundaries between characters from the set given by the tokenize option, see the tokenize template option ; placeholders translate literally. If a separator containing any layout characters is given, the placeholder maps to a list with separator that strips the layout. An example of a template rule: Exp.Addition = < $Exp + $Exp > Here, the + symbol is a literal string and $Exp is a placeholder for sort Exp . Placeholders are of the form: $Sort? : optional placeholder $Sort* : repetition (0...n) $Sort+ : repetition (1...n) <{$Sort \",\"}*> : repetition with separator","title":"Template Productions"},{"location":"references/syntax/templates/#case-insensitive-literals","text":"As we showed before, SDF3 allows defining case-insensitive literals as single-quoted strings in regular productions. For example: Exp.If = 'if' \"(\" Exp \")\" Exp 'else' Exp accepts case-insensitive keywords for if and else such as if , IF , If , else , ELSE or ELsE . However, to generate case-insensitive literals from template productions, it is necessary to add annotate these productions as case-insensitive. For example, a template production: Exp.If = < if($Exp) $Exp else $Exp > {case-insensitive} accepts the same input as the regular production mentioned before. Moreover, lexical symbols can also be annotated as case-insensitive to parse as such. The constructed abstract syntax tree contains lower-case symbols, but the original term is preserved via origin-tracking. For example: ID = [a-zA-z][a-zA-Z0-9]* {case-insensitive} can parse foo , Foo , FOo , fOo , foO , fOO or FOO . Whichever option generates a node \"foo\" in the abstract syntax tree. By consulting the origin information on this node, it is possible to know which term was used as input to the parser.","title":"Case-insensitive Literals"},{"location":"references/syntax/templates/#template-options","text":"Template options are options that are applied to the current file. A template options section is structured as follows: template options $TemplateOption* Multiple template option sections are not supported. If multiple template option sections are specified, the last one is used. There are three kinds of template options.","title":"Template options"},{"location":"references/syntax/templates/#keyword","text":"Convenient way for setting up lexical follow restrictions for keywords. See the section on follow restrictions for more information. The structure of the keyword option is as follows: keyword -/- $Pattern This will add a follow restriction on the pattern for each keyword in the language. Keywords are automatically detected, any terminal that ends with an alphanumeric character is considered a keyword. Multiple keyword options are not supported. If multiple keyword options are specified, the last one is used. Note that this only sets up follow restrictions, rejection of keywords as identifiers still needs to be written manually.","title":"keyword"},{"location":"references/syntax/templates/#tokenize","text":"Specifies which characters may have layout around them. The structure of a tokenize option is as follows: tokenize : \"$Character*\" Consider the following grammar specification: template options tokenize : \"(\" context-free syntax Exp.Call = <<ID>();> Because layout is allowed around the ( and ) characters, there may be layout between () and ; in the template rule. If no tokenize option is specified, it defaults to the default value of () . Multiple tokenize options are not supported. If multiple tokenize options are specified, the last one is used.","title":"tokenize"},{"location":"references/syntax/templates/#reject","text":"Convenient way for setting up reject rules for keywords. See the section on rejections for more information. The structure of the reject option is as follows: Symbol = keyword {attrs} where Symbol is the symbol to generate the rules for. Note that attrs can be include any attribute, but by using reject , reject rules such as ID = \"true\" {reject} are generated for all keywords that appear in the templates. Multiple reject template options are not supported. If multiple reject template options are specified, the last one is used.","title":"reject"},{"location":"references/testing/","text":"SPT: Spoofax Testing Language \u00b6","title":"SPT: Spoofax Testing Language"},{"location":"references/testing/#spt-spoofax-testing-language","text":"","title":"SPT: Spoofax Testing Language"},{"location":"release/develop/","text":"Development Releases \u00b6 Use the development releases of Spoofax only if you want to be on the cutting-edge of Spoofax development. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the From Source installation: Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://buildfarm.metaborg.org/job/metaborg/job/spoofax-releng/job/master/lastSuccessfulBuild/artifact/dist/spoofax/eclipse/site/ Installation instructions . From Source Use Git to clone the Spoofax Github repository : HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Installation instructions .","title":"Development Releases"},{"location":"release/develop/#development-releases","text":"Use the development releases of Spoofax only if you want to be on the cutting-edge of Spoofax development. Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the From Source installation: Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://buildfarm.metaborg.org/job/metaborg/job/spoofax-releng/job/master/lastSuccessfulBuild/artifact/dist/spoofax/eclipse/site/ Installation instructions . From Source Use Git to clone the Spoofax Github repository : HTTPS git clone https://github.com/metaborg/spoofax-releng.git HTTPS git clone git@github.com:metaborg/spoofax-releng.git GitHub CLI gh repo clone metaborg/spoofax-releng Installation instructions .","title":"Development Releases"},{"location":"release/stable/","text":"Stable Releases \u00b6 This page lists the latest stable release of Spoofax: version 2.5.16 released on 04-06-2021 . Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the Homebrew installation ( macOS only): Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Stable Releases"},{"location":"release/stable/#stable-releases","text":"This page lists the latest stable release of Spoofax: version 2.5.16 released on 04-06-2021 . Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the Homebrew installation ( macOS only): Eclipse Bundle with JRE (recommended) Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform: + macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit) Installation instructions . Eclipse Bundle Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform: macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit) Installation instructions . Eclipse Plugin Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Installation instructions . Homebrew On macOS Spoofax can be installed easily using Homebrew . Install the latest release of Spoofax Eclipse as follows: brew tap metaborg/metaborg brew install --cask spoofax The optional command-line tools are installed with: brew install strategoxt Upgrading the Spoofax cask is not recommended Upgrading the Spoofax cask using brew cask upgrade --greedy will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.","title":"Stable Releases"},{"location":"release/migrate/2.0.0/","text":"Spoofax 2.0.0 Migration Guide \u00b6 This migration guide describes the differences between Spoofax 1.5 and 2.0 and describes the steps to convert a Spoofax 1.5 project to Spoofax 2.0 project. To gather the required knowledge for migrating a language project, go through the documentation in the following order: Spoofax 2.0 Release Notes , for a general overview of the changes in Spoofax 2.0. This document, for the concrete differences and steps to convert your Spoofax project. Differences \u00b6 Concepts \u00b6 Spoofax 2.0 introduces several new concepts and terminology. A language specification is the specification of a language using meta-languages. A language specification project specifies a language component . When the specification is compiled, the result is a component which can be loaded into Spoofax. A language component has specifications and implementations for parts of a language, such as its parser, pretty-printer, analysis, transformations, editor services, etc. A component contributes these parts to a language implementation . Multiple components can contribute to the same language implementation, and components can contribute to multiple language implementations. In the most simple case, a single component contributes all parts of the language to a single implementation. Language components can depend on other language components to depend on parts of a language. Currently, there are two kinds of dependencies: compile and source dependencies. A compile dependency on a language component is used to compile source files of that language component. For example, a compile dependency on NaBL will ensure that all .nab files are compiled into .str files. A source dependency is used to depend on source files of a language component. Source dependencies are used to depend on libraries, for example to depend on a Stratego library for name and type analysis. They are also used to compose multiple language components into a single language component, for example to do language extension. A language is the more abstract notion of a language, which has multiple language implementations. For example, the Java language has the JDK7 and JDK8 implementations , which each have front-end and back-end components . An end-user project is a project with programs of an end-user language, in contrast to a language specification project which has programs of meta-languages. For example, a Java project is a Java end-user project, whereas the JDK project is a language specification project. Project structure \u00b6 The project structure of language specification projects has significantly changed. The biggest change is that these projects are no longer Eclipse (plugin) projects, so that they can be used outside of the Eclipse platform as well. Ant build files have also been removed since we do not use Ant to build projects any more. Many ESV files have been deprecated, and all generated ESV files in the editor directory have been removed. The following files and directories are no longer part of the project structure: Ant build: .externalToolBuilders , build.generated.xml , build.main.xml Eclipse plugin: plugin.xml , META-INF Eclipse project: .settings , .classpath , .project , build.properties Refactoring: lib/refactor-common.generated.str Deprecated ESV files: editor/langname-Completions.esv , editor/langname-Folding.esv , editor/langname-Outliner.str , editor/langname-Refactorings.esv Generated ESV files: editor/langname-*.generated.esv , editor/langname-Outliner.generated.str The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures. The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files. The following files and directories have been moved: ESV Main ESV file must be at editor/Main.esv . If it does not exist, no packed ESV file will be generated. Packed ESV file: target/metaborg/editor.esv.af SDF Definition: src-gen/syntax/[LanguageName].def Permissive definition: src-gen/syntax/[LanguageName]-permissive.def Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str Parse table: target/metaborg/sdf.tbl Stratego 'editor-common.generated' file: src-gen/stratego/metaborg.str Ctree: target/metaborg/stratego.ctree Generated Java files: src-gen/stratego-java JAR: target/metaborg/stratego.jar Java strategies: src/main/strategies Java strategies JAR: target/metaborg/stratego-javastrat.jar Build cache: target/stratego-cache DynSem Manual Java: src/main/ds Generated Java: src-gen/ds-java The following generated files and directories still exist, but should not be published to source control any more: lib/editor-common.generated.str or stratego/metaborg.str src-gen When importing a language specification project into Eclipse or IntelliJ, several platform-specific files will be generated. These files should not be published to source control to keep projects as platform-agnostic as possible. Eclipse \u00b6 Importing \u00b6 To import a language specification project into Eclipse, use Import... \u2023 Maven \u2023 Existing Maven Projects . We use Maven to set up the correct Java dependencies, which is why there is no special 'Existing Spoofax Projects' importer. Builds \u00b6 Eclipse has the concept of incremental project builders, which incrementally parse, analyze, and compile files inside a project. An example of such a project builder is the Eclipse JDT builder which incrementally builds Java files. Spoofax 1.5 did not use this functionality, but the new Eclipse plugin in Spoofax 2.0 does. The project builder for Spoofax parses, analyses, executes transformations, and shows all error markers, for all language files (Stratego files, SDF3 files, files of your language, etc.) in the project. If the project is opened for the first time, a full build will occur, building all language files. When changes occur in the project, an incremental build occurs, building only changed files. The commands under the Project menu in Eclipse now also affect Spoofax projects. Executing Project \u2023 Build... (or pressing Ctrl/Cmd+Alt+B ) will build the project. Executing Project \u2023 Clean... will delete the .cache directory, reset the index and task engine, remove all error markers, and reanalyze and rebuild all files in the project. This makes the Reset and Reanalyze builder unnecessary, since this is now properly integrated with Eclipse. Automatic building can also be turned off by disabling Project \u2023 Build Automatically . Builds will then only occur if Project \u2023 Build Project is executed or if Ctrl/Cmd+Alt+B is pressed. Furthermore, the language specification build is no longer written in Ant, but in Java using the Pluto incremental build system. Natures \u00b6 The Spoofax language specification project builder is not enabled by default, to enable it a 'Spoofax meta nature' must be added to the project. A nature in Eclipse is a project tag which enables functionality for that project. To add the Spoofax nature to a project, right click the project, and choose Spoofax (meta) \u2023 Add Spoofax meta nature . When importing a language specification, this nature is automatically added. For end-user projects, right click the project, and choose Spoofax \u2023 Add Spoofax nature to add a nature for end-user projects. Editors will parse and analyze files regardless of there being a Spoofax nature, but the on-save handler will not be called. Builders \u00b6 Builders for the open editor are now located in the Spoofax main menu instead of buttons on the tool bar. Builders wait for the analyzed AST if needed, so the issue where builders are sometimes not executed on the analyzed AST should be solved now. Builders can also be executed on a set of files by selecting the files in the project or package explorer, right clicking the files, selecting the language name from the menu, and then selecting a builder. Cancellation \u00b6 Editor updates can now be cancelled by clicking the red stop button in the progress view. If the progress view is not visible, you can open it by choosing Window \u2023 Show View \u2023 Progress . If the editor update is not responsive (it is looping for example), the thread running the editor update will be killed after a while. Killing a thread during analysis may leave the index and task engine in an inconsistent state. If this happens, clean the project using Project \u2023 Clean... to force a full build, which makes the state consistent again. Killing a thread is not very well supported in Java and may break Eclipse or even the JVM, which then requires a restart. Project builds and transformations can also be cancelled in the progress view. Console logging \u00b6 Console logging in the new plugin is more prominent so that we can diagnose problems more easily. If the console is not visible, you can open it by choosing Window \u2023 Show View \u2023 Console . The console does not automatically pop-up when there is a message any more, so it can also be hidden by just closing it. All warning and error messages are also sent to Eclipse's error log. The error log can sometimes contain more information about exceptions and stack traces in errors. If the error log is not visible, you can open it by choosing Window \u2023 Show View \u2023 Error Log . Manually loading/unloading a language \u00b6 A language can be manually loaded or reloaded by right clicking a project and choosing Spoofax (meta) \u2023 Load language , and unloaded with Spoofax (meta) \u2023 Unload language . External dependencies \u00b6 The new plugin does not depend on a modified version of IMP, making it possible to install the Rascal plugin alongside the Spoofax plugin. All other external dependencies are limited to the Spoofax plugin, which should prevent conflicts with other Eclipse plugins. Converting a project \u00b6 If your project is simple (e.g. it only has syntax and a few transformations), the easiest way to convert your project is to create a new Spoofax language specification project, and to copy your files into that project. Otherwise, Spoofax 2.0 supports converting an old Spoofax project into a new Spoofax project, but some conversions need to be done manually. Warning Converting a Spoofax project is a destructive operation, some files will be deleted, replaced, or changed. Make a backup of your projects before doing any conversions! Automatic conversion \u00b6 First, import your existing Spoofax project into Eclipse using File \u2023 Import... \u2023 Existing Projects into Workspace . Right click the project, and choose Spoofax (meta) \u2023 Upgrade language project . A wizard screen will pop up where you have to fill in some details about your language. If a packed.esv file was found, Spoofax will try to fill in some fields for you. If not, all fields need to be filled in manually. The id and name of your language can be found in the main ESV file. For group id , use a Maven identifier for your organization (e.g. org.metaborg), and as version : 1.0.0-SNAPSHOT. Warning Make sure that the id and name fields match exactly with the fields in your ESV file, otherwise the conversion will go wrong. Press finish to convert the language project. Manual conversion \u00b6 Unfortunately, not all required conversions can be done automatically. Do the following conversions manually. Project configuration \u00b6 Most of the project configuration is now in the metaborg.yaml file. The manual page on configuration lists all configuration options. Add/remove compile and source dependencies as needed. Add build configuration, such as Stratego compiler arguments, SDF compiler arguments, external def files, and external JAR files. Imports \u00b6 In Stratego, SDF2, SDF3, NaBL, and TS files: Remove src-gen , lib , and trans , from module names and imports. These paths are now on the source path of the SDF and Stratego compilers. In Stratego, NaBL, and TS files: Instead of importing lib/editor-common.generated , import stratego/metaborg . Instead of importing include/<langname>-parenthesize , import pp/<langname>-parenthesize . If you're using SDF3: Instead of importing the signatures from include/<langname> , import them from signatures/<langname>-sig . These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import signatures/- to import all signature files, if your syntax definition is not spread over multiple directories. If you're using SDF2 or an external definition file: Instead of importing the signatures from include/<langname> , import th em from signatures/<langname> . SDF \u00b6 If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file: language : sdf : version : sdf2 NaBL and TS \u00b6 If you\u2019re using a NaBL/TS based analysis, perform the following changes: NaBL files are now generated into src-gen/names , fix imports to NaBL files, delete old generated NaBL files. TS files are now generated into src-gen/types , fix imports to TS files, delete old generated TS files. The editor-analyze calls have been changed. Remove analysis-single-default-interface , analysis-multiple-default-interface , and editor-analyze . Replace it with: editor-analyze = analyze-all ( pre-analysis , post-analysis , pp-message |< language >) with the pre-analysis , post-analysis , and pp-message arguments that you were using before. Also make sure the observer (in your esv) has the (multifile) property. The editor-save call to analysis-save-default(|<language>) has been removed, remove that call. You can remove editor-save entirely if you don\u2019t do any generation, also remove the on save strategy from ESV if you do. If you do generation but do not return a (file, text) tuple from editor-save, be sure to return a !None() to tell Spoofax that you\u2019re returning nothing. The index-setup and task-setup strategies have been removed, Spoofax Core does this for you now. Remove all calls to these strategies. Remove the path argument to analysis-resolve in editor-resolve . Remove the path argument to analysis-propose-completions in editor-complete . Remove the debug-reanalyze strategy, and remove it from your menu in ESV. You can reanalyze by cleaning the project. ESV \u00b6 The following ESV files are now deprecated, delete and remove any imports to these files: editor/langname-Completions.esv editor/langname-Folding.esv editor/langname-Refactorings.esv Previously generated ESV files in the editor directory are not generated any more. Delete the generated files and remove the imports to generated files. The colorer ESV file is now generated to src-gen/editor/Colorer.generated.esv , import it with imports editor/Colorer.generated in an ESV file. The generated syntax ESV file is no longer generated. If you were using the defaults from the generated file, add them to an ESV file: language line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { } The outliner ( editor/langname-Outliner.str ) must be moved to the trans directory. Rename it to trans/outline.str , change its module to outline , and fix imports of the outliner. Change the file name of the main ESV file to Main.esv , and change its module to Main . In the main ESV file: Change the parse table: table : target/metaborg/sdf . tbl Change the Stratego providers For ctree projects: provider : target/metaborg/stratego . ctree For jar projects: provider : target/metaborg/stratego . jar For projects with Java strategies: provider : target/metaborg/stratego . jar provider : target/metaborg/stratego-javastrat . jar Java strategies \u00b6 If your project has Java strategies: Create the src/main/strategies directory. Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... , to update the Java source directories of the project. DynSem \u00b6 If your project has manual DynSem Java files: Create the src/main/ds directory. Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... , to update the Java source directories of the project. Ant build customization \u00b6 Language specification builds do not use Ant any more, so any customizations to the build.main.xml are lost. To perform an Ant task before and after the build, add the following configuration option to your metaborg.yaml file: build : ant : - phase : preCompile file : ${path:root}/ant.xml target : generate-xml - phase : postCompile file : ${path:root}/ant.xml target : package-xml See the manual page on configuration for more information about configuring Ant build steps. Eclipse plugin \u00b6 Language specification projects are not Eclipse plugins anymore. Git \u00b6 If you're using Git, the .gitignore file is replaced with a new one, add entries that you need again. All generated files that were previously not ignored, are ignored now. To delete all ignored files from the Git index (the files will remain on the filesystem but Git will forget about them), make sure all your useful changes are committed and pushed, then run the following commands: git rm -r --cached . git add . git commit -am \"Remove ignored files\" Building \u00b6 When you are done with converting the project, build it with Cmd+Shift+B or Project \u2023 Build . If the build does not work, try cleaning the project first with Project \u2023 Clean , and then building again. Also make sure that Project \u2023 Build Automatically is turned on.","title":"Spoofax 2.0.0 Migration Guide"},{"location":"release/migrate/2.0.0/#spoofax-200-migration-guide","text":"This migration guide describes the differences between Spoofax 1.5 and 2.0 and describes the steps to convert a Spoofax 1.5 project to Spoofax 2.0 project. To gather the required knowledge for migrating a language project, go through the documentation in the following order: Spoofax 2.0 Release Notes , for a general overview of the changes in Spoofax 2.0. This document, for the concrete differences and steps to convert your Spoofax project.","title":"Spoofax 2.0.0 Migration Guide"},{"location":"release/migrate/2.0.0/#differences","text":"","title":"Differences"},{"location":"release/migrate/2.0.0/#concepts","text":"Spoofax 2.0 introduces several new concepts and terminology. A language specification is the specification of a language using meta-languages. A language specification project specifies a language component . When the specification is compiled, the result is a component which can be loaded into Spoofax. A language component has specifications and implementations for parts of a language, such as its parser, pretty-printer, analysis, transformations, editor services, etc. A component contributes these parts to a language implementation . Multiple components can contribute to the same language implementation, and components can contribute to multiple language implementations. In the most simple case, a single component contributes all parts of the language to a single implementation. Language components can depend on other language components to depend on parts of a language. Currently, there are two kinds of dependencies: compile and source dependencies. A compile dependency on a language component is used to compile source files of that language component. For example, a compile dependency on NaBL will ensure that all .nab files are compiled into .str files. A source dependency is used to depend on source files of a language component. Source dependencies are used to depend on libraries, for example to depend on a Stratego library for name and type analysis. They are also used to compose multiple language components into a single language component, for example to do language extension. A language is the more abstract notion of a language, which has multiple language implementations. For example, the Java language has the JDK7 and JDK8 implementations , which each have front-end and back-end components . An end-user project is a project with programs of an end-user language, in contrast to a language specification project which has programs of meta-languages. For example, a Java project is a Java end-user project, whereas the JDK project is a language specification project.","title":"Concepts"},{"location":"release/migrate/2.0.0/#project-structure","text":"The project structure of language specification projects has significantly changed. The biggest change is that these projects are no longer Eclipse (plugin) projects, so that they can be used outside of the Eclipse platform as well. Ant build files have also been removed since we do not use Ant to build projects any more. Many ESV files have been deprecated, and all generated ESV files in the editor directory have been removed. The following files and directories are no longer part of the project structure: Ant build: .externalToolBuilders , build.generated.xml , build.main.xml Eclipse plugin: plugin.xml , META-INF Eclipse project: .settings , .classpath , .project , build.properties Refactoring: lib/refactor-common.generated.str Deprecated ESV files: editor/langname-Completions.esv , editor/langname-Folding.esv , editor/langname-Outliner.str , editor/langname-Refactorings.esv Generated ESV files: editor/langname-*.generated.esv , editor/langname-Outliner.generated.str The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures. The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files. The following files and directories have been moved: ESV Main ESV file must be at editor/Main.esv . If it does not exist, no packed ESV file will be generated. Packed ESV file: target/metaborg/editor.esv.af SDF Definition: src-gen/syntax/[LanguageName].def Permissive definition: src-gen/syntax/[LanguageName]-permissive.def Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str Parse table: target/metaborg/sdf.tbl Stratego 'editor-common.generated' file: src-gen/stratego/metaborg.str Ctree: target/metaborg/stratego.ctree Generated Java files: src-gen/stratego-java JAR: target/metaborg/stratego.jar Java strategies: src/main/strategies Java strategies JAR: target/metaborg/stratego-javastrat.jar Build cache: target/stratego-cache DynSem Manual Java: src/main/ds Generated Java: src-gen/ds-java The following generated files and directories still exist, but should not be published to source control any more: lib/editor-common.generated.str or stratego/metaborg.str src-gen When importing a language specification project into Eclipse or IntelliJ, several platform-specific files will be generated. These files should not be published to source control to keep projects as platform-agnostic as possible.","title":"Project structure"},{"location":"release/migrate/2.0.0/#eclipse","text":"","title":"Eclipse"},{"location":"release/migrate/2.0.0/#importing","text":"To import a language specification project into Eclipse, use Import... \u2023 Maven \u2023 Existing Maven Projects . We use Maven to set up the correct Java dependencies, which is why there is no special 'Existing Spoofax Projects' importer.","title":"Importing"},{"location":"release/migrate/2.0.0/#builds","text":"Eclipse has the concept of incremental project builders, which incrementally parse, analyze, and compile files inside a project. An example of such a project builder is the Eclipse JDT builder which incrementally builds Java files. Spoofax 1.5 did not use this functionality, but the new Eclipse plugin in Spoofax 2.0 does. The project builder for Spoofax parses, analyses, executes transformations, and shows all error markers, for all language files (Stratego files, SDF3 files, files of your language, etc.) in the project. If the project is opened for the first time, a full build will occur, building all language files. When changes occur in the project, an incremental build occurs, building only changed files. The commands under the Project menu in Eclipse now also affect Spoofax projects. Executing Project \u2023 Build... (or pressing Ctrl/Cmd+Alt+B ) will build the project. Executing Project \u2023 Clean... will delete the .cache directory, reset the index and task engine, remove all error markers, and reanalyze and rebuild all files in the project. This makes the Reset and Reanalyze builder unnecessary, since this is now properly integrated with Eclipse. Automatic building can also be turned off by disabling Project \u2023 Build Automatically . Builds will then only occur if Project \u2023 Build Project is executed or if Ctrl/Cmd+Alt+B is pressed. Furthermore, the language specification build is no longer written in Ant, but in Java using the Pluto incremental build system.","title":"Builds"},{"location":"release/migrate/2.0.0/#natures","text":"The Spoofax language specification project builder is not enabled by default, to enable it a 'Spoofax meta nature' must be added to the project. A nature in Eclipse is a project tag which enables functionality for that project. To add the Spoofax nature to a project, right click the project, and choose Spoofax (meta) \u2023 Add Spoofax meta nature . When importing a language specification, this nature is automatically added. For end-user projects, right click the project, and choose Spoofax \u2023 Add Spoofax nature to add a nature for end-user projects. Editors will parse and analyze files regardless of there being a Spoofax nature, but the on-save handler will not be called.","title":"Natures"},{"location":"release/migrate/2.0.0/#builders","text":"Builders for the open editor are now located in the Spoofax main menu instead of buttons on the tool bar. Builders wait for the analyzed AST if needed, so the issue where builders are sometimes not executed on the analyzed AST should be solved now. Builders can also be executed on a set of files by selecting the files in the project or package explorer, right clicking the files, selecting the language name from the menu, and then selecting a builder.","title":"Builders"},{"location":"release/migrate/2.0.0/#cancellation","text":"Editor updates can now be cancelled by clicking the red stop button in the progress view. If the progress view is not visible, you can open it by choosing Window \u2023 Show View \u2023 Progress . If the editor update is not responsive (it is looping for example), the thread running the editor update will be killed after a while. Killing a thread during analysis may leave the index and task engine in an inconsistent state. If this happens, clean the project using Project \u2023 Clean... to force a full build, which makes the state consistent again. Killing a thread is not very well supported in Java and may break Eclipse or even the JVM, which then requires a restart. Project builds and transformations can also be cancelled in the progress view.","title":"Cancellation"},{"location":"release/migrate/2.0.0/#console-logging","text":"Console logging in the new plugin is more prominent so that we can diagnose problems more easily. If the console is not visible, you can open it by choosing Window \u2023 Show View \u2023 Console . The console does not automatically pop-up when there is a message any more, so it can also be hidden by just closing it. All warning and error messages are also sent to Eclipse's error log. The error log can sometimes contain more information about exceptions and stack traces in errors. If the error log is not visible, you can open it by choosing Window \u2023 Show View \u2023 Error Log .","title":"Console logging"},{"location":"release/migrate/2.0.0/#manually-loadingunloading-a-language","text":"A language can be manually loaded or reloaded by right clicking a project and choosing Spoofax (meta) \u2023 Load language , and unloaded with Spoofax (meta) \u2023 Unload language .","title":"Manually loading/unloading a language"},{"location":"release/migrate/2.0.0/#external-dependencies","text":"The new plugin does not depend on a modified version of IMP, making it possible to install the Rascal plugin alongside the Spoofax plugin. All other external dependencies are limited to the Spoofax plugin, which should prevent conflicts with other Eclipse plugins.","title":"External dependencies"},{"location":"release/migrate/2.0.0/#converting-a-project","text":"If your project is simple (e.g. it only has syntax and a few transformations), the easiest way to convert your project is to create a new Spoofax language specification project, and to copy your files into that project. Otherwise, Spoofax 2.0 supports converting an old Spoofax project into a new Spoofax project, but some conversions need to be done manually. Warning Converting a Spoofax project is a destructive operation, some files will be deleted, replaced, or changed. Make a backup of your projects before doing any conversions!","title":"Converting a project"},{"location":"release/migrate/2.0.0/#automatic-conversion","text":"First, import your existing Spoofax project into Eclipse using File \u2023 Import... \u2023 Existing Projects into Workspace . Right click the project, and choose Spoofax (meta) \u2023 Upgrade language project . A wizard screen will pop up where you have to fill in some details about your language. If a packed.esv file was found, Spoofax will try to fill in some fields for you. If not, all fields need to be filled in manually. The id and name of your language can be found in the main ESV file. For group id , use a Maven identifier for your organization (e.g. org.metaborg), and as version : 1.0.0-SNAPSHOT. Warning Make sure that the id and name fields match exactly with the fields in your ESV file, otherwise the conversion will go wrong. Press finish to convert the language project.","title":"Automatic conversion"},{"location":"release/migrate/2.0.0/#manual-conversion","text":"Unfortunately, not all required conversions can be done automatically. Do the following conversions manually.","title":"Manual conversion"},{"location":"release/migrate/2.0.0/#project-configuration","text":"Most of the project configuration is now in the metaborg.yaml file. The manual page on configuration lists all configuration options. Add/remove compile and source dependencies as needed. Add build configuration, such as Stratego compiler arguments, SDF compiler arguments, external def files, and external JAR files.","title":"Project configuration"},{"location":"release/migrate/2.0.0/#imports","text":"In Stratego, SDF2, SDF3, NaBL, and TS files: Remove src-gen , lib , and trans , from module names and imports. These paths are now on the source path of the SDF and Stratego compilers. In Stratego, NaBL, and TS files: Instead of importing lib/editor-common.generated , import stratego/metaborg . Instead of importing include/<langname>-parenthesize , import pp/<langname>-parenthesize . If you're using SDF3: Instead of importing the signatures from include/<langname> , import them from signatures/<langname>-sig . These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import signatures/- to import all signature files, if your syntax definition is not spread over multiple directories. If you're using SDF2 or an external definition file: Instead of importing the signatures from include/<langname> , import th em from signatures/<langname> .","title":"Imports"},{"location":"release/migrate/2.0.0/#sdf","text":"If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file: language : sdf : version : sdf2","title":"SDF"},{"location":"release/migrate/2.0.0/#nabl-and-ts","text":"If you\u2019re using a NaBL/TS based analysis, perform the following changes: NaBL files are now generated into src-gen/names , fix imports to NaBL files, delete old generated NaBL files. TS files are now generated into src-gen/types , fix imports to TS files, delete old generated TS files. The editor-analyze calls have been changed. Remove analysis-single-default-interface , analysis-multiple-default-interface , and editor-analyze . Replace it with: editor-analyze = analyze-all ( pre-analysis , post-analysis , pp-message |< language >) with the pre-analysis , post-analysis , and pp-message arguments that you were using before. Also make sure the observer (in your esv) has the (multifile) property. The editor-save call to analysis-save-default(|<language>) has been removed, remove that call. You can remove editor-save entirely if you don\u2019t do any generation, also remove the on save strategy from ESV if you do. If you do generation but do not return a (file, text) tuple from editor-save, be sure to return a !None() to tell Spoofax that you\u2019re returning nothing. The index-setup and task-setup strategies have been removed, Spoofax Core does this for you now. Remove all calls to these strategies. Remove the path argument to analysis-resolve in editor-resolve . Remove the path argument to analysis-propose-completions in editor-complete . Remove the debug-reanalyze strategy, and remove it from your menu in ESV. You can reanalyze by cleaning the project.","title":"NaBL and TS"},{"location":"release/migrate/2.0.0/#esv","text":"The following ESV files are now deprecated, delete and remove any imports to these files: editor/langname-Completions.esv editor/langname-Folding.esv editor/langname-Refactorings.esv Previously generated ESV files in the editor directory are not generated any more. Delete the generated files and remove the imports to generated files. The colorer ESV file is now generated to src-gen/editor/Colorer.generated.esv , import it with imports editor/Colorer.generated in an ESV file. The generated syntax ESV file is no longer generated. If you were using the defaults from the generated file, add them to an ESV file: language line comment : \"//\" block comment : \"/*\" * \"*/\" fences : [ ] ( ) { } The outliner ( editor/langname-Outliner.str ) must be moved to the trans directory. Rename it to trans/outline.str , change its module to outline , and fix imports of the outliner. Change the file name of the main ESV file to Main.esv , and change its module to Main . In the main ESV file: Change the parse table: table : target/metaborg/sdf . tbl Change the Stratego providers For ctree projects: provider : target/metaborg/stratego . ctree For jar projects: provider : target/metaborg/stratego . jar For projects with Java strategies: provider : target/metaborg/stratego . jar provider : target/metaborg/stratego-javastrat . jar","title":"ESV"},{"location":"release/migrate/2.0.0/#java-strategies","text":"If your project has Java strategies: Create the src/main/strategies directory. Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... , to update the Java source directories of the project.","title":"Java strategies"},{"location":"release/migrate/2.0.0/#dynsem","text":"If your project has manual DynSem Java files: Create the src/main/ds directory. Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... , to update the Java source directories of the project.","title":"DynSem"},{"location":"release/migrate/2.0.0/#ant-build-customization","text":"Language specification builds do not use Ant any more, so any customizations to the build.main.xml are lost. To perform an Ant task before and after the build, add the following configuration option to your metaborg.yaml file: build : ant : - phase : preCompile file : ${path:root}/ant.xml target : generate-xml - phase : postCompile file : ${path:root}/ant.xml target : package-xml See the manual page on configuration for more information about configuring Ant build steps.","title":"Ant build customization"},{"location":"release/migrate/2.0.0/#eclipse-plugin","text":"Language specification projects are not Eclipse plugins anymore.","title":"Eclipse plugin"},{"location":"release/migrate/2.0.0/#git","text":"If you're using Git, the .gitignore file is replaced with a new one, add entries that you need again. All generated files that were previously not ignored, are ignored now. To delete all ignored files from the Git index (the files will remain on the filesystem but Git will forget about them), make sure all your useful changes are committed and pushed, then run the following commands: git rm -r --cached . git add . git commit -am \"Remove ignored files\"","title":"Git"},{"location":"release/migrate/2.0.0/#building","text":"When you are done with converting the project, build it with Cmd+Shift+B or Project \u2023 Build . If the build does not work, try cleaning the project first with Project \u2023 Clean , and then building again. Also make sure that Project \u2023 Build Automatically is turned on.","title":"Building"},{"location":"release/migrate/2.1.0/","text":"Spoofax 2.1.0 Migration Guide \u00b6 This migration guide describes the differences between Spoofax 2.0 and 2.1 and how to convert to 2.1. New Stratego library for Spoofax \u00b6 Historically, the org.metaborg.meta.lib.analysis library (also called the runtime libraries ) from this repo , was first used as a library to support NaBL, TS, and task engine based static analysis. However, a lot of other functionality such as completions, refactoring, origin tracking, and annotation handling, was also added to the library for convenience. Likewise, the src-gen/stratego/metaborg.str generated file also contains arbitrary functionality such as parsing and import path primitives, and the src-gen/editor/Colorer.generated generated file contains a default coloring scheme. Since this kind of functionality does not belong the analysis library and generated files, we have moved this into a new library, libspoofax , which can be found at this repo . Migration \u00b6 The org.metaborg.meta.lib.analysis library still contains the old arbitrary functionality, but is now deprecated , meaning we will not update that functionality any more, and that it will be removed in a future version. Any functionality pertaining NaBL, TS, and task engine based static analysis will of course be retained. Likewise, the src-gen/stratego/metaborg.str and src-gen/editor/Colorer.generated generated files are also deprecated , meaning that they will stop being generated in a future version. The new libspoofax library is now required for every Spoofax project. Add a source dependency to org.metaborg:meta.lib.spoofax:${metaborgVersion} in your metaborg.yaml file. For example, change the following dependencies: dependencies : compile : - org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion} source : - org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} into: dependencies : compile : - org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion} source : - org.metaborg:meta.lib.spoofax:${metaborgVersion} - org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} If you do not use NaBL, TS, and task engine based analysis any more, you can also delete the org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} source dependency. Some imports have to be changed to point to the new libspoofax library: In editor/Syntax.esv or your equivalent ESV file that handles coloring: Change import editor/Colorer.generated to libspoofax/color/default In trans/analysis.str for NaBL/TS projects: Add import libspoofax/core/language In trans/outline.str : Remove imports to the runtime libraries Add import libspoofax/editor/outline In trans/pp.str : Remove imports to the runtime libraries Add imports libspoofax/sdf/pp and libspoofax/editor/refactoring/- In other Stratego files: Remove all imports to the runtime libraries that do not pertain NaBL, TS, and task engine based static analysis, and replace them with libspoofax equivalents. Remove all imports to the stratego/metaborg generated file, and replace them with libspoofax equivalents. Here is a list of other imports and strategies that were moved: Imports: runtime/editor/origins -> libspoofax/term/origin runtime/editor/annotations -> libspoofax/term/annotation runtime/completion/- -> libspoofax/editor/completion/- Strategies: *-at-position : libspoofax/term/position parse-file : libspoofax/core/parse language : libspoofax/core/language project-path : libspoofax/resource/path open-import : libspoofax/resource/cache refresh-workspace-file : removed, not needed any more since all file system operations go though VFS, which routes them through Eclipse.","title":"Spoofax 2.1.0 Migration Guide"},{"location":"release/migrate/2.1.0/#spoofax-210-migration-guide","text":"This migration guide describes the differences between Spoofax 2.0 and 2.1 and how to convert to 2.1.","title":"Spoofax 2.1.0 Migration Guide"},{"location":"release/migrate/2.1.0/#new-stratego-library-for-spoofax","text":"Historically, the org.metaborg.meta.lib.analysis library (also called the runtime libraries ) from this repo , was first used as a library to support NaBL, TS, and task engine based static analysis. However, a lot of other functionality such as completions, refactoring, origin tracking, and annotation handling, was also added to the library for convenience. Likewise, the src-gen/stratego/metaborg.str generated file also contains arbitrary functionality such as parsing and import path primitives, and the src-gen/editor/Colorer.generated generated file contains a default coloring scheme. Since this kind of functionality does not belong the analysis library and generated files, we have moved this into a new library, libspoofax , which can be found at this repo .","title":"New Stratego library for Spoofax"},{"location":"release/migrate/2.1.0/#migration","text":"The org.metaborg.meta.lib.analysis library still contains the old arbitrary functionality, but is now deprecated , meaning we will not update that functionality any more, and that it will be removed in a future version. Any functionality pertaining NaBL, TS, and task engine based static analysis will of course be retained. Likewise, the src-gen/stratego/metaborg.str and src-gen/editor/Colorer.generated generated files are also deprecated , meaning that they will stop being generated in a future version. The new libspoofax library is now required for every Spoofax project. Add a source dependency to org.metaborg:meta.lib.spoofax:${metaborgVersion} in your metaborg.yaml file. For example, change the following dependencies: dependencies : compile : - org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion} source : - org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} into: dependencies : compile : - org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion} - org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion} source : - org.metaborg:meta.lib.spoofax:${metaborgVersion} - org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} If you do not use NaBL, TS, and task engine based analysis any more, you can also delete the org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion} source dependency. Some imports have to be changed to point to the new libspoofax library: In editor/Syntax.esv or your equivalent ESV file that handles coloring: Change import editor/Colorer.generated to libspoofax/color/default In trans/analysis.str for NaBL/TS projects: Add import libspoofax/core/language In trans/outline.str : Remove imports to the runtime libraries Add import libspoofax/editor/outline In trans/pp.str : Remove imports to the runtime libraries Add imports libspoofax/sdf/pp and libspoofax/editor/refactoring/- In other Stratego files: Remove all imports to the runtime libraries that do not pertain NaBL, TS, and task engine based static analysis, and replace them with libspoofax equivalents. Remove all imports to the stratego/metaborg generated file, and replace them with libspoofax equivalents. Here is a list of other imports and strategies that were moved: Imports: runtime/editor/origins -> libspoofax/term/origin runtime/editor/annotations -> libspoofax/term/annotation runtime/completion/- -> libspoofax/editor/completion/- Strategies: *-at-position : libspoofax/term/position parse-file : libspoofax/core/parse language : libspoofax/core/language project-path : libspoofax/resource/path open-import : libspoofax/resource/cache refresh-workspace-file : removed, not needed any more since all file system operations go though VFS, which routes them through Eclipse.","title":"Migration"},{"location":"release/migrate/2.5.10/","text":"Spoofax 2.5.10 Migration Guide \u00b6 A change in Statix need migration for users of the Stratego API. SDF3 \u00b6 In an upcoming version of Spoofax 2 it will be required to properly declare sorts in SDF3 syntax definitions. Sorts for which context-free rules are defined should be declared in a context-free sorts block: context-free sorts Stmt Expr Note : For backward compatibility, sorts declared in a plain sorts block are treated as context-free sorts. So this is equivalent and also fine: sorts Stmt Expr Sorts for which lexical rules are defined should be declared in a lexical sorts block: lexical sorts ID INT STRING Note : Lexical sorts are not supported in combination with sdf2table: c . Typesmart \u00b6 If your metaborg.yaml file still contains mention of Typesmart (e.g. debug: typesmart: false ), you can remove it. See the release notes for why Typesmart support was removed. Stratego \u00b6 Spoofax languages used to always generate target/metaborg/stratego-javastrat.jar which contains the compiled Java code from src/main/stratego . Conditional on your settings in the metaborg.yaml file, your Stratego code would be turned into target/metaborg/stratego.ctree or target/metaborg/stratego.jar depending on whether you chose compilation or interpretation. As of this release, there is no longer a separate stratego-javastrat.jar . Instead stratego.jar is always generated and always contains at least the compiled Java code from src/main/stratego . If you choose compilation for your Stratego code, the compiled Stratego code is added to the stratego.jar file as was already the case originally. What you need to do: Go to your editor/main.esv file and find the provider: ... lines (or search your other ESV files if it's not there). The line provider: target/metaborg/stratego-javastrat.jar should be replaced by provider: target/metaborg/stratego.jar . If you already have a provider: target/metaborg/stratego.jar , one is enough and you can remove the stratego-javastrat.jar provider directive entirely. Statix \u00b6 The AST property type is now a built-in property. Users of the Stratego API to get this property should change their API calls. Instead of stx-get-ast-property (| a , \"type\" ) one should now use: stx-get-ast-type (| a ) SPT \u00b6 In SPT, parse succeeds tests will now fail when the input parses ambiguously. If this is intended, use parse ambiguous instead.","title":"Spoofax 2.5.10 Migration Guide"},{"location":"release/migrate/2.5.10/#spoofax-2510-migration-guide","text":"A change in Statix need migration for users of the Stratego API.","title":"Spoofax 2.5.10 Migration Guide"},{"location":"release/migrate/2.5.10/#sdf3","text":"In an upcoming version of Spoofax 2 it will be required to properly declare sorts in SDF3 syntax definitions. Sorts for which context-free rules are defined should be declared in a context-free sorts block: context-free sorts Stmt Expr Note : For backward compatibility, sorts declared in a plain sorts block are treated as context-free sorts. So this is equivalent and also fine: sorts Stmt Expr Sorts for which lexical rules are defined should be declared in a lexical sorts block: lexical sorts ID INT STRING Note : Lexical sorts are not supported in combination with sdf2table: c .","title":"SDF3"},{"location":"release/migrate/2.5.10/#typesmart","text":"If your metaborg.yaml file still contains mention of Typesmart (e.g. debug: typesmart: false ), you can remove it. See the release notes for why Typesmart support was removed.","title":"Typesmart"},{"location":"release/migrate/2.5.10/#stratego","text":"Spoofax languages used to always generate target/metaborg/stratego-javastrat.jar which contains the compiled Java code from src/main/stratego . Conditional on your settings in the metaborg.yaml file, your Stratego code would be turned into target/metaborg/stratego.ctree or target/metaborg/stratego.jar depending on whether you chose compilation or interpretation. As of this release, there is no longer a separate stratego-javastrat.jar . Instead stratego.jar is always generated and always contains at least the compiled Java code from src/main/stratego . If you choose compilation for your Stratego code, the compiled Stratego code is added to the stratego.jar file as was already the case originally. What you need to do: Go to your editor/main.esv file and find the provider: ... lines (or search your other ESV files if it's not there). The line provider: target/metaborg/stratego-javastrat.jar should be replaced by provider: target/metaborg/stratego.jar . If you already have a provider: target/metaborg/stratego.jar , one is enough and you can remove the stratego-javastrat.jar provider directive entirely.","title":"Stratego"},{"location":"release/migrate/2.5.10/#statix","text":"The AST property type is now a built-in property. Users of the Stratego API to get this property should change their API calls. Instead of stx-get-ast-property (| a , \"type\" ) one should now use: stx-get-ast-type (| a )","title":"Statix"},{"location":"release/migrate/2.5.10/#spt","text":"In SPT, parse succeeds tests will now fail when the input parses ambiguously. If this is intended, use parse ambiguous instead.","title":"SPT"},{"location":"release/migrate/2.5.15/","text":"Spoofax 2.5.15 Migration Guide \u00b6 Statix Injection Explication \u00b6 There was an issue with Statix injection explication where the origin of the top-level term was lost and this caused SPT tests of Stratego strategies on analyzed ASTs to fail. Fix this by wrapping the bodies of the pre-analyze and post-analyze strategies in analyze.str with origin-track-forced , like this: imports libspoofax / term / origin rules pre-analyze = origin-track-forced ( explicate-injections-MyLang-Start ) post-analyze = origin-track-forced ( implicate-injections-MyLang-Start ) This is already fixed in new projects.","title":"Spoofax 2.5.15 Migration Guide"},{"location":"release/migrate/2.5.15/#spoofax-2515-migration-guide","text":"","title":"Spoofax 2.5.15 Migration Guide"},{"location":"release/migrate/2.5.15/#statix-injection-explication","text":"There was an issue with Statix injection explication where the origin of the top-level term was lost and this caused SPT tests of Stratego strategies on analyzed ASTs to fail. Fix this by wrapping the bodies of the pre-analyze and post-analyze strategies in analyze.str with origin-track-forced , like this: imports libspoofax / term / origin rules pre-analyze = origin-track-forced ( explicate-injections-MyLang-Start ) post-analyze = origin-track-forced ( implicate-injections-MyLang-Start ) This is already fixed in new projects.","title":"Statix Injection Explication"},{"location":"release/migrate/2.5.5/","text":"Spoofax 2.5.5 Migration Guide \u00b6 A few changes in Statix need migration for specs written for older versions. Statix \u00b6 A few features in Statix were not well-defined and removed until a better way to support them is found. Therefore, the following changes may require you to make small modifications to a specification: Functional constraints can only have a single output. Regular expression and label order must be direct parameters to queries. Namespace based query short-hands require a literal occurrence as argument, and an explicit resolution policy entry. Functional constraint outputs \u00b6 Functional constraints previously were allowed to have multiple output arguments, such as: f : T * T -> T * T ` This was sometimes indistinguishable from types with a single tuple output, such as: f : T * T -> ( T * T ) ` From now on, functional constraints can only have a single output. Constraints with multiple outputs need to be rewritten to return a tuple instead. Query parameters \u00b6 Queries would accept arbitrary predicates for the label regular expression and label order. For example, a query could be written as: query filter myWf and true min myOrd and false in s |-> _ with myWf ( ls ) : - pathMatch [ P *] ( ls ). myOrd ( l1 , l2 ) : - pathLt [$ < P ] ( l1 , l2 ). This is not possible anymore, instead the regular expression and label order must be direct parameters of the query. The query above should be directly written as: query filter P * and true min $ < P and false in s |-> _ The following syntax is still accepted, but deprecated: query filter pathMatch [ P *] and true min pathLt [$ < P ] and false in s |-> _ Namespace-based resolution shorthands \u00b6 The requirements for namespace-based resolution shorthands have become stricter. First, if they are used, ther emust be an explicit resolution policy for the namespace. For example, using a constraints such as: Var { x @ - } in s |-> _ type of Var { x @ - } in s |-> _ requires in the signature at least: signature name-resolution resolve Var A full resolution policy with regular expression and label order looks like this: signature name-resolution resolve Var filter P * min $ < P Second, the namespace-based constraints require an occurrence literal. The following does not work anymore: d == Var { x @ - }, d in s |-> _ The occurrence has to be repeated in the constraints, as: Var { x @ - } in s |-> _","title":"Spoofax 2.5.5 Migration Guide"},{"location":"release/migrate/2.5.5/#spoofax-255-migration-guide","text":"A few changes in Statix need migration for specs written for older versions.","title":"Spoofax 2.5.5 Migration Guide"},{"location":"release/migrate/2.5.5/#statix","text":"A few features in Statix were not well-defined and removed until a better way to support them is found. Therefore, the following changes may require you to make small modifications to a specification: Functional constraints can only have a single output. Regular expression and label order must be direct parameters to queries. Namespace based query short-hands require a literal occurrence as argument, and an explicit resolution policy entry.","title":"Statix"},{"location":"release/migrate/2.5.5/#functional-constraint-outputs","text":"Functional constraints previously were allowed to have multiple output arguments, such as: f : T * T -> T * T ` This was sometimes indistinguishable from types with a single tuple output, such as: f : T * T -> ( T * T ) ` From now on, functional constraints can only have a single output. Constraints with multiple outputs need to be rewritten to return a tuple instead.","title":"Functional constraint outputs"},{"location":"release/migrate/2.5.5/#query-parameters","text":"Queries would accept arbitrary predicates for the label regular expression and label order. For example, a query could be written as: query filter myWf and true min myOrd and false in s |-> _ with myWf ( ls ) : - pathMatch [ P *] ( ls ). myOrd ( l1 , l2 ) : - pathLt [$ < P ] ( l1 , l2 ). This is not possible anymore, instead the regular expression and label order must be direct parameters of the query. The query above should be directly written as: query filter P * and true min $ < P and false in s |-> _ The following syntax is still accepted, but deprecated: query filter pathMatch [ P *] and true min pathLt [$ < P ] and false in s |-> _","title":"Query parameters"},{"location":"release/migrate/2.5.5/#namespace-based-resolution-shorthands","text":"The requirements for namespace-based resolution shorthands have become stricter. First, if they are used, ther emust be an explicit resolution policy for the namespace. For example, using a constraints such as: Var { x @ - } in s |-> _ type of Var { x @ - } in s |-> _ requires in the signature at least: signature name-resolution resolve Var A full resolution policy with regular expression and label order looks like this: signature name-resolution resolve Var filter P * min $ < P Second, the namespace-based constraints require an occurrence literal. The following does not work anymore: d == Var { x @ - }, d in s |-> _ The occurrence has to be repeated in the constraints, as: Var { x @ - } in s |-> _","title":"Namespace-based resolution shorthands"},{"location":"release/migrate/march2016_project_structure/","text":"Directory structure migration (March 2016) \u00b6 To clean up the structure of a language specification project, we've made the following changes: ESV Main ESV file must be at editor/Main.esv . If it does not exist, no packed ESV file will be generated. Packed ESV file: target/metaborg/editor.esv.af SDF The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures. The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files. Definition: src-gen/syntax/[LanguageName].def Permissive definition: src-gen/syntax/[LanguageName]-permissive.def Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str Parse table: target/metaborg/sdf.tbl Stratego 'editor-common.generated' file: src-gen/stratego/metaborg.str Ctree: target/metaborg/stratego.ctree Generated Java files: src-gen/stratego-java JAR: target/metaborg/stratego.jar Java strategies: src/main/strategies Java strategies JAR: target/metaborg/stratego-javastrat.jar Build cache: target/stratego-cache DynSem Manual Java: src/main/ds Generated Java: src-gen/ds-java Other Pluto build cache: target/pluto To migrate your project, make the following changes: Change the file name of the main ESV file to Main.esv , and change its module to Main . In the main ESV file: Change the parse table: table : target/metaborg/sdf . tbl Change the Stratego providers For ctree projects: provider : target/metaborg/stratego . ctree For jar projects: provider : target/metaborg/stratego . jar For projects with Java strategies: esv provider : target/metaborg/stratego.jar provider : target/metaborg/stratego-javastrat.jar In all Stratego, NaBL, TS files Instead of importing lib/editor-common.generated , import stratego/metaborg . Instead of importing include/<langname>-parenthesize , import pp/<langname>-parenthesize . If you're using SDF3: Instead of importing the signatures from include/<langname> , import them from signatures/<langname>-sig . These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import signatures/- to import all signature files, if your syntax definition is not spread over multiple directories. If you're using SDF2 or an external definition file: Instead of importing the signatures from include/<langname> , import them from signatures/<langname> . If your project has Java strategies: Create the src/main/strategies directory. Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure. If your project has manual DynSem Java files: Create the src/main/ds directory. Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... . Enable Force Update of Snapshots/Releases in the new window and press Ok . This updates the Java source directories of the project. If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file: language : sdf : version : sdf2","title":"Directory structure migration (March 2016)"},{"location":"release/migrate/march2016_project_structure/#directory-structure-migration-march-2016","text":"To clean up the structure of a language specification project, we've made the following changes: ESV Main ESV file must be at editor/Main.esv . If it does not exist, no packed ESV file will be generated. Packed ESV file: target/metaborg/editor.esv.af SDF The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures. The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files. Definition: src-gen/syntax/[LanguageName].def Permissive definition: src-gen/syntax/[LanguageName]-permissive.def Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str Parse table: target/metaborg/sdf.tbl Stratego 'editor-common.generated' file: src-gen/stratego/metaborg.str Ctree: target/metaborg/stratego.ctree Generated Java files: src-gen/stratego-java JAR: target/metaborg/stratego.jar Java strategies: src/main/strategies Java strategies JAR: target/metaborg/stratego-javastrat.jar Build cache: target/stratego-cache DynSem Manual Java: src/main/ds Generated Java: src-gen/ds-java Other Pluto build cache: target/pluto To migrate your project, make the following changes: Change the file name of the main ESV file to Main.esv , and change its module to Main . In the main ESV file: Change the parse table: table : target/metaborg/sdf . tbl Change the Stratego providers For ctree projects: provider : target/metaborg/stratego . ctree For jar projects: provider : target/metaborg/stratego . jar For projects with Java strategies: esv provider : target/metaborg/stratego.jar provider : target/metaborg/stratego-javastrat.jar In all Stratego, NaBL, TS files Instead of importing lib/editor-common.generated , import stratego/metaborg . Instead of importing include/<langname>-parenthesize , import pp/<langname>-parenthesize . If you're using SDF3: Instead of importing the signatures from include/<langname> , import them from signatures/<langname>-sig . These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import signatures/- to import all signature files, if your syntax definition is not spread over multiple directories. If you're using SDF2 or an external definition file: Instead of importing the signatures from include/<langname> , import them from signatures/<langname> . If your project has Java strategies: Create the src/main/strategies directory. Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure. If your project has manual DynSem Java files: Create the src/main/ds directory. Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure. Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project... . Enable Force Update of Snapshots/Releases in the new window and press Ok . This updates the Java source directories of the project. If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file: language : sdf : version : sdf2","title":"Directory structure migration (March 2016)"},{"location":"release/migrate/vnext/","text":"Spoofax vNext Migration Guide \u00b6 This is a stub for the migration guide of the upcoming version of Spoofax. Update the current documentation vnext.md file instead Until we have migrated to this new documentation, update the vnext.md in the current documentation repository .","title":"Spoofax vNext Migration Guide"},{"location":"release/migrate/vnext/#spoofax-vnext-migration-guide","text":"This is a stub for the migration guide of the upcoming version of Spoofax. Update the current documentation vnext.md file instead Until we have migrated to this new documentation, update the vnext.md in the current documentation repository .","title":"Spoofax vNext Migration Guide"},{"location":"release/note/1.0.0/","text":"Spoofax 1.0.0 (28-12-2011) \u00b6 We're pleased to announce the release of Spoofax 1.0.0. A number of significant new features have been added since the last stable release, a long list of bugs has been fixed, and various minor improvements were introduced. Highlights of the release include: Support for writing tests for language definitions Support for defining refactorings Major improvements to content completion: Spoofax/289 , Spoofax/357 Support for using rewrite rules to disambiguate syntax: Spoofax/328 In addition to these features, we're actively working on improving Spoofax with new features. In particular, we are now working on providing full support for debugging, on an interactive shell for Stratego and custom languages, and a new meta-language called SpoofaxLang to define languages in a more modular fashion. A full list of feature requests and issues addressed in the new version is provided at http://yellowgrass.org/tag/Spoofax/1.0 .","title":"Spoofax 1.0.0 (28-12-2011)"},{"location":"release/note/1.0.0/#spoofax-100-28-12-2011","text":"We're pleased to announce the release of Spoofax 1.0.0. A number of significant new features have been added since the last stable release, a long list of bugs has been fixed, and various minor improvements were introduced. Highlights of the release include: Support for writing tests for language definitions Support for defining refactorings Major improvements to content completion: Spoofax/289 , Spoofax/357 Support for using rewrite rules to disambiguate syntax: Spoofax/328 In addition to these features, we're actively working on improving Spoofax with new features. In particular, we are now working on providing full support for debugging, on an interactive shell for Stratego and custom languages, and a new meta-language called SpoofaxLang to define languages in a more modular fashion. A full list of feature requests and issues addressed in the new version is provided at http://yellowgrass.org/tag/Spoofax/1.0 .","title":"Spoofax 1.0.0 (28-12-2011)"},{"location":"release/note/1.0.2/","text":"Spoofax 1.0.2 (15-02-2012) \u00b6 Today we're releasing a minor maintenance release of Spoofax, version 1.0.2. This release fixes a memory leak that was introduced in the 1.0 release. There are no new features in this release, those will be included in the upcoming 1.1 release instead.","title":"Spoofax 1.0.2 (15-02-2012)"},{"location":"release/note/1.0.2/#spoofax-102-15-02-2012","text":"Today we're releasing a minor maintenance release of Spoofax, version 1.0.2. This release fixes a memory leak that was introduced in the 1.0 release. There are no new features in this release, those will be included in the upcoming 1.1 release instead.","title":"Spoofax 1.0.2 (15-02-2012)"},{"location":"release/note/1.1.0/","text":"Spoofax 1.1.0 (25-03-2013) \u00b6 We are happy to announce the release of Spoofax 1.1! This is the first major release since version 1.0.2 and includes major features and improvements. Spoofax 1.1 supports all current Eclipse versions, up to version 4.2.2. Changes \u00b6 NaBL \u00b6 One of the most important improvements in Spoofax 1.1 is the inclusion of NaBL, the Spoofax Name Binding Language. NaBL is used in all new projects created and significantly simplifies name binding analysis, as well as any editor services that depend on it (e.g., code completion, reference resolving) NaBL is documented at the following pages: Research paper Other \u00b6 Other highlights of the 1.1 release include: Improved build process: generated files can be deleted, building & loading are separated, projects can be cleaned ( http://yellowgrass.org/issue/Spoofax/577 , http://yellowgrass.org/issue/Spoofax/591 , http://yellowgrass.org/issue/Spoofax/578 ) Improved Stratego editor with multi-file reference resolving based on NaBL ( http://yellowgrass.org/issue/Spoofax/12 ) Extended support for customizing refactoring UI ( http://yellowgrass.org/issue/Spoofax/440 ) Automatic configuration of git/svn ignore settings ( http://yellowgrass.org/issue/Spoofax/573 ) Added support loading for Java-based plugin dependencies, in case your plugin depends on some other plugin such as EMF ( http://yellowgrass.org/issue/Spoofax/322 ) And there were a number of notable changes under the hood: Much improved completion engine ( http://yellowgrass.org/issue/Spoofax/360 ) We now show a nice warning if Eclipse is not configured with a proper stack and heap size ( http://yellowgrass.org/issue/Spoofax/86 ) Files are now queued for re-analysis even if their editor is not open ( http://yellowgrass.org/issue/Spoofax/224 ) A comprehensive list of changes can be viewed at http://yellowgrass.org/tag/Spoofax/1.1 .","title":"Spoofax 1.1.0 (25-03-2013)"},{"location":"release/note/1.1.0/#spoofax-110-25-03-2013","text":"We are happy to announce the release of Spoofax 1.1! This is the first major release since version 1.0.2 and includes major features and improvements. Spoofax 1.1 supports all current Eclipse versions, up to version 4.2.2.","title":"Spoofax 1.1.0 (25-03-2013)"},{"location":"release/note/1.1.0/#changes","text":"","title":"Changes"},{"location":"release/note/1.1.0/#nabl","text":"One of the most important improvements in Spoofax 1.1 is the inclusion of NaBL, the Spoofax Name Binding Language. NaBL is used in all new projects created and significantly simplifies name binding analysis, as well as any editor services that depend on it (e.g., code completion, reference resolving) NaBL is documented at the following pages: Research paper","title":"NaBL"},{"location":"release/note/1.1.0/#other","text":"Other highlights of the 1.1 release include: Improved build process: generated files can be deleted, building & loading are separated, projects can be cleaned ( http://yellowgrass.org/issue/Spoofax/577 , http://yellowgrass.org/issue/Spoofax/591 , http://yellowgrass.org/issue/Spoofax/578 ) Improved Stratego editor with multi-file reference resolving based on NaBL ( http://yellowgrass.org/issue/Spoofax/12 ) Extended support for customizing refactoring UI ( http://yellowgrass.org/issue/Spoofax/440 ) Automatic configuration of git/svn ignore settings ( http://yellowgrass.org/issue/Spoofax/573 ) Added support loading for Java-based plugin dependencies, in case your plugin depends on some other plugin such as EMF ( http://yellowgrass.org/issue/Spoofax/322 ) And there were a number of notable changes under the hood: Much improved completion engine ( http://yellowgrass.org/issue/Spoofax/360 ) We now show a nice warning if Eclipse is not configured with a proper stack and heap size ( http://yellowgrass.org/issue/Spoofax/86 ) Files are now queued for re-analysis even if their editor is not open ( http://yellowgrass.org/issue/Spoofax/224 ) A comprehensive list of changes can be viewed at http://yellowgrass.org/tag/Spoofax/1.1 .","title":"Other"},{"location":"release/note/1.2.0/","text":"Spoofax 1.2.0 (13-08-2014) \u00b6 We're happy to announce the release of Spoofax 1.2! This document describes the changes in Spoofax 1.2 since Spoofax 1.1. Changes \u00b6 Editor interface \u00b6 Several aspects of the editor interface for Spoofax languages have been improved. Menus \u00b6 Each language now has its own set of menus. These menus replace the Transform menu that was shared among all Spoofax-based languages. The new menus dynamically pop up in the Eclipse menus toolbar, based on the current active editor. There is now support for submenus, icons and menu separators. Contributors: Oskar van Rest Outline \u00b6 Editor outlines are now specified in Stratego instead of ESV, to allow for full customization. A library with reusable outline strategies is provided to allow you to quickly realize an outline. It is now possible to have icons in your outline. It is now possible to also base an outline on the current text selection instead of the complete text. Contributors: Oskar van Rest Properties view \u00b6 A property view has been added that shows properties for the selected AST node. By default, the new properties view integrates with NaBL and presents (NaBL) properties associated with the selected text in the editor. The properties view can be customized to show different kinds of properties, either to aid language development or to provide language users with additional information about their programs. Contributors: Daco Harkes, Oskar van Rest Meta-languages \u00b6 We have created a new version of SDF, improved NaBL and developed a DSL for describing type systems: TS. SDF3 \u00b6 SDF3 is the next iteration of SDF, replacing SDF2. The most important new features are: Productive productions can be used in context-free syntax sections, improving readability and consistency with main-stream grammar notation. Constructors are now formally integrated to the language. A productive production introduces the constructor directly after the left hand side non-terminal. By using constructors, productions can now be uniquely identified. Therefore, it is no longer necessary to repeat the entire production in the priorities section, but use its Sort.Constructor shorthand. Template productions are the major change from SDF2. They can be used to define what the concrete syntax of the language should look like. Syntactic completion and pretty-printer rules are automatically generated from templates. Documentation Contributors: Eduardo Amorim, Guido Wachsmuth NaBL \u00b6 NaBL has received many bug fixes and several new features. New features include: Filter clauses can be used to constrain valid resolution targets based on properties such as types. Disambiguation clauses can be used to disambiguate resolutions based on relations between properties, for example type hierarchies. It is now possible to specify non-transitive scopes, in which resolution ignores lexical parent scopes. Where clauses can include constraints and type calculations in TS syntax. We added new scope calculation constructs, which can be used to navigate the scope hierarchy. For example, it is possible to calculate the surrounding class of the current variable scope. For examples of name binding rules, see the Java front project Contributors: Guido Wachsmuth, Gabri\u00ebl Konat TS \u00b6 TS is a new meta-language for the specification of type analysis that is complementary to NaBL. Type rules in TS define constraints on abstract syntax tree nodes and may compute a type or other property. In addition, type rules can define subtyping predicates (relations on types) and type functions. For examples of type system rules, see the Java front project Contributors: Eelco Visser, Guido Wachsmuth, Gabri\u00ebl Konat Command-line integration \u00b6 Programs of your language can now be parsed, analyzed, and transformed from the command-line using Sunshine (in contrast with an Eclipse). Sunshine can also be used as a Java API to develop new language tooling. Contributors: Vlad Vergu Finer-grained incrementality \u00b6 Incrementality in the previous version of Spoofax was based on files. Any file that changed, and any dependent files would be reparsed and reanalysed completely. In the new version of Spoofax, there is more fine-grained dependency tracking which allows more fine-grained incrementality. If a file changes, that file is reparsed, but only affected computations are recomputed, and other files are never reparsed. Name and type computations which are described in NaBL and TS are incrementally executed. Incrementality is powered by a task engine, described in our paper . Contributors: Gabri\u00ebl Konat, Guido Wachsmuth Modelware \u00b6 Spoofax Modelware is a new Spoofax component that provides integration with the Eclipse Modeling Framework (EMF) and the Graphical Modeling Framework (GMF) to allow for real-time synchronized textual and graphical editors and/or views. It also allows you to use other EMF-based tooling in combination with Spoofax. Contributors: Oskar van Rest Documentation \u00b6 We have moved most of our documentation to the doc repository on GitHub. We're still in the process of moving over other documentation and writing more documentation. There are also two new tutorials available: Questionaire language tutorial : learn to create a questionaire language. This tutorial was given in a hands-on session at the Code Generation conference in 2014. Compiler Construction lab assignments : a more in-depth tutorial. These are the assignments from our Compiler Construction lab where we teach students to create MiniJava inside Spoofax. Contributors: Guido Wachsmuth and others Other \u00b6 To reduce maintenance effort, we have dropped support for Eclipse 3.7 (Indigo) and lower. We now support Eclipse 4.2 (Juno), 4.3 (Kepler), and 4.4 (Luna). We recommend you to download and install Eclipse 4.4 (Luna) for Java Developers . We have also dropped support for Java 5 and 6. Java 7 and 8 are supported, we recommend you to download and install Java 8 . Note that on OSX, Java 6 is installed by default which is not enough to run Spoofax, install Java 8 from the previous link. All source code has been moved to our organization on GitHub . Feel free to fork our code and send pull requests for patches or improvements! More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.2 Contributors: Vlad Vergu, Gabri\u00ebl Konat","title":"Spoofax 1.2.0 (13-08-2014)"},{"location":"release/note/1.2.0/#spoofax-120-13-08-2014","text":"We're happy to announce the release of Spoofax 1.2! This document describes the changes in Spoofax 1.2 since Spoofax 1.1.","title":"Spoofax 1.2.0 (13-08-2014)"},{"location":"release/note/1.2.0/#changes","text":"","title":"Changes"},{"location":"release/note/1.2.0/#editor-interface","text":"Several aspects of the editor interface for Spoofax languages have been improved.","title":"Editor interface"},{"location":"release/note/1.2.0/#menus","text":"Each language now has its own set of menus. These menus replace the Transform menu that was shared among all Spoofax-based languages. The new menus dynamically pop up in the Eclipse menus toolbar, based on the current active editor. There is now support for submenus, icons and menu separators. Contributors: Oskar van Rest","title":"Menus"},{"location":"release/note/1.2.0/#outline","text":"Editor outlines are now specified in Stratego instead of ESV, to allow for full customization. A library with reusable outline strategies is provided to allow you to quickly realize an outline. It is now possible to have icons in your outline. It is now possible to also base an outline on the current text selection instead of the complete text. Contributors: Oskar van Rest","title":"Outline"},{"location":"release/note/1.2.0/#properties-view","text":"A property view has been added that shows properties for the selected AST node. By default, the new properties view integrates with NaBL and presents (NaBL) properties associated with the selected text in the editor. The properties view can be customized to show different kinds of properties, either to aid language development or to provide language users with additional information about their programs. Contributors: Daco Harkes, Oskar van Rest","title":"Properties view"},{"location":"release/note/1.2.0/#meta-languages","text":"We have created a new version of SDF, improved NaBL and developed a DSL for describing type systems: TS.","title":"Meta-languages"},{"location":"release/note/1.2.0/#sdf3","text":"SDF3 is the next iteration of SDF, replacing SDF2. The most important new features are: Productive productions can be used in context-free syntax sections, improving readability and consistency with main-stream grammar notation. Constructors are now formally integrated to the language. A productive production introduces the constructor directly after the left hand side non-terminal. By using constructors, productions can now be uniquely identified. Therefore, it is no longer necessary to repeat the entire production in the priorities section, but use its Sort.Constructor shorthand. Template productions are the major change from SDF2. They can be used to define what the concrete syntax of the language should look like. Syntactic completion and pretty-printer rules are automatically generated from templates. Documentation Contributors: Eduardo Amorim, Guido Wachsmuth","title":"SDF3"},{"location":"release/note/1.2.0/#nabl","text":"NaBL has received many bug fixes and several new features. New features include: Filter clauses can be used to constrain valid resolution targets based on properties such as types. Disambiguation clauses can be used to disambiguate resolutions based on relations between properties, for example type hierarchies. It is now possible to specify non-transitive scopes, in which resolution ignores lexical parent scopes. Where clauses can include constraints and type calculations in TS syntax. We added new scope calculation constructs, which can be used to navigate the scope hierarchy. For example, it is possible to calculate the surrounding class of the current variable scope. For examples of name binding rules, see the Java front project Contributors: Guido Wachsmuth, Gabri\u00ebl Konat","title":"NaBL"},{"location":"release/note/1.2.0/#ts","text":"TS is a new meta-language for the specification of type analysis that is complementary to NaBL. Type rules in TS define constraints on abstract syntax tree nodes and may compute a type or other property. In addition, type rules can define subtyping predicates (relations on types) and type functions. For examples of type system rules, see the Java front project Contributors: Eelco Visser, Guido Wachsmuth, Gabri\u00ebl Konat","title":"TS"},{"location":"release/note/1.2.0/#command-line-integration","text":"Programs of your language can now be parsed, analyzed, and transformed from the command-line using Sunshine (in contrast with an Eclipse). Sunshine can also be used as a Java API to develop new language tooling. Contributors: Vlad Vergu","title":"Command-line integration"},{"location":"release/note/1.2.0/#finer-grained-incrementality","text":"Incrementality in the previous version of Spoofax was based on files. Any file that changed, and any dependent files would be reparsed and reanalysed completely. In the new version of Spoofax, there is more fine-grained dependency tracking which allows more fine-grained incrementality. If a file changes, that file is reparsed, but only affected computations are recomputed, and other files are never reparsed. Name and type computations which are described in NaBL and TS are incrementally executed. Incrementality is powered by a task engine, described in our paper . Contributors: Gabri\u00ebl Konat, Guido Wachsmuth","title":"Finer-grained incrementality"},{"location":"release/note/1.2.0/#modelware","text":"Spoofax Modelware is a new Spoofax component that provides integration with the Eclipse Modeling Framework (EMF) and the Graphical Modeling Framework (GMF) to allow for real-time synchronized textual and graphical editors and/or views. It also allows you to use other EMF-based tooling in combination with Spoofax. Contributors: Oskar van Rest","title":"Modelware"},{"location":"release/note/1.2.0/#documentation","text":"We have moved most of our documentation to the doc repository on GitHub. We're still in the process of moving over other documentation and writing more documentation. There are also two new tutorials available: Questionaire language tutorial : learn to create a questionaire language. This tutorial was given in a hands-on session at the Code Generation conference in 2014. Compiler Construction lab assignments : a more in-depth tutorial. These are the assignments from our Compiler Construction lab where we teach students to create MiniJava inside Spoofax. Contributors: Guido Wachsmuth and others","title":"Documentation"},{"location":"release/note/1.2.0/#other","text":"To reduce maintenance effort, we have dropped support for Eclipse 3.7 (Indigo) and lower. We now support Eclipse 4.2 (Juno), 4.3 (Kepler), and 4.4 (Luna). We recommend you to download and install Eclipse 4.4 (Luna) for Java Developers . We have also dropped support for Java 5 and 6. Java 7 and 8 are supported, we recommend you to download and install Java 8 . Note that on OSX, Java 6 is installed by default which is not enough to run Spoofax, install Java 8 from the previous link. All source code has been moved to our organization on GitHub . Feel free to fork our code and send pull requests for patches or improvements! More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.2 Contributors: Vlad Vergu, Gabri\u00ebl Konat","title":"Other"},{"location":"release/note/1.3.0/","text":"Spoofax 1.3.0 (12-11-2014) \u00b6 We're happy to announce the release of Spoofax 1.3, which improves SDF3, the build system for languages, and the build system for Spoofax itself. Porting \u00b6 Language projects \u00b6 The build for language projects has changed since the last Spoofax, so your language projects need to be migrated. To automatically migrate your project, follow these steps: Right click the project in Eclipse Choose Spoofax -> Upgrade Spoofax project Press Finish This will automatically upgrade your project to the latest format, after which you can build your project normally. The build might fail with: sdf2parenthesize: BUILD FAILED /Users/gohla/spoofax/workspace/runtime-Spoofax/Entity/build.generated.xml:266: The following error occurred while executing this line: Target \"sdf2parenthesize.helper\" does not exist in the project \"Entity\". If this is the case, build again, because some files are only upgraded after building once. Compiled Java files are now stored in the target/classes directory instead of the bin directory, so the bin directory can be deleted. SDF3 grammars \u00b6 SDF2 and old SDF3 grammars can be migrated. Some manual changes might still be necessary since a sort cannot have more than one constructor with the same name and arity, and priority rules may contain the entire production instead of priority shorthands. Changes \u00b6 SDF3 \u00b6 Several improvements have been made to increase the consistency and robustness of SDF3. Regular productive productions can be mixed with template productions in the context-free syntax section. Each production defines a non-unique sort and a unique constructor of that sort. References point to these definitions and errors are given for undefined elements in the grammar. Signatures are generated on-save following the sorts used in the right-hand side of a production and the sort and constructor that are being defined. All code generated from SDF3 grammars is organized in the src-gen directory of the project, which keeps Spoofax projects more clean and structured. Contributors: Eduardo Amorim Building language projects \u00b6 Projects are built using Ant Macros tailored to make the build system more incremental. Language projects can now also be built on the command-line using Maven. Contributors: Eduardo Amorim, Gabri\u00ebl Konat Building and developing Spoofax \u00b6 The build system for Spoofax itself has been refactored from a Nix build into a full Maven build. This enables local builds on any system that Maven supports, which is basically any system that supports Java. See the instructions on building Spoofax for more information follow the instructions on using MetaBorg Maven artifacts for more information. There is now also documentation on Setting up Eclipse for Spoofax development , which explains how to set up an environment for developing projects which are included in Spoofax. The nightly version of Spoofax is now built on our Jenkins server: http://buildfarm.metaborg.org/ . It publishes artifacts to our artifact server: http://artifacts.metaborg.org/ . To use these artifacts, read the instructions on the instructions on using MetaBorg Maven artifacts for more information. Contributors: Gabri\u00ebl Konat, Danny Groenewegen, Elmer van Chastelet Other \u00b6 More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.3","title":"Spoofax 1.3.0 (12-11-2014)"},{"location":"release/note/1.3.0/#spoofax-130-12-11-2014","text":"We're happy to announce the release of Spoofax 1.3, which improves SDF3, the build system for languages, and the build system for Spoofax itself.","title":"Spoofax 1.3.0 (12-11-2014)"},{"location":"release/note/1.3.0/#porting","text":"","title":"Porting"},{"location":"release/note/1.3.0/#language-projects","text":"The build for language projects has changed since the last Spoofax, so your language projects need to be migrated. To automatically migrate your project, follow these steps: Right click the project in Eclipse Choose Spoofax -> Upgrade Spoofax project Press Finish This will automatically upgrade your project to the latest format, after which you can build your project normally. The build might fail with: sdf2parenthesize: BUILD FAILED /Users/gohla/spoofax/workspace/runtime-Spoofax/Entity/build.generated.xml:266: The following error occurred while executing this line: Target \"sdf2parenthesize.helper\" does not exist in the project \"Entity\". If this is the case, build again, because some files are only upgraded after building once. Compiled Java files are now stored in the target/classes directory instead of the bin directory, so the bin directory can be deleted.","title":"Language projects"},{"location":"release/note/1.3.0/#sdf3-grammars","text":"SDF2 and old SDF3 grammars can be migrated. Some manual changes might still be necessary since a sort cannot have more than one constructor with the same name and arity, and priority rules may contain the entire production instead of priority shorthands.","title":"SDF3 grammars"},{"location":"release/note/1.3.0/#changes","text":"","title":"Changes"},{"location":"release/note/1.3.0/#sdf3","text":"Several improvements have been made to increase the consistency and robustness of SDF3. Regular productive productions can be mixed with template productions in the context-free syntax section. Each production defines a non-unique sort and a unique constructor of that sort. References point to these definitions and errors are given for undefined elements in the grammar. Signatures are generated on-save following the sorts used in the right-hand side of a production and the sort and constructor that are being defined. All code generated from SDF3 grammars is organized in the src-gen directory of the project, which keeps Spoofax projects more clean and structured. Contributors: Eduardo Amorim","title":"SDF3"},{"location":"release/note/1.3.0/#building-language-projects","text":"Projects are built using Ant Macros tailored to make the build system more incremental. Language projects can now also be built on the command-line using Maven. Contributors: Eduardo Amorim, Gabri\u00ebl Konat","title":"Building language projects"},{"location":"release/note/1.3.0/#building-and-developing-spoofax","text":"The build system for Spoofax itself has been refactored from a Nix build into a full Maven build. This enables local builds on any system that Maven supports, which is basically any system that supports Java. See the instructions on building Spoofax for more information follow the instructions on using MetaBorg Maven artifacts for more information. There is now also documentation on Setting up Eclipse for Spoofax development , which explains how to set up an environment for developing projects which are included in Spoofax. The nightly version of Spoofax is now built on our Jenkins server: http://buildfarm.metaborg.org/ . It publishes artifacts to our artifact server: http://artifacts.metaborg.org/ . To use these artifacts, read the instructions on the instructions on using MetaBorg Maven artifacts for more information. Contributors: Gabri\u00ebl Konat, Danny Groenewegen, Elmer van Chastelet","title":"Building and developing Spoofax"},{"location":"release/note/1.3.0/#other","text":"More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.3","title":"Other"},{"location":"release/note/1.3.1/","text":"Spoofax 1.3.1 (09-12-2014) \u00b6 We're happy to announce the release of Spoofax 1.3.1, a maintenance release which fixes several issues in SDF3, and compatibility with Eclipse 4.3 (Kepler). Changes \u00b6 Fix: Allowing sequences in SDF3 lexical syntax. Fix: Allowing specific arguments of productions in SDF3 priorities. Fix: SDF3 outliner not working. Fix: Unable to install in Eclipse 4.3. Contributors: Eduardo Amorim","title":"Spoofax 1.3.1 (09-12-2014)"},{"location":"release/note/1.3.1/#spoofax-131-09-12-2014","text":"We're happy to announce the release of Spoofax 1.3.1, a maintenance release which fixes several issues in SDF3, and compatibility with Eclipse 4.3 (Kepler).","title":"Spoofax 1.3.1 (09-12-2014)"},{"location":"release/note/1.3.1/#changes","text":"Fix: Allowing sequences in SDF3 lexical syntax. Fix: Allowing specific arguments of productions in SDF3 priorities. Fix: SDF3 outliner not working. Fix: Unable to install in Eclipse 4.3. Contributors: Eduardo Amorim","title":"Changes"},{"location":"release/note/1.4.0/","text":"Spoofax 1.4.0 (06-03-2015) \u00b6 We're happy to announce the release of Spoofax 1.4.0, a minor release with SDF3 fixes and improvements to language plugins. Changes \u00b6 SDF3 \u00b6 Fix: Supporting Windows line endings in SDF3. Fix: Providing warnings for literals that could be placeholders. Contributors: Eduardo Amorim Language plugins \u00b6 Reduced download size of deployed plugins \u00b6 Previously, when creating an Eclipse update site for your language (see tutorial ), the result was a ~90MB download that included meta-tools such as SDF3 and NaBL. We brought the download size down to ~60MB by removing dependencies to some of the meta-tools, since end-users of deployed languages don't need them. In the future, we plan to bring the size further down by removing more dependencies. Contributors: Oskar van Rest Setting Java VM options for your language \u00b6 For Spoofax and Spoofax-based languages to run smoothly, it is recommended to set Java's -server flag and to increase the stack size and memory allocation pool: -Xss<size> specifies the thread stack size -Xmx<size> specifies the maximum size, in bytes, of the memory allocation pool. -server selects server application runtime optimizations. The server VM will take longer to start and \u201cwarm up\u201d but will be more aggressively optimized. The -server option only affects 32-bit VMs and has influence on 64-bit VMs because these always use server optimizations. These options can be configured in eclipse.ini as described on the download page. The recommended settings for Spoofax are -server -Xss8m -Xmx1024m and a warning will pop-up if Eclipse is started with settings that are too low. Previously, the same settings were assumed for deployed plugins and were enforced by a similar pup-up warning. With Spoofax 1.4.0, language developers can choose their own Java VM settings, which are then recommended to end-users of their language. This can be configured in editor/yourlang.main.esv . The syntax is as follows: jvm opts: [-server | -X[ss|mx]<size>[g|G|m|M|k|K]]+ For example: jvm opts: -server -Xss8m -Xmx1024m . If multiple Spoofax-based languages are installed, the configuration warning will tell how eclipse.ini needs to be updated such that the requirements of all languages are satisfied. Contributors: Oskar van Rest","title":"Spoofax 1.4.0 (06-03-2015)"},{"location":"release/note/1.4.0/#spoofax-140-06-03-2015","text":"We're happy to announce the release of Spoofax 1.4.0, a minor release with SDF3 fixes and improvements to language plugins.","title":"Spoofax 1.4.0 (06-03-2015)"},{"location":"release/note/1.4.0/#changes","text":"","title":"Changes"},{"location":"release/note/1.4.0/#sdf3","text":"Fix: Supporting Windows line endings in SDF3. Fix: Providing warnings for literals that could be placeholders. Contributors: Eduardo Amorim","title":"SDF3"},{"location":"release/note/1.4.0/#language-plugins","text":"","title":"Language plugins"},{"location":"release/note/1.4.0/#reduced-download-size-of-deployed-plugins","text":"Previously, when creating an Eclipse update site for your language (see tutorial ), the result was a ~90MB download that included meta-tools such as SDF3 and NaBL. We brought the download size down to ~60MB by removing dependencies to some of the meta-tools, since end-users of deployed languages don't need them. In the future, we plan to bring the size further down by removing more dependencies. Contributors: Oskar van Rest","title":"Reduced download size of deployed plugins"},{"location":"release/note/1.4.0/#setting-java-vm-options-for-your-language","text":"For Spoofax and Spoofax-based languages to run smoothly, it is recommended to set Java's -server flag and to increase the stack size and memory allocation pool: -Xss<size> specifies the thread stack size -Xmx<size> specifies the maximum size, in bytes, of the memory allocation pool. -server selects server application runtime optimizations. The server VM will take longer to start and \u201cwarm up\u201d but will be more aggressively optimized. The -server option only affects 32-bit VMs and has influence on 64-bit VMs because these always use server optimizations. These options can be configured in eclipse.ini as described on the download page. The recommended settings for Spoofax are -server -Xss8m -Xmx1024m and a warning will pop-up if Eclipse is started with settings that are too low. Previously, the same settings were assumed for deployed plugins and were enforced by a similar pup-up warning. With Spoofax 1.4.0, language developers can choose their own Java VM settings, which are then recommended to end-users of their language. This can be configured in editor/yourlang.main.esv . The syntax is as follows: jvm opts: [-server | -X[ss|mx]<size>[g|G|m|M|k|K]]+ For example: jvm opts: -server -Xss8m -Xmx1024m . If multiple Spoofax-based languages are installed, the configuration warning will tell how eclipse.ini needs to be updated such that the requirements of all languages are satisfied. Contributors: Oskar van Rest","title":"Setting Java VM options for your language"},{"location":"release/note/1.5.0/","text":"Spoofax 1.5.0 (18-12-2015) \u00b6 We're happy to announce the release of Spoofax 1.5.0 with new SDF3 features and fixes, and support for Eclipse Mars. Changes \u00b6 SDF3 \u00b6 Feature: support for case insensitive keywords . All keywords in a template production are case insensitive if the production has the attribute case-insensitive . Feature: pretty-print ambiguous programs (by taking the first alternative). Feature: give an error if the filename does not match the module name. Fix: ESV generation with empty imports . Fix: disallow empty placeholders <> in template productions. Contributor: Eduardo Amorim Eclipse \u00b6 Feature: support for Eclipse Mars. Feature: generation of premade Eclipse installations with Spoofax installed. Contributor: Gabriel Konat Command-line tools \u00b6 Fix: Sunshine now pretty-prints ATerms before presenting them, mimicking the behavior in Eclipse. Contributor: Gabriel Konat","title":"Spoofax 1.5.0 (18-12-2015)"},{"location":"release/note/1.5.0/#spoofax-150-18-12-2015","text":"We're happy to announce the release of Spoofax 1.5.0 with new SDF3 features and fixes, and support for Eclipse Mars.","title":"Spoofax 1.5.0 (18-12-2015)"},{"location":"release/note/1.5.0/#changes","text":"","title":"Changes"},{"location":"release/note/1.5.0/#sdf3","text":"Feature: support for case insensitive keywords . All keywords in a template production are case insensitive if the production has the attribute case-insensitive . Feature: pretty-print ambiguous programs (by taking the first alternative). Feature: give an error if the filename does not match the module name. Fix: ESV generation with empty imports . Fix: disallow empty placeholders <> in template productions. Contributor: Eduardo Amorim","title":"SDF3"},{"location":"release/note/1.5.0/#eclipse","text":"Feature: support for Eclipse Mars. Feature: generation of premade Eclipse installations with Spoofax installed. Contributor: Gabriel Konat","title":"Eclipse"},{"location":"release/note/1.5.0/#command-line-tools","text":"Fix: Sunshine now pretty-prints ATerms before presenting them, mimicking the behavior in Eclipse. Contributor: Gabriel Konat","title":"Command-line tools"},{"location":"release/note/2.0.0-beta1/","text":"Spoofax 2.0.0-beta1 (07-04-2016) \u00b6 This is the first beta release of Spoofax 2.0. These notes provide the download links for the various artifacts. See the 2.0.0 release notes for more information about Spoofax 2.0. See the 2.0.0 migration guide for migrating a Spoofax 1.5 project to a Spoofax 2.0 project.","title":"Spoofax 2.0.0-beta1 (07-04-2016)"},{"location":"release/note/2.0.0-beta1/#spoofax-200-beta1-07-04-2016","text":"This is the first beta release of Spoofax 2.0. These notes provide the download links for the various artifacts. See the 2.0.0 release notes for more information about Spoofax 2.0. See the 2.0.0 migration guide for migrating a Spoofax 1.5 project to a Spoofax 2.0 project.","title":"Spoofax 2.0.0-beta1 (07-04-2016)"},{"location":"release/note/2.0.0/","text":"Spoofax 2.0.0 (08-07-2016) \u00b6 Spoofax 2.0 is a complete rewrite of Spoofax which improves the architecture by separating Spoofax into the Spoofax Core API and implementations on top of that API, massively improves the language development workflow, and properly supports language extension. See the corresponding migration guide for migrating from Spoofax 1.5 to Spoofax 2.0. Known Issues \u00b6 Stratego imports do not work. To work around this issue, add an explicit compile dependency to Stratego: dependencies: compile: - org.metaborg:org.metaborg.meta.lang.stratego:${metaborgVersion} Changes \u00b6 Architecture \u00b6 The biggest change in Spoofax 2.0 is the architecture. Previously, Spoofax was built on top of the Eclipse and IMP platform, meaning Spoofax was not usable outside of the Eclipse platform. In Spoofax 2.0, all platform-agnostic functionality such as language management, parsing, analysis, transformation, and editor services, are implemented in Spoofax Core, which is a portable Java library with an API. This means that the Spoofax language workbench, and any language implementations made with Spoofax, can now be used by any application, platform, or framework in the Java ecosystem. Integrations \u00b6 We have integrated Spoofax Core with Eclipse, IntelliJ, Maven, and the command-line. We support the Eclipse platform through a new plugin that integrates Spoofax Core as an Eclipse plugin. The new Eclipse plugin supports language development in Eclipse, and supports exporting languages made with Spoofax as an Eclipse plugin with full-fledged editor support. We have also performed a more faithful Eclipse integration than Spoofax 1.5 did. For example, we now use natures to enable Spoofax for a project, use the incremental builder framework to allow suspending automatic builds, and use Eclipse's menu system for builders instead of non-standard buttons. See the migration guide for a full list of changes to the Eclipse plugin. IntelliJ is an experimentally supported platform through the Eclipse IntelliJ plugin. Languages can be developed in IntelliJ, and exported as IntelliJ plugins with full-fledged editor support. The Spoofax Maven plugin supports command-line builds and continuous integration of language implementations in Maven. Language implementations can be exported as Maven artifacts which can be depended on and used to build programs of that language. Command-line use of language implementations is supported through Sunshine's integration with Spoofax Core. Sunshine's command-line interface has been simplified to improve ease of use, and now also supports a server mode to reduce the high cost of starting a new JVM and loading a language. Furthermore, anyone can make new integrations using the Core API. Language Development Workflow \u00b6 There are several improvements to the language development workflow in Spoofax 2.0. Almost all generated files are now generated to the src-gen directory of a language project. All required generated files are now (re)generated when building, so it is no longer necessary to commit generated files to source control. This results in much cleaner projects. Furthermore, the language build is now incremental, which speeds up the build in many cases. The bootstrapping process of meta-languages has been significantly improved by versioning languages. It is now possible to load multiple versions of the same language implementation into Spoofax. Meta-languages are bootstrapped by building them against baseline versions of the meta-languages. When a meta-language under development breaks, it is possible to revert back to a previous version to get things working again. Extension \u00b6 Spoofax 2.0 supports language extension on the source level, without the need to copy-paste files around. A dependency can be made from a language specification to another language specification, which then allows importing modules of the specification into the other. For example, language extensions can depend on a base language and extend its concepts. Those extensions can be composed together with the base language specification into a new language specification that contains the base and extensions. There is also limited support for dynamic extension, i.e. extension at the runtime level instead of the source level. A language implementation can be extended with new builders at runtime. This allows adding builders to existing language implementations, and supports separating the front-end and back-end of a language into multiple projects. License \u00b6 The license has been changed from LPGLv2.1 to the Apache 2.0 license, to improve adoption of Spoofax. Any contributions made to Spoofax must be licensed under the Apache 2.0 license as well. Missing Features \u00b6 A few features didn't make it to Spoofax 2.0, with the biggest one being semantic completions. Semantic completions were already very dodgy in Spoofax 1.5, only working in some specific cases. This is why we did not port the completion algorithm from Spoofax 1.5 to 2.0, and are instead working on a new completion algorithm that will be included in a future version. Refactorings were already broken in Spoofax 1.5, so we did not port refactorings to Spoofax 2.0. In the future we will revisit refactorings for Spoofax 2.0 with our new meta-languages. The Spoofax modelware component was not ported to Spoofax 2.0 since we do not have the knowledge to port this component. Folding, realtime builders, and the eclipse.ini check are minor features that are not implemented in 2.0, but may be implemented in the future. A missing integration in Spoofax 2.0 is a Spoofax Gradle plugin, we are working on that integration for inclusion in a future version.","title":"Spoofax 2.0.0 (08-07-2016)"},{"location":"release/note/2.0.0/#spoofax-200-08-07-2016","text":"Spoofax 2.0 is a complete rewrite of Spoofax which improves the architecture by separating Spoofax into the Spoofax Core API and implementations on top of that API, massively improves the language development workflow, and properly supports language extension. See the corresponding migration guide for migrating from Spoofax 1.5 to Spoofax 2.0.","title":"Spoofax 2.0.0 (08-07-2016)"},{"location":"release/note/2.0.0/#known-issues","text":"Stratego imports do not work. To work around this issue, add an explicit compile dependency to Stratego: dependencies: compile: - org.metaborg:org.metaborg.meta.lang.stratego:${metaborgVersion}","title":"Known Issues"},{"location":"release/note/2.0.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.0.0/#architecture","text":"The biggest change in Spoofax 2.0 is the architecture. Previously, Spoofax was built on top of the Eclipse and IMP platform, meaning Spoofax was not usable outside of the Eclipse platform. In Spoofax 2.0, all platform-agnostic functionality such as language management, parsing, analysis, transformation, and editor services, are implemented in Spoofax Core, which is a portable Java library with an API. This means that the Spoofax language workbench, and any language implementations made with Spoofax, can now be used by any application, platform, or framework in the Java ecosystem.","title":"Architecture"},{"location":"release/note/2.0.0/#integrations","text":"We have integrated Spoofax Core with Eclipse, IntelliJ, Maven, and the command-line. We support the Eclipse platform through a new plugin that integrates Spoofax Core as an Eclipse plugin. The new Eclipse plugin supports language development in Eclipse, and supports exporting languages made with Spoofax as an Eclipse plugin with full-fledged editor support. We have also performed a more faithful Eclipse integration than Spoofax 1.5 did. For example, we now use natures to enable Spoofax for a project, use the incremental builder framework to allow suspending automatic builds, and use Eclipse's menu system for builders instead of non-standard buttons. See the migration guide for a full list of changes to the Eclipse plugin. IntelliJ is an experimentally supported platform through the Eclipse IntelliJ plugin. Languages can be developed in IntelliJ, and exported as IntelliJ plugins with full-fledged editor support. The Spoofax Maven plugin supports command-line builds and continuous integration of language implementations in Maven. Language implementations can be exported as Maven artifacts which can be depended on and used to build programs of that language. Command-line use of language implementations is supported through Sunshine's integration with Spoofax Core. Sunshine's command-line interface has been simplified to improve ease of use, and now also supports a server mode to reduce the high cost of starting a new JVM and loading a language. Furthermore, anyone can make new integrations using the Core API.","title":"Integrations"},{"location":"release/note/2.0.0/#language-development-workflow","text":"There are several improvements to the language development workflow in Spoofax 2.0. Almost all generated files are now generated to the src-gen directory of a language project. All required generated files are now (re)generated when building, so it is no longer necessary to commit generated files to source control. This results in much cleaner projects. Furthermore, the language build is now incremental, which speeds up the build in many cases. The bootstrapping process of meta-languages has been significantly improved by versioning languages. It is now possible to load multiple versions of the same language implementation into Spoofax. Meta-languages are bootstrapped by building them against baseline versions of the meta-languages. When a meta-language under development breaks, it is possible to revert back to a previous version to get things working again.","title":"Language Development Workflow"},{"location":"release/note/2.0.0/#extension","text":"Spoofax 2.0 supports language extension on the source level, without the need to copy-paste files around. A dependency can be made from a language specification to another language specification, which then allows importing modules of the specification into the other. For example, language extensions can depend on a base language and extend its concepts. Those extensions can be composed together with the base language specification into a new language specification that contains the base and extensions. There is also limited support for dynamic extension, i.e. extension at the runtime level instead of the source level. A language implementation can be extended with new builders at runtime. This allows adding builders to existing language implementations, and supports separating the front-end and back-end of a language into multiple projects.","title":"Extension"},{"location":"release/note/2.0.0/#license","text":"The license has been changed from LPGLv2.1 to the Apache 2.0 license, to improve adoption of Spoofax. Any contributions made to Spoofax must be licensed under the Apache 2.0 license as well.","title":"License"},{"location":"release/note/2.0.0/#missing-features","text":"A few features didn't make it to Spoofax 2.0, with the biggest one being semantic completions. Semantic completions were already very dodgy in Spoofax 1.5, only working in some specific cases. This is why we did not port the completion algorithm from Spoofax 1.5 to 2.0, and are instead working on a new completion algorithm that will be included in a future version. Refactorings were already broken in Spoofax 1.5, so we did not port refactorings to Spoofax 2.0. In the future we will revisit refactorings for Spoofax 2.0 with our new meta-languages. The Spoofax modelware component was not ported to Spoofax 2.0 since we do not have the knowledge to port this component. Folding, realtime builders, and the eclipse.ini check are minor features that are not implemented in 2.0, but may be implemented in the future. A missing integration in Spoofax 2.0 is a Spoofax Gradle plugin, we are working on that integration for inclusion in a future version.","title":"Missing Features"},{"location":"release/note/2.1.0/","text":"Spoofax 2.1.0 (10-01-2017) \u00b6 Spoofax 2.1 improves on Spoofax 2.0 with several bug fixes, an implementation of syntactic completions based on SDF3, and addition of the DynSem dynamic semantics specification meta-language. See the corresponding migration guide <2.1.0-migration-guide> for migrating from Spoofax 2.0 to Spoofax 2.1. Changes \u00b6 Syntactic Completions \u00b6 Spoofax now has support for syntactic completions. Syntactic completions are generated automatically from an SDF3 specification. New projects using SDF3 automatically support syntactic completions. Existing projects need to make a few changes, documented in the migration guide <new-completion-framework-migration-guide> {.interpreted-text role=\"ref\"}. DynSem \u00b6 DynSem is a DSL for concise and modular specification of dynamic semantics of programming languages. Fully functional interpreters are automatically derived from dynamic semantics specifications. For more information about DynSem, see the following sources: Paper Documentation <dynsem-index> Getting started tutorial <dynsem-getting-started> {.interpreted-text role=\"ref\"} Example language While DynSem was included in Spoofax 2.0.0, we did not advertise this as it was still under heavy development. Since 2.0.0, the following major improvements were made: Redesigned semantic component and explication subsystem Support for tuples Updated tutorial for SIMPL <dynsem-getting-started> {.interpreted-text role=\"ref\"} Added support for unit testing and continuous integration of generated interpreters <dynsem-ci> {.interpreted-text role=\"ref\"}","title":"Spoofax 2.1.0 (10-01-2017)"},{"location":"release/note/2.1.0/#spoofax-210-10-01-2017","text":"Spoofax 2.1 improves on Spoofax 2.0 with several bug fixes, an implementation of syntactic completions based on SDF3, and addition of the DynSem dynamic semantics specification meta-language. See the corresponding migration guide <2.1.0-migration-guide> for migrating from Spoofax 2.0 to Spoofax 2.1.","title":"Spoofax 2.1.0 (10-01-2017)"},{"location":"release/note/2.1.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.1.0/#syntactic-completions","text":"Spoofax now has support for syntactic completions. Syntactic completions are generated automatically from an SDF3 specification. New projects using SDF3 automatically support syntactic completions. Existing projects need to make a few changes, documented in the migration guide <new-completion-framework-migration-guide> {.interpreted-text role=\"ref\"}.","title":"Syntactic Completions"},{"location":"release/note/2.1.0/#dynsem","text":"DynSem is a DSL for concise and modular specification of dynamic semantics of programming languages. Fully functional interpreters are automatically derived from dynamic semantics specifications. For more information about DynSem, see the following sources: Paper Documentation <dynsem-index> Getting started tutorial <dynsem-getting-started> {.interpreted-text role=\"ref\"} Example language While DynSem was included in Spoofax 2.0.0, we did not advertise this as it was still under heavy development. Since 2.0.0, the following major improvements were made: Redesigned semantic component and explication subsystem Support for tuples Updated tutorial for SIMPL <dynsem-getting-started> {.interpreted-text role=\"ref\"} Added support for unit testing and continuous integration of generated interpreters <dynsem-ci> {.interpreted-text role=\"ref\"}","title":"DynSem"},{"location":"release/note/2.2.0/","text":"Spoofax 2.2.0 (18-04-2017) \u00b6 Spoofax 2.2 improves on Spoofax 2.1 with a new NaBL2 constraint solver which is optimised for performance, improved progress reporting and cancellation in Eclipse, an experimental replacement for sdf2table which fixes several long-standing bugs, improvements to the core API, and several bug fixes. See the corresponding migration guide <2.2.0-migration-guide> for migrating from Spoofax 2.1 to Spoofax 2.2. Changes \u00b6 Overall \u00b6 The deprecated libraries and files from Spoofax 2.1.0 have been removed. If you have not done so yet, follow the Spoofax 2.1.0 migration guide <2.1.0-migration-guide> {.interpreted-text role=\"ref\"} to migrate your project to the new Spoofax library. Core API \u00b6 Improve: Spoofax/190 - Extend API for language discovery . This deprecates several methods in the language discovery API, see the migration guide <2.2.0-migration-guide> {.interpreted-text role=\"ref\"} on how to migrate your code. Improve: Spoofax/193 - Stratego warnings in Spoofax language projects with NaBL2 analysis . The excessive number of warnings from Stratego compilation are now filtered out. Improve: Parsing and analysis can report progress and be cancelled. Improve: Builds now report progress. Fix: Path and project path that are passed to the editor hover strategy are now consistent with paths passed to other strategies. Fix: Spoofax/187 - Provide simplified builder API . Fix: Spoofax/188 - Java type error in documented language processing code . Eclipse \u00b6 Upgrade: Eclipse Neon (4.6) is now required. Improve: Added several switches to the Spoofax (meta) menu for disabling analyses and builds, to improve usability in cases where these operations are very slow. Improve: Bind new progress reporting and cancellation in core to Eclipse progress monitors, enabling reporting of builds and cancellation of analysis. Fix: Fix cancellation not being propagated in SubMonitors, preventing cancellation from working in many places. SDF3 \u00b6 Feature: Re-implemented the parse table generator in Java, removing the dependency on a platform-specific sdf2table binary, and fixing several long-standing bugs. This implementation is still being tested, it is therefore only enabled after opt-in. To enable the new implementation, set the following option in your metaborg.yaml file: language : sdf : sdf2table : java Improve: Moved the placeholder and pretty-print options in the metaborg.yaml file to be under language.sdf , as in: language : sdf : placeholder : prefix : \"[[\" suffix : \"]]\" pretty-print : LangName NaBL2 \u00b6 Improve: Introduces a new solver implementation with improved performance. Improve: Introduces separate signature sections for constructors , relations , and functions . Deprecate: The types signature, which will be removed in the next release. SPT \u00b6 Fix: Several origin tracking issues related to section markers. DynSem \u00b6 Fix: Analysis crashes on empty rules sections ( #161 ) Improve: Support for abrupt termination: automatic expansion and propagation of read-write semantic components with default values Improve: Analysis performance improvements Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.0/org.metaborg.spoofax.eclipse.updatesite-2.2.0-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.2.0 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.2.0 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.2.0 .","title":"Spoofax 2.2.0 (18-04-2017)"},{"location":"release/note/2.2.0/#spoofax-220-18-04-2017","text":"Spoofax 2.2 improves on Spoofax 2.1 with a new NaBL2 constraint solver which is optimised for performance, improved progress reporting and cancellation in Eclipse, an experimental replacement for sdf2table which fixes several long-standing bugs, improvements to the core API, and several bug fixes. See the corresponding migration guide <2.2.0-migration-guide> for migrating from Spoofax 2.1 to Spoofax 2.2.","title":"Spoofax 2.2.0 (18-04-2017)"},{"location":"release/note/2.2.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.2.0/#overall","text":"The deprecated libraries and files from Spoofax 2.1.0 have been removed. If you have not done so yet, follow the Spoofax 2.1.0 migration guide <2.1.0-migration-guide> {.interpreted-text role=\"ref\"} to migrate your project to the new Spoofax library.","title":"Overall"},{"location":"release/note/2.2.0/#core-api","text":"Improve: Spoofax/190 - Extend API for language discovery . This deprecates several methods in the language discovery API, see the migration guide <2.2.0-migration-guide> {.interpreted-text role=\"ref\"} on how to migrate your code. Improve: Spoofax/193 - Stratego warnings in Spoofax language projects with NaBL2 analysis . The excessive number of warnings from Stratego compilation are now filtered out. Improve: Parsing and analysis can report progress and be cancelled. Improve: Builds now report progress. Fix: Path and project path that are passed to the editor hover strategy are now consistent with paths passed to other strategies. Fix: Spoofax/187 - Provide simplified builder API . Fix: Spoofax/188 - Java type error in documented language processing code .","title":"Core API"},{"location":"release/note/2.2.0/#eclipse","text":"Upgrade: Eclipse Neon (4.6) is now required. Improve: Added several switches to the Spoofax (meta) menu for disabling analyses and builds, to improve usability in cases where these operations are very slow. Improve: Bind new progress reporting and cancellation in core to Eclipse progress monitors, enabling reporting of builds and cancellation of analysis. Fix: Fix cancellation not being propagated in SubMonitors, preventing cancellation from working in many places.","title":"Eclipse"},{"location":"release/note/2.2.0/#sdf3","text":"Feature: Re-implemented the parse table generator in Java, removing the dependency on a platform-specific sdf2table binary, and fixing several long-standing bugs. This implementation is still being tested, it is therefore only enabled after opt-in. To enable the new implementation, set the following option in your metaborg.yaml file: language : sdf : sdf2table : java Improve: Moved the placeholder and pretty-print options in the metaborg.yaml file to be under language.sdf , as in: language : sdf : placeholder : prefix : \"[[\" suffix : \"]]\" pretty-print : LangName","title":"SDF3"},{"location":"release/note/2.2.0/#nabl2","text":"Improve: Introduces a new solver implementation with improved performance. Improve: Introduces separate signature sections for constructors , relations , and functions . Deprecate: The types signature, which will be removed in the next release.","title":"NaBL2"},{"location":"release/note/2.2.0/#spt","text":"Fix: Several origin tracking issues related to section markers.","title":"SPT"},{"location":"release/note/2.2.0/#dynsem","text":"Fix: Analysis crashes on empty rules sections ( #161 ) Improve: Support for abrupt termination: automatic expansion and propagation of read-write semantic components with default values Improve: Analysis performance improvements","title":"DynSem"},{"location":"release/note/2.2.0/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.2.0/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.2.0/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.2.0/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.0/org.metaborg.spoofax.eclipse.updatesite-2.2.0-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.2.0/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.2.0 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.2.0/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.2.0/#core-api_1","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.2.0","title":"Core API"},{"location":"release/note/2.2.0/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.2.0/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.2.0 .","title":"Maven artifacts"},{"location":"release/note/2.2.1/","text":"Spoofax 2.2.1 (04-05-2017) \u00b6 Spoofax 2.2.1 is a minor bugfix release. Changes \u00b6 Overall \u00b6 Fix: error when generating projects with analysis enabled (which is enabled by default). Fix: possibly erroneous completions file in spoofax meta library. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.1/org.metaborg.spoofax.eclipse.updatesite-2.2.1-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.2.1 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.2.1 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.2.1 .","title":"Spoofax 2.2.1 (04-05-2017)"},{"location":"release/note/2.2.1/#spoofax-221-04-05-2017","text":"Spoofax 2.2.1 is a minor bugfix release.","title":"Spoofax 2.2.1 (04-05-2017)"},{"location":"release/note/2.2.1/#changes","text":"","title":"Changes"},{"location":"release/note/2.2.1/#overall","text":"Fix: error when generating projects with analysis enabled (which is enabled by default). Fix: possibly erroneous completions file in spoofax meta library.","title":"Overall"},{"location":"release/note/2.2.1/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.2.1/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.2.1/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.2.1/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.1/org.metaborg.spoofax.eclipse.updatesite-2.2.1-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.2.1/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.2.1 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.2.1/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.2.1/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.2.1","title":"Core API"},{"location":"release/note/2.2.1/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.2.1/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.2.1 .","title":"Maven artifacts"},{"location":"release/note/2.3.0/","text":"Spoofax 2.3.0 (29-09-2017) \u00b6 Spoofax 2.3 fixes several minor bugs, upgrades to the latest Eclipse and Java versions, includes improvements to SDF3 and NaBL2, and introduces experimental parse table generation and parsing features. Changes \u00b6 Overall \u00b6 Improvement: made NaBL2 the default static semantics language. Improvement: put deprecated markers on NaBL+TS and Stratego as static semantics languages, and SDF2 as syntax language. Improvement: allow configuration of source folders in metaborg.yaml. Improvement: allow multiple languages in source and export entries. Improvement: add dynsem as a compile dependency to newly generated languages. Language specification build \u00b6 Fix: occasional NPEs when the build failed. Fix: hidden dependency error when building Stratego concrete syntax extensions. Eclipse plugin \u00b6 Improvement: updated Eclipse instance generator to generate Eclipse Oxygen instances. Improvement: updated Eclipse instance generator to include JDK 8u144b01. Improvement: do not reanalyze already analyzed files when opening an editor. Improvement: use a default configuration if metaborg.yaml is not present. NaBL2 \u00b6 Improvement: extended Stratego API to query reference resolution. Improvement: add ? and + operators to regexp syntax for path well-formedness. Fix: regexp normalization was only one level deep. Fix: non-termination in name resolution in the cases of a direct cycle between a scope. Update: conform to latest DynSem version. Fix: support all Stratego constructor and sort names, by allowing dashes and single quotes in sort and constructor names. Fix: do not crash if dynsem properties file is missing. SDF3 \u00b6 Improvement: more stable SDF3 parser generator. Improvement: new parenthesizer that considers deep priority conflicts. Improvement: (experimental) support for lazy parse table generation, where the parse table is generated on-the-fly by the parser. Fix: bug in the SDF3 normalizer for groups of priorities outside of a chain. Fix: added support for generating the parse table from a \\\"permissive\\\" grammar Fix: not necessary to specify the parse table as sdf-new.tbl in the ESV file when using the new parse table generator. Parser \u00b6 Added the new (experimental) SGLR parser implementation JSGLR2. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.3.0/org.metaborg.spoofax.eclipse.updatesite-2.3.0-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.3.0 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.3.0 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.3.0 .","title":"Spoofax 2.3.0 (29-09-2017)"},{"location":"release/note/2.3.0/#spoofax-230-29-09-2017","text":"Spoofax 2.3 fixes several minor bugs, upgrades to the latest Eclipse and Java versions, includes improvements to SDF3 and NaBL2, and introduces experimental parse table generation and parsing features.","title":"Spoofax 2.3.0 (29-09-2017)"},{"location":"release/note/2.3.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.3.0/#overall","text":"Improvement: made NaBL2 the default static semantics language. Improvement: put deprecated markers on NaBL+TS and Stratego as static semantics languages, and SDF2 as syntax language. Improvement: allow configuration of source folders in metaborg.yaml. Improvement: allow multiple languages in source and export entries. Improvement: add dynsem as a compile dependency to newly generated languages.","title":"Overall"},{"location":"release/note/2.3.0/#language-specification-build","text":"Fix: occasional NPEs when the build failed. Fix: hidden dependency error when building Stratego concrete syntax extensions.","title":"Language specification build"},{"location":"release/note/2.3.0/#eclipse-plugin","text":"Improvement: updated Eclipse instance generator to generate Eclipse Oxygen instances. Improvement: updated Eclipse instance generator to include JDK 8u144b01. Improvement: do not reanalyze already analyzed files when opening an editor. Improvement: use a default configuration if metaborg.yaml is not present.","title":"Eclipse plugin"},{"location":"release/note/2.3.0/#nabl2","text":"Improvement: extended Stratego API to query reference resolution. Improvement: add ? and + operators to regexp syntax for path well-formedness. Fix: regexp normalization was only one level deep. Fix: non-termination in name resolution in the cases of a direct cycle between a scope. Update: conform to latest DynSem version. Fix: support all Stratego constructor and sort names, by allowing dashes and single quotes in sort and constructor names. Fix: do not crash if dynsem properties file is missing.","title":"NaBL2"},{"location":"release/note/2.3.0/#sdf3","text":"Improvement: more stable SDF3 parser generator. Improvement: new parenthesizer that considers deep priority conflicts. Improvement: (experimental) support for lazy parse table generation, where the parse table is generated on-the-fly by the parser. Fix: bug in the SDF3 normalizer for groups of priorities outside of a chain. Fix: added support for generating the parse table from a \\\"permissive\\\" grammar Fix: not necessary to specify the parse table as sdf-new.tbl in the ESV file when using the new parse table generator.","title":"SDF3"},{"location":"release/note/2.3.0/#parser","text":"Added the new (experimental) SGLR parser implementation JSGLR2.","title":"Parser"},{"location":"release/note/2.3.0/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.3.0/#eclipse-plugin_1","text":"","title":"Eclipse plugin"},{"location":"release/note/2.3.0/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.3.0/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.3.0/org.metaborg.spoofax.eclipse.updatesite-2.3.0-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.3.0/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.3.0 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.3.0/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.3.0/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.3.0","title":"Core API"},{"location":"release/note/2.3.0/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.3.0/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.3.0 .","title":"Maven artifacts"},{"location":"release/note/2.4.0/","text":"Spoofax 2.4.0 (09-01-2018) \u00b6 Spoofax 2.4 fixes several bugs and includes a program generator. Changes \u00b6 Eclipse Plugin \u00b6 Fix: re-parse and re-analyze open editors if the language is reloaded. NaBL2 \u00b6 Fix: use deep equality instead of object equality to compare elements in set constraints. Fix: prevent clashes of variable names with known lower-case Stratego constructors. Improvement: add strategies to the Stratego API to query references and declaration associated with AST nodes. Fix: prevent exception traces when hovering over the editor. Fix: bug in Stratego generation when complex terms are used in occurrences. Fix: bug where editor resolution would only consider leaf nodes, but not parents if the leafs do not resolve. Fix: bug where sometimes error messages of files were lost. Parser \u00b6 Improvement: latest JSGLR2 performance optimizations. Fix: bug in JSGLR2 where non-default start symbols were not taken into account. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.0/org.metaborg.spoofax.eclipse.updatesite-2.4.0-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.4.0 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.4.0 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.4.0 .","title":"Spoofax 2.4.0 (09-01-2018)"},{"location":"release/note/2.4.0/#spoofax-240-09-01-2018","text":"Spoofax 2.4 fixes several bugs and includes a program generator.","title":"Spoofax 2.4.0 (09-01-2018)"},{"location":"release/note/2.4.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.4.0/#eclipse-plugin","text":"Fix: re-parse and re-analyze open editors if the language is reloaded.","title":"Eclipse Plugin"},{"location":"release/note/2.4.0/#nabl2","text":"Fix: use deep equality instead of object equality to compare elements in set constraints. Fix: prevent clashes of variable names with known lower-case Stratego constructors. Improvement: add strategies to the Stratego API to query references and declaration associated with AST nodes. Fix: prevent exception traces when hovering over the editor. Fix: bug in Stratego generation when complex terms are used in occurrences. Fix: bug where editor resolution would only consider leaf nodes, but not parents if the leafs do not resolve. Fix: bug where sometimes error messages of files were lost.","title":"NaBL2"},{"location":"release/note/2.4.0/#parser","text":"Improvement: latest JSGLR2 performance optimizations. Fix: bug in JSGLR2 where non-default start symbols were not taken into account.","title":"Parser"},{"location":"release/note/2.4.0/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.4.0/#eclipse-plugin_1","text":"","title":"Eclipse plugin"},{"location":"release/note/2.4.0/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.4.0/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.0/org.metaborg.spoofax.eclipse.updatesite-2.4.0-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.4.0/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.4.0 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.4.0/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.4.0/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.4.0","title":"Core API"},{"location":"release/note/2.4.0/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.4.0/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.4.0 .","title":"Maven artifacts"},{"location":"release/note/2.4.1/","text":"Spoofax 2.4.1 (29-01-2018) \u00b6 Spoofax 2.4.1 is a minor bugfix release. Changes \u00b6 Fix: remove dependency on nativebundle from jsglr2 , preventing native binaries (with a cygwin vulnerability) from showing up in Spoofax Core. Update jackson-core , jackson-databind , jackson-annotations , jackson-dataformat-yaml dependencies to 2.9.3 to avoid a vulnerability in those libraries. Update commons-configuration2 to 2.2 , commons-configuration2-jackson to 0.7.0 , and snakeyaml to 1.18 , for compatibility with jackson version 2.9.3 . Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.1/org.metaborg.spoofax.eclipse.updatesite-2.4.1-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.4.1 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.4.1 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.4.1 .","title":"Spoofax 2.4.1 (29-01-2018)"},{"location":"release/note/2.4.1/#spoofax-241-29-01-2018","text":"Spoofax 2.4.1 is a minor bugfix release.","title":"Spoofax 2.4.1 (29-01-2018)"},{"location":"release/note/2.4.1/#changes","text":"Fix: remove dependency on nativebundle from jsglr2 , preventing native binaries (with a cygwin vulnerability) from showing up in Spoofax Core. Update jackson-core , jackson-databind , jackson-annotations , jackson-dataformat-yaml dependencies to 2.9.3 to avoid a vulnerability in those libraries. Update commons-configuration2 to 2.2 , commons-configuration2-jackson to 0.7.0 , and snakeyaml to 1.18 , for compatibility with jackson version 2.9.3 .","title":"Changes"},{"location":"release/note/2.4.1/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.4.1/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.4.1/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.4.1/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.1/org.metaborg.spoofax.eclipse.updatesite-2.4.1-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.4.1/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.4.1 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.4.1/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.4.1/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.4.1","title":"Core API"},{"location":"release/note/2.4.1/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.4.1/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.4.1 .","title":"Maven artifacts"},{"location":"release/note/2.5.0/","text":"Spoofax 2.5.0 (11-09-2018) \u00b6 Spoofax 2.5 introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis; layout-sensitive parsing in SDF3; and has several small improvements and bug fixes. Changes \u00b6 Maven \u00b6 We updated the Guice version that Spoofax uses to 4.2.0. This has the cascading effect that we need Maven 3.5.4, since Spoofax is used in a maven plugin. Be sure to have this version of Maven installed, or you will run into MethodNotFoundException s for com.google.inject.internal.* . Core \u00b6 The constraint analyzer was generalized: The constraint analyzer is now independent of NaBL2, and can be used as a generic analysis mechanism from Stratego. The analysis cycle and the Stratego interface to it are defined ans documented in module libspoofax/analysis/constraint . Fixed a bug where ambiguity errors were not always correctly reported. FlowSpec \u00b6 This release introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis. See the documentation of the language for more details. Stratego \u00b6 Stratego received some small patches to improve user experience. Stratego editor now gives warnings when using left , right and a couple of other variables names as these are also constructors in libstratego-sglr and interpreted as constructor match patterns. When the Stratego compiler generates names for code generation, these now start with the source code name if available or with a constant name related to the language feature (e.g. a where(s) is turned into ?where243;s;!where243 ). Since some generated names turn up in a stack trace from a Stratego, this should improve readability of the stack trace. Complex closures are still named lifted26 , as the compiler cannot replace humans in properly naming things. SPT \u00b6 Problems related to escaping in string terms of expectations are fixed: Double quotes ( \" ) in expectation require escaping using backslashes, but were not unescaped when comparing with actual parse results. This made correct tests containing double quotes in strings fail. This is fixed by unescaping the expectation terms. Formatting expectation terms as strings was different than default ATerms ( \" and \\ were not escaped), which was confusing when a test fails and the actual and expected terms were reported. This is fixed by aligning the SPT expectation terms formatting with default ATerm formatting. NaBL2 \u00b6 Small usability improvements: Empty parameter tuples in rules can be omitted. Accidentally writing a dot instead of a comma before a recursive rule invocation could make that constraint look like a rule without constraints. Layout is now used to give a warning when such a case is written. Fix import problems caused by nabl2.runtime exports. The exports are restricted such that layout syntax and DynSem signatures are not exported anymore. The sorts defined by the runtime are all prefixed with NaBL2 to prevent accidental merges with sorts from the importing language. Allow all Stratego identifiers to be used as constructor names. Solver changes: Adopt new naming convention, with packages named mb.nabl2.* , and artifacts named nabl2.* . Add classes for matching and subtitution of terms, independent of unification. Use the generalized constraint analyzer for the NaBL2 analysis strategy. SDF3 \u00b6 The experimental support for generating Scala case classes from an SDF3 specification was removed. It was incomplete, unmaintained and unused. Added support for Layout Declarations <layout-declarations> {.interpreted-text role=\"ref\"} for layout-sensitive parsing and pretty-printing. Eclipse \u00b6 Small fixes and improvements: Execute builders for languages which have no analysis defined. Previously builders would always wait until an analysis result was produced. Cancel running SPT test suites. It is now possible to cancel a running SPT test suite in the progress window. IntelliJ \u00b6 Small fixes and improvements: Can now be installed into any latest IntelliJ, not just the last version we tested By default runs in IntelliJ 2018.1.1 Simplified project structure Updated dependencies Changes to support Java 9 in the future Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.0/org.metaborg.spoofax.eclipse.updatesite-2.5.0-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.0 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.0 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.0 .","title":"Spoofax 2.5.0 (11-09-2018)"},{"location":"release/note/2.5.0/#spoofax-250-11-09-2018","text":"Spoofax 2.5 introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis; layout-sensitive parsing in SDF3; and has several small improvements and bug fixes.","title":"Spoofax 2.5.0 (11-09-2018)"},{"location":"release/note/2.5.0/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.0/#maven","text":"We updated the Guice version that Spoofax uses to 4.2.0. This has the cascading effect that we need Maven 3.5.4, since Spoofax is used in a maven plugin. Be sure to have this version of Maven installed, or you will run into MethodNotFoundException s for com.google.inject.internal.* .","title":"Maven"},{"location":"release/note/2.5.0/#core","text":"The constraint analyzer was generalized: The constraint analyzer is now independent of NaBL2, and can be used as a generic analysis mechanism from Stratego. The analysis cycle and the Stratego interface to it are defined ans documented in module libspoofax/analysis/constraint . Fixed a bug where ambiguity errors were not always correctly reported.","title":"Core"},{"location":"release/note/2.5.0/#flowspec","text":"This release introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis. See the documentation of the language for more details.","title":"FlowSpec"},{"location":"release/note/2.5.0/#stratego","text":"Stratego received some small patches to improve user experience. Stratego editor now gives warnings when using left , right and a couple of other variables names as these are also constructors in libstratego-sglr and interpreted as constructor match patterns. When the Stratego compiler generates names for code generation, these now start with the source code name if available or with a constant name related to the language feature (e.g. a where(s) is turned into ?where243;s;!where243 ). Since some generated names turn up in a stack trace from a Stratego, this should improve readability of the stack trace. Complex closures are still named lifted26 , as the compiler cannot replace humans in properly naming things.","title":"Stratego"},{"location":"release/note/2.5.0/#spt","text":"Problems related to escaping in string terms of expectations are fixed: Double quotes ( \" ) in expectation require escaping using backslashes, but were not unescaped when comparing with actual parse results. This made correct tests containing double quotes in strings fail. This is fixed by unescaping the expectation terms. Formatting expectation terms as strings was different than default ATerms ( \" and \\ were not escaped), which was confusing when a test fails and the actual and expected terms were reported. This is fixed by aligning the SPT expectation terms formatting with default ATerm formatting.","title":"SPT"},{"location":"release/note/2.5.0/#nabl2","text":"Small usability improvements: Empty parameter tuples in rules can be omitted. Accidentally writing a dot instead of a comma before a recursive rule invocation could make that constraint look like a rule without constraints. Layout is now used to give a warning when such a case is written. Fix import problems caused by nabl2.runtime exports. The exports are restricted such that layout syntax and DynSem signatures are not exported anymore. The sorts defined by the runtime are all prefixed with NaBL2 to prevent accidental merges with sorts from the importing language. Allow all Stratego identifiers to be used as constructor names. Solver changes: Adopt new naming convention, with packages named mb.nabl2.* , and artifacts named nabl2.* . Add classes for matching and subtitution of terms, independent of unification. Use the generalized constraint analyzer for the NaBL2 analysis strategy.","title":"NaBL2"},{"location":"release/note/2.5.0/#sdf3","text":"The experimental support for generating Scala case classes from an SDF3 specification was removed. It was incomplete, unmaintained and unused. Added support for Layout Declarations <layout-declarations> {.interpreted-text role=\"ref\"} for layout-sensitive parsing and pretty-printing.","title":"SDF3"},{"location":"release/note/2.5.0/#eclipse","text":"Small fixes and improvements: Execute builders for languages which have no analysis defined. Previously builders would always wait until an analysis result was produced. Cancel running SPT test suites. It is now possible to cancel a running SPT test suite in the progress window.","title":"Eclipse"},{"location":"release/note/2.5.0/#intellij","text":"Small fixes and improvements: Can now be installed into any latest IntelliJ, not just the last version we tested By default runs in IntelliJ 2018.1.1 Simplified project structure Updated dependencies Changes to support Java 9 in the future","title":"IntelliJ"},{"location":"release/note/2.5.0/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.0/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.0/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.0/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.0/org.metaborg.spoofax.eclipse.updatesite-2.5.0-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.0/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.0 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.0/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.0/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.0","title":"Core API"},{"location":"release/note/2.5.0/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.0/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.0 .","title":"Maven artifacts"},{"location":"release/note/2.5.1/","text":"Spoofax 2.5.1 (02-10-2018) \u00b6 Spoofax 2.5.1 is a minor bugfix release. Changes \u00b6 Core \u00b6 Fix: ( Spoofax/242 ) StrategoMix.def not found error, after incrementally building a language specification project with a Stratego mix grammar. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.1/org.metaborg.spoofax.eclipse.updatesite-2.5.1-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.1 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.1 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.1 .","title":"Spoofax 2.5.1 (02-10-2018)"},{"location":"release/note/2.5.1/#spoofax-251-02-10-2018","text":"Spoofax 2.5.1 is a minor bugfix release.","title":"Spoofax 2.5.1 (02-10-2018)"},{"location":"release/note/2.5.1/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.1/#core","text":"Fix: ( Spoofax/242 ) StrategoMix.def not found error, after incrementally building a language specification project with a Stratego mix grammar.","title":"Core"},{"location":"release/note/2.5.1/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.1/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.1/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.1/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.1/org.metaborg.spoofax.eclipse.updatesite-2.5.1-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.1/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.1 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.1/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.1/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.1","title":"Core API"},{"location":"release/note/2.5.1/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.1/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.1 .","title":"Maven artifacts"},{"location":"release/note/2.5.10/","text":"Spoofax 2.5.10 (07-07-2020) \u00b6 Spoofax 2.5.10 contains several smaller improvements. Changes \u00b6 Overall \u00b6 Update Apache VFS2 to 2.6.0 Support for TypeSmart was removed. We anticipate a more useable type analysis for Stratego in the form of a gradual type system. The metaborg.yaml file of a generated project used to contain a debug: typesmart: false . This was to turn off the TypeSmart dynamic analysis by default. This analysis would stop any Stratego code when it tried to construct a tree that did not conform to the grammar of the project. To our knowledge TypeSmart was not used in any active Spoofax project. It did, however, slow down the build time of all Spoofax projects, because extraction of the grammar into a TypeSmart readable format had to be done even if the analysis was off for that project. These two points, and the anticipation of a gradual type system for Stratego, were the reasons to drop TypeSmart support. SDF3 \u00b6 Lexical and context-free sort declarations: In SDF3 you can now explicitly declare your sorts. Declare lexical sorts in a lexical sorts block, and context-free sorts in a context-free sorts block. Sorts declared in a kernel sorts block default to declaring context-free sorts until a suffix such as -LEX is added. Note that you have to use sdf2table: java to support lexical sorts. Statix \u00b6 New project that use Statix automatically have the Statix signature generator enabled. For this to work properly, declare your lexical and context-free sorts in SDF3 explicitly. See the Statix signature generator <statix-signature-generator> {.interpreted-text role=\"ref\"} documentation for more information. Statix specifications are now compiled as much as possible, even if there are errors in some files. Errors in Statix files that are not actually imported, do not cause analysis to fail on an empty specification anymore. The AST property [type]{.title-ref} is now a built-in, which is automatically used in the default editor hover strategy. Stratego \u00b6 Combined compiled Stratego and helper code Compilation of Stratego and helper code written in Java (in src/main/strategies ) is now combined in a single jar file per Spoofax language instead of two. See the migration guide for more information on what to change in your Spoofax project. SPT \u00b6 SPT gains support for the parse ambiguous expectation, which succeeds when a fragment parses successfully but with ambiguities. Tests with the parse succeeds expectation will now fail when the input parses ambiguously. To write tests for ambiguous parses, use the parse ambiguous expectation instead. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.10/org.metaborg.spoofax.eclipse.updatesite-2.5.10-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.10 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.10 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.10 .","title":"Spoofax 2.5.10 (07-07-2020)"},{"location":"release/note/2.5.10/#spoofax-2510-07-07-2020","text":"Spoofax 2.5.10 contains several smaller improvements.","title":"Spoofax 2.5.10 (07-07-2020)"},{"location":"release/note/2.5.10/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.10/#overall","text":"Update Apache VFS2 to 2.6.0 Support for TypeSmart was removed. We anticipate a more useable type analysis for Stratego in the form of a gradual type system. The metaborg.yaml file of a generated project used to contain a debug: typesmart: false . This was to turn off the TypeSmart dynamic analysis by default. This analysis would stop any Stratego code when it tried to construct a tree that did not conform to the grammar of the project. To our knowledge TypeSmart was not used in any active Spoofax project. It did, however, slow down the build time of all Spoofax projects, because extraction of the grammar into a TypeSmart readable format had to be done even if the analysis was off for that project. These two points, and the anticipation of a gradual type system for Stratego, were the reasons to drop TypeSmart support.","title":"Overall"},{"location":"release/note/2.5.10/#sdf3","text":"Lexical and context-free sort declarations: In SDF3 you can now explicitly declare your sorts. Declare lexical sorts in a lexical sorts block, and context-free sorts in a context-free sorts block. Sorts declared in a kernel sorts block default to declaring context-free sorts until a suffix such as -LEX is added. Note that you have to use sdf2table: java to support lexical sorts.","title":"SDF3"},{"location":"release/note/2.5.10/#statix","text":"New project that use Statix automatically have the Statix signature generator enabled. For this to work properly, declare your lexical and context-free sorts in SDF3 explicitly. See the Statix signature generator <statix-signature-generator> {.interpreted-text role=\"ref\"} documentation for more information. Statix specifications are now compiled as much as possible, even if there are errors in some files. Errors in Statix files that are not actually imported, do not cause analysis to fail on an empty specification anymore. The AST property [type]{.title-ref} is now a built-in, which is automatically used in the default editor hover strategy.","title":"Statix"},{"location":"release/note/2.5.10/#stratego","text":"Combined compiled Stratego and helper code Compilation of Stratego and helper code written in Java (in src/main/strategies ) is now combined in a single jar file per Spoofax language instead of two. See the migration guide for more information on what to change in your Spoofax project.","title":"Stratego"},{"location":"release/note/2.5.10/#spt","text":"SPT gains support for the parse ambiguous expectation, which succeeds when a fragment parses successfully but with ambiguities. Tests with the parse succeeds expectation will now fail when the input parses ambiguously. To write tests for ambiguous parses, use the parse ambiguous expectation instead.","title":"SPT"},{"location":"release/note/2.5.10/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.10/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.10/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.10/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.10/org.metaborg.spoofax.eclipse.updatesite-2.5.10-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.10/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.10 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.10/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.10/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.10","title":"Core API"},{"location":"release/note/2.5.10/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.10/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.10 .","title":"Maven artifacts"},{"location":"release/note/2.5.11/","text":"Spoofax 2.5.11 (17-07-2020) \u00b6 Spoofax 2.5.11 contains a dependency bugfix. Changes \u00b6 Overall \u00b6 Exclude the hadoop-hdfs-client transitive dependency from Apache VFS2 Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.11/org.metaborg.spoofax.eclipse.updatesite-2.5.11-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.11 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.11 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.11 .","title":"Spoofax 2.5.11 (17-07-2020)"},{"location":"release/note/2.5.11/#spoofax-2511-17-07-2020","text":"Spoofax 2.5.11 contains a dependency bugfix.","title":"Spoofax 2.5.11 (17-07-2020)"},{"location":"release/note/2.5.11/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.11/#overall","text":"Exclude the hadoop-hdfs-client transitive dependency from Apache VFS2","title":"Overall"},{"location":"release/note/2.5.11/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.11/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.11/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.11/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.11/org.metaborg.spoofax.eclipse.updatesite-2.5.11-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.11/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.11 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.11/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.11/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.11","title":"Core API"},{"location":"release/note/2.5.11/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.11/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.11 .","title":"Maven artifacts"},{"location":"release/note/2.5.12/","text":"Spoofax 2.5.12 (08-10-2020) \u00b6 Spoofax 2.5.12 contains an experimental gradual type system for Stratego, performance improvements to NaBL2 and Statix, and updates to Eclipse installations and their embedded JREs. Changes \u00b6 Stratego \u00b6 Stratego has two new reserved words: cast and is . Local variables can be reserved words if they start with ' , so you can use 'cast and 'is . Under the Stratego language options in your metaborg.yaml file you can turn on the gradual type system, if you use the incremental compiler. This option is gradual: static , and only tests the types statically. The default is gradual: none right now, meaning the gradual type system is not on by default. The is dynamic type check is not yet supported at runtime, you may get Java compilation errors when attempting to compile Stratego code with that. Dynamic type casts inserted by the gradual type system are also forthcoming, runtime support for this is not yet ready. NaBL2 \u00b6 NaBL2 supports a new resolution algorithm based on fexid-point environment computation instead of graph search, which can be enabled by adding strategy environments to the name-resolution signature section. It has much better performance characteristics, especially when dealing with mutually importing scopes and transitive imports. Compared the the search-based, the environment-based algorithm can get stuck on scope graphs with cycles involving scopes importing references that can be resolved via that same scope. Note that the environment-based algorithm may increase memory usage. The default remains the search-based algorithm. If a file was already analyzed in the editor, it is not reanalyzed on save anoymore. Statix \u00b6 Analysis times of large, multi-file Statix specifications has improved significantly. If a file was already analyzed in the editor, it is not reanalyzed on save anoymore. Eclipse \u00b6 Premade Eclipse installations have been updated from Eclipse Photon to Eclipse 2020-6. Premade Eclipse installations for 32-bit Linux are no longer created. Embedded JRE in premade Eclipse installations has been updated from 8u162 (Oracle JRE) to 8u265-b01 (AdoptOpenJDK). Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.12/org.metaborg.spoofax.eclipse.updatesite-2.5.12-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.12 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.12 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.12 .","title":"Spoofax 2.5.12 (08-10-2020)"},{"location":"release/note/2.5.12/#spoofax-2512-08-10-2020","text":"Spoofax 2.5.12 contains an experimental gradual type system for Stratego, performance improvements to NaBL2 and Statix, and updates to Eclipse installations and their embedded JREs.","title":"Spoofax 2.5.12 (08-10-2020)"},{"location":"release/note/2.5.12/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.12/#stratego","text":"Stratego has two new reserved words: cast and is . Local variables can be reserved words if they start with ' , so you can use 'cast and 'is . Under the Stratego language options in your metaborg.yaml file you can turn on the gradual type system, if you use the incremental compiler. This option is gradual: static , and only tests the types statically. The default is gradual: none right now, meaning the gradual type system is not on by default. The is dynamic type check is not yet supported at runtime, you may get Java compilation errors when attempting to compile Stratego code with that. Dynamic type casts inserted by the gradual type system are also forthcoming, runtime support for this is not yet ready.","title":"Stratego"},{"location":"release/note/2.5.12/#nabl2","text":"NaBL2 supports a new resolution algorithm based on fexid-point environment computation instead of graph search, which can be enabled by adding strategy environments to the name-resolution signature section. It has much better performance characteristics, especially when dealing with mutually importing scopes and transitive imports. Compared the the search-based, the environment-based algorithm can get stuck on scope graphs with cycles involving scopes importing references that can be resolved via that same scope. Note that the environment-based algorithm may increase memory usage. The default remains the search-based algorithm. If a file was already analyzed in the editor, it is not reanalyzed on save anoymore.","title":"NaBL2"},{"location":"release/note/2.5.12/#statix","text":"Analysis times of large, multi-file Statix specifications has improved significantly. If a file was already analyzed in the editor, it is not reanalyzed on save anoymore.","title":"Statix"},{"location":"release/note/2.5.12/#eclipse","text":"Premade Eclipse installations have been updated from Eclipse Photon to Eclipse 2020-6. Premade Eclipse installations for 32-bit Linux are no longer created. Embedded JRE in premade Eclipse installations has been updated from 8u162 (Oracle JRE) to 8u265-b01 (AdoptOpenJDK).","title":"Eclipse"},{"location":"release/note/2.5.12/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.12/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.12/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.12/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.12/org.metaborg.spoofax.eclipse.updatesite-2.5.12-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.12/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.12 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.12/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.12/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.12","title":"Core API"},{"location":"release/note/2.5.12/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.12/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.12 .","title":"Maven artifacts"},{"location":"release/note/2.5.13/","text":"Spoofax 2.5.13 (20-11-2020) \u00b6 Spoofax 2.5.13 contains a couple of small improvements. Changes \u00b6 SDF3 \u00b6 prefer and avoid are now deprecated. Usages of the operators will be marked with a deprecation warning. Parser \u00b6 The JSGLR2 parser variants now report warnings on ambiguously parsed substrings. This includes ambiguities in lexical and layout syntax that do not result into amb nodes in the AST. SPT \u00b6 The run expectation now allows to call strategies with term arguments. It\\'s now also possible to test if a strategy failed. See the SPT documentation for more details. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.13/org.metaborg.spoofax.eclipse.updatesite-2.5.13-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.13 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.13 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.13 .","title":"Spoofax 2.5.13 (20-11-2020)"},{"location":"release/note/2.5.13/#spoofax-2513-20-11-2020","text":"Spoofax 2.5.13 contains a couple of small improvements.","title":"Spoofax 2.5.13 (20-11-2020)"},{"location":"release/note/2.5.13/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.13/#sdf3","text":"prefer and avoid are now deprecated. Usages of the operators will be marked with a deprecation warning.","title":"SDF3"},{"location":"release/note/2.5.13/#parser","text":"The JSGLR2 parser variants now report warnings on ambiguously parsed substrings. This includes ambiguities in lexical and layout syntax that do not result into amb nodes in the AST.","title":"Parser"},{"location":"release/note/2.5.13/#spt","text":"The run expectation now allows to call strategies with term arguments. It\\'s now also possible to test if a strategy failed. See the SPT documentation for more details.","title":"SPT"},{"location":"release/note/2.5.13/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.13/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.13/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.13/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.13/org.metaborg.spoofax.eclipse.updatesite-2.5.13-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.13/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.13 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.13/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.13/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.13","title":"Core API"},{"location":"release/note/2.5.13/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.13/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.13 .","title":"Maven artifacts"},{"location":"release/note/2.5.14/","text":"Spoofax 2.5.14 (16-12-2020) \u00b6 Spoofax 2.5.14 was released. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.14/org.metaborg.spoofax.eclipse.updatesite-2.5.14-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.14 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.14 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.14 .","title":"Spoofax 2.5.14 (16-12-2020)"},{"location":"release/note/2.5.14/#spoofax-2514-16-12-2020","text":"Spoofax 2.5.14 was released.","title":"Spoofax 2.5.14 (16-12-2020)"},{"location":"release/note/2.5.14/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.14/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.14/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.14/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.14/org.metaborg.spoofax.eclipse.updatesite-2.5.14-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.14/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.14 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.14/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.14/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.14","title":"Core API"},{"location":"release/note/2.5.14/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.14/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.14 .","title":"Maven artifacts"},{"location":"release/note/2.5.15/","text":"Spoofax 2.5.15 (11-05-2021) \u00b6 Spoofax 2.5.15 contains a couple of small improvements and bug fixes, and supports the old SDF2-based parse table generator on macOS Catalina (10.15) and above. See the corresponding migration guide for migrating from Spoofax 2.5.14 to Spoofax 2.5.15. Changes \u00b6 macOS \u00b6 On macOS, Spoofax temporarily requires Docker and coreutils when building Spoofax on macOS Catalina, Big Sur, or newer. (This is only when you build Spoofax yourself instead of downloading it for this website, it does not influence building Spoofax projects.) SDF3 \u00b6 Fixed tree indexes in layout constraints/declarations to make them 0-based. The generate namespaced grammar option will now generate the namespaced grammar in src-gen . This feature can also be set to generate the grammar automatically similar to other extractions of the grammar like Stratego signatures. See the documentation for more information. Sadly, due to a bug in the changes for automatic generation, a build in Eclipse of a language project with namespaced grammar will work, but the build of that project with Maven will not work. Statix \u00b6 Fixed origin tracking in Statix injection explication for new projects that caused the top-level term of an AST to be missing when a Stratego strategy is applied to an analyzed AST in an SPT test. Add a menu action to view the scope graph resulting from Statix analysis. Deprecate namespaces, occurrences and query sugar. Fix bug in evaluation of try construct. Improvements to memory usage and runtime of the solver. Improve rule overlap handling: consider variables already bound to the left more specific than concrete patterns, to keep with left-to-right specificity. Add configuration settings to control trace length and term depth in error messages. Stratego \u00b6 The previously advertised incremental compiler was considered too slow and attempts to make it faster made it less stable. It is currently not recommended for general use, while we develop a new version. The documentation on how to use contains a similar warning now. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.15/org.metaborg.spoofax.eclipse.updatesite-2.5.15-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.15 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.15 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.15 .","title":"Spoofax 2.5.15 (11-05-2021)"},{"location":"release/note/2.5.15/#spoofax-2515-11-05-2021","text":"Spoofax 2.5.15 contains a couple of small improvements and bug fixes, and supports the old SDF2-based parse table generator on macOS Catalina (10.15) and above. See the corresponding migration guide for migrating from Spoofax 2.5.14 to Spoofax 2.5.15.","title":"Spoofax 2.5.15 (11-05-2021)"},{"location":"release/note/2.5.15/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.15/#macos","text":"On macOS, Spoofax temporarily requires Docker and coreutils when building Spoofax on macOS Catalina, Big Sur, or newer. (This is only when you build Spoofax yourself instead of downloading it for this website, it does not influence building Spoofax projects.)","title":"macOS"},{"location":"release/note/2.5.15/#sdf3","text":"Fixed tree indexes in layout constraints/declarations to make them 0-based. The generate namespaced grammar option will now generate the namespaced grammar in src-gen . This feature can also be set to generate the grammar automatically similar to other extractions of the grammar like Stratego signatures. See the documentation for more information. Sadly, due to a bug in the changes for automatic generation, a build in Eclipse of a language project with namespaced grammar will work, but the build of that project with Maven will not work.","title":"SDF3"},{"location":"release/note/2.5.15/#statix","text":"Fixed origin tracking in Statix injection explication for new projects that caused the top-level term of an AST to be missing when a Stratego strategy is applied to an analyzed AST in an SPT test. Add a menu action to view the scope graph resulting from Statix analysis. Deprecate namespaces, occurrences and query sugar. Fix bug in evaluation of try construct. Improvements to memory usage and runtime of the solver. Improve rule overlap handling: consider variables already bound to the left more specific than concrete patterns, to keep with left-to-right specificity. Add configuration settings to control trace length and term depth in error messages.","title":"Statix"},{"location":"release/note/2.5.15/#stratego","text":"The previously advertised incremental compiler was considered too slow and attempts to make it faster made it less stable. It is currently not recommended for general use, while we develop a new version. The documentation on how to use contains a similar warning now.","title":"Stratego"},{"location":"release/note/2.5.15/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.15/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.15/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.15/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.15/org.metaborg.spoofax.eclipse.updatesite-2.5.15-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.15/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.15 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.15/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.15/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.15","title":"Core API"},{"location":"release/note/2.5.15/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.15/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.15 .","title":"Maven artifacts"},{"location":"release/note/2.5.16/","text":"Spoofax 2.5.16 (04-06-2021) \u00b6 Spoofax 2.5.16 contains a couple of small improvements and bug fixes. Changes \u00b6 SDF3 \u00b6 Fix a bug with the automatic generation of namespaced grammars, which was introduced in the previous release. Statix \u00b6 Added stc-get-ast-ref rule to the Stratego API, which can be used to query ref properties. The Stratego primitives now issue console warnings when invalid labels or properties are used. Fixed a bug where stx-get-scopegraph-data would return unification variables instead of their values. Changed the default data order to true , to make queries where only a label order is provided apply shadowing as expected. Added a menu option to execute tests with the concurrent solver. Fixed a completeness bug in the traditional solver when executing queries in dataWf or dataLeq predicates. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.16 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.16 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.16 .","title":"Spoofax 2.5.16 (04-06-2021)"},{"location":"release/note/2.5.16/#spoofax-2516-04-06-2021","text":"Spoofax 2.5.16 contains a couple of small improvements and bug fixes.","title":"Spoofax 2.5.16 (04-06-2021)"},{"location":"release/note/2.5.16/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.16/#sdf3","text":"Fix a bug with the automatic generation of namespaced grammars, which was introduced in the previous release.","title":"SDF3"},{"location":"release/note/2.5.16/#statix","text":"Added stc-get-ast-ref rule to the Stratego API, which can be used to query ref properties. The Stratego primitives now issue console warnings when invalid labels or properties are used. Fixed a bug where stx-get-scopegraph-data would return unification variables instead of their values. Changed the default data order to true , to make queries where only a label order is provided apply shadowing as expected. Added a menu option to execute tests with the concurrent solver. Fixed a completeness bug in the traditional solver when executing queries in dataWf or dataLeq predicates.","title":"Statix"},{"location":"release/note/2.5.16/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.16/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.16/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.16/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.16/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.16 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.16/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.16/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.16","title":"Core API"},{"location":"release/note/2.5.16/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.16/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.16 .","title":"Maven artifacts"},{"location":"release/note/2.5.2/","text":"Spoofax 2.5.2 (12-03-2019) \u00b6 Spoofax 2.5.2 is a minor bugfix and performance improvement release. Changes \u00b6 NaBL2 \u00b6 A bug introduced in 2.5.2 would remove the parse error in the editor as soon as analysis failed. This bug has been fixed. FlowSpec \u00b6 A whole host of bugs has been fixed in FlowSpec, mostly ones that lead to no clear error message. Much of the system has also been optimized for speed. Stratego \u00b6 Separate compilation for Stratego was added in this release. It is currently still experimental. It is documented as a separate item under the Stratego documentation, including instructions on how to opt-in to it and what its limitations are. The Stratego primitives all , some and one sometimes lost annotations and origins of list tails when an element in the list was transformed. This bug has been fixed. The Stratego editor used to give spurious errors on missing variable definitions if those were list variables that were bound in a concrete syntax pattern. This long-standing bug has been fixed in this release. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.2/org.metaborg.spoofax.eclipse.updatesite-2.5.2-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.2 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.2 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.2 .","title":"Spoofax 2.5.2 (12-03-2019)"},{"location":"release/note/2.5.2/#spoofax-252-12-03-2019","text":"Spoofax 2.5.2 is a minor bugfix and performance improvement release.","title":"Spoofax 2.5.2 (12-03-2019)"},{"location":"release/note/2.5.2/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.2/#nabl2","text":"A bug introduced in 2.5.2 would remove the parse error in the editor as soon as analysis failed. This bug has been fixed.","title":"NaBL2"},{"location":"release/note/2.5.2/#flowspec","text":"A whole host of bugs has been fixed in FlowSpec, mostly ones that lead to no clear error message. Much of the system has also been optimized for speed.","title":"FlowSpec"},{"location":"release/note/2.5.2/#stratego","text":"Separate compilation for Stratego was added in this release. It is currently still experimental. It is documented as a separate item under the Stratego documentation, including instructions on how to opt-in to it and what its limitations are. The Stratego primitives all , some and one sometimes lost annotations and origins of list tails when an element in the list was transformed. This bug has been fixed. The Stratego editor used to give spurious errors on missing variable definitions if those were list variables that were bound in a concrete syntax pattern. This long-standing bug has been fixed in this release.","title":"Stratego"},{"location":"release/note/2.5.2/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.2/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.2/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.2/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.2/org.metaborg.spoofax.eclipse.updatesite-2.5.2-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.2/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.2 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.2/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.2/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.2","title":"Core API"},{"location":"release/note/2.5.2/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.2/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.2 .","title":"Maven artifacts"},{"location":"release/note/2.5.3/","text":"Spoofax 2.5.3 (02-05-2019) \u00b6 Spoofax 2.5.3 is a minor release with bugfixes, performance improvements, and new small and/or experimental features. Changes \u00b6 Overall \u00b6 Added support for getting the selected term in Stratego builders/transformations. In the builder tuple (node, _, ast, path, projectPath) , the first term ( node ) is now the selected term when a builder is executed in the context of an editor with a selection. The term is selected by finding the outermost term that has an origin that fits in the selection. Fixed a bug that prevented source transformations from being run if context or analysis were missing. Changed constraint analyzer to support more multi-file scenarios. JSGLR2 \u00b6 Added an incremental variant of the JSGLR2 parser (experimental). NaBL2 \u00b6 Improved preformance of AST resolution lookups. Statix (experimental) \u00b6 Fixed bugs and improved performance. Eclipse \u00b6 Added a lifecycle mapping that adds a Spoofax nature to an imported spoofax-project. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.3/org.metaborg.spoofax.eclipse.updatesite-2.5.3-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.3 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.3 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.3 .","title":"Spoofax 2.5.3 (02-05-2019)"},{"location":"release/note/2.5.3/#spoofax-253-02-05-2019","text":"Spoofax 2.5.3 is a minor release with bugfixes, performance improvements, and new small and/or experimental features.","title":"Spoofax 2.5.3 (02-05-2019)"},{"location":"release/note/2.5.3/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.3/#overall","text":"Added support for getting the selected term in Stratego builders/transformations. In the builder tuple (node, _, ast, path, projectPath) , the first term ( node ) is now the selected term when a builder is executed in the context of an editor with a selection. The term is selected by finding the outermost term that has an origin that fits in the selection. Fixed a bug that prevented source transformations from being run if context or analysis were missing. Changed constraint analyzer to support more multi-file scenarios.","title":"Overall"},{"location":"release/note/2.5.3/#jsglr2","text":"Added an incremental variant of the JSGLR2 parser (experimental).","title":"JSGLR2"},{"location":"release/note/2.5.3/#nabl2","text":"Improved preformance of AST resolution lookups.","title":"NaBL2"},{"location":"release/note/2.5.3/#statix-experimental","text":"Fixed bugs and improved performance.","title":"Statix (experimental)"},{"location":"release/note/2.5.3/#eclipse","text":"Added a lifecycle mapping that adds a Spoofax nature to an imported spoofax-project.","title":"Eclipse"},{"location":"release/note/2.5.3/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.3/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.3/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.3/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.3/org.metaborg.spoofax.eclipse.updatesite-2.5.3-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.3/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.3 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.3/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.3/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.3","title":"Core API"},{"location":"release/note/2.5.3/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.3/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.3 .","title":"Maven artifacts"},{"location":"release/note/2.5.4/","text":"Spoofax 2.5.4 (08-05-2019) \u00b6 Spoofax 2.5.4 is a minor bugfix release. Changes \u00b6 Maven \u00b6 Fixed failing SPT tests failing the build immediately. All SPT files are processed and a summary of how many tests failed is shown at the end. Fixed class loading errors at the end of Maven builds. Fixed application icon from showing up when building languages on some platforms. Statix \u00b6 Fix Statix analysis crash when detailed logging is enabled. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.4/org.metaborg.spoofax.eclipse.updatesite-2.5.4-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.4 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.4 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.4 .","title":"Spoofax 2.5.4 (08-05-2019)"},{"location":"release/note/2.5.4/#spoofax-254-08-05-2019","text":"Spoofax 2.5.4 is a minor bugfix release.","title":"Spoofax 2.5.4 (08-05-2019)"},{"location":"release/note/2.5.4/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.4/#maven","text":"Fixed failing SPT tests failing the build immediately. All SPT files are processed and a summary of how many tests failed is shown at the end. Fixed class loading errors at the end of Maven builds. Fixed application icon from showing up when building languages on some platforms.","title":"Maven"},{"location":"release/note/2.5.4/#statix","text":"Fix Statix analysis crash when detailed logging is enabled.","title":"Statix"},{"location":"release/note/2.5.4/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.4/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.4/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.4/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.4/org.metaborg.spoofax.eclipse.updatesite-2.5.4-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.4/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.4 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.4/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.4/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.4","title":"Core API"},{"location":"release/note/2.5.4/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.4/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.4 .","title":"Maven artifacts"},{"location":"release/note/2.5.5/","text":"Spoofax 2.5.5 (23-05-2019) \u00b6 Spoofax 2.5.5 is a minor bugfix release. There are a few incompatiable changes in Statix, which are described in the migration guide <2.5.5-migration-guide> . Changes \u00b6 Overall \u00b6 Do not throw away error messages in unchanged files if other files changed, when using constraint analyzer. JSGLR \u00b6 Add missing location information on sublists. Statix \u00b6 Improve speed of normalization. Add AST properties and editor reference resolution. Regular expression and label order are direct parameters to queries. It is not possible anymore to pass an arbitary predicate there. Special path constraints are removed in favour of concrete path terms that can be matched as terms. Functional constraints can only have a single output. Namespace based resolution short-hands must contain a occurrence literal, and explicit resolution policies. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.5/org.metaborg.spoofax.eclipse.updatesite-2.5.5-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.5 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.5 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.5 .","title":"Spoofax 2.5.5 (23-05-2019)"},{"location":"release/note/2.5.5/#spoofax-255-23-05-2019","text":"Spoofax 2.5.5 is a minor bugfix release. There are a few incompatiable changes in Statix, which are described in the migration guide <2.5.5-migration-guide> .","title":"Spoofax 2.5.5 (23-05-2019)"},{"location":"release/note/2.5.5/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.5/#overall","text":"Do not throw away error messages in unchanged files if other files changed, when using constraint analyzer.","title":"Overall"},{"location":"release/note/2.5.5/#jsglr","text":"Add missing location information on sublists.","title":"JSGLR"},{"location":"release/note/2.5.5/#statix","text":"Improve speed of normalization. Add AST properties and editor reference resolution. Regular expression and label order are direct parameters to queries. It is not possible anymore to pass an arbitary predicate there. Special path constraints are removed in favour of concrete path terms that can be matched as terms. Functional constraints can only have a single output. Namespace based resolution short-hands must contain a occurrence literal, and explicit resolution policies.","title":"Statix"},{"location":"release/note/2.5.5/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.5/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.5/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.5/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.5/org.metaborg.spoofax.eclipse.updatesite-2.5.5-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.5/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.5 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.5/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.5/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.5","title":"Core API"},{"location":"release/note/2.5.5/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.5/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.5 .","title":"Maven artifacts"},{"location":"release/note/2.5.6/","text":"Spoofax 2.5.6 (24-05-2019) \u00b6 Spoofax 2.5.6 is a minor bugfix release. Changes \u00b6 Overall \u00b6 Statix \u00b6 Fix a crash in single-file analysis. Fix several bugs in scope extension checking. Fix bug in rule application that dropped cause. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.6/org.metaborg.spoofax.eclipse.updatesite-2.5.6-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.6 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.6 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.6 .","title":"Spoofax 2.5.6 (24-05-2019)"},{"location":"release/note/2.5.6/#spoofax-256-24-05-2019","text":"Spoofax 2.5.6 is a minor bugfix release.","title":"Spoofax 2.5.6 (24-05-2019)"},{"location":"release/note/2.5.6/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.6/#overall","text":"","title":"Overall"},{"location":"release/note/2.5.6/#statix","text":"Fix a crash in single-file analysis. Fix several bugs in scope extension checking. Fix bug in rule application that dropped cause.","title":"Statix"},{"location":"release/note/2.5.6/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.6/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.6/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.6/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.6/org.metaborg.spoofax.eclipse.updatesite-2.5.6-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.6/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.6 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.6/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.6/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.6","title":"Core API"},{"location":"release/note/2.5.6/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.6/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.6 .","title":"Maven artifacts"},{"location":"release/note/2.5.7/","text":"Spoofax 2.5.7 (26-06-2019) \u00b6 Spoofax 2.5.7 includes minor bugfixes and improvements to the experimental Stratego separate compiler. Changes \u00b6 FlowSpec \u00b6 Bugfix: Names with namespaces were broken in an earlier version during performance optimization. The error would like: java.lang.AssertionError: Unrecognised Namespace: Namespace(\"Var\") . Stratego \u00b6 Stratego separate compilation is now switched to the new system. It no longer has any limitations that were previously mentioned. Do note that separate compilation will give the same stricter error messages that the editor does: You need to import anything you use, you cannot use something that another module imports that imports your module. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.7/org.metaborg.spoofax.eclipse.updatesite-2.5.7-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.7 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.7 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.7 .","title":"Spoofax 2.5.7 (26-06-2019)"},{"location":"release/note/2.5.7/#spoofax-257-26-06-2019","text":"Spoofax 2.5.7 includes minor bugfixes and improvements to the experimental Stratego separate compiler.","title":"Spoofax 2.5.7 (26-06-2019)"},{"location":"release/note/2.5.7/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.7/#flowspec","text":"Bugfix: Names with namespaces were broken in an earlier version during performance optimization. The error would like: java.lang.AssertionError: Unrecognised Namespace: Namespace(\"Var\") .","title":"FlowSpec"},{"location":"release/note/2.5.7/#stratego","text":"Stratego separate compilation is now switched to the new system. It no longer has any limitations that were previously mentioned. Do note that separate compilation will give the same stricter error messages that the editor does: You need to import anything you use, you cannot use something that another module imports that imports your module.","title":"Stratego"},{"location":"release/note/2.5.7/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.7/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.7/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.7/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.7/org.metaborg.spoofax.eclipse.updatesite-2.5.7-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.7/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.7 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.7/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.7/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.7","title":"Core API"},{"location":"release/note/2.5.7/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.7/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.7 .","title":"Maven artifacts"},{"location":"release/note/2.5.8/","text":"Spoofax 2.5.8 (28-04-2020) \u00b6 Spoofax 2.5.8 includes several bugfixes and improvements. Changes \u00b6 SDF \u00b6 The Java version of sdf2table is now slightly faster and takes up less peak memory due to improvements in writing away the parsetable to file. The old (Aster based) version of make-permissive (to add error recovery to your grammar) used to be called in a way that create a small memory leak, which would compound over time with subsequent builds. This is has now been fixed. The old version of make-permissive is only in effect if you use sdf2table: c in your metaborg.yaml file. Parser \u00b6 Add two experimental variants to the JSGLR2 parser: recovery and recovery-incremental . Add Unicode support to the JSGLR1 and JSGLR2 parsers. The meta-languages themselves do not support Unicode yet, because they are bootstrapped with and old version of SDF3. However, other languages built with Spoofax can use Unicode. Add logging to the JSGLR2 parser. Configure by setting language.sdf.jsglr2-logging to all , none , minimal , parsing or recovery in metaborg.yaml . Programmatic API \u00b6 TermFactory for building Stratego terms now supports a builder for lists that creates an arraylist-like structure instead of the standard linkedlist-like structure. This is typically more efficient for building stratego list terms in Java. Add org.spoofax.terms.util.TermUtils class with functions for working with terms. This replaces the equivalent (now deprecated) functions in org.spoofax.interpreter.core.Tools . NaBL2 \u00b6 Improve error message location when scopes are used as term indices. Dropped support for polymorphism, which was unsound. Small improvements to solver performance. Add support for external calls for language with Stratego JAR compilation. Statix \u00b6 Ability to automatically generate <statix-signature-generator> {.interpreted-text role=\"ref\"} Statix signatures from SDF3 specifications. Add support for importing other modules in Statix specifications. Add support for custom messages, and a try construct for warnings and notes. Add support for adding multiple values to AST properties. Improve disunification support in the solver. Extend reserved keywords to fix parsing problems. Several smaller bugfixes. Overall \u00b6 Fixed several issues with files not being released properly, causing file I/O errors on Windows. Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.8/org.metaborg.spoofax.eclipse.updatesite-2.5.8-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.8 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.8 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.8 .","title":"Spoofax 2.5.8 (28-04-2020)"},{"location":"release/note/2.5.8/#spoofax-258-28-04-2020","text":"Spoofax 2.5.8 includes several bugfixes and improvements.","title":"Spoofax 2.5.8 (28-04-2020)"},{"location":"release/note/2.5.8/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.8/#sdf","text":"The Java version of sdf2table is now slightly faster and takes up less peak memory due to improvements in writing away the parsetable to file. The old (Aster based) version of make-permissive (to add error recovery to your grammar) used to be called in a way that create a small memory leak, which would compound over time with subsequent builds. This is has now been fixed. The old version of make-permissive is only in effect if you use sdf2table: c in your metaborg.yaml file.","title":"SDF"},{"location":"release/note/2.5.8/#parser","text":"Add two experimental variants to the JSGLR2 parser: recovery and recovery-incremental . Add Unicode support to the JSGLR1 and JSGLR2 parsers. The meta-languages themselves do not support Unicode yet, because they are bootstrapped with and old version of SDF3. However, other languages built with Spoofax can use Unicode. Add logging to the JSGLR2 parser. Configure by setting language.sdf.jsglr2-logging to all , none , minimal , parsing or recovery in metaborg.yaml .","title":"Parser"},{"location":"release/note/2.5.8/#programmatic-api","text":"TermFactory for building Stratego terms now supports a builder for lists that creates an arraylist-like structure instead of the standard linkedlist-like structure. This is typically more efficient for building stratego list terms in Java. Add org.spoofax.terms.util.TermUtils class with functions for working with terms. This replaces the equivalent (now deprecated) functions in org.spoofax.interpreter.core.Tools .","title":"Programmatic API"},{"location":"release/note/2.5.8/#nabl2","text":"Improve error message location when scopes are used as term indices. Dropped support for polymorphism, which was unsound. Small improvements to solver performance. Add support for external calls for language with Stratego JAR compilation.","title":"NaBL2"},{"location":"release/note/2.5.8/#statix","text":"Ability to automatically generate <statix-signature-generator> {.interpreted-text role=\"ref\"} Statix signatures from SDF3 specifications. Add support for importing other modules in Statix specifications. Add support for custom messages, and a try construct for warnings and notes. Add support for adding multiple values to AST properties. Improve disunification support in the solver. Extend reserved keywords to fix parsing problems. Several smaller bugfixes.","title":"Statix"},{"location":"release/note/2.5.8/#overall","text":"Fixed several issues with files not being released properly, causing file I/O errors on Windows.","title":"Overall"},{"location":"release/note/2.5.8/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.8/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.8/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.8/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.8/org.metaborg.spoofax.eclipse.updatesite-2.5.8-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.8/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.8 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.8/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.8/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.8","title":"Core API"},{"location":"release/note/2.5.8/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.8/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.8 .","title":"Maven artifacts"},{"location":"release/note/2.5.9/","text":"Spoofax 2.5.9 (08-05-2020) \u00b6 Spoofax 2.5.9 includes dependency upgrades. Changes \u00b6 Overall \u00b6 The following dependencies of Spoofax Core have been updated to the latest version: com.netflix.rxjava:rxjava:0.20.7 -> io.reactivex.rxjava3:rxjava:3.0.2 New transitive dependency: org.reactivestreams:reactive-streams:1.0.3 org.apache.commons:commons-configuration2:2.2 -> org.apache.commons:commons-configuration2:2.7 New transitive dependency: org.apache.commons:commons-text:1.8 com.virtlink.commons:commons-configuration2-jackson:0.7.0 -> com.virtlink.commons:commons-configuration2-jackson:0.10.0 com.fasterxml.jackson.core:jackson-core:2.9.5 -> com.fasterxml.jackson.core:jackson-core:2.11.0 com.fasterxml.jackson.core:jackson-databind:2.9.5 -> com.fasterxml.jackson.core:jackson-databind:2.11.0 com.fasterxml.jackson.core:jackson-annotations:2.9.5 -> com.fasterxml.jackson.core:jackson-annotations:2.11.0 com.fasterxml.jackson.core:jackson-dataformat-yaml:2.9.5 -> com.fasterxml.jackson.core:jackson-dataformat-yaml:2.11.0 org.yaml:snakeyaml:1.18 -> org.yaml:snakeyaml:1.26 The following dependencies of Spoofax-Meta Core have been updated: org.apache.commons:commons-compress:1.16.1 -> org.apache.commons:commons-compress:1.20 Downloads \u00b6 Eclipse plugin \u00b6 Premade Eclipse installations \u00b6 With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit Update site \u00b6 Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.9/org.metaborg.spoofax.eclipse.updatesite-2.5.9-assembly.zip-unzip/ Eclipse update site archive IntelliJ plugin \u00b6 IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.9 IntelliJ update site archive Command-line utilities \u00b6 Sunshine JAR SPT testrunner JAR Core API \u00b6 Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.9 StrategoXT \u00b6 Stratego/XT distribution Stratego/XT JAR Maven artifacts \u00b6 Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.9 .","title":"Spoofax 2.5.9 (08-05-2020)"},{"location":"release/note/2.5.9/#spoofax-259-08-05-2020","text":"Spoofax 2.5.9 includes dependency upgrades.","title":"Spoofax 2.5.9 (08-05-2020)"},{"location":"release/note/2.5.9/#changes","text":"","title":"Changes"},{"location":"release/note/2.5.9/#overall","text":"The following dependencies of Spoofax Core have been updated to the latest version: com.netflix.rxjava:rxjava:0.20.7 -> io.reactivex.rxjava3:rxjava:3.0.2 New transitive dependency: org.reactivestreams:reactive-streams:1.0.3 org.apache.commons:commons-configuration2:2.2 -> org.apache.commons:commons-configuration2:2.7 New transitive dependency: org.apache.commons:commons-text:1.8 com.virtlink.commons:commons-configuration2-jackson:0.7.0 -> com.virtlink.commons:commons-configuration2-jackson:0.10.0 com.fasterxml.jackson.core:jackson-core:2.9.5 -> com.fasterxml.jackson.core:jackson-core:2.11.0 com.fasterxml.jackson.core:jackson-databind:2.9.5 -> com.fasterxml.jackson.core:jackson-databind:2.11.0 com.fasterxml.jackson.core:jackson-annotations:2.9.5 -> com.fasterxml.jackson.core:jackson-annotations:2.11.0 com.fasterxml.jackson.core:jackson-dataformat-yaml:2.9.5 -> com.fasterxml.jackson.core:jackson-dataformat-yaml:2.11.0 org.yaml:snakeyaml:1.18 -> org.yaml:snakeyaml:1.26 The following dependencies of Spoofax-Meta Core have been updated: org.apache.commons:commons-compress:1.16.1 -> org.apache.commons:commons-compress:1.20","title":"Overall"},{"location":"release/note/2.5.9/#downloads","text":"","title":"Downloads"},{"location":"release/note/2.5.9/#eclipse-plugin","text":"","title":"Eclipse plugin"},{"location":"release/note/2.5.9/#premade-eclipse-installations","text":"With embedded JRE: macOS 64-bit with embedded JVM Linux 64-bit with embedded JVM Windows 64-bit with embedded JVM Windows 32-bit with embedded JVM Without embedded JRE: macOS 64-bit Linux 64-bit Windows 64-bit Windows 32-bit","title":"Premade Eclipse installations"},{"location":"release/note/2.5.9/#update-site","text":"Eclipse update site: https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.9/org.metaborg.spoofax.eclipse.updatesite-2.5.9-assembly.zip-unzip/ Eclipse update site archive","title":"Update site"},{"location":"release/note/2.5.9/#intellij-plugin","text":"IntelliJ update site: https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&g=org.metaborg&a=org.metaborg.intellij.dist&p=zip&v=2.5.9 IntelliJ update site archive","title":"IntelliJ plugin"},{"location":"release/note/2.5.9/#command-line-utilities","text":"Sunshine JAR SPT testrunner JAR","title":"Command-line utilities"},{"location":"release/note/2.5.9/#core-api","text":"Spoofax Core Uber JAR Spoofax Core uber Maven artifact: org.metaborg:org.metaborg.spoofax.core.uber:2.5.9","title":"Core API"},{"location":"release/note/2.5.9/#strategoxt","text":"Stratego/XT distribution Stratego/XT JAR","title":"StrategoXT"},{"location":"release/note/2.5.9/#maven-artifacts","text":"Maven artifacts can be found on our artifact server . The Maven version used for this release is 2.5.9 .","title":"Maven artifacts"},{"location":"release/note/vnext/","text":"Spoofax vNext \u00b6 These are the release notes for the upcoming version of Spoofax. Update the current documentation vnext.rst file instead Until we have migrated to this new documentation, update the vnext.rst in the current documentation repository . See the corresponding migration guide for migrating from Spoofax vPrev to Spoofax vNext. Changes \u00b6","title":"Spoofax vNext"},{"location":"release/note/vnext/#spoofax-vnext","text":"These are the release notes for the upcoming version of Spoofax. Update the current documentation vnext.rst file instead Until we have migrated to this new documentation, update the vnext.rst in the current documentation repository . See the corresponding migration guide for migrating from Spoofax vPrev to Spoofax vNext.","title":"Spoofax vNext"},{"location":"release/note/vnext/#changes","text":"","title":"Changes"},{"location":"support/","text":"Support \u00b6 Spoofax is an open source project. We welcome contributions from the community. Spoofax is developed by the TU Delft Programming Languages group . We do our best to make Spoofax usable by everyone and to help you when you encounter issues. However, our resources are limited, so please be patient. I have a question \u00b6 The search functionality of this documentation should bring you right to a relevant How-to or Reference page. If this doesn't answer your question, please join us in the SLDE/#spoofax-users Slack channel and ask your question there. To get access, drop us a line. Please do not make an issue with your question on the Github repository. I found a bug \u00b6 Search the Issues to ensure the bug has not been reported before. If the bug is new, open a new issue with a clear title and description . Please indicate: what you did (i.e., how to reproduce), what you expected to happen, what actually happened, what version of Spoofax and Eclipse you are using, and any logs, exceptions, and stack traces relevant to the bug. Try to include as much relevant information as you have. For example, a code sample or executable test case are very helpful. Getting the Spoofax and Eclipse version In Eclipse, go to the Spoofax (meta) menu, and click Report issue . Copy the displayed version information from this dialog into your issue. I wrote a patch with a cosmetic change \u00b6 Please do not submit pull requests for cosmetic changes, such as whitespace and formatting changes. I wrote a patch with a bug fix \u00b6 Thank you! Please open a GitHub pull request with the patch. I wrote a patch that adds a new feature or changes an existing one \u00b6 Please open an issue first , so we can discuss the change. I want to contribute to the documentation or test suite \u00b6 Thank you! Please open a GitHub pull request with the patch. Thank you for your contributions! \u2014 The Spoofax Team","title":"Support"},{"location":"support/#support","text":"Spoofax is an open source project. We welcome contributions from the community. Spoofax is developed by the TU Delft Programming Languages group . We do our best to make Spoofax usable by everyone and to help you when you encounter issues. However, our resources are limited, so please be patient.","title":"Support"},{"location":"support/#i-have-a-question","text":"The search functionality of this documentation should bring you right to a relevant How-to or Reference page. If this doesn't answer your question, please join us in the SLDE/#spoofax-users Slack channel and ask your question there. To get access, drop us a line. Please do not make an issue with your question on the Github repository.","title":"&nbsp; I have a question"},{"location":"support/#i-found-a-bug","text":"Search the Issues to ensure the bug has not been reported before. If the bug is new, open a new issue with a clear title and description . Please indicate: what you did (i.e., how to reproduce), what you expected to happen, what actually happened, what version of Spoofax and Eclipse you are using, and any logs, exceptions, and stack traces relevant to the bug. Try to include as much relevant information as you have. For example, a code sample or executable test case are very helpful. Getting the Spoofax and Eclipse version In Eclipse, go to the Spoofax (meta) menu, and click Report issue . Copy the displayed version information from this dialog into your issue.","title":"&nbsp; I found a bug"},{"location":"support/#i-wrote-a-patch-with-a-cosmetic-change","text":"Please do not submit pull requests for cosmetic changes, such as whitespace and formatting changes.","title":"&nbsp; I wrote a patch with a cosmetic change"},{"location":"support/#i-wrote-a-patch-with-a-bug-fix","text":"Thank you! Please open a GitHub pull request with the patch.","title":"&nbsp; I wrote a patch with a bug fix"},{"location":"support/#i-wrote-a-patch-that-adds-a-new-feature-or-changes-an-existing-one","text":"Please open an issue first , so we can discuss the change.","title":"&nbsp; I wrote a patch that adds a new feature or changes an existing one"},{"location":"support/#i-want-to-contribute-to-the-documentation-or-test-suite","text":"Thank you! Please open a GitHub pull request with the patch. Thank you for your contributions! \u2014 The Spoofax Team","title":"&nbsp; I want to contribute to the documentation or test suite"},{"location":"support/contributions/","text":"Contributions \u00b6 Spoofax and its components have been developed by many researchers, student, and developers supported by universities and funding agencies. Universities \u00b6 The main research effort on Spoofax and it predecessors (SDF2, Stratego, XT) was conducted at the following universities: University of Amsterdam Oregon Graduate Institute Utrecht University University of Bergen Delft University of Technology Funding \u00b6 Funding was provided by the following funding agencies and companies: The Netherlands Organisation for Scientific Research (NWO) Philips Research Oracle Labs Capes, Coordenaca de Bolsas, Brasil Tooling \u00b6 The following tools were used to develop and maintain Spoofax: \u2014 We use the YourKit Java profiler to diagnose and fix performance problems in Spoofax, provided free-of-charge by YourKit . Contributors \u00b6 Many people have contributed to Spoofax as bachelor student, master student, PhD student, postdoc, professor, or as an external contributor. This is an attempt at listing at least the main contributors to the various main projects. SDF2 Eelco Visser Jeroen Scheerder Mark van den Brand Jurgen Vinju Stratego/XT Eelco Visser Martin Bravenboer Karina Olmos Karl Trygve Kalleberg Anya Bagge Joost Visser Merijn de Jonge Rob Vermaas Eelco Dolstra Spoofax 1 Eelco Visser Lennart Kats Oskar van Rest Karl Trygve Kalleberg Rob Vermaas Guido Wachsmuth Maartje de Jonge Ricky Lindeman Sebastian Erdweg Tobi Vollebregt Spoofax 2 Eelco Visser Gabri\u00ebl Konat Eduardo Souza Vlad Vergu Volker Lanting Daniel A. A. Pelsmaeker Andrew Tolmach Pierre N\u00e9ron Hendrik van Antwerpen Volker Lanting Martijn Dwars Tobi Vollebregt Nathan Bruning Maarten Sijm Jasper Denkers Phil Misteli Daco Harkes JSGLR2 Eelco Visser Jasper Denkers Karl Trygve Lennart Kats Maarten Sijm Maartje de Jonge Gabri\u00ebl Konat Eduardo Souza SDF3 Eelco Visser Eduardo Souza Gabri\u00ebl Konat Daniel A. A. Pelsmaeker Jasper Denkers NaBL2 & Statix Eelco Visser Hendrik van Antwerpen Guido Wachsmuth Gabri\u00ebl Konat Jeff Smits Aron Zwaan Daniel A. A. Pelsmaeker Phil Misteli Dynsem Eelco Visser Vlag Vergu Casper Back Poulsen Hendrik van Antwerpen Gabri\u00ebl Konat Flowspec Eelco Visser Jeff Smits Hendrik van Antwerpen SPT Eelco Visser Gabri\u00ebl Konat Lennart Kats Volker Lanting Daniel A. A. Pelsmaeker Phil Misteli Stratego Eelco Visser Jeff Smits Gabri\u00ebl Konat Maartje de Jonge Oskar van Rest Nathan Bruning Spoofax 3 Eelco Visser Gabri\u00ebl Konat Daniel A. A. Pelsmaeker Aron Zwaan PIE Eelco Visser Gabri\u00ebl Konat Ivo Wilms","title":"Contributions"},{"location":"support/contributions/#contributions","text":"Spoofax and its components have been developed by many researchers, student, and developers supported by universities and funding agencies.","title":"Contributions"},{"location":"support/contributions/#universities","text":"The main research effort on Spoofax and it predecessors (SDF2, Stratego, XT) was conducted at the following universities: University of Amsterdam Oregon Graduate Institute Utrecht University University of Bergen Delft University of Technology","title":"Universities"},{"location":"support/contributions/#funding","text":"Funding was provided by the following funding agencies and companies: The Netherlands Organisation for Scientific Research (NWO) Philips Research Oracle Labs Capes, Coordenaca de Bolsas, Brasil","title":"Funding"},{"location":"support/contributions/#tooling","text":"The following tools were used to develop and maintain Spoofax: \u2014 We use the YourKit Java profiler to diagnose and fix performance problems in Spoofax, provided free-of-charge by YourKit .","title":"Tooling"},{"location":"support/contributions/#contributors","text":"Many people have contributed to Spoofax as bachelor student, master student, PhD student, postdoc, professor, or as an external contributor. This is an attempt at listing at least the main contributors to the various main projects. SDF2 Eelco Visser Jeroen Scheerder Mark van den Brand Jurgen Vinju Stratego/XT Eelco Visser Martin Bravenboer Karina Olmos Karl Trygve Kalleberg Anya Bagge Joost Visser Merijn de Jonge Rob Vermaas Eelco Dolstra Spoofax 1 Eelco Visser Lennart Kats Oskar van Rest Karl Trygve Kalleberg Rob Vermaas Guido Wachsmuth Maartje de Jonge Ricky Lindeman Sebastian Erdweg Tobi Vollebregt Spoofax 2 Eelco Visser Gabri\u00ebl Konat Eduardo Souza Vlad Vergu Volker Lanting Daniel A. A. Pelsmaeker Andrew Tolmach Pierre N\u00e9ron Hendrik van Antwerpen Volker Lanting Martijn Dwars Tobi Vollebregt Nathan Bruning Maarten Sijm Jasper Denkers Phil Misteli Daco Harkes JSGLR2 Eelco Visser Jasper Denkers Karl Trygve Lennart Kats Maarten Sijm Maartje de Jonge Gabri\u00ebl Konat Eduardo Souza SDF3 Eelco Visser Eduardo Souza Gabri\u00ebl Konat Daniel A. A. Pelsmaeker Jasper Denkers NaBL2 & Statix Eelco Visser Hendrik van Antwerpen Guido Wachsmuth Gabri\u00ebl Konat Jeff Smits Aron Zwaan Daniel A. A. Pelsmaeker Phil Misteli Dynsem Eelco Visser Vlag Vergu Casper Back Poulsen Hendrik van Antwerpen Gabri\u00ebl Konat Flowspec Eelco Visser Jeff Smits Hendrik van Antwerpen SPT Eelco Visser Gabri\u00ebl Konat Lennart Kats Volker Lanting Daniel A. A. Pelsmaeker Phil Misteli Stratego Eelco Visser Jeff Smits Gabri\u00ebl Konat Maartje de Jonge Oskar van Rest Nathan Bruning Spoofax 3 Eelco Visser Gabri\u00ebl Konat Daniel A. A. Pelsmaeker Aron Zwaan PIE Eelco Visser Gabri\u00ebl Konat Ivo Wilms","title":"Contributors"},{"location":"tutorials/","text":"Tutorials \u00b6 This page lists tutorials that take you step-by-step through a project to learn a variety of concepts and aspects of Spoofax in a specific scope. For guides on achieving specific tasks, see the How To's section. For the Spoofax language reference, see the References section. No tutorials yet.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"This page lists tutorials that take you step-by-step through a project to learn a variety of concepts and aspects of Spoofax in a specific scope. For guides on achieving specific tasks, see the How To's section. For the Spoofax language reference, see the References section. No tutorials yet.","title":"Tutorials"}]}